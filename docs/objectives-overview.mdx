---
id: objectives-overview
title: 🎯 Workshop Objectives
sidebar_label: 🎯 Objectives
---

# Workshop Objectives: Multimodal PDF Agents

## 🎯 What You'll Build

Create intelligent agents that can process, understand, and interact with PDF documents containing both text and images.

### Core Capabilities
- **Process PDFs** - Extract and chunk text content from PDF documents
- **Generate Embeddings** - Create vector representations using pre-generated multimodal embeddings
- **Store & Search** - Use MongoDB Vector Search for semantic retrieval
- **Reason & Act** - Build agents using the ReAct pattern (Reasoning + Acting)
- **Chat Interface** - Natural conversations about document content

## 🛤️ Two Learning Paths

### Path 1: Python + Jupyter + LangChain
**Best for:** Developers who want to understand the code and algorithms

**What you'll do:**
- Work with pre-generated embeddings from the enhanced notebook
- Use MongoDB Atlas Local (Docker-based)
- Build ReAct agents with LangChain
- Complete 4 hands-on exercises

### Path 2: n8n Visual Workflows  
**Best for:** No-code/low-code builders and workflow automation

**What you'll do:**
- Visual drag-and-drop interface
- Pre-built nodes for PDF processing
- Create webhook-based agent workflows
- Complete 4 hands-on exercises

## 📚 Technologies Used

- **MongoDB Atlas Vector Search** - Document storage and semantic search
- **Voyage AI Multimodal Embeddings** - 1024-dimensional vectors for text + images
- **Google Gemini 2.0** - LLM with function calling capabilities
- **ReAct Pattern** - Reasoning + Acting agent architecture

## 🎯 Learning Outcomes

After completing this workshop, you will:

1. **Understand multimodal AI** and how to work with text + image embeddings
2. **Build production-ready vector search** using MongoDB Atlas
3. **Create intelligent agents** that can reason and take actions
4. **Process real PDF documents** and make them searchable

## 🚀 Ready to Start?

Choose your preferred path below and complete the exercises to build your multimodal PDF agent!