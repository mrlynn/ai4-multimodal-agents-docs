---
sidebar_position: 85
---

# üêç Python Approaches to MongoDB Vector Search

While n8n provides an excellent visual workflow approach, developers often need programmatic control. Let's explore different ways to interact with MongoDB vector search and Voyage AI using Python.

<InstructorNotes 
  timing="Python Integration Overview (15-20 minutes)"
  notes={[
    "This section complements the n8n approach - not a replacement",
    "Great for developers who want to understand what's happening 'under the hood'",
    "Python examples help attendees bridge visual workflows to code",
    "MongoDB's new multimodal search library simplifies a lot of complexity",
    "Some attendees may prefer Python for production systems"
  ]}
  tips={[
    "Emphasize that both approaches (n8n and Python) can coexist",
    "Show how n8n workflows can call Python scripts via HTTP",
    "Demonstrate the MongoDB multimodal search library live if time permits",
    "Point out that the concepts learned in n8n transfer directly to Python",
    "Consider this section optional if workshop is running behind schedule"
  ]}
/>

<SlideRecap 
  title="From Visual to Programmatic"
  items={[
    {
      icon: "üîÑ",
      title: "Multiple Interfaces",
      description: "n8n workflows, Python SDKs, and direct MongoDB drivers all access the same powerful vector search"
    },
    {
      icon: "üêç", 
      title: "Python Ecosystem",
      description: "Rich libraries for document processing, ML model integration, and data analysis"
    },
    {
      icon: "‚ö°",
      title: "Best of Both Worlds",
      description: "Use n8n for rapid prototyping, Python for custom logic and production systems"
    }
  ]}
  nextSection="Let's explore the different Python approaches available!"
/>

## üéØ Comparison: n8n vs Python Approaches

| Aspect | n8n Visual Workflows | Python Programming |
|--------|---------------------|-------------------|
| **Learning Curve** | Low - visual interface | Medium - requires Python knowledge |
| **Development Speed** | Fast prototyping | Slower initial setup |
| **Customization** | Limited to available nodes | Unlimited flexibility |
| **Debugging** | Visual execution flow | Traditional debugging tools |
| **Integration** | 400+ pre-built integrations | Vast Python ecosystem |
| **Production** | Enterprise-ready | Full control over deployment |
| **Team Collaboration** | Non-technical team friendly | Requires developer skills |

## üöÄ MongoDB Multimodal Search Library

MongoDB's new Python library simplifies multimodal vector search with a clean, intuitive API.

### Installation

```python
pip install mongodb-multimodal-search
```

### Basic Setup

```python
from mongodb_multimodal_search import MultimodalSearch
from pymongo import MongoClient

# Initialize MongoDB connection
client = MongoClient("your-mongodb-connection-string")
db = client["multimodal_workshop"]
collection = db["pdf_documents"]

# Initialize multimodal search
search = MultimodalSearch(
    collection=collection,
    embedding_provider="voyage",  # or "openai", "cohere"
    embedding_model="voyage-multimodal-3",
    api_key="your-voyage-api-key"
)
```

### Document Ingestion

```python
# Process a PDF document
document_results = await search.ingest_document(
    file_path="arxiv-paper.pdf",
    document_metadata={
        "source": "workshop",
        "category": "tutorial",
        "processed_date": datetime.now()
    },
    chunk_size=1000,  # Text chunk size
    overlap=200       # Chunk overlap
)

print(f"Processed {document_results.total_chunks} chunks")
print(f"Generated {document_results.total_embeddings} embeddings")
```

### Vector Search

```python
# Perform semantic search
results = await search.semantic_search(
    query="How do I create a vector index?",
    limit=5,
    filters={
        "metadata.category": "tutorial"
    },
    include_scores=True
)

for result in results:
    print(f"Score: {result.score:.3f}")
    print(f"Content: {result.content[:200]}...")
    print(f"Metadata: {result.metadata}")
    print("---")
```

### Multimodal Queries

```python
# Search with both text and image
from PIL import Image

image = Image.open("query_image.png")

results = await search.multimodal_search(
    text_query="architectural diagrams",
    image_query=image,
    limit=3,
    combine_strategy="weighted",  # "text_priority", "image_priority", "balanced"
    weights={"text": 0.6, "image": 0.4}
)
```

## üîß Direct PyMongo Approach

For maximum control, you can interact directly with MongoDB using PyMongo and handle embeddings manually.

### Vector Search Pipeline

```python
from pymongo import MongoClient
import requests

class VectorSearchClient:
    def __init__(self, connection_string, database, collection):
        self.client = MongoClient(connection_string)
        self.db = self.client[database]
        self.collection = self.db[collection]
    
    async def generate_embedding(self, content, content_type="text"):
        """Generate embeddings using Voyage AI API"""
        response = requests.post(
            "https://api.voyageai.com/v1/embeddings",
            headers={
                "Authorization": f"Bearer {voyage_api_key}",
                "Content-Type": "application/json"
            },
            json={
                "input": content,
                "model": "voyage-multimodal-3",
                "input_type": content_type
            }
        )
        return response.json()["data"][0]["embedding"]
    
    async def vector_search(self, query_text, limit=5):
        """Perform vector search using MongoDB aggregation"""
        # Generate query embedding
        query_embedding = await self.generate_embedding(query_text)
        
        # MongoDB vector search pipeline
        pipeline = [
            {
                "$vectorSearch": {
                    "index": "vector_index",
                    "path": "embedding",
                    "queryVector": query_embedding,
                    "numCandidates": limit * 10,
                    "limit": limit
                }
            },
            {
                "$project": {
                    "content": 1,
                    "metadata": 1,
                    "score": {"$meta": "vectorSearchScore"}
                }
            }
        ]
        
        return list(self.collection.aggregate(pipeline))

# Usage
search_client = VectorSearchClient(
    connection_string="mongodb+srv://...",
    database="multimodal_workshop",
    collection="pdf_documents"
)

results = await search_client.vector_search("machine learning concepts")
```

### Advanced Filtering

```python
# Hybrid search with metadata filtering
pipeline = [
    {
        "$vectorSearch": {
            "index": "vector_index",
            "path": "embedding", 
            "queryVector": query_embedding,
            "numCandidates": 100,
            "limit": 20,
            "filter": {
                "metadata.document_type": {"$eq": "technical"},
                "metadata.date": {"$gte": datetime(2024, 1, 1)}
            }
        }
    },
    {
        "$match": {
            "score": {"$gte": 0.7}  # Minimum similarity threshold
        }
    },
    {
        "$lookup": {
            "from": "document_metadata",
            "localField": "document_id",
            "foreignField": "_id",
            "as": "full_metadata"
        }
    }
]
```

## üåê LangChain Integration

Integrate MongoDB vector search with LangChain for advanced RAG applications.

### Setup

```python
from langchain.vectorstores import MongoDBAtlasVectorSearch
from langchain.embeddings import VoyageAIEmbeddings
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

# Initialize embeddings
embeddings = VoyageAIEmbeddings(
    voyage_api_key="your-api-key",
    model="voyage-multimodal-3"
)

# Setup vector store
vector_store = MongoDBAtlasVectorSearch(
    collection=collection,
    embedding=embeddings,
    index_name="vector_index"
)
```

### RAG Chain

```python
from langchain.chains import RetrievalQA
from langchain.llms import GoogleGenerativeAI

# Setup retrieval chain
qa_chain = RetrievalQA.from_chain_type(
    llm=GoogleGenerativeAI(model="gemini-2.0-flash-exp"),
    chain_type="stuff",
    retriever=vector_store.as_retriever(
        search_kwargs={"k": 5, "score_threshold": 0.7}
    ),
    return_source_documents=True
)

# Ask questions
result = qa_chain.invoke({
    "query": "How do I optimize vector search performance?"
})

print(f"Answer: {result['result']}")
print(f"Sources: {len(result['source_documents'])} documents")
```

## üîÑ Hybrid n8n + Python Approach

Combine the best of both worlds by using n8n for orchestration and Python for custom logic.

### Python Microservice

```python
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()

class SearchRequest(BaseModel):
    query: str
    filters: dict = {}
    limit: int = 5

@app.post("/advanced-search")
async def advanced_search(request: SearchRequest):
    """Custom search logic called from n8n"""
    
    # Custom preprocessing
    processed_query = preprocess_query(request.query)
    
    # Advanced search logic
    results = await custom_vector_search(
        query=processed_query,
        filters=request.filters,
        limit=request.limit
    )
    
    # Post-processing
    enhanced_results = enhance_results(results)
    
    return {
        "results": enhanced_results,
        "total": len(enhanced_results),
        "query_processed": processed_query
    }

# Custom functions
def preprocess_query(query: str) -> str:
    # Query expansion, spell check, etc.
    return enhanced_query

async def custom_vector_search(query, filters, limit):
    # Your custom search logic
    pass

def enhance_results(results):
    # Add custom scoring, ranking, metadata
    return enhanced_results
```

### n8n HTTP Request Node

```json
{
  "method": "POST",
  "url": "http://your-python-service/advanced-search",
  "body": {
    "query": "{{ $json.user_query }}",
    "filters": {
      "document_type": "{{ $json.doc_type }}",
      "date_range": "{{ $json.date_filter }}"
    },
    "limit": 10
  }
}
```

## üìä Performance Comparison

| Approach | Setup Time | Development Speed | Performance | Scalability |
|----------|------------|------------------|-------------|-------------|
| **MongoDB Multimodal Library** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **Direct PyMongo** | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **LangChain Integration** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |
| **n8n Visual Workflows** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |

## üéØ When to Choose Which Approach

### Use **n8n Visual Workflows** when:
- ‚úÖ Rapid prototyping and testing
- ‚úÖ Non-technical team members involved
- ‚úÖ Standard workflow patterns
- ‚úÖ Need many integrations quickly

### Use **MongoDB Multimodal Library** when:
- ‚úÖ Python-first development approach
- ‚úÖ Need multimodal capabilities out-of-the-box
- ‚úÖ Want MongoDB best practices built-in
- ‚úÖ Balancing simplicity with control

### Use **Direct PyMongo** when:
- ‚úÖ Maximum performance requirements
- ‚úÖ Complex custom logic needed
- ‚úÖ Fine-grained control over queries
- ‚úÖ Existing MongoDB infrastructure

### Use **Hybrid Approach** when:
- ‚úÖ Team has mixed skill levels
- ‚úÖ Need both visual workflows and custom logic
- ‚úÖ Want to leverage existing n8n infrastructure
- ‚úÖ Iterative development process

## üîó Code Examples Repository

All Python examples from this section are available in the workshop repository:

<QRCodeAccess 
  url="https://github.com/mrlynn/ai4-multimodal-agents-n8n/tree/main/python-examples"
  title="Python Examples Repository"
/>

```bash
# Clone and explore Python examples
git clone https://github.com/mrlynn/ai4-multimodal-agents-n8n.git
cd multimodal-pdf-agent-n8n/python-examples

# Install dependencies
pip install -r requirements.txt

# Run examples
python multimodal_search_example.py
python direct_pymongo_example.py
python langchain_integration_example.py
```

## üöÄ Next Steps

1. **Try the MongoDB Multimodal Library** - Start with the high-level API
2. **Experiment with Hybrid Approaches** - Combine n8n with Python microservices  
3. **Optimize for Your Use Case** - Choose the right tool for each task
4. **Join the Community** - Share your Python integration patterns

The power of MongoDB vector search is that it works seamlessly across all these approaches - choose the one that fits your team and project best!

<WorkshopResources 
  title="Python Integration Resources"
  categories={{
    "MongoDB Python Libraries": [
      {
        title: "MongoDB Multimodal Search Library",
        url: "https://github.com/mongodb-labs/multimodal-search-python",
        description: "High-level Python library for multimodal vector search",
        icon: "üêç"
      },
      {
        title: "PyMongo Documentation", 
        url: "https://pymongo.readthedocs.io/",
        description: "Official MongoDB Python driver documentation",
        icon: "üìö"
      },
      {
        title: "Motor (Async MongoDB)",
        url: "https://motor.readthedocs.io/",
        description: "Asynchronous Python driver for MongoDB",
        icon: "‚ö°"
      }
    ],
    "ML/AI Integration": [
      {
        title: "LangChain MongoDB Integration",
        url: "https://python.langchain.com/docs/integrations/vectorstores/mongodb_atlas",
        description: "LangChain vector store integration",
        icon: "ü¶ú"
      },
      {
        title: "Voyage AI Python SDK",
        url: "https://docs.voyageai.com/docs/python-sdk",
        description: "Official Python SDK for Voyage AI embeddings",
        icon: "üö¢"
      },
      {
        title: "Hugging Face Transformers",
        url: "https://huggingface.co/docs/transformers/",
        description: "Alternative embedding and model options",
        icon: "ü§ó"
      }
    ],
    "Development Tools": [
      {
        title: "Jupyter Notebooks Examples",
        url: "https://github.com/mrlynn/vector-search-examples",
        description: "Interactive Python examples and tutorials",
        icon: "üìì"
      },
      {
        title: "FastAPI Documentation",
        url: "https://fastapi.tiangolo.com/",
        description: "For building Python microservices",
        icon: "üöÄ"
      },
      {
        title: "Streamlit",
        url: "https://streamlit.io/",
        description: "Rapid Python web app development",
        icon: "üé®"
      }
    ]
  }}
/>