---
id: index
sidebar_position: 1
slug: /
title: Workshop Home
---

# 🎓 Multimodal PDF Agent Workshop

**Build Intelligent AI Systems That Understand Both Text and Images**

Welcome to our comprehensive workshop where you'll learn to create sophisticated AI agents that can reason, plan, use tools, and understand multimodal content from PDFs.

---

## 🧠 What Are We Learning?

You're learning what **AI agents** are—systems that don't just answer simple prompts, but can:

- **Reason through problems** step-by-step
- **Plan solutions** across multiple steps  
- **Use external tools** (vector databases, APIs, search, etc.)
- **Remember previous conversations** (short- and long-term memory)
- **Iterate and refine** their answers

### 🔍 Key Components You'll Master

**🎯 Perception**: How the agent "sees" and ingests information (text, images, audio, etc.)

**🧩 Planning & Reasoning**: How it decides what to do, possibly in multiple steps

**🛠️ Tools**: How it interacts with the outside world (searches, code execution, APIs)

**💾 Memory**: How it recalls and uses past interactions or data

We dive deep into **multimodality**—meaning models that process more than one kind of data. Not just text, but also images, charts, diagrams, and visual elements that contain critical information.

---

## 🏗️ What Are We Building?

You're building a **multimodal AI agent from scratch** that can:

✅ **Answer questions** about a collection of documents (PDFs, reports, etc.)

✅ **Understand both text and visual elements** (charts, diagrams, tables) inside those documents

✅ **Explain charts, diagrams, and content** across modalities—not just copy text

✅ **Remember conversations** and build context over time

✅ **Use tools intelligently** to search, retrieve, and reason

You'll prepare data for mixed-modal retrieval, feed it into a vector store, and wire up a system that leverages the latest LLMs and multimodal models for robust, intelligent answers.

---

## 🌟 Why Does This Matter?

### 📊 Real-World Data is Multimodal
Business documents, scientific papers, and reports all have **critical information in images, diagrams, and tables**—not just text. Traditional approaches miss this entirely.

### ❌ Classic AI Falls Short
- **Text-only models** can't "see" a chart or interpret a figure
- **Image-only models** can't explain what's written
- **Simple chatbots** can't reason through complex, multi-step problems

### ✨ Multimodal Agents Bridge the Gap
Combining LLMs, perception, memory, and external tools to solve **more complex, useful, real-world tasks**. You're not just using AI—you're **engineering it** to reason, search, and respond with context from all types of content.

---

## 🍃 Why MongoDB?

You'll see how **MongoDB's vector search**, document flexibility, and ability to store mixed data types make it a perfect fit for building these next-generation AI agents.

- **Native vector search** with HNSW algorithms for lightning-fast similarity matching
- **Flexible document storage** that handles text, images, and metadata seamlessly  
- **Production-ready scaling** that grows with your application
- **Real tools and code** you can adapt for production systems

---

## 🛤️ Workshop Approach

### 🐍 **Python & Jupyter Notebooks**  
**Perfect for:** Developers, data scientists, and AI engineers

Build multimodal AI agents with Python:
- Hands-on coding with Jupyter notebooks
- VoyageAI embeddings for multimodal search
- MongoDB Atlas vector search integration
- ReAct agent architecture implementation
- Full control over the implementation
- Production-ready patterns and best practices

**[Start Workshop →](./python-exercise-1)**

---

## 🎯 Big Picture: What You'll Walk Away With

### 🧠 **Deep Understanding**
- The key patterns for building modern AI agents
- How to handle and retrieve from mixed-modal data  
- Where the field is going, and how you can contribute right now

### 🛠️ **Practical Skills**
- Production-ready code and workflows
- Experience with cutting-edge AI tools
- Real systems you can adapt and extend

### 🚀 **Future-Ready Knowledge**
This workshop is about creating agents that can answer questions about **both the words and the pictures**—true "understanding" at machine scale.

---

## 🚀 Ready to Start Building?

<div style={{
  textAlign: 'center', 
  padding: '3rem', 
  background: 'linear-gradient(135deg, #7C3AED 0%, #A855F7 100%)', 
  borderRadius: '12px',
  color: 'white',
  marginTop: '2rem',
  marginBottom: '2rem'
}}>
  <h3 style={{color: 'white', marginBottom: '1rem', fontSize: '1.8rem'}}>🐍 Build with Python & Jupyter</h3>
  <p style={{marginBottom: '2rem', fontSize: '1.2rem'}}>Create production-ready multimodal AI agents<br/>with VoyageAI embeddings and MongoDB Atlas</p>
  <a 
    href="/docs/python-exercise-1"
    style={{
      display: 'inline-block',
      padding: '1rem 3rem',
      background: 'white',
      color: '#7C3AED',
      textDecoration: 'none',
      borderRadius: '8px',
      fontWeight: 'bold',
      fontSize: '1.2rem',
      boxShadow: '0 4px 6px rgba(0,0,0,0.1)'
    }}
  >
    Start Workshop →
  </a>
</div>

---

## 📚 Additional Resources

- **[Workshop Overview & Slides](./workshop-overview)** - Complete presentation materials
- **[Workshop Objectives](./objectives-overview)** - Detailed learning outcomes
- **[PDF Tester](/upload)** - Test your workflows as you build

---

<div style={{
  marginTop: '3rem',
  padding: '2rem',
  background: 'var(--ifm-color-primary-lightest)',
  borderRadius: '12px',
  textAlign: 'center'
}}>
  <h2>🎉 Let's Build Something Amazing!</h2>
  <p style={{fontSize: '1.2rem', marginBottom: '0'}}>
    Ready to create AI agents that understand both words and pictures?<br/>
    <strong>Let's get started with Python and Jupyter!</strong>
  </p>
</div>