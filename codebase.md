# .docusaurus/client-manifest.json

```json
{
  "entrypoints": [
    "main"
  ],
  "origins": {
    "165": [
      725,
      3624,
      6433,
      8731,
      165
    ],
    "310": [
      8379,
      310
    ],
    "375": [
      3624,
      8731,
      375
    ],
    "725": [
      165,
      3624,
      8731,
      725
    ],
    "1039": [
      1039
    ],
    "2068": [
      2068
    ],
    "2076": [
      8379,
      2076
    ],
    "2130": [
      2130
    ],
    "2159": [
      8583,
      2159
    ],
    "2334": [
      3624,
      5759,
      8583,
      8665,
      2334
    ],
    "2498": [
      2498
    ],
    "2822": [
      2822
    ],
    "3624": [
      165,
      375,
      725,
      2334,
      4866,
      4914,
      5388,
      5759,
      5775,
      6795,
      6796,
      8583,
      8665,
      8731,
      3624
    ],
    "3736": [
      3736
    ],
    "3956": [
      3956
    ],
    "4458": [
      4458
    ],
    "4504": [
      4504
    ],
    "4781": [
      8946,
      4781
    ],
    "4866": [
      3624,
      8731,
      4866
    ],
    "4914": [
      3624,
      4914
    ],
    "5388": [
      3624,
      8731,
      5388
    ],
    "5392": [
      5392
    ],
    "5759": [
      2334,
      3624,
      8583,
      5759
    ],
    "5775": [
      3624,
      8731,
      5775
    ],
    "5864": [
      5864
    ],
    "6143": [
      6143
    ],
    "6433": [
      165,
      6433
    ],
    "6577": [
      6577
    ],
    "6795": [
      3624,
      8731,
      6795
    ],
    "6796": [
      3624,
      8731,
      6796
    ],
    "7340": [
      7340
    ],
    "7434": [
      1869,
      8401,
      7434
    ],
    "7835": [
      7835
    ],
    "7900": [
      7900
    ],
    "8188": [
      8188
    ],
    "8379": [
      310,
      2076,
      8379
    ],
    "8583": [
      2159,
      2334,
      3624,
      5759,
      8583
    ],
    "8665": [
      2334,
      3624,
      8665
    ],
    "8716": [
      8716
    ],
    "8731": [
      165,
      375,
      725,
      3624,
      4866,
      5388,
      5775,
      6795,
      6796,
      8731
    ],
    "8946": [
      4781,
      8946
    ],
    "9107": [
      9107
    ],
    "9157": [
      9157
    ],
    "9278": [
      1869,
      9278
    ],
    "9349": [
      9349
    ],
    "13701908": [
      5808
    ],
    "17896441": [
      1869,
      7434,
      8401
    ],
    "60085230": [
      5273
    ],
    "main": [
      1869,
      5354,
      8792
    ],
    "runtime~main": [
      1869,
      8792,
      5354
    ],
    "02d7a79a": [
      5024
    ],
    "03ac89dd": [
      6085
    ],
    "05ed9f9f": [
      6145
    ],
    "282a68b4": [
      7366
    ],
    "314d8dff": [
      4103
    ],
    "317957c9": [
      1869,
      7391
    ],
    "3aaaf183": [
      5093
    ],
    "42d68c3c": [
      9770
    ],
    "4429c3d9": [
      4211
    ],
    "4edc808e": [
      308
    ],
    "5117ca29": [
      6874
    ],
    "5129cb42": [
      4427
    ],
    "561b9617": [
      1142
    ],
    "57a1c685": [
      9039
    ],
    "5e95c892": [
      9647
    ],
    "658a454b": [
      442
    ],
    "68d5ec65": [
      5387
    ],
    "72d756b8": [
      2256
    ],
    "73da31c7": [
      5270
    ],
    "7fe8ecaf": [
      1390
    ],
    "802ad398": [
      208
    ],
    "827087dc": [
      4704
    ],
    "a7456010": [
      1235
    ],
    "a7bd4aaa": [
      7098
    ],
    "a94703ab": [
      1869,
      9048
    ],
    "aba21aa0": [
      5742
    ],
    "abe4f9c1": [
      9754
    ],
    "ad9dd368": [
      8122
    ],
    "b49ab2f2": [
      1869,
      7099
    ],
    "b5e167d0": [
      4015
    ],
    "c4f5d8e4": [
      1869,
      2634
    ],
    "c740305b": [
      7413
    ],
    "d2310bce": [
      9595
    ],
    "de64aa43": [
      6917
    ],
    "e725529d": [
      9470
    ],
    "eb7a2200": [
      7038
    ],
    "styles": [
      2634,
      5354,
      7099,
      7391,
      7434,
      8401,
      8792,
      9048,
      9278,
      1869
    ]
  },
  "assets": {
    "165": {
      "js": [
        {
          "file": "assets/js/165.0d57f42d.js",
          "hash": "f8ad84f5dfed970c",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/165.0d57f42d.js"
        }
      ]
    },
    "208": {
      "js": [
        {
          "file": "assets/js/802ad398.e09b3d11.js",
          "hash": "aa54d71f94886431",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/802ad398.e09b3d11.js"
        }
      ]
    },
    "308": {
      "js": [
        {
          "file": "assets/js/4edc808e.a1e5e114.js",
          "hash": "d6190c3974cdcb9a",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/4edc808e.a1e5e114.js"
        }
      ]
    },
    "310": {
      "js": [
        {
          "file": "assets/js/310.912a04a8.js",
          "hash": "9a8e6d4fe0c4ab89",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/310.912a04a8.js"
        }
      ]
    },
    "375": {
      "js": [
        {
          "file": "assets/js/375.f9d9e59b.js",
          "hash": "004571af4af2b3a7",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/375.f9d9e59b.js"
        }
      ]
    },
    "442": {
      "js": [
        {
          "file": "assets/js/658a454b.61a72816.js",
          "hash": "8262ecff0e33e255",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/658a454b.61a72816.js"
        }
      ]
    },
    "725": {
      "js": [
        {
          "file": "assets/js/725.9242d8ee.js",
          "hash": "ad0a4a24b5841e24",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/725.9242d8ee.js"
        }
      ]
    },
    "1039": {
      "js": [
        {
          "file": "assets/js/1039.8020e533.js",
          "hash": "5361832abee97a9b",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/1039.8020e533.js"
        }
      ]
    },
    "1142": {
      "js": [
        {
          "file": "assets/js/561b9617.0bb1e7ec.js",
          "hash": "e48220c2511d4365",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/561b9617.0bb1e7ec.js"
        }
      ]
    },
    "1235": {
      "js": [
        {
          "file": "assets/js/a7456010.df49b093.js",
          "hash": "d99264d130fd8935",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/a7456010.df49b093.js"
        }
      ]
    },
    "1390": {
      "js": [
        {
          "file": "assets/js/7fe8ecaf.31938121.js",
          "hash": "08d7671c0b25bb30",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/7fe8ecaf.31938121.js"
        }
      ]
    },
    "1869": {
      "css": [
        {
          "file": "assets/css/styles.3ec4684c.css",
          "hash": "8db26432371ae78f",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/css/styles.3ec4684c.css"
        }
      ]
    },
    "2068": {
      "js": [
        {
          "file": "assets/js/2068.45bf95f7.js",
          "hash": "c71c92faef0295c3",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/2068.45bf95f7.js"
        }
      ]
    },
    "2076": {
      "js": [
        {
          "file": "assets/js/2076.b8d5d6ce.js",
          "hash": "ccbd0591cdb8d30b",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/2076.b8d5d6ce.js"
        }
      ]
    },
    "2130": {
      "js": [
        {
          "file": "assets/js/2130.1d9afb20.js",
          "hash": "339107b9049cc482",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/2130.1d9afb20.js"
        }
      ]
    },
    "2159": {
      "js": [
        {
          "file": "assets/js/2159.f1c39805.js",
          "hash": "3a4b59bdbdd30a7c",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/2159.f1c39805.js"
        }
      ]
    },
    "2256": {
      "js": [
        {
          "file": "assets/js/72d756b8.346bfef7.js",
          "hash": "ad2a37a7c5162efb",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/72d756b8.346bfef7.js"
        }
      ]
    },
    "2334": {
      "js": [
        {
          "file": "assets/js/2334.6bc0be5f.js",
          "hash": "d7eec4df418654b9",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/2334.6bc0be5f.js"
        }
      ]
    },
    "2498": {
      "js": [
        {
          "file": "assets/js/2498.19792bde.js",
          "hash": "f24fd21c406b96bd",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/2498.19792bde.js"
        }
      ]
    },
    "2634": {
      "js": [
        {
          "file": "assets/js/c4f5d8e4.a29171c7.js",
          "hash": "57661e0583d3c28e",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/c4f5d8e4.a29171c7.js"
        }
      ]
    },
    "2822": {
      "js": [
        {
          "file": "assets/js/2822.7e66804c.js",
          "hash": "90b7a6db329bd89d",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/2822.7e66804c.js"
        }
      ]
    },
    "3624": {
      "js": [
        {
          "file": "assets/js/3624.4db48a06.js",
          "hash": "29838d35b3ad918c",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/3624.4db48a06.js"
        }
      ]
    },
    "3736": {
      "js": [
        {
          "file": "assets/js/3736.31c543b2.js",
          "hash": "d4f11946e9e1aced",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/3736.31c543b2.js"
        }
      ]
    },
    "3956": {
      "js": [
        {
          "file": "assets/js/3956.96638b7b.js",
          "hash": "89cc515025e6771c",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/3956.96638b7b.js"
        }
      ]
    },
    "4015": {
      "js": [
        {
          "file": "assets/js/b5e167d0.4985c1ff.js",
          "hash": "574f268be4b19e23",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/b5e167d0.4985c1ff.js"
        }
      ]
    },
    "4103": {
      "js": [
        {
          "file": "assets/js/314d8dff.d497d3dd.js",
          "hash": "95c6a280717877ab",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/314d8dff.d497d3dd.js"
        }
      ]
    },
    "4211": {
      "js": [
        {
          "file": "assets/js/4429c3d9.91569750.js",
          "hash": "c52d9e07287ad538",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/4429c3d9.91569750.js"
        }
      ]
    },
    "4427": {
      "js": [
        {
          "file": "assets/js/5129cb42.97dd8ff9.js",
          "hash": "ae95dd4470179f5a",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/5129cb42.97dd8ff9.js"
        }
      ]
    },
    "4458": {
      "js": [
        {
          "file": "assets/js/4458.2184a2b0.js",
          "hash": "9693a596e0a58366",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/4458.2184a2b0.js"
        }
      ]
    },
    "4504": {
      "js": [
        {
          "file": "assets/js/4504.7f49951b.js",
          "hash": "52fcde08b3f61d9e",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/4504.7f49951b.js"
        }
      ]
    },
    "4704": {
      "js": [
        {
          "file": "assets/js/827087dc.e29942cb.js",
          "hash": "759520b87f49e227",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/827087dc.e29942cb.js"
        }
      ]
    },
    "4781": {
      "js": [
        {
          "file": "assets/js/4781.f1aa190e.js",
          "hash": "c7c946d78fe20fe6",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/4781.f1aa190e.js"
        }
      ]
    },
    "4866": {
      "js": [
        {
          "file": "assets/js/4866.094d4d83.js",
          "hash": "932eb990045693df",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/4866.094d4d83.js"
        }
      ]
    },
    "4914": {
      "js": [
        {
          "file": "assets/js/4914.3db18a8f.js",
          "hash": "dc89677c104b6ae6",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/4914.3db18a8f.js"
        }
      ]
    },
    "5024": {
      "js": [
        {
          "file": "assets/js/02d7a79a.0d516b36.js",
          "hash": "c77f1c05d9e725d3",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/02d7a79a.0d516b36.js"
        }
      ]
    },
    "5093": {
      "js": [
        {
          "file": "assets/js/3aaaf183.dc0abee2.js",
          "hash": "78aa6d75838b6750",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/3aaaf183.dc0abee2.js"
        }
      ]
    },
    "5270": {
      "js": [
        {
          "file": "assets/js/73da31c7.6e5a5364.js",
          "hash": "c0ed3a4ab36cddd8",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/73da31c7.6e5a5364.js"
        }
      ]
    },
    "5273": {
      "js": [
        {
          "file": "assets/js/60085230.66ffc500.js",
          "hash": "1c9fcdfd41773de6",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/60085230.66ffc500.js"
        }
      ]
    },
    "5354": {
      "js": [
        {
          "file": "assets/js/runtime~main.ffc02d6e.js",
          "hash": "032f873e0fbb716f",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/runtime~main.ffc02d6e.js"
        }
      ]
    },
    "5387": {
      "js": [
        {
          "file": "assets/js/68d5ec65.3065f3f9.js",
          "hash": "5cd0c9ee8de9a072",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/68d5ec65.3065f3f9.js"
        }
      ]
    },
    "5388": {
      "js": [
        {
          "file": "assets/js/5388.7967370d.js",
          "hash": "fe72ca08c9dc19b4",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/5388.7967370d.js"
        }
      ]
    },
    "5392": {
      "js": [
        {
          "file": "assets/js/5392.58e19685.js",
          "hash": "53a5b3eeb725a1a0",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/5392.58e19685.js"
        }
      ]
    },
    "5742": {
      "js": [
        {
          "file": "assets/js/aba21aa0.997c8f1a.js",
          "hash": "94828330fe02cd0f",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/aba21aa0.997c8f1a.js"
        }
      ]
    },
    "5759": {
      "js": [
        {
          "file": "assets/js/5759.f9fd17ae.js",
          "hash": "955212853b181203",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/5759.f9fd17ae.js"
        }
      ]
    },
    "5775": {
      "js": [
        {
          "file": "assets/js/5775.dc39a4fe.js",
          "hash": "e5aea7e84429b227",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/5775.dc39a4fe.js"
        }
      ]
    },
    "5808": {
      "js": [
        {
          "file": "assets/js/13701908.9e1730d1.js",
          "hash": "ba55b91731b90e67",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/13701908.9e1730d1.js"
        }
      ]
    },
    "5864": {
      "js": [
        {
          "file": "assets/js/5864.60ae8f9c.js",
          "hash": "eed8c0ae36a5f630",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/5864.60ae8f9c.js"
        }
      ]
    },
    "6085": {
      "js": [
        {
          "file": "assets/js/03ac89dd.bdb8a320.js",
          "hash": "4a3b80f470d9f49f",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/03ac89dd.bdb8a320.js"
        }
      ]
    },
    "6143": {
      "js": [
        {
          "file": "assets/js/6143.2242df17.js",
          "hash": "24b65781a9151b0c",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/6143.2242df17.js"
        }
      ]
    },
    "6145": {
      "js": [
        {
          "file": "assets/js/05ed9f9f.34d09173.js",
          "hash": "bd81f3e7f7beac33",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/05ed9f9f.34d09173.js"
        }
      ]
    },
    "6433": {
      "js": [
        {
          "file": "assets/js/6433.93940c6e.js",
          "hash": "40b90db9e05004f0",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/6433.93940c6e.js"
        }
      ]
    },
    "6577": {
      "js": [
        {
          "file": "assets/js/6577.f4127f30.js",
          "hash": "06c5b5b62cc6ed2d",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/6577.f4127f30.js"
        }
      ]
    },
    "6795": {
      "js": [
        {
          "file": "assets/js/6795.47bafe40.js",
          "hash": "cd6ad64dffe7c09b",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/6795.47bafe40.js"
        }
      ]
    },
    "6796": {
      "js": [
        {
          "file": "assets/js/6796.17779958.js",
          "hash": "979febc6642e3a35",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/6796.17779958.js"
        }
      ]
    },
    "6874": {
      "js": [
        {
          "file": "assets/js/5117ca29.b52f43ab.js",
          "hash": "0877b0afaedce0fa",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/5117ca29.b52f43ab.js"
        }
      ]
    },
    "6917": {
      "js": [
        {
          "file": "assets/js/de64aa43.c6f08905.js",
          "hash": "876e6078ea09885a",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/de64aa43.c6f08905.js"
        }
      ]
    },
    "7038": {
      "js": [
        {
          "file": "assets/js/eb7a2200.312316b5.js",
          "hash": "dd226759a66999ec",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/eb7a2200.312316b5.js"
        }
      ]
    },
    "7098": {
      "js": [
        {
          "file": "assets/js/a7bd4aaa.019b4a72.js",
          "hash": "40727190fb4bbf73",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/a7bd4aaa.019b4a72.js"
        }
      ]
    },
    "7099": {
      "js": [
        {
          "file": "assets/js/b49ab2f2.3ef187d0.js",
          "hash": "8a75fa443ac4a9ad",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/b49ab2f2.3ef187d0.js"
        }
      ]
    },
    "7340": {
      "js": [
        {
          "file": "assets/js/7340.8f53d1fb.js",
          "hash": "de87390ba7d781d7",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/7340.8f53d1fb.js"
        }
      ]
    },
    "7366": {
      "js": [
        {
          "file": "assets/js/282a68b4.52b805f6.js",
          "hash": "0f51117832cf517d",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/282a68b4.52b805f6.js"
        }
      ]
    },
    "7391": {
      "js": [
        {
          "file": "assets/js/317957c9.2cc2cac4.js",
          "hash": "78db1b7ac428f3e0",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/317957c9.2cc2cac4.js"
        }
      ]
    },
    "7413": {
      "js": [
        {
          "file": "assets/js/c740305b.2272be4a.js",
          "hash": "15da5e2cf6d96b23",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/c740305b.2272be4a.js"
        }
      ]
    },
    "7434": {
      "js": [
        {
          "file": "assets/js/7434.d483ede7.js",
          "hash": "e6b2bf27a9996e30",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/7434.d483ede7.js"
        }
      ]
    },
    "7835": {
      "js": [
        {
          "file": "assets/js/7835.6fe455d2.js",
          "hash": "9a84a65b968e2233",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/7835.6fe455d2.js"
        }
      ]
    },
    "7900": {
      "js": [
        {
          "file": "assets/js/7900.fc04fffd.js",
          "hash": "cfe89bbf0eddda3d",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/7900.fc04fffd.js"
        }
      ]
    },
    "8122": {
      "js": [
        {
          "file": "assets/js/ad9dd368.6fb00cd1.js",
          "hash": "019364cec9fe3120",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/ad9dd368.6fb00cd1.js"
        }
      ]
    },
    "8188": {
      "js": [
        {
          "file": "assets/js/8188.a989ceb1.js",
          "hash": "2d9da18a337907a1",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/8188.a989ceb1.js"
        }
      ]
    },
    "8379": {
      "js": [
        {
          "file": "assets/js/8379.b72e46ed.js",
          "hash": "d2fe050f4647a140",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/8379.b72e46ed.js"
        }
      ]
    },
    "8401": {
      "js": [
        {
          "file": "assets/js/17896441.ae8d6f1a.js",
          "hash": "f5430a418ff2b5aa",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/17896441.ae8d6f1a.js"
        }
      ]
    },
    "8583": {
      "js": [
        {
          "file": "assets/js/8583.839eb310.js",
          "hash": "dc7c1015bbdff2c6",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/8583.839eb310.js"
        }
      ]
    },
    "8665": {
      "js": [
        {
          "file": "assets/js/8665.f025359a.js",
          "hash": "07d218f03ae9e922",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/8665.f025359a.js"
        }
      ]
    },
    "8716": {
      "js": [
        {
          "file": "assets/js/8716.bb825f14.js",
          "hash": "6eb79dcfb5a89718",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/8716.bb825f14.js"
        }
      ]
    },
    "8731": {
      "js": [
        {
          "file": "assets/js/8731.30d0b384.js",
          "hash": "8b33c85192c97656",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/8731.30d0b384.js"
        }
      ]
    },
    "8792": {
      "js": [
        {
          "file": "assets/js/main.f1737bca.js",
          "hash": "63382039b7c00cf8",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/main.f1737bca.js"
        }
      ]
    },
    "8946": {
      "js": [
        {
          "file": "assets/js/8946.1b8da8eb.js",
          "hash": "3f92ae77fe4fa5b4",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/8946.1b8da8eb.js"
        }
      ]
    },
    "9039": {
      "js": [
        {
          "file": "assets/js/57a1c685.6e348517.js",
          "hash": "2df45d0037e6b475",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/57a1c685.6e348517.js"
        }
      ]
    },
    "9048": {
      "js": [
        {
          "file": "assets/js/a94703ab.bcf3b5d7.js",
          "hash": "518e0698020e4096",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/a94703ab.bcf3b5d7.js"
        }
      ]
    },
    "9107": {
      "js": [
        {
          "file": "assets/js/9107.cd04f8a8.js",
          "hash": "c6955235be837396",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/9107.cd04f8a8.js"
        }
      ]
    },
    "9157": {
      "js": [
        {
          "file": "assets/js/9157.6284199f.js",
          "hash": "50a9a1ed295e58b8",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/9157.6284199f.js"
        }
      ]
    },
    "9278": {
      "js": [
        {
          "file": "assets/js/9278.197365f1.js",
          "hash": "008b723ec1fea6ae",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/9278.197365f1.js"
        }
      ]
    },
    "9349": {
      "js": [
        {
          "file": "assets/js/9349.03262524.js",
          "hash": "07248bf4c0e92782",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/9349.03262524.js"
        }
      ]
    },
    "9470": {
      "js": [
        {
          "file": "assets/js/e725529d.26065c02.js",
          "hash": "82791407c965efeb",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/e725529d.26065c02.js"
        }
      ]
    },
    "9595": {
      "js": [
        {
          "file": "assets/js/d2310bce.2103fd24.js",
          "hash": "dc349cb63914e0bf",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/d2310bce.2103fd24.js"
        }
      ]
    },
    "9647": {
      "js": [
        {
          "file": "assets/js/5e95c892.538275d6.js",
          "hash": "76390f6708751877",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/5e95c892.538275d6.js"
        }
      ]
    },
    "9754": {
      "js": [
        {
          "file": "assets/js/abe4f9c1.54baf23a.js",
          "hash": "4559f4872fcaa60d",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/abe4f9c1.54baf23a.js"
        }
      ]
    },
    "9770": {
      "js": [
        {
          "file": "assets/js/42d68c3c.f6abf6d3.js",
          "hash": "87e258d44c47ac2d",
          "publicPath": "/multimodal-pdf-agent-n8n/es/assets/js/42d68c3c.f6abf6d3.js"
        }
      ]
    }
  }
}
```

# .docusaurus/client-modules.js

```js
export default [
  require("/Users/michael.lynn/code/ai4/workshop-docs/.docusaurus/docusaurus-plugin-css-cascade-layers/default/layers.css"),
  require("/Users/michael.lynn/code/ai4/workshop-docs/node_modules/infima/dist/css/default/default.css"),
  require("/Users/michael.lynn/code/ai4/workshop-docs/node_modules/@docusaurus/theme-classic/lib/prism-include-languages"),
  require("/Users/michael.lynn/code/ai4/workshop-docs/node_modules/@docusaurus/theme-classic/lib/nprogress"),
  require("/Users/michael.lynn/code/ai4/workshop-docs/src/css/custom.css"),
];

```

# .docusaurus/codeTranslations.json

```json
{}
```

# .docusaurus/docusaurus-lunr-search/default/__plugin.json

```json
{
  "name": "docusaurus-lunr-search",
  "id": "default"
}
```

# .docusaurus/docusaurus-plugin-content-blog/default/__plugin.json

```json
{
  "name": "docusaurus-plugin-content-blog",
  "id": "default"
}
```

# .docusaurus/docusaurus-plugin-content-blog/default/blog-post-list-prop-default.json

```json
{
  "title": "Recent posts",
  "items": []
}
```

# .docusaurus/docusaurus-plugin-content-blog/default/blogMetadata-default.json

```json
{
  "blogBasePath": "/multimodal-pdf-agent-n8n/blog",
  "blogTitle": "Blog",
  "authorsListPath": "/multimodal-pdf-agent-n8n/blog/authors"
}
```

# .docusaurus/docusaurus-plugin-content-docs/default/__mdx-loader-dependency.json

```json
{"options":{"sidebarPath":"/Users/michael.lynn/code/ai4/workshop-docs/sidebars.js","editUrl":"https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main","path":"docs","editCurrentVersion":false,"editLocalizedFiles":false,"routeBasePath":"docs","tagsBasePath":"tags","include":["**/*.{md,mdx}"],"exclude":["**/_*.{js,jsx,ts,tsx,md,mdx}","**/_*/**","**/*.test.{js,jsx,ts,tsx}","**/__tests__/**"],"sidebarCollapsible":true,"sidebarCollapsed":true,"docsRootComponent":"@theme/DocsRoot","docVersionRootComponent":"@theme/DocVersionRoot","docRootComponent":"@theme/DocRoot","docItemComponent":"@theme/DocItem","docTagsListComponent":"@theme/DocTagsListPage","docTagDocListComponent":"@theme/DocTagDocListPage","docCategoryGeneratedIndexComponent":"@theme/DocCategoryGeneratedIndexPage","remarkPlugins":[],"rehypePlugins":[],"recmaPlugins":[],"beforeDefaultRemarkPlugins":[],"beforeDefaultRehypePlugins":[],"admonitions":true,"showLastUpdateTime":false,"showLastUpdateAuthor":false,"includeCurrentVersion":true,"disableVersioning":false,"versions":{},"breadcrumbs":true,"onInlineTags":"warn","id":"default"},"versionsMetadata":[{"versionName":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","path":"/multimodal-pdf-agent-n8n/docs","tagsPath":"/multimodal-pdf-agent-n8n/docs/tags","editUrl":"https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs","editUrlLocalized":"https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/i18n/en/docusaurus-plugin-content-docs/current","isLast":true,"routePriority":-1,"sidebarFilePath":"/Users/michael.lynn/code/ai4/workshop-docs/sidebars.js","contentPath":"/Users/michael.lynn/code/ai4/workshop-docs/docs","contentPathLocalized":"/Users/michael.lynn/code/ai4/workshop-docs/i18n/en/docusaurus-plugin-content-docs/current"}]}
```

# .docusaurus/docusaurus-plugin-content-docs/default/__plugin.json

```json
{
  "name": "docusaurus-plugin-content-docs",
  "id": "default"
}
```

# .docusaurus/docusaurus-plugin-content-docs/default/p/multimodal-pdf-agent-n-8-n-docs-a69.json

```json
{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","label":"🎓 Workshop Overview","href":"/multimodal-pdf-agent-n8n/docs/","docId":"index","unlisted":false},{"type":"category","label":"🚀 Getting Started","collapsible":true,"collapsed":false,"className":"sidebar-getting-started","description":"Begin your journey with environment setup and n8n basics","items":[{"type":"link","label":"Workshop Introduction","href":"/multimodal-pdf-agent-n8n/docs/intro","docId":"intro","unlisted":false},{"type":"link","label":"🏗️ Architecture Overview","href":"/multimodal-pdf-agent-n8n/docs/architecture-overview","docId":"architecture-overview","unlisted":false},{"type":"link","label":"GitHub Codespaces Setup","href":"/multimodal-pdf-agent-n8n/docs/github-codespaces","docId":"github-codespaces","unlisted":false},{"type":"link","label":"Prerequisites & Local Setup","href":"/multimodal-pdf-agent-n8n/docs/prerequisites","docId":"prerequisites","unlisted":false},{"type":"link","label":"n8n First Run Experience","href":"/multimodal-pdf-agent-n8n/docs/n8n-first-run","docId":"n8n-first-run","unlisted":false}]},{"type":"category","label":"⚙️ Setup & Configuration","collapsible":true,"collapsed":false,"className":"sidebar-setup","description":"Configure MongoDB Atlas and Voyage AI for your agent","items":[{"type":"link","label":"🌐 API Gateway Architecture","href":"/multimodal-pdf-agent-n8n/docs/api-architecture","docId":"api-architecture","unlisted":false},{"type":"link","label":"MongoDB Atlas Setup","href":"/multimodal-pdf-agent-n8n/docs/mongodb-atlas-setup","docId":"mongodb-atlas-setup","unlisted":false},{"type":"link","label":"Voyage AI Configuration","href":"/multimodal-pdf-agent-n8n/docs/voyage-ai-setup","docId":"voyage-ai-setup","unlisted":false}]},{"type":"category","label":"🔧 Building Workflows","collapsible":true,"collapsed":false,"className":"sidebar-workflows","description":"Create powerful automation workflows step by step","items":[{"type":"link","label":"PDF Processing Workflow","href":"/multimodal-pdf-agent-n8n/docs/pdf-processing-workflow","docId":"pdf-processing-workflow","unlisted":false},{"type":"link","label":"Vector Search Implementation","href":"/multimodal-pdf-agent-n8n/docs/vector-search-workflow","docId":"vector-search-workflow","unlisted":false},{"type":"link","label":"AI Agent with Tool Calling","href":"/multimodal-pdf-agent-n8n/docs/ai-agent-workflow","docId":"ai-agent-workflow","unlisted":false}]},{"type":"category","label":"🧪 Hands-On Exercises","collapsible":true,"collapsed":false,"className":"sidebar-exercises","description":"Structured exercises to build complete AI agents","items":[{"type":"link","label":"🧪 Exercise: Build a PDF RAG Agent","href":"/multimodal-pdf-agent-n8n/docs/exercise-pdf-rag-agent","docId":"exercise-pdf-rag-agent","unlisted":false},{"type":"link","label":"🧪 Exercise: Memory & Context","href":"/multimodal-pdf-agent-n8n/docs/exercise-memory-context","docId":"exercise-memory-context","unlisted":false},{"type":"link","label":"🧪 Exercise: Advanced Tool Calling","href":"/multimodal-pdf-agent-n8n/docs/exercise-advanced-tools","docId":"exercise-advanced-tools","unlisted":false}]},{"type":"category","label":"🎯 Advanced Topics","collapsible":true,"collapsed":true,"className":"sidebar-advanced","description":"Take your agent to production with advanced features","items":[{"type":"link","label":"Complete Multimodal Agent","href":"/multimodal-pdf-agent-n8n/docs/complete-multimodal-agent","docId":"complete-multimodal-agent","unlisted":false},{"type":"link","label":"Production Vector Search","href":"/multimodal-pdf-agent-n8n/docs/mongodb-vector-setup","docId":"mongodb-vector-setup","unlisted":false},{"type":"link","label":"Web Upload Interface","href":"/multimodal-pdf-agent-n8n/docs/upload-interface","docId":"upload-interface","unlisted":false},{"type":"link","label":"🐍 Python Integration Options","href":"/multimodal-pdf-agent-n8n/docs/python-mongodb-approaches","docId":"python-mongodb-approaches","unlisted":false},{"type":"link","label":"⚖️ n8n vs Python Comparison","href":"/multimodal-pdf-agent-n8n/docs/approach-comparison","docId":"approach-comparison","unlisted":false},{"type":"link","label":"🧠 AI Agent Planning Patterns","href":"/multimodal-pdf-agent-n8n/docs/agent-patterns","docId":"agent-patterns","unlisted":false},{"type":"link","label":"💾 Memory & Context Patterns","href":"/multimodal-pdf-agent-n8n/docs/memory-context-patterns","docId":"memory-context-patterns","unlisted":false},{"type":"link","label":"🛠️ Tool Definition & Function Calling","href":"/multimodal-pdf-agent-n8n/docs/tool-definition-primer","docId":"tool-definition-primer","unlisted":false},{"type":"link","label":"🖼️ Multimodal Image Queries","href":"/multimodal-pdf-agent-n8n/docs/multimodal-image-queries","docId":"multimodal-image-queries","unlisted":false}]},{"type":"category","label":"📚 Resources & Support","collapsible":true,"collapsed":true,"className":"sidebar-resources","description":"Additional resources, troubleshooting, and community","items":[{"type":"link","label":"Docker Best Practices","href":"/multimodal-pdf-agent-n8n/docs/local-setup-tips","docId":"local-setup-tips","unlisted":false},{"type":"link","label":"Troubleshooting Guide","href":"/multimodal-pdf-agent-n8n/docs/docker-troubleshooting","docId":"docker-troubleshooting","unlisted":false},{"type":"link","label":"Community Resources","href":"/multimodal-pdf-agent-n8n/docs/community-resources","docId":"community-resources","unlisted":false},{"type":"link","label":"Status Badge Usage Guide","href":"/multimodal-pdf-agent-n8n/docs/status-badge-usage-guide","docId":"status-badge-usage-guide","unlisted":false},{"type":"link","label":"🎉 Workshop Summary","href":"/multimodal-pdf-agent-n8n/docs/summary","docId":"summary","unlisted":false}]}]},"docs":{"agent-patterns":{"id":"agent-patterns","title":"🧠 AI Agent Planning Patterns","description":"Understanding how AI agents reason, plan, and act is crucial for building effective multimodal systems. This section covers the key planning patterns that power modern AI agents.","sidebar":"tutorialSidebar"},"ai-agent-workflow":{"id":"ai-agent-workflow","title":"🤖 AI Agent with Function Calling","description":"Build an intelligent agent using Gemini 2.0 Flash and n8n's powerful workflow capabilities.","sidebar":"tutorialSidebar"},"api-architecture":{"id":"api-architecture","title":"🌐 API Gateway Architecture: The Workshop Proxy System","description":"The workshop API gateway serves as both an educational tool and practical infrastructure. Let's explore why it exists, how it works, and how it compares to production systems.","sidebar":"tutorialSidebar"},"approach-comparison":{"id":"approach-comparison","title":"⚖️ n8n vs Python: Choosing Your Development Approach","description":"Now that you've seen both visual workflows and programmatic approaches, let's dive deep into when and why to choose each method for your multimodal PDF agent projects.","sidebar":"tutorialSidebar"},"architecture-overview":{"id":"architecture-overview","title":"🏗️ Architecture Overview: Multimodal AI Agent Workshop","description":"Understanding the complete system architecture helps you see how all components work together to create intelligent, multimodal AI agents. Let's explore the full stack from your browser to the AI models.","sidebar":"tutorialSidebar"},"codebase":{"id":"codebase","title":"10-intro.mdx","description":""},"community-resources":{"id":"community-resources","title":"🌐 Community Nodes & Extensions","description":"Extend your PDF analysis system with community contributions!","sidebar":"tutorialSidebar"},"complete-multimodal-agent":{"id":"complete-multimodal-agent","title":"🧠 Complete Multimodal PDF Agent","description":"Build a complete multimodal AI agent that can process PDFs, understand both text and images, and answer questions using MongoDB Vector Search and Voyage AI.","sidebar":"tutorialSidebar"},"docker-troubleshooting":{"id":"docker-troubleshooting","title":"🐳 Docker Troubleshooting Guide","description":"Common issues and solutions when running the workshop with Docker.","sidebar":"tutorialSidebar"},"exercise-advanced-tools":{"id":"exercise-advanced-tools","title":"🧪 Exercise: Advanced Tool Calling & Function Integration","description":"<InstructorNotes","sidebar":"tutorialSidebar"},"exercise-memory-context":{"id":"exercise-memory-context","title":"🧪 Exercise: Memory & Context Management","description":"<InstructorNotes","sidebar":"tutorialSidebar"},"exercise-pdf-rag-agent":{"id":"exercise-pdf-rag-agent","title":"🧪 Exercise: Build a PDF RAG Agent","description":"<InstructorNotes","sidebar":"tutorialSidebar"},"github-codespaces":{"id":"github-codespaces","title":"🌐 GitHub Codespaces: Zero-Install Workshop","description":"The fastest way to start this workshop - no local setup required!","sidebar":"tutorialSidebar"},"index":{"id":"index","title":"Workshop Overview","description":"Welcome to the Build a Multimodal PDF Agent with n8n workshop! This interactive, hands-on experience will guide you through creating a production-ready AI system that processes PDFs using cutting-edge technologies.","sidebar":"tutorialSidebar"},"intro":{"id":"intro","title":"📘 Introduction to Multimodal PDF Agents with n8n","description":"|Workshop goals|Build a multimodal AI agent that processes PDFs using n8n, MongoDB Atlas, and Voyage AI|","sidebar":"tutorialSidebar"},"local-setup-tips":{"id":"local-setup-tips","title":"💻 Docker Development Best Practices","description":"Based on real-world experience, here's how to optimize your Docker-based n8n development environment.","sidebar":"tutorialSidebar"},"memory-context-patterns":{"id":"memory-context-patterns","title":"🧠 Memory & Context Patterns","description":"Real AI agents need memory to maintain context across conversations and learn from interactions. This section shows how to implement different memory patterns using MongoDB and n8n workflows.","sidebar":"tutorialSidebar"},"mongodb-atlas-setup":{"id":"mongodb-atlas-setup","title":"🗄️ MongoDB Atlas Setup for Vector Search","description":"This workshop uses MongoDB Atlas for vector search capabilities.","sidebar":"tutorialSidebar"},"mongodb-vector-setup":{"id":"mongodb-vector-setup","title":"🗄️ MongoDB Vector Search Setup","description":"Configure MongoDB for real vector search capabilities in your multimodal PDF agent.","sidebar":"tutorialSidebar"},"multimodal-image-queries":{"id":"multimodal-image-queries","title":"🖼️ Multimodal Image Queries & Visual Understanding","description":"\"Screenshots are all you need\" - this powerful concept from multimodal AI means agents can understand and analyze visual content just as well as text. Let's build workflows that handle image queries and visual document analysis.","sidebar":"tutorialSidebar"},"n8n-first-run":{"id":"n8n-first-run","title":"🚀 n8n First Run Experience","description":"<StepIndicator current= total={6} titles={[","sidebar":"tutorialSidebar"},"pdf-processing-workflow":{"id":"pdf-processing-workflow","title":"📄 PDF Processing Workflow","description":"Build your first n8n workflow to process PDFs into searchable multimodal embeddings.","sidebar":"tutorialSidebar"},"prerequisites":{"id":"prerequisites","title":"🛠️ Prerequisites & Setup","description":"Before we start building, let's get all the tools and accounts you'll need.","sidebar":"tutorialSidebar"},"python-mongodb-approaches":{"id":"python-mongodb-approaches","title":"🐍 Python Approaches to MongoDB Vector Search","description":"While n8n provides an excellent visual workflow approach, developers often need programmatic control. Let's explore different ways to interact with MongoDB vector search and Voyage AI using Python.","sidebar":"tutorialSidebar"},"status-badge-usage-guide":{"id":"status-badge-usage-guide","title":"📊 Status Badge Usage Guide","description":"This guide shows instructors and content creators how to use the specialized LiveStatusBadge components throughout the workshop to provide progressive validation and real-time feedback.","sidebar":"tutorialSidebar"},"summary":{"id":"summary","title":"🎯 Workshop Summary","description":"Congratulations! Following this tutorial, you have successfully:","sidebar":"tutorialSidebar"},"tool-definition-primer":{"id":"tool-definition-primer","title":"🛠️ Tool Definition & Function Calling Primer","description":"Tools are what transform AI models from conversational interfaces into capable agents that can interact with the world. This section covers how to define, configure, and optimize tools for your multimodal PDF agent.","sidebar":"tutorialSidebar"},"upload-interface":{"id":"upload-interface","title":"🌐 Web Upload Interface","description":"A complete web interface for uploading PDFs and chatting with your multimodal agent.","sidebar":"tutorialSidebar"},"vector-search-workflow":{"id":"vector-search-workflow","title":"🔍 Vector Search Workflow","description":"Create a search endpoint that uses MongoDB Atlas Vector Search to find relevant PDF content.","sidebar":"tutorialSidebar"},"voyage-ai-setup":{"id":"voyage-ai-setup","title":"🚢 Voyage AI Embedding Service Setup","description":"Configure access to multimodal embeddings that process both text and images using our workshop serverless endpoint.","sidebar":"tutorialSidebar"}}}}
```

# .docusaurus/docusaurus-plugin-content-docs/default/p/multimodal-pdf-agent-n-8-n-es-docs-0cf.json

```json
{"version":{"pluginId":"default","version":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","isLast":true,"docsSidebars":{"tutorialSidebar":[{"type":"link","label":"🎓 Workshop Overview","href":"/multimodal-pdf-agent-n8n/es/docs/","docId":"index","unlisted":false},{"type":"category","label":"🚀 Getting Started","collapsible":true,"collapsed":false,"className":"sidebar-getting-started","description":"Begin your journey with environment setup and n8n basics","items":[{"type":"link","label":"Workshop Introduction","href":"/multimodal-pdf-agent-n8n/es/docs/intro","docId":"intro","unlisted":false},{"type":"link","label":"🏗️ Architecture Overview","href":"/multimodal-pdf-agent-n8n/es/docs/architecture-overview","docId":"architecture-overview","unlisted":false},{"type":"link","label":"GitHub Codespaces Setup","href":"/multimodal-pdf-agent-n8n/es/docs/github-codespaces","docId":"github-codespaces","unlisted":false},{"type":"link","label":"Prerequisites & Local Setup","href":"/multimodal-pdf-agent-n8n/es/docs/prerequisites","docId":"prerequisites","unlisted":false},{"type":"link","label":"n8n First Run Experience","href":"/multimodal-pdf-agent-n8n/es/docs/n8n-first-run","docId":"n8n-first-run","unlisted":false}]},{"type":"category","label":"⚙️ Setup & Configuration","collapsible":true,"collapsed":false,"className":"sidebar-setup","description":"Configure MongoDB Atlas and Voyage AI for your agent","items":[{"type":"link","label":"🌐 API Gateway Architecture","href":"/multimodal-pdf-agent-n8n/es/docs/api-architecture","docId":"api-architecture","unlisted":false},{"type":"link","label":"MongoDB Atlas Setup","href":"/multimodal-pdf-agent-n8n/es/docs/mongodb-atlas-setup","docId":"mongodb-atlas-setup","unlisted":false},{"type":"link","label":"Voyage AI Configuration","href":"/multimodal-pdf-agent-n8n/es/docs/voyage-ai-setup","docId":"voyage-ai-setup","unlisted":false}]},{"type":"category","label":"🔧 Building Workflows","collapsible":true,"collapsed":false,"className":"sidebar-workflows","description":"Create powerful automation workflows step by step","items":[{"type":"link","label":"PDF Processing Workflow","href":"/multimodal-pdf-agent-n8n/es/docs/pdf-processing-workflow","docId":"pdf-processing-workflow","unlisted":false},{"type":"link","label":"Vector Search Implementation","href":"/multimodal-pdf-agent-n8n/es/docs/vector-search-workflow","docId":"vector-search-workflow","unlisted":false},{"type":"link","label":"AI Agent with Tool Calling","href":"/multimodal-pdf-agent-n8n/es/docs/ai-agent-workflow","docId":"ai-agent-workflow","unlisted":false}]},{"type":"category","label":"🧪 Hands-On Exercises","collapsible":true,"collapsed":false,"className":"sidebar-exercises","description":"Structured exercises to build complete AI agents","items":[{"type":"link","label":"🧪 Exercise: Build a PDF RAG Agent","href":"/multimodal-pdf-agent-n8n/es/docs/exercise-pdf-rag-agent","docId":"exercise-pdf-rag-agent","unlisted":false},{"type":"link","label":"🧪 Exercise: Memory & Context","href":"/multimodal-pdf-agent-n8n/es/docs/exercise-memory-context","docId":"exercise-memory-context","unlisted":false},{"type":"link","label":"🧪 Exercise: Advanced Tool Calling","href":"/multimodal-pdf-agent-n8n/es/docs/exercise-advanced-tools","docId":"exercise-advanced-tools","unlisted":false}]},{"type":"category","label":"🎯 Advanced Topics","collapsible":true,"collapsed":true,"className":"sidebar-advanced","description":"Take your agent to production with advanced features","items":[{"type":"link","label":"Complete Multimodal Agent","href":"/multimodal-pdf-agent-n8n/es/docs/complete-multimodal-agent","docId":"complete-multimodal-agent","unlisted":false},{"type":"link","label":"Production Vector Search","href":"/multimodal-pdf-agent-n8n/es/docs/mongodb-vector-setup","docId":"mongodb-vector-setup","unlisted":false},{"type":"link","label":"Web Upload Interface","href":"/multimodal-pdf-agent-n8n/es/docs/upload-interface","docId":"upload-interface","unlisted":false},{"type":"link","label":"🐍 Python Integration Options","href":"/multimodal-pdf-agent-n8n/es/docs/python-mongodb-approaches","docId":"python-mongodb-approaches","unlisted":false},{"type":"link","label":"⚖️ n8n vs Python Comparison","href":"/multimodal-pdf-agent-n8n/es/docs/approach-comparison","docId":"approach-comparison","unlisted":false},{"type":"link","label":"🧠 AI Agent Planning Patterns","href":"/multimodal-pdf-agent-n8n/es/docs/agent-patterns","docId":"agent-patterns","unlisted":false},{"type":"link","label":"💾 Memory & Context Patterns","href":"/multimodal-pdf-agent-n8n/es/docs/memory-context-patterns","docId":"memory-context-patterns","unlisted":false},{"type":"link","label":"🛠️ Tool Definition & Function Calling","href":"/multimodal-pdf-agent-n8n/es/docs/tool-definition-primer","docId":"tool-definition-primer","unlisted":false},{"type":"link","label":"🖼️ Multimodal Image Queries","href":"/multimodal-pdf-agent-n8n/es/docs/multimodal-image-queries","docId":"multimodal-image-queries","unlisted":false}]},{"type":"category","label":"📚 Resources & Support","collapsible":true,"collapsed":true,"className":"sidebar-resources","description":"Additional resources, troubleshooting, and community","items":[{"type":"link","label":"Docker Best Practices","href":"/multimodal-pdf-agent-n8n/es/docs/local-setup-tips","docId":"local-setup-tips","unlisted":false},{"type":"link","label":"Troubleshooting Guide","href":"/multimodal-pdf-agent-n8n/es/docs/docker-troubleshooting","docId":"docker-troubleshooting","unlisted":false},{"type":"link","label":"Community Resources","href":"/multimodal-pdf-agent-n8n/es/docs/community-resources","docId":"community-resources","unlisted":false},{"type":"link","label":"Status Badge Usage Guide","href":"/multimodal-pdf-agent-n8n/es/docs/status-badge-usage-guide","docId":"status-badge-usage-guide","unlisted":false},{"type":"link","label":"🎉 Workshop Summary","href":"/multimodal-pdf-agent-n8n/es/docs/summary","docId":"summary","unlisted":false}]}]},"docs":{"agent-patterns":{"id":"agent-patterns","title":"🧠 AI Agent Planning Patterns","description":"Understanding how AI agents reason, plan, and act is crucial for building effective multimodal systems. This section covers the key planning patterns that power modern AI agents.","sidebar":"tutorialSidebar"},"ai-agent-workflow":{"id":"ai-agent-workflow","title":"🤖 AI Agent with Function Calling","description":"Build an intelligent agent using Gemini 2.0 Flash and n8n's powerful workflow capabilities.","sidebar":"tutorialSidebar"},"api-architecture":{"id":"api-architecture","title":"🌐 API Gateway Architecture: The Workshop Proxy System","description":"The workshop API gateway serves as both an educational tool and practical infrastructure. Let's explore why it exists, how it works, and how it compares to production systems.","sidebar":"tutorialSidebar"},"approach-comparison":{"id":"approach-comparison","title":"⚖️ n8n vs Python: Choosing Your Development Approach","description":"Now that you've seen both visual workflows and programmatic approaches, let's dive deep into when and why to choose each method for your multimodal PDF agent projects.","sidebar":"tutorialSidebar"},"architecture-overview":{"id":"architecture-overview","title":"🏗️ Architecture Overview: Multimodal AI Agent Workshop","description":"Understanding the complete system architecture helps you see how all components work together to create intelligent, multimodal AI agents. Let's explore the full stack from your browser to the AI models.","sidebar":"tutorialSidebar"},"codebase":{"id":"codebase","title":"10-intro.mdx","description":""},"community-resources":{"id":"community-resources","title":"🌐 Community Nodes & Extensions","description":"Extend your PDF analysis system with community contributions!","sidebar":"tutorialSidebar"},"complete-multimodal-agent":{"id":"complete-multimodal-agent","title":"🧠 Complete Multimodal PDF Agent","description":"Build a complete multimodal AI agent that can process PDFs, understand both text and images, and answer questions using MongoDB Vector Search and Voyage AI.","sidebar":"tutorialSidebar"},"docker-troubleshooting":{"id":"docker-troubleshooting","title":"🐳 Docker Troubleshooting Guide","description":"Common issues and solutions when running the workshop with Docker.","sidebar":"tutorialSidebar"},"exercise-advanced-tools":{"id":"exercise-advanced-tools","title":"🧪 Exercise: Advanced Tool Calling & Function Integration","description":"<InstructorNotes","sidebar":"tutorialSidebar"},"exercise-memory-context":{"id":"exercise-memory-context","title":"🧪 Exercise: Memory & Context Management","description":"<InstructorNotes","sidebar":"tutorialSidebar"},"exercise-pdf-rag-agent":{"id":"exercise-pdf-rag-agent","title":"🧪 Exercise: Build a PDF RAG Agent","description":"<InstructorNotes","sidebar":"tutorialSidebar"},"github-codespaces":{"id":"github-codespaces","title":"🌐 GitHub Codespaces: Zero-Install Workshop","description":"The fastest way to start this workshop - no local setup required!","sidebar":"tutorialSidebar"},"index":{"id":"index","title":"Workshop Overview","description":"Welcome to the Build a Multimodal PDF Agent with n8n workshop! This interactive, hands-on experience will guide you through creating a production-ready AI system that processes PDFs using cutting-edge technologies.","sidebar":"tutorialSidebar"},"intro":{"id":"intro","title":"📘 Introduction to Multimodal PDF Agents with n8n","description":"|Workshop goals|Build a multimodal AI agent that processes PDFs using n8n, MongoDB Atlas, and Voyage AI|","sidebar":"tutorialSidebar"},"local-setup-tips":{"id":"local-setup-tips","title":"💻 Docker Development Best Practices","description":"Based on real-world experience, here's how to optimize your Docker-based n8n development environment.","sidebar":"tutorialSidebar"},"memory-context-patterns":{"id":"memory-context-patterns","title":"🧠 Memory & Context Patterns","description":"Real AI agents need memory to maintain context across conversations and learn from interactions. This section shows how to implement different memory patterns using MongoDB and n8n workflows.","sidebar":"tutorialSidebar"},"mongodb-atlas-setup":{"id":"mongodb-atlas-setup","title":"🗄️ MongoDB Atlas Setup for Vector Search","description":"This workshop uses MongoDB Atlas for vector search capabilities.","sidebar":"tutorialSidebar"},"mongodb-vector-setup":{"id":"mongodb-vector-setup","title":"🗄️ MongoDB Vector Search Setup","description":"Configure MongoDB for real vector search capabilities in your multimodal PDF agent.","sidebar":"tutorialSidebar"},"multimodal-image-queries":{"id":"multimodal-image-queries","title":"🖼️ Multimodal Image Queries & Visual Understanding","description":"\"Screenshots are all you need\" - this powerful concept from multimodal AI means agents can understand and analyze visual content just as well as text. Let's build workflows that handle image queries and visual document analysis.","sidebar":"tutorialSidebar"},"n8n-first-run":{"id":"n8n-first-run","title":"🚀 n8n First Run Experience","description":"<StepIndicator current= total={6} titles={[","sidebar":"tutorialSidebar"},"pdf-processing-workflow":{"id":"pdf-processing-workflow","title":"📄 PDF Processing Workflow","description":"Build your first n8n workflow to process PDFs into searchable multimodal embeddings.","sidebar":"tutorialSidebar"},"prerequisites":{"id":"prerequisites","title":"🛠️ Prerequisites & Setup","description":"Before we start building, let's get all the tools and accounts you'll need.","sidebar":"tutorialSidebar"},"python-mongodb-approaches":{"id":"python-mongodb-approaches","title":"🐍 Python Approaches to MongoDB Vector Search","description":"While n8n provides an excellent visual workflow approach, developers often need programmatic control. Let's explore different ways to interact with MongoDB vector search and Voyage AI using Python.","sidebar":"tutorialSidebar"},"status-badge-usage-guide":{"id":"status-badge-usage-guide","title":"📊 Status Badge Usage Guide","description":"This guide shows instructors and content creators how to use the specialized LiveStatusBadge components throughout the workshop to provide progressive validation and real-time feedback.","sidebar":"tutorialSidebar"},"summary":{"id":"summary","title":"🎯 Workshop Summary","description":"Congratulations! Following this tutorial, you have successfully:","sidebar":"tutorialSidebar"},"tool-definition-primer":{"id":"tool-definition-primer","title":"🛠️ Tool Definition & Function Calling Primer","description":"Tools are what transform AI models from conversational interfaces into capable agents that can interact with the world. This section covers how to define, configure, and optimize tools for your multimodal PDF agent.","sidebar":"tutorialSidebar"},"upload-interface":{"id":"upload-interface","title":"🌐 Web Upload Interface","description":"A complete web interface for uploading PDFs and chatting with your multimodal agent.","sidebar":"tutorialSidebar"},"vector-search-workflow":{"id":"vector-search-workflow","title":"🔍 Vector Search Workflow","description":"Create a search endpoint that uses MongoDB Atlas Vector Search to find relevant PDF content.","sidebar":"tutorialSidebar"},"voyage-ai-setup":{"id":"voyage-ai-setup","title":"🚢 Voyage AI Embedding Service Setup","description":"Configure access to multimodal embeddings that process both text and images using our workshop serverless endpoint.","sidebar":"tutorialSidebar"}}}}
```

# .docusaurus/docusaurus-plugin-content-docs/default/site-docs-00-architecture-overview-mdx-0f8.json

```json
{
  "id": "architecture-overview",
  "title": "🏗️ Architecture Overview: Multimodal AI Agent Workshop",
  "description": "Understanding the complete system architecture helps you see how all components work together to create intelligent, multimodal AI agents. Let's explore the full stack from your browser to the AI models.",
  "source": "@site/docs/00-architecture-overview.mdx",
  "sourceDirName": ".",
  "slug": "/architecture-overview",
  "permalink": "/multimodal-pdf-agent-n8n/docs/architecture-overview",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/00-architecture-overview.mdx",
  "tags": [],
  "version": "current",
  "sidebarPosition": 0,
  "frontMatter": {
    "sidebar_position": 0
  }
}
```

# .docusaurus/docusaurus-plugin-content-docs/default/site-docs-10-intro-mdx-317.json

```json
{
  "id": "intro",
  "title": "📘 Introduction to Multimodal PDF Agents with n8n",
  "description": "|Workshop goals|Build a multimodal AI agent that processes PDFs using n8n, MongoDB Atlas, and Voyage AI|",
  "source": "@site/docs/10-intro.mdx",
  "sourceDirName": ".",
  "slug": "/intro",
  "permalink": "/multimodal-pdf-agent-n8n/docs/intro",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/10-intro.mdx",
  "tags": [],
  "version": "current",
  "sidebarPosition": 10,
  "frontMatter": {
    "sidebar_position": 10
  },
  "sidebar": "tutorialSidebar",
  "previous": {
    "title": "🎓 Workshop Overview",
    "permalink": "/multimodal-pdf-agent-n8n/docs/"
  },
  "next": {
    "title": "🏗️ Architecture Overview",
    "permalink": "/multimodal-pdf-agent-n8n/docs/architecture-overview"
  }
}
```

# .docusaurus/docusaurus-plugin-content-docs/default/site-docs-15-github-codespaces-mdx-eb7.json

```json
{
  "id": "github-codespaces",
  "title": "🌐 GitHub Codespaces: Zero-Install Workshop",
  "description": "The fastest way to start this workshop - no local setup required!",
  "source": "@site/docs/15-github-codespaces.mdx",
  "sourceDirName": ".",
  "slug": "/github-codespaces",
  "permalink": "/multimodal-pdf-agent-n8n/docs/github-codespaces",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/15-github-codespaces.mdx",
  "tags": [],
  "version": "current",
  "sidebarPosition": 15,
  "frontMatter": {
    "sidebar_position": 15
  },
  "sidebar": "tutorialSidebar",
  "previous": {
    "title": "🏗️ Architecture Overview",
    "permalink": "/multimodal-pdf-agent-n8n/docs/architecture-overview"
  },
  "next": {
    "title": "Prerequisites & Local Setup",
    "permalink": "/multimodal-pdf-agent-n8n/docs/prerequisites"
  }
}
```

# .docusaurus/docusaurus-plugin-content-docs/default/site-docs-20-api-architecture-mdx-bc4.json

```json
{
  "id": "api-architecture",
  "title": "🌐 API Gateway Architecture: The Workshop Proxy System",
  "description": "The workshop API gateway serves as both an educational tool and practical infrastructure. Let's explore why it exists, how it works, and how it compares to production systems.",
  "source": "@site/docs/20-api-architecture.mdx",
  "sourceDirName": ".",
  "slug": "/api-architecture",
  "permalink": "/multimodal-pdf-agent-n8n/docs/api-architecture",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/20-api-architecture.mdx",
  "tags": [],
  "version": "current",
  "sidebarPosition": 20,
  "frontMatter": {
    "sidebar_position": 20
  }
}
```

# .docusaurus/docusaurus-plugin-content-docs/default/site-docs-20-prerequisites-mdx-b49.json

```json
{
  "id": "prerequisites",
  "title": "🛠️ Prerequisites & Setup",
  "description": "Before we start building, let's get all the tools and accounts you'll need.",
  "source": "@site/docs/20-prerequisites.mdx",
  "sourceDirName": ".",
  "slug": "/prerequisites",
  "permalink": "/multimodal-pdf-agent-n8n/docs/prerequisites",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/20-prerequisites.mdx",
  "tags": [],
  "version": "current",
  "sidebarPosition": 20,
  "frontMatter": {
    "sidebar_position": 20
  },
  "sidebar": "tutorialSidebar",
  "previous": {
    "title": "GitHub Codespaces Setup",
    "permalink": "/multimodal-pdf-agent-n8n/docs/github-codespaces"
  },
  "next": {
    "title": "n8n First Run Experience",
    "permalink": "/multimodal-pdf-agent-n8n/docs/n8n-first-run"
  }
}
```

# .docusaurus/docusaurus-plugin-content-docs/default/site-docs-25-n-8-n-first-run-mdx-658.json

```json
{
  "id": "n8n-first-run",
  "title": "🚀 n8n First Run Experience",
  "description": "<StepIndicator current= total={6} titles={[",
  "source": "@site/docs/25-n8n-first-run.mdx",
  "sourceDirName": ".",
  "slug": "/n8n-first-run",
  "permalink": "/multimodal-pdf-agent-n8n/docs/n8n-first-run",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/25-n8n-first-run.mdx",
  "tags": [],
  "version": "current",
  "sidebarPosition": 25,
  "frontMatter": {
    "sidebar_position": 25
  },
  "sidebar": "tutorialSidebar",
  "previous": {
    "title": "Prerequisites & Local Setup",
    "permalink": "/multimodal-pdf-agent-n8n/docs/prerequisites"
  },
  "next": {
    "title": "🌐 API Gateway Architecture",
    "permalink": "/multimodal-pdf-agent-n8n/docs/api-architecture"
  }
}
```

# .docusaurus/docusaurus-plugin-content-docs/default/site-docs-30-exercise-pdf-rag-agent-mdx-179.json

```json
{
  "id": "exercise-pdf-rag-agent",
  "title": "🧪 Exercise: Build a PDF RAG Agent",
  "description": "<InstructorNotes",
  "source": "@site/docs/30-exercise-pdf-rag-agent.mdx",
  "sourceDirName": ".",
  "slug": "/exercise-pdf-rag-agent",
  "permalink": "/multimodal-pdf-agent-n8n/docs/exercise-pdf-rag-agent",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/30-exercise-pdf-rag-agent.mdx",
  "tags": [],
  "version": "current",
  "sidebarPosition": 30,
  "frontMatter": {
    "sidebar_position": 30
  }
}
```

# .docusaurus/docusaurus-plugin-content-docs/default/site-docs-30-mongodb-atlas-setup-mdx-7fe.json

```json
{
  "id": "mongodb-atlas-setup",
  "title": "🗄️ MongoDB Atlas Setup for Vector Search",
  "description": "This workshop uses MongoDB Atlas for vector search capabilities.",
  "source": "@site/docs/30-mongodb-atlas-setup.mdx",
  "sourceDirName": ".",
  "slug": "/mongodb-atlas-setup",
  "permalink": "/multimodal-pdf-agent-n8n/docs/mongodb-atlas-setup",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/30-mongodb-atlas-setup.mdx",
  "tags": [],
  "version": "current",
  "sidebarPosition": 30,
  "frontMatter": {
    "sidebar_position": 30
  },
  "sidebar": "tutorialSidebar",
  "previous": {
    "title": "🌐 API Gateway Architecture",
    "permalink": "/multimodal-pdf-agent-n8n/docs/api-architecture"
  },
  "next": {
    "title": "Voyage AI Configuration",
    "permalink": "/multimodal-pdf-agent-n8n/docs/voyage-ai-setup"
  }
}
```

# .docusaurus/docusaurus-plugin-content-docs/default/site-docs-31-exercise-memory-context-mdx-497.json

```json
{
  "id": "exercise-memory-context",
  "title": "🧪 Exercise: Memory & Context Management",
  "description": "<InstructorNotes",
  "source": "@site/docs/31-exercise-memory-context.mdx",
  "sourceDirName": ".",
  "slug": "/exercise-memory-context",
  "permalink": "/multimodal-pdf-agent-n8n/docs/exercise-memory-context",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/31-exercise-memory-context.mdx",
  "tags": [],
  "version": "current",
  "sidebarPosition": 31,
  "frontMatter": {
    "sidebar_position": 31
  }
}
```

# .docusaurus/docusaurus-plugin-content-docs/default/site-docs-32-exercise-advanced-tools-mdx-a97.json

```json
{
  "id": "exercise-advanced-tools",
  "title": "🧪 Exercise: Advanced Tool Calling & Function Integration",
  "description": "<InstructorNotes",
  "source": "@site/docs/32-exercise-advanced-tools.mdx",
  "sourceDirName": ".",
  "slug": "/exercise-advanced-tools",
  "permalink": "/multimodal-pdf-agent-n8n/docs/exercise-advanced-tools",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/32-exercise-advanced-tools.mdx",
  "tags": [],
  "version": "current",
  "sidebarPosition": 32,
  "frontMatter": {
    "sidebar_position": 32
  }
}
```

# .docusaurus/docusaurus-plugin-content-docs/default/site-docs-35-voyage-ai-setup-mdx-314.json

```json
{
  "id": "voyage-ai-setup",
  "title": "🚢 Voyage AI Embedding Service Setup",
  "description": "Configure access to multimodal embeddings that process both text and images using our workshop serverless endpoint.",
  "source": "@site/docs/35-voyage-ai-setup.mdx",
  "sourceDirName": ".",
  "slug": "/voyage-ai-setup",
  "permalink": "/multimodal-pdf-agent-n8n/docs/voyage-ai-setup",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/35-voyage-ai-setup.mdx",
  "tags": [],
  "version": "current",
  "sidebarPosition": 35,
  "frontMatter": {
    "sidebar_position": 35
  },
  "sidebar": "tutorialSidebar",
  "previous": {
    "title": "MongoDB Atlas Setup",
    "permalink": "/multimodal-pdf-agent-n8n/docs/mongodb-atlas-setup"
  },
  "next": {
    "title": "PDF Processing Workflow",
    "permalink": "/multimodal-pdf-agent-n8n/docs/pdf-processing-workflow"
  }
}
```

# .docusaurus/docusaurus-plugin-content-docs/default/site-docs-40-pdf-processing-workflow-mdx-05e.json

```json
{
  "id": "pdf-processing-workflow",
  "title": "📄 PDF Processing Workflow",
  "description": "Build your first n8n workflow to process PDFs into searchable multimodal embeddings.",
  "source": "@site/docs/40-pdf-processing-workflow.mdx",
  "sourceDirName": ".",
  "slug": "/pdf-processing-workflow",
  "permalink": "/multimodal-pdf-agent-n8n/docs/pdf-processing-workflow",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/40-pdf-processing-workflow.mdx",
  "tags": [],
  "version": "current",
  "sidebarPosition": 40,
  "frontMatter": {
    "sidebar_position": 40
  },
  "sidebar": "tutorialSidebar",
  "previous": {
    "title": "Voyage AI Configuration",
    "permalink": "/multimodal-pdf-agent-n8n/docs/voyage-ai-setup"
  },
  "next": {
    "title": "Vector Search Implementation",
    "permalink": "/multimodal-pdf-agent-n8n/docs/vector-search-workflow"
  }
}
```

# .docusaurus/docusaurus-plugin-content-docs/default/site-docs-45-local-setup-tips-mdx-68d.json

```json
{
  "id": "local-setup-tips",
  "title": "💻 Docker Development Best Practices",
  "description": "Based on real-world experience, here's how to optimize your Docker-based n8n development environment.",
  "source": "@site/docs/45-local-setup-tips.mdx",
  "sourceDirName": ".",
  "slug": "/local-setup-tips",
  "permalink": "/multimodal-pdf-agent-n8n/docs/local-setup-tips",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/45-local-setup-tips.mdx",
  "tags": [],
  "version": "current",
  "sidebarPosition": 45,
  "frontMatter": {
    "sidebar_position": 45
  },
  "sidebar": "tutorialSidebar",
  "previous": {
    "title": "🖼️ Multimodal Image Queries",
    "permalink": "/multimodal-pdf-agent-n8n/docs/multimodal-image-queries"
  },
  "next": {
    "title": "Troubleshooting Guide",
    "permalink": "/multimodal-pdf-agent-n8n/docs/docker-troubleshooting"
  }
}
```

# .docusaurus/docusaurus-plugin-content-docs/default/site-docs-50-vector-search-workflow-mdx-02d.json

```json
{
  "id": "vector-search-workflow",
  "title": "🔍 Vector Search Workflow",
  "description": "Create a search endpoint that uses MongoDB Atlas Vector Search to find relevant PDF content.",
  "source": "@site/docs/50-vector-search-workflow.mdx",
  "sourceDirName": ".",
  "slug": "/vector-search-workflow",
  "permalink": "/multimodal-pdf-agent-n8n/docs/vector-search-workflow",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/50-vector-search-workflow.mdx",
  "tags": [],
  "version": "current",
  "sidebarPosition": 50,
  "frontMatter": {
    "sidebar_position": 50
  },
  "sidebar": "tutorialSidebar",
  "previous": {
    "title": "PDF Processing Workflow",
    "permalink": "/multimodal-pdf-agent-n8n/docs/pdf-processing-workflow"
  },
  "next": {
    "title": "AI Agent with Tool Calling",
    "permalink": "/multimodal-pdf-agent-n8n/docs/ai-agent-workflow"
  }
}
```

# .docusaurus/docusaurus-plugin-content-docs/default/site-docs-60-ai-agent-workflow-mdx-600.json

```json
{
  "id": "ai-agent-workflow",
  "title": "🤖 AI Agent with Function Calling",
  "description": "Build an intelligent agent using Gemini 2.0 Flash and n8n's powerful workflow capabilities.",
  "source": "@site/docs/60-ai-agent-workflow.mdx",
  "sourceDirName": ".",
  "slug": "/ai-agent-workflow",
  "permalink": "/multimodal-pdf-agent-n8n/docs/ai-agent-workflow",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/60-ai-agent-workflow.mdx",
  "tags": [],
  "version": "current",
  "sidebarPosition": 60,
  "frontMatter": {
    "sidebar_position": 60
  },
  "sidebar": "tutorialSidebar",
  "previous": {
    "title": "Vector Search Implementation",
    "permalink": "/multimodal-pdf-agent-n8n/docs/vector-search-workflow"
  },
  "next": {
    "title": "🧪 Exercise: Build a PDF RAG Agent",
    "permalink": "/multimodal-pdf-agent-n8n/docs/exercise-pdf-rag-agent"
  }
}
```

# .docusaurus/docusaurus-plugin-content-docs/default/site-docs-65-agent-patterns-mdx-42d.json

```json
{
  "id": "agent-patterns",
  "title": "🧠 AI Agent Planning Patterns",
  "description": "Understanding how AI agents reason, plan, and act is crucial for building effective multimodal systems. This section covers the key planning patterns that power modern AI agents.",
  "source": "@site/docs/65-agent-patterns.mdx",
  "sourceDirName": ".",
  "slug": "/agent-patterns",
  "permalink": "/multimodal-pdf-agent-n8n/docs/agent-patterns",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/65-agent-patterns.mdx",
  "tags": [],
  "version": "current",
  "sidebarPosition": 65,
  "frontMatter": {
    "sidebar_position": 65
  },
  "sidebar": "tutorialSidebar",
  "previous": {
    "title": "⚖️ n8n vs Python Comparison",
    "permalink": "/multimodal-pdf-agent-n8n/docs/approach-comparison"
  },
  "next": {
    "title": "💾 Memory & Context Patterns",
    "permalink": "/multimodal-pdf-agent-n8n/docs/memory-context-patterns"
  }
}
```

# .docusaurus/docusaurus-plugin-content-docs/default/site-docs-67-memory-context-patterns-mdx-57a.json

```json
{
  "id": "memory-context-patterns",
  "title": "🧠 Memory & Context Patterns",
  "description": "Real AI agents need memory to maintain context across conversations and learn from interactions. This section shows how to implement different memory patterns using MongoDB and n8n workflows.",
  "source": "@site/docs/67-memory-context-patterns.mdx",
  "sourceDirName": ".",
  "slug": "/memory-context-patterns",
  "permalink": "/multimodal-pdf-agent-n8n/docs/memory-context-patterns",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/67-memory-context-patterns.mdx",
  "tags": [],
  "version": "current",
  "sidebarPosition": 67,
  "frontMatter": {
    "sidebar_position": 67
  },
  "sidebar": "tutorialSidebar",
  "previous": {
    "title": "🧠 AI Agent Planning Patterns",
    "permalink": "/multimodal-pdf-agent-n8n/docs/agent-patterns"
  },
  "next": {
    "title": "🛠️ Tool Definition & Function Calling",
    "permalink": "/multimodal-pdf-agent-n8n/docs/tool-definition-primer"
  }
}
```

# .docusaurus/docusaurus-plugin-content-docs/default/site-docs-68-tool-definition-primer-mdx-c74.json

```json
{
  "id": "tool-definition-primer",
  "title": "🛠️ Tool Definition & Function Calling Primer",
  "description": "Tools are what transform AI models from conversational interfaces into capable agents that can interact with the world. This section covers how to define, configure, and optimize tools for your multimodal PDF agent.",
  "source": "@site/docs/68-tool-definition-primer.mdx",
  "sourceDirName": ".",
  "slug": "/tool-definition-primer",
  "permalink": "/multimodal-pdf-agent-n8n/docs/tool-definition-primer",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/68-tool-definition-primer.mdx",
  "tags": [],
  "version": "current",
  "sidebarPosition": 68,
  "frontMatter": {
    "sidebar_position": 68
  },
  "sidebar": "tutorialSidebar",
  "previous": {
    "title": "💾 Memory & Context Patterns",
    "permalink": "/multimodal-pdf-agent-n8n/docs/memory-context-patterns"
  },
  "next": {
    "title": "🖼️ Multimodal Image Queries",
    "permalink": "/multimodal-pdf-agent-n8n/docs/multimodal-image-queries"
  }
}
```

# .docusaurus/docusaurus-plugin-content-docs/default/site-docs-69-multimodal-image-queries-mdx-512.json

```json
{
  "id": "multimodal-image-queries",
  "title": "🖼️ Multimodal Image Queries & Visual Understanding",
  "description": "\"Screenshots are all you need\" - this powerful concept from multimodal AI means agents can understand and analyze visual content just as well as text. Let's build workflows that handle image queries and visual document analysis.",
  "source": "@site/docs/69-multimodal-image-queries.mdx",
  "sourceDirName": ".",
  "slug": "/multimodal-image-queries",
  "permalink": "/multimodal-pdf-agent-n8n/docs/multimodal-image-queries",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/69-multimodal-image-queries.mdx",
  "tags": [],
  "version": "current",
  "sidebarPosition": 69,
  "frontMatter": {
    "sidebar_position": 69
  },
  "sidebar": "tutorialSidebar",
  "previous": {
    "title": "🛠️ Tool Definition & Function Calling",
    "permalink": "/multimodal-pdf-agent-n8n/docs/tool-definition-primer"
  },
  "next": {
    "title": "Docker Best Practices",
    "permalink": "/multimodal-pdf-agent-n8n/docs/local-setup-tips"
  }
}
```

# .docusaurus/docusaurus-plugin-content-docs/default/site-docs-70-complete-multimodal-agent-mdx-802.json

```json
{
  "id": "complete-multimodal-agent",
  "title": "🧠 Complete Multimodal PDF Agent",
  "description": "Build a complete multimodal AI agent that can process PDFs, understand both text and images, and answer questions using MongoDB Vector Search and Voyage AI.",
  "source": "@site/docs/70-complete-multimodal-agent.mdx",
  "sourceDirName": ".",
  "slug": "/complete-multimodal-agent",
  "permalink": "/multimodal-pdf-agent-n8n/docs/complete-multimodal-agent",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/70-complete-multimodal-agent.mdx",
  "tags": [],
  "version": "current",
  "sidebarPosition": 70,
  "frontMatter": {
    "sidebar_position": 70
  },
  "sidebar": "tutorialSidebar",
  "previous": {
    "title": "🧪 Exercise: Advanced Tool Calling",
    "permalink": "/multimodal-pdf-agent-n8n/docs/exercise-advanced-tools"
  },
  "next": {
    "title": "Production Vector Search",
    "permalink": "/multimodal-pdf-agent-n8n/docs/mongodb-vector-setup"
  }
}
```

# .docusaurus/docusaurus-plugin-content-docs/default/site-docs-75-mongodb-vector-setup-mdx-e72.json

```json
{
  "id": "mongodb-vector-setup",
  "title": "🗄️ MongoDB Vector Search Setup",
  "description": "Configure MongoDB for real vector search capabilities in your multimodal PDF agent.",
  "source": "@site/docs/75-mongodb-vector-setup.mdx",
  "sourceDirName": ".",
  "slug": "/mongodb-vector-setup",
  "permalink": "/multimodal-pdf-agent-n8n/docs/mongodb-vector-setup",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/75-mongodb-vector-setup.mdx",
  "tags": [],
  "version": "current",
  "sidebarPosition": 75,
  "frontMatter": {
    "sidebar_position": 75
  },
  "sidebar": "tutorialSidebar",
  "previous": {
    "title": "Complete Multimodal Agent",
    "permalink": "/multimodal-pdf-agent-n8n/docs/complete-multimodal-agent"
  },
  "next": {
    "title": "Web Upload Interface",
    "permalink": "/multimodal-pdf-agent-n8n/docs/upload-interface"
  }
}
```

# .docusaurus/docusaurus-plugin-content-docs/default/site-docs-80-upload-interface-mdx-442.json

```json
{
  "id": "upload-interface",
  "title": "🌐 Web Upload Interface",
  "description": "A complete web interface for uploading PDFs and chatting with your multimodal agent.",
  "source": "@site/docs/80-upload-interface.mdx",
  "sourceDirName": ".",
  "slug": "/upload-interface",
  "permalink": "/multimodal-pdf-agent-n8n/docs/upload-interface",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/80-upload-interface.mdx",
  "tags": [],
  "version": "current",
  "sidebarPosition": 80,
  "frontMatter": {
    "sidebar_position": 80
  },
  "sidebar": "tutorialSidebar",
  "previous": {
    "title": "Production Vector Search",
    "permalink": "/multimodal-pdf-agent-n8n/docs/mongodb-vector-setup"
  },
  "next": {
    "title": "🐍 Python Integration Options",
    "permalink": "/multimodal-pdf-agent-n8n/docs/python-mongodb-approaches"
  }
}
```

# .docusaurus/docusaurus-plugin-content-docs/default/site-docs-85-python-mongodb-approaches-mdx-03a.json

```json
{
  "id": "python-mongodb-approaches",
  "title": "🐍 Python Approaches to MongoDB Vector Search",
  "description": "While n8n provides an excellent visual workflow approach, developers often need programmatic control. Let's explore different ways to interact with MongoDB vector search and Voyage AI using Python.",
  "source": "@site/docs/85-python-mongodb-approaches.mdx",
  "sourceDirName": ".",
  "slug": "/python-mongodb-approaches",
  "permalink": "/multimodal-pdf-agent-n8n/docs/python-mongodb-approaches",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/85-python-mongodb-approaches.mdx",
  "tags": [],
  "version": "current",
  "sidebarPosition": 85,
  "frontMatter": {
    "sidebar_position": 85
  },
  "sidebar": "tutorialSidebar",
  "previous": {
    "title": "Web Upload Interface",
    "permalink": "/multimodal-pdf-agent-n8n/docs/upload-interface"
  },
  "next": {
    "title": "⚖️ n8n vs Python Comparison",
    "permalink": "/multimodal-pdf-agent-n8n/docs/approach-comparison"
  }
}
```

# .docusaurus/docusaurus-plugin-content-docs/default/site-docs-90-approach-comparison-mdx-abe.json

```json
{
  "id": "approach-comparison",
  "title": "⚖️ n8n vs Python: Choosing Your Development Approach",
  "description": "Now that you've seen both visual workflows and programmatic approaches, let's dive deep into when and why to choose each method for your multimodal PDF agent projects.",
  "source": "@site/docs/90-approach-comparison.mdx",
  "sourceDirName": ".",
  "slug": "/approach-comparison",
  "permalink": "/multimodal-pdf-agent-n8n/docs/approach-comparison",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/90-approach-comparison.mdx",
  "tags": [],
  "version": "current",
  "sidebarPosition": 90,
  "frontMatter": {
    "sidebar_position": 90
  },
  "sidebar": "tutorialSidebar",
  "previous": {
    "title": "🐍 Python Integration Options",
    "permalink": "/multimodal-pdf-agent-n8n/docs/python-mongodb-approaches"
  },
  "next": {
    "title": "🧠 AI Agent Planning Patterns",
    "permalink": "/multimodal-pdf-agent-n8n/docs/agent-patterns"
  }
}
```

# .docusaurus/docusaurus-plugin-content-docs/default/site-docs-95-community-resources-mdx-b5e.json

```json
{
  "id": "community-resources",
  "title": "🌐 Community Nodes & Extensions",
  "description": "Extend your PDF analysis system with community contributions!",
  "source": "@site/docs/95-community-resources.mdx",
  "sourceDirName": ".",
  "slug": "/community-resources",
  "permalink": "/multimodal-pdf-agent-n8n/docs/community-resources",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/95-community-resources.mdx",
  "tags": [],
  "version": "current",
  "sidebarPosition": 95,
  "frontMatter": {
    "sidebar_position": 95
  },
  "sidebar": "tutorialSidebar",
  "previous": {
    "title": "Troubleshooting Guide",
    "permalink": "/multimodal-pdf-agent-n8n/docs/docker-troubleshooting"
  },
  "next": {
    "title": "Status Badge Usage Guide",
    "permalink": "/multimodal-pdf-agent-n8n/docs/status-badge-usage-guide"
  }
}
```

# .docusaurus/docusaurus-plugin-content-docs/default/site-docs-95-docker-troubleshooting-mdx-827.json

```json
{
  "id": "docker-troubleshooting",
  "title": "🐳 Docker Troubleshooting Guide",
  "description": "Common issues and solutions when running the workshop with Docker.",
  "source": "@site/docs/95-docker-troubleshooting.mdx",
  "sourceDirName": ".",
  "slug": "/docker-troubleshooting",
  "permalink": "/multimodal-pdf-agent-n8n/docs/docker-troubleshooting",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/95-docker-troubleshooting.mdx",
  "tags": [],
  "version": "current",
  "sidebarPosition": 95,
  "frontMatter": {
    "sidebar_position": 95
  },
  "sidebar": "tutorialSidebar",
  "previous": {
    "title": "Docker Best Practices",
    "permalink": "/multimodal-pdf-agent-n8n/docs/local-setup-tips"
  },
  "next": {
    "title": "Community Resources",
    "permalink": "/multimodal-pdf-agent-n8n/docs/community-resources"
  }
}
```

# .docusaurus/docusaurus-plugin-content-docs/default/site-docs-api-architecture-mdx-137.json

```json
{
  "id": "api-architecture",
  "title": "🌐 API Gateway Architecture: The Workshop Proxy System",
  "description": "The workshop API gateway serves as both an educational tool and practical infrastructure. Let's explore why it exists, how it works, and how it compares to production systems.",
  "source": "@site/docs/api-architecture.mdx",
  "sourceDirName": ".",
  "slug": "/api-architecture",
  "permalink": "/multimodal-pdf-agent-n8n/docs/api-architecture",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/api-architecture.mdx",
  "tags": [],
  "version": "current",
  "sidebarPosition": 20,
  "frontMatter": {
    "sidebar_position": 20
  },
  "sidebar": "tutorialSidebar",
  "previous": {
    "title": "n8n First Run Experience",
    "permalink": "/multimodal-pdf-agent-n8n/docs/n8n-first-run"
  },
  "next": {
    "title": "MongoDB Atlas Setup",
    "permalink": "/multimodal-pdf-agent-n8n/docs/mongodb-atlas-setup"
  }
}
```

# .docusaurus/docusaurus-plugin-content-docs/default/site-docs-architecture-overview-mdx-ad9.json

```json
{
  "id": "architecture-overview",
  "title": "🏗️ Architecture Overview: Multimodal AI Agent Workshop",
  "description": "Understanding the complete system architecture helps you see how all components work together to create intelligent, multimodal AI agents. Let's explore the full stack from your browser to the AI models.",
  "source": "@site/docs/architecture-overview.mdx",
  "sourceDirName": ".",
  "slug": "/architecture-overview",
  "permalink": "/multimodal-pdf-agent-n8n/docs/architecture-overview",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/architecture-overview.mdx",
  "tags": [],
  "version": "current",
  "sidebarPosition": 0,
  "frontMatter": {
    "sidebar_position": 0
  },
  "sidebar": "tutorialSidebar",
  "previous": {
    "title": "Workshop Introduction",
    "permalink": "/multimodal-pdf-agent-n8n/docs/intro"
  },
  "next": {
    "title": "GitHub Codespaces Setup",
    "permalink": "/multimodal-pdf-agent-n8n/docs/github-codespaces"
  }
}
```

# .docusaurus/docusaurus-plugin-content-docs/default/site-docs-codebase-md-282.json

```json
{
  "id": "codebase",
  "title": "10-intro.mdx",
  "description": "",
  "source": "@site/docs/codebase.md",
  "sourceDirName": ".",
  "slug": "/codebase",
  "permalink": "/multimodal-pdf-agent-n8n/docs/codebase",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/codebase.md",
  "tags": [],
  "version": "current",
  "frontMatter": {}
}
```

# .docusaurus/docusaurus-plugin-content-docs/default/site-docs-exercise-advanced-tools-mdx-561.json

```json
{
  "id": "exercise-advanced-tools",
  "title": "🧪 Exercise: Advanced Tool Calling & Function Integration",
  "description": "<InstructorNotes",
  "source": "@site/docs/exercise-advanced-tools.mdx",
  "sourceDirName": ".",
  "slug": "/exercise-advanced-tools",
  "permalink": "/multimodal-pdf-agent-n8n/docs/exercise-advanced-tools",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/exercise-advanced-tools.mdx",
  "tags": [],
  "version": "current",
  "sidebarPosition": 32,
  "frontMatter": {
    "sidebar_position": 32
  },
  "sidebar": "tutorialSidebar",
  "previous": {
    "title": "🧪 Exercise: Memory & Context",
    "permalink": "/multimodal-pdf-agent-n8n/docs/exercise-memory-context"
  },
  "next": {
    "title": "Complete Multimodal Agent",
    "permalink": "/multimodal-pdf-agent-n8n/docs/complete-multimodal-agent"
  }
}
```

# .docusaurus/docusaurus-plugin-content-docs/default/site-docs-exercise-memory-context-mdx-d23.json

```json
{
  "id": "exercise-memory-context",
  "title": "🧪 Exercise: Memory & Context Management",
  "description": "<InstructorNotes",
  "source": "@site/docs/exercise-memory-context.mdx",
  "sourceDirName": ".",
  "slug": "/exercise-memory-context",
  "permalink": "/multimodal-pdf-agent-n8n/docs/exercise-memory-context",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/exercise-memory-context.mdx",
  "tags": [],
  "version": "current",
  "sidebarPosition": 31,
  "frontMatter": {
    "sidebar_position": 31
  },
  "sidebar": "tutorialSidebar",
  "previous": {
    "title": "🧪 Exercise: Build a PDF RAG Agent",
    "permalink": "/multimodal-pdf-agent-n8n/docs/exercise-pdf-rag-agent"
  },
  "next": {
    "title": "🧪 Exercise: Advanced Tool Calling",
    "permalink": "/multimodal-pdf-agent-n8n/docs/exercise-advanced-tools"
  }
}
```

# .docusaurus/docusaurus-plugin-content-docs/default/site-docs-exercise-pdf-rag-agent-mdx-de6.json

```json
{
  "id": "exercise-pdf-rag-agent",
  "title": "🧪 Exercise: Build a PDF RAG Agent",
  "description": "<InstructorNotes",
  "source": "@site/docs/exercise-pdf-rag-agent.mdx",
  "sourceDirName": ".",
  "slug": "/exercise-pdf-rag-agent",
  "permalink": "/multimodal-pdf-agent-n8n/docs/exercise-pdf-rag-agent",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/exercise-pdf-rag-agent.mdx",
  "tags": [],
  "version": "current",
  "sidebarPosition": 30,
  "frontMatter": {
    "sidebar_position": 30
  },
  "sidebar": "tutorialSidebar",
  "previous": {
    "title": "AI Agent with Tool Calling",
    "permalink": "/multimodal-pdf-agent-n8n/docs/ai-agent-workflow"
  },
  "next": {
    "title": "🧪 Exercise: Memory & Context",
    "permalink": "/multimodal-pdf-agent-n8n/docs/exercise-memory-context"
  }
}
```

# .docusaurus/docusaurus-plugin-content-docs/default/site-docs-index-mdx-4ed.json

```json
{
  "id": "index",
  "title": "Workshop Overview",
  "description": "Welcome to the Build a Multimodal PDF Agent with n8n workshop! This interactive, hands-on experience will guide you through creating a production-ready AI system that processes PDFs using cutting-edge technologies.",
  "source": "@site/docs/index.mdx",
  "sourceDirName": ".",
  "slug": "/",
  "permalink": "/multimodal-pdf-agent-n8n/docs/",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/index.mdx",
  "tags": [],
  "version": "current",
  "sidebarPosition": 1,
  "frontMatter": {
    "sidebar_position": 1,
    "slug": "/",
    "title": "Workshop Overview"
  },
  "sidebar": "tutorialSidebar",
  "next": {
    "title": "Workshop Introduction",
    "permalink": "/multimodal-pdf-agent-n8n/docs/intro"
  }
}
```

# .docusaurus/docusaurus-plugin-content-docs/default/site-docs-status-badge-usage-guide-mdx-73d.json

```json
{
  "id": "status-badge-usage-guide",
  "title": "📊 Status Badge Usage Guide",
  "description": "This guide shows instructors and content creators how to use the specialized LiveStatusBadge components throughout the workshop to provide progressive validation and real-time feedback.",
  "source": "@site/docs/status-badge-usage-guide.mdx",
  "sourceDirName": ".",
  "slug": "/status-badge-usage-guide",
  "permalink": "/multimodal-pdf-agent-n8n/docs/status-badge-usage-guide",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/status-badge-usage-guide.mdx",
  "tags": [],
  "version": "current",
  "sidebarPosition": 100,
  "frontMatter": {
    "sidebar_position": 100
  },
  "sidebar": "tutorialSidebar",
  "previous": {
    "title": "Community Resources",
    "permalink": "/multimodal-pdf-agent-n8n/docs/community-resources"
  },
  "next": {
    "title": "🎉 Workshop Summary",
    "permalink": "/multimodal-pdf-agent-n8n/docs/summary"
  }
}
```

# .docusaurus/docusaurus-plugin-content-docs/default/site-docs-summary-mdx-3aa.json

```json
{
  "id": "summary",
  "title": "🎯 Workshop Summary",
  "description": "Congratulations! Following this tutorial, you have successfully:",
  "source": "@site/docs/summary.mdx",
  "sourceDirName": ".",
  "slug": "/summary",
  "permalink": "/multimodal-pdf-agent-n8n/docs/summary",
  "draft": false,
  "unlisted": false,
  "editUrl": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/summary.mdx",
  "tags": [],
  "version": "current",
  "sidebarPosition": 100,
  "frontMatter": {
    "sidebar_position": 100
  },
  "sidebar": "tutorialSidebar",
  "previous": {
    "title": "Status Badge Usage Guide",
    "permalink": "/multimodal-pdf-agent-n8n/docs/status-badge-usage-guide"
  }
}
```

# .docusaurus/docusaurus-plugin-content-pages/default/__plugin.json

```json
{
  "name": "docusaurus-plugin-content-pages",
  "id": "default"
}
```

# .docusaurus/docusaurus-plugin-css-cascade-layers/default/__plugin.json

```json
{
  "name": "docusaurus-plugin-css-cascade-layers",
  "id": "default"
}
```

# .docusaurus/docusaurus-plugin-css-cascade-layers/default/layers.css

```css
@layer docusaurus.infima, docusaurus.theme-common, docusaurus.theme-classic, docusaurus.core, docusaurus.plugin-debug, docusaurus.theme-mermaid, docusaurus.theme-live-codeblock, docusaurus.theme-search-algolia.docsearch, docusaurus.theme-search-algolia;
```

# .docusaurus/docusaurus-plugin-debug/default/__plugin.json

```json
{
  "name": "docusaurus-plugin-debug",
  "id": "default"
}
```

# .docusaurus/docusaurus-plugin-debug/default/p/multimodal-pdf-agent-n-8-n-docusaurus-debug-content-b60.json

```json
{"allContent":{"docusaurus-plugin-css-cascade-layers":{},"docusaurus-plugin-content-docs":{"default":{"loadedVersions":[{"versionName":"current","label":"Next","banner":null,"badge":false,"noIndex":false,"className":"docs-version-current","path":"/multimodal-pdf-agent-n8n/docs","tagsPath":"/multimodal-pdf-agent-n8n/docs/tags","editUrl":"https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs","editUrlLocalized":"https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/i18n/en/docusaurus-plugin-content-docs/current","isLast":true,"routePriority":-1,"sidebarFilePath":"/Users/michael.lynn/code/ai4/workshop-docs/sidebars.js","contentPath":"/Users/michael.lynn/code/ai4/workshop-docs/docs","contentPathLocalized":"/Users/michael.lynn/code/ai4/workshop-docs/i18n/en/docusaurus-plugin-content-docs/current","docs":[{"id":"agent-patterns","title":"🧠 AI Agent Planning Patterns","description":"Understanding how AI agents reason, plan, and act is crucial for building effective multimodal systems. This section covers the key planning patterns that power modern AI agents.","source":"@site/docs/65-agent-patterns.mdx","sourceDirName":".","slug":"/agent-patterns","permalink":"/multimodal-pdf-agent-n8n/docs/agent-patterns","draft":false,"unlisted":false,"editUrl":"https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/65-agent-patterns.mdx","tags":[],"version":"current","sidebarPosition":65,"frontMatter":{"sidebar_position":65},"sidebar":"tutorialSidebar","previous":{"title":"⚖️ n8n vs Python Comparison","permalink":"/multimodal-pdf-agent-n8n/docs/approach-comparison"},"next":{"title":"💾 Memory & Context Patterns","permalink":"/multimodal-pdf-agent-n8n/docs/memory-context-patterns"}},{"id":"ai-agent-workflow","title":"🤖 AI Agent with Function Calling","description":"Build an intelligent agent using Gemini 2.0 Flash and n8n's powerful workflow capabilities.","source":"@site/docs/60-ai-agent-workflow.mdx","sourceDirName":".","slug":"/ai-agent-workflow","permalink":"/multimodal-pdf-agent-n8n/docs/ai-agent-workflow","draft":false,"unlisted":false,"editUrl":"https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/60-ai-agent-workflow.mdx","tags":[],"version":"current","sidebarPosition":60,"frontMatter":{"sidebar_position":60},"sidebar":"tutorialSidebar","previous":{"title":"Vector Search Implementation","permalink":"/multimodal-pdf-agent-n8n/docs/vector-search-workflow"},"next":{"title":"🧪 Exercise: Build a PDF RAG Agent","permalink":"/multimodal-pdf-agent-n8n/docs/exercise-pdf-rag-agent"}},{"id":"api-architecture","title":"🌐 API Gateway Architecture: The Workshop Proxy System","description":"The workshop API gateway serves as both an educational tool and practical infrastructure. Let's explore why it exists, how it works, and how it compares to production systems.","source":"@site/docs/api-architecture.mdx","sourceDirName":".","slug":"/api-architecture","permalink":"/multimodal-pdf-agent-n8n/docs/api-architecture","draft":false,"unlisted":false,"editUrl":"https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/api-architecture.mdx","tags":[],"version":"current","sidebarPosition":20,"frontMatter":{"sidebar_position":20},"sidebar":"tutorialSidebar","previous":{"title":"n8n First Run Experience","permalink":"/multimodal-pdf-agent-n8n/docs/n8n-first-run"},"next":{"title":"MongoDB Atlas Setup","permalink":"/multimodal-pdf-agent-n8n/docs/mongodb-atlas-setup"}},{"id":"approach-comparison","title":"⚖️ n8n vs Python: Choosing Your Development Approach","description":"Now that you've seen both visual workflows and programmatic approaches, let's dive deep into when and why to choose each method for your multimodal PDF agent projects.","source":"@site/docs/90-approach-comparison.mdx","sourceDirName":".","slug":"/approach-comparison","permalink":"/multimodal-pdf-agent-n8n/docs/approach-comparison","draft":false,"unlisted":false,"editUrl":"https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/90-approach-comparison.mdx","tags":[],"version":"current","sidebarPosition":90,"frontMatter":{"sidebar_position":90},"sidebar":"tutorialSidebar","previous":{"title":"🐍 Python Integration Options","permalink":"/multimodal-pdf-agent-n8n/docs/python-mongodb-approaches"},"next":{"title":"🧠 AI Agent Planning Patterns","permalink":"/multimodal-pdf-agent-n8n/docs/agent-patterns"}},{"id":"architecture-overview","title":"🏗️ Architecture Overview: Multimodal AI Agent Workshop","description":"Understanding the complete system architecture helps you see how all components work together to create intelligent, multimodal AI agents. Let's explore the full stack from your browser to the AI models.","source":"@site/docs/architecture-overview.mdx","sourceDirName":".","slug":"/architecture-overview","permalink":"/multimodal-pdf-agent-n8n/docs/architecture-overview","draft":false,"unlisted":false,"editUrl":"https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/architecture-overview.mdx","tags":[],"version":"current","sidebarPosition":0,"frontMatter":{"sidebar_position":0},"sidebar":"tutorialSidebar","previous":{"title":"Workshop Introduction","permalink":"/multimodal-pdf-agent-n8n/docs/intro"},"next":{"title":"GitHub Codespaces Setup","permalink":"/multimodal-pdf-agent-n8n/docs/github-codespaces"}},{"id":"codebase","title":"10-intro.mdx","description":"","source":"@site/docs/codebase.md","sourceDirName":".","slug":"/codebase","permalink":"/multimodal-pdf-agent-n8n/docs/codebase","draft":false,"unlisted":false,"editUrl":"https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/codebase.md","tags":[],"version":"current","frontMatter":{}},{"id":"community-resources","title":"🌐 Community Nodes & Extensions","description":"Extend your PDF analysis system with community contributions!","source":"@site/docs/95-community-resources.mdx","sourceDirName":".","slug":"/community-resources","permalink":"/multimodal-pdf-agent-n8n/docs/community-resources","draft":false,"unlisted":false,"editUrl":"https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/95-community-resources.mdx","tags":[],"version":"current","sidebarPosition":95,"frontMatter":{"sidebar_position":95},"sidebar":"tutorialSidebar","previous":{"title":"Troubleshooting Guide","permalink":"/multimodal-pdf-agent-n8n/docs/docker-troubleshooting"},"next":{"title":"Status Badge Usage Guide","permalink":"/multimodal-pdf-agent-n8n/docs/status-badge-usage-guide"}},{"id":"complete-multimodal-agent","title":"🧠 Complete Multimodal PDF Agent","description":"Build a complete multimodal AI agent that can process PDFs, understand both text and images, and answer questions using MongoDB Vector Search and Voyage AI.","source":"@site/docs/70-complete-multimodal-agent.mdx","sourceDirName":".","slug":"/complete-multimodal-agent","permalink":"/multimodal-pdf-agent-n8n/docs/complete-multimodal-agent","draft":false,"unlisted":false,"editUrl":"https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/70-complete-multimodal-agent.mdx","tags":[],"version":"current","sidebarPosition":70,"frontMatter":{"sidebar_position":70},"sidebar":"tutorialSidebar","previous":{"title":"🧪 Exercise: Advanced Tool Calling","permalink":"/multimodal-pdf-agent-n8n/docs/exercise-advanced-tools"},"next":{"title":"Production Vector Search","permalink":"/multimodal-pdf-agent-n8n/docs/mongodb-vector-setup"}},{"id":"docker-troubleshooting","title":"🐳 Docker Troubleshooting Guide","description":"Common issues and solutions when running the workshop with Docker.","source":"@site/docs/95-docker-troubleshooting.mdx","sourceDirName":".","slug":"/docker-troubleshooting","permalink":"/multimodal-pdf-agent-n8n/docs/docker-troubleshooting","draft":false,"unlisted":false,"editUrl":"https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/95-docker-troubleshooting.mdx","tags":[],"version":"current","sidebarPosition":95,"frontMatter":{"sidebar_position":95},"sidebar":"tutorialSidebar","previous":{"title":"Docker Best Practices","permalink":"/multimodal-pdf-agent-n8n/docs/local-setup-tips"},"next":{"title":"Community Resources","permalink":"/multimodal-pdf-agent-n8n/docs/community-resources"}},{"id":"exercise-advanced-tools","title":"🧪 Exercise: Advanced Tool Calling & Function Integration","description":"<InstructorNotes","source":"@site/docs/exercise-advanced-tools.mdx","sourceDirName":".","slug":"/exercise-advanced-tools","permalink":"/multimodal-pdf-agent-n8n/docs/exercise-advanced-tools","draft":false,"unlisted":false,"editUrl":"https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/exercise-advanced-tools.mdx","tags":[],"version":"current","sidebarPosition":32,"frontMatter":{"sidebar_position":32},"sidebar":"tutorialSidebar","previous":{"title":"🧪 Exercise: Memory & Context","permalink":"/multimodal-pdf-agent-n8n/docs/exercise-memory-context"},"next":{"title":"Complete Multimodal Agent","permalink":"/multimodal-pdf-agent-n8n/docs/complete-multimodal-agent"}},{"id":"exercise-memory-context","title":"🧪 Exercise: Memory & Context Management","description":"<InstructorNotes","source":"@site/docs/exercise-memory-context.mdx","sourceDirName":".","slug":"/exercise-memory-context","permalink":"/multimodal-pdf-agent-n8n/docs/exercise-memory-context","draft":false,"unlisted":false,"editUrl":"https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/exercise-memory-context.mdx","tags":[],"version":"current","sidebarPosition":31,"frontMatter":{"sidebar_position":31},"sidebar":"tutorialSidebar","previous":{"title":"🧪 Exercise: Build a PDF RAG Agent","permalink":"/multimodal-pdf-agent-n8n/docs/exercise-pdf-rag-agent"},"next":{"title":"🧪 Exercise: Advanced Tool Calling","permalink":"/multimodal-pdf-agent-n8n/docs/exercise-advanced-tools"}},{"id":"exercise-pdf-rag-agent","title":"🧪 Exercise: Build a PDF RAG Agent","description":"<InstructorNotes","source":"@site/docs/exercise-pdf-rag-agent.mdx","sourceDirName":".","slug":"/exercise-pdf-rag-agent","permalink":"/multimodal-pdf-agent-n8n/docs/exercise-pdf-rag-agent","draft":false,"unlisted":false,"editUrl":"https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/exercise-pdf-rag-agent.mdx","tags":[],"version":"current","sidebarPosition":30,"frontMatter":{"sidebar_position":30},"sidebar":"tutorialSidebar","previous":{"title":"AI Agent with Tool Calling","permalink":"/multimodal-pdf-agent-n8n/docs/ai-agent-workflow"},"next":{"title":"🧪 Exercise: Memory & Context","permalink":"/multimodal-pdf-agent-n8n/docs/exercise-memory-context"}},{"id":"github-codespaces","title":"🌐 GitHub Codespaces: Zero-Install Workshop","description":"The fastest way to start this workshop - no local setup required!","source":"@site/docs/15-github-codespaces.mdx","sourceDirName":".","slug":"/github-codespaces","permalink":"/multimodal-pdf-agent-n8n/docs/github-codespaces","draft":false,"unlisted":false,"editUrl":"https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/15-github-codespaces.mdx","tags":[],"version":"current","sidebarPosition":15,"frontMatter":{"sidebar_position":15},"sidebar":"tutorialSidebar","previous":{"title":"🏗️ Architecture Overview","permalink":"/multimodal-pdf-agent-n8n/docs/architecture-overview"},"next":{"title":"Prerequisites & Local Setup","permalink":"/multimodal-pdf-agent-n8n/docs/prerequisites"}},{"id":"index","title":"Workshop Overview","description":"Welcome to the Build a Multimodal PDF Agent with n8n workshop! This interactive, hands-on experience will guide you through creating a production-ready AI system that processes PDFs using cutting-edge technologies.","source":"@site/docs/index.mdx","sourceDirName":".","slug":"/","permalink":"/multimodal-pdf-agent-n8n/docs/","draft":false,"unlisted":false,"editUrl":"https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/index.mdx","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"sidebar_position":1,"slug":"/","title":"Workshop Overview"},"sidebar":"tutorialSidebar","next":{"title":"Workshop Introduction","permalink":"/multimodal-pdf-agent-n8n/docs/intro"}},{"id":"intro","title":"📘 Introduction to Multimodal PDF Agents with n8n","description":"|Workshop goals|Build a multimodal AI agent that processes PDFs using n8n, MongoDB Atlas, and Voyage AI|","source":"@site/docs/10-intro.mdx","sourceDirName":".","slug":"/intro","permalink":"/multimodal-pdf-agent-n8n/docs/intro","draft":false,"unlisted":false,"editUrl":"https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/10-intro.mdx","tags":[],"version":"current","sidebarPosition":10,"frontMatter":{"sidebar_position":10},"sidebar":"tutorialSidebar","previous":{"title":"🎓 Workshop Overview","permalink":"/multimodal-pdf-agent-n8n/docs/"},"next":{"title":"🏗️ Architecture Overview","permalink":"/multimodal-pdf-agent-n8n/docs/architecture-overview"}},{"id":"local-setup-tips","title":"💻 Docker Development Best Practices","description":"Based on real-world experience, here's how to optimize your Docker-based n8n development environment.","source":"@site/docs/45-local-setup-tips.mdx","sourceDirName":".","slug":"/local-setup-tips","permalink":"/multimodal-pdf-agent-n8n/docs/local-setup-tips","draft":false,"unlisted":false,"editUrl":"https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/45-local-setup-tips.mdx","tags":[],"version":"current","sidebarPosition":45,"frontMatter":{"sidebar_position":45},"sidebar":"tutorialSidebar","previous":{"title":"🖼️ Multimodal Image Queries","permalink":"/multimodal-pdf-agent-n8n/docs/multimodal-image-queries"},"next":{"title":"Troubleshooting Guide","permalink":"/multimodal-pdf-agent-n8n/docs/docker-troubleshooting"}},{"id":"memory-context-patterns","title":"🧠 Memory & Context Patterns","description":"Real AI agents need memory to maintain context across conversations and learn from interactions. This section shows how to implement different memory patterns using MongoDB and n8n workflows.","source":"@site/docs/67-memory-context-patterns.mdx","sourceDirName":".","slug":"/memory-context-patterns","permalink":"/multimodal-pdf-agent-n8n/docs/memory-context-patterns","draft":false,"unlisted":false,"editUrl":"https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/67-memory-context-patterns.mdx","tags":[],"version":"current","sidebarPosition":67,"frontMatter":{"sidebar_position":67},"sidebar":"tutorialSidebar","previous":{"title":"🧠 AI Agent Planning Patterns","permalink":"/multimodal-pdf-agent-n8n/docs/agent-patterns"},"next":{"title":"🛠️ Tool Definition & Function Calling","permalink":"/multimodal-pdf-agent-n8n/docs/tool-definition-primer"}},{"id":"mongodb-atlas-setup","title":"🗄️ MongoDB Atlas Setup for Vector Search","description":"This workshop uses MongoDB Atlas for vector search capabilities.","source":"@site/docs/30-mongodb-atlas-setup.mdx","sourceDirName":".","slug":"/mongodb-atlas-setup","permalink":"/multimodal-pdf-agent-n8n/docs/mongodb-atlas-setup","draft":false,"unlisted":false,"editUrl":"https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/30-mongodb-atlas-setup.mdx","tags":[],"version":"current","sidebarPosition":30,"frontMatter":{"sidebar_position":30},"sidebar":"tutorialSidebar","previous":{"title":"🌐 API Gateway Architecture","permalink":"/multimodal-pdf-agent-n8n/docs/api-architecture"},"next":{"title":"Voyage AI Configuration","permalink":"/multimodal-pdf-agent-n8n/docs/voyage-ai-setup"}},{"id":"mongodb-vector-setup","title":"🗄️ MongoDB Vector Search Setup","description":"Configure MongoDB for real vector search capabilities in your multimodal PDF agent.","source":"@site/docs/75-mongodb-vector-setup.mdx","sourceDirName":".","slug":"/mongodb-vector-setup","permalink":"/multimodal-pdf-agent-n8n/docs/mongodb-vector-setup","draft":false,"unlisted":false,"editUrl":"https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/75-mongodb-vector-setup.mdx","tags":[],"version":"current","sidebarPosition":75,"frontMatter":{"sidebar_position":75},"sidebar":"tutorialSidebar","previous":{"title":"Complete Multimodal Agent","permalink":"/multimodal-pdf-agent-n8n/docs/complete-multimodal-agent"},"next":{"title":"Web Upload Interface","permalink":"/multimodal-pdf-agent-n8n/docs/upload-interface"}},{"id":"multimodal-image-queries","title":"🖼️ Multimodal Image Queries & Visual Understanding","description":"\"Screenshots are all you need\" - this powerful concept from multimodal AI means agents can understand and analyze visual content just as well as text. Let's build workflows that handle image queries and visual document analysis.","source":"@site/docs/69-multimodal-image-queries.mdx","sourceDirName":".","slug":"/multimodal-image-queries","permalink":"/multimodal-pdf-agent-n8n/docs/multimodal-image-queries","draft":false,"unlisted":false,"editUrl":"https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/69-multimodal-image-queries.mdx","tags":[],"version":"current","sidebarPosition":69,"frontMatter":{"sidebar_position":69},"sidebar":"tutorialSidebar","previous":{"title":"🛠️ Tool Definition & Function Calling","permalink":"/multimodal-pdf-agent-n8n/docs/tool-definition-primer"},"next":{"title":"Docker Best Practices","permalink":"/multimodal-pdf-agent-n8n/docs/local-setup-tips"}},{"id":"n8n-first-run","title":"🚀 n8n First Run Experience","description":"<StepIndicator current= total={6} titles={[","source":"@site/docs/25-n8n-first-run.mdx","sourceDirName":".","slug":"/n8n-first-run","permalink":"/multimodal-pdf-agent-n8n/docs/n8n-first-run","draft":false,"unlisted":false,"editUrl":"https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/25-n8n-first-run.mdx","tags":[],"version":"current","sidebarPosition":25,"frontMatter":{"sidebar_position":25},"sidebar":"tutorialSidebar","previous":{"title":"Prerequisites & Local Setup","permalink":"/multimodal-pdf-agent-n8n/docs/prerequisites"},"next":{"title":"🌐 API Gateway Architecture","permalink":"/multimodal-pdf-agent-n8n/docs/api-architecture"}},{"id":"pdf-processing-workflow","title":"📄 PDF Processing Workflow","description":"Build your first n8n workflow to process PDFs into searchable multimodal embeddings.","source":"@site/docs/40-pdf-processing-workflow.mdx","sourceDirName":".","slug":"/pdf-processing-workflow","permalink":"/multimodal-pdf-agent-n8n/docs/pdf-processing-workflow","draft":false,"unlisted":false,"editUrl":"https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/40-pdf-processing-workflow.mdx","tags":[],"version":"current","sidebarPosition":40,"frontMatter":{"sidebar_position":40},"sidebar":"tutorialSidebar","previous":{"title":"Voyage AI Configuration","permalink":"/multimodal-pdf-agent-n8n/docs/voyage-ai-setup"},"next":{"title":"Vector Search Implementation","permalink":"/multimodal-pdf-agent-n8n/docs/vector-search-workflow"}},{"id":"prerequisites","title":"🛠️ Prerequisites & Setup","description":"Before we start building, let's get all the tools and accounts you'll need.","source":"@site/docs/20-prerequisites.mdx","sourceDirName":".","slug":"/prerequisites","permalink":"/multimodal-pdf-agent-n8n/docs/prerequisites","draft":false,"unlisted":false,"editUrl":"https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/20-prerequisites.mdx","tags":[],"version":"current","sidebarPosition":20,"frontMatter":{"sidebar_position":20},"sidebar":"tutorialSidebar","previous":{"title":"GitHub Codespaces Setup","permalink":"/multimodal-pdf-agent-n8n/docs/github-codespaces"},"next":{"title":"n8n First Run Experience","permalink":"/multimodal-pdf-agent-n8n/docs/n8n-first-run"}},{"id":"python-mongodb-approaches","title":"🐍 Python Approaches to MongoDB Vector Search","description":"While n8n provides an excellent visual workflow approach, developers often need programmatic control. Let's explore different ways to interact with MongoDB vector search and Voyage AI using Python.","source":"@site/docs/85-python-mongodb-approaches.mdx","sourceDirName":".","slug":"/python-mongodb-approaches","permalink":"/multimodal-pdf-agent-n8n/docs/python-mongodb-approaches","draft":false,"unlisted":false,"editUrl":"https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/85-python-mongodb-approaches.mdx","tags":[],"version":"current","sidebarPosition":85,"frontMatter":{"sidebar_position":85},"sidebar":"tutorialSidebar","previous":{"title":"Web Upload Interface","permalink":"/multimodal-pdf-agent-n8n/docs/upload-interface"},"next":{"title":"⚖️ n8n vs Python Comparison","permalink":"/multimodal-pdf-agent-n8n/docs/approach-comparison"}},{"id":"status-badge-usage-guide","title":"📊 Status Badge Usage Guide","description":"This guide shows instructors and content creators how to use the specialized LiveStatusBadge components throughout the workshop to provide progressive validation and real-time feedback.","source":"@site/docs/status-badge-usage-guide.mdx","sourceDirName":".","slug":"/status-badge-usage-guide","permalink":"/multimodal-pdf-agent-n8n/docs/status-badge-usage-guide","draft":false,"unlisted":false,"editUrl":"https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/status-badge-usage-guide.mdx","tags":[],"version":"current","sidebarPosition":100,"frontMatter":{"sidebar_position":100},"sidebar":"tutorialSidebar","previous":{"title":"Community Resources","permalink":"/multimodal-pdf-agent-n8n/docs/community-resources"},"next":{"title":"🎉 Workshop Summary","permalink":"/multimodal-pdf-agent-n8n/docs/summary"}},{"id":"summary","title":"🎯 Workshop Summary","description":"Congratulations! Following this tutorial, you have successfully:","source":"@site/docs/summary.mdx","sourceDirName":".","slug":"/summary","permalink":"/multimodal-pdf-agent-n8n/docs/summary","draft":false,"unlisted":false,"editUrl":"https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/summary.mdx","tags":[],"version":"current","sidebarPosition":100,"frontMatter":{"sidebar_position":100},"sidebar":"tutorialSidebar","previous":{"title":"Status Badge Usage Guide","permalink":"/multimodal-pdf-agent-n8n/docs/status-badge-usage-guide"}},{"id":"tool-definition-primer","title":"🛠️ Tool Definition & Function Calling Primer","description":"Tools are what transform AI models from conversational interfaces into capable agents that can interact with the world. This section covers how to define, configure, and optimize tools for your multimodal PDF agent.","source":"@site/docs/68-tool-definition-primer.mdx","sourceDirName":".","slug":"/tool-definition-primer","permalink":"/multimodal-pdf-agent-n8n/docs/tool-definition-primer","draft":false,"unlisted":false,"editUrl":"https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/68-tool-definition-primer.mdx","tags":[],"version":"current","sidebarPosition":68,"frontMatter":{"sidebar_position":68},"sidebar":"tutorialSidebar","previous":{"title":"💾 Memory & Context Patterns","permalink":"/multimodal-pdf-agent-n8n/docs/memory-context-patterns"},"next":{"title":"🖼️ Multimodal Image Queries","permalink":"/multimodal-pdf-agent-n8n/docs/multimodal-image-queries"}},{"id":"upload-interface","title":"🌐 Web Upload Interface","description":"A complete web interface for uploading PDFs and chatting with your multimodal agent.","source":"@site/docs/80-upload-interface.mdx","sourceDirName":".","slug":"/upload-interface","permalink":"/multimodal-pdf-agent-n8n/docs/upload-interface","draft":false,"unlisted":false,"editUrl":"https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/80-upload-interface.mdx","tags":[],"version":"current","sidebarPosition":80,"frontMatter":{"sidebar_position":80},"sidebar":"tutorialSidebar","previous":{"title":"Production Vector Search","permalink":"/multimodal-pdf-agent-n8n/docs/mongodb-vector-setup"},"next":{"title":"🐍 Python Integration Options","permalink":"/multimodal-pdf-agent-n8n/docs/python-mongodb-approaches"}},{"id":"vector-search-workflow","title":"🔍 Vector Search Workflow","description":"Create a search endpoint that uses MongoDB Atlas Vector Search to find relevant PDF content.","source":"@site/docs/50-vector-search-workflow.mdx","sourceDirName":".","slug":"/vector-search-workflow","permalink":"/multimodal-pdf-agent-n8n/docs/vector-search-workflow","draft":false,"unlisted":false,"editUrl":"https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/50-vector-search-workflow.mdx","tags":[],"version":"current","sidebarPosition":50,"frontMatter":{"sidebar_position":50},"sidebar":"tutorialSidebar","previous":{"title":"PDF Processing Workflow","permalink":"/multimodal-pdf-agent-n8n/docs/pdf-processing-workflow"},"next":{"title":"AI Agent with Tool Calling","permalink":"/multimodal-pdf-agent-n8n/docs/ai-agent-workflow"}},{"id":"voyage-ai-setup","title":"🚢 Voyage AI Embedding Service Setup","description":"Configure access to multimodal embeddings that process both text and images using our workshop serverless endpoint.","source":"@site/docs/35-voyage-ai-setup.mdx","sourceDirName":".","slug":"/voyage-ai-setup","permalink":"/multimodal-pdf-agent-n8n/docs/voyage-ai-setup","draft":false,"unlisted":false,"editUrl":"https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main/docs/35-voyage-ai-setup.mdx","tags":[],"version":"current","sidebarPosition":35,"frontMatter":{"sidebar_position":35},"sidebar":"tutorialSidebar","previous":{"title":"MongoDB Atlas Setup","permalink":"/multimodal-pdf-agent-n8n/docs/mongodb-atlas-setup"},"next":{"title":"PDF Processing Workflow","permalink":"/multimodal-pdf-agent-n8n/docs/pdf-processing-workflow"}}],"drafts":[],"sidebars":{"tutorialSidebar":[{"type":"doc","id":"index","label":"🎓 Workshop Overview","translatable":true},{"type":"category","label":"🚀 Getting Started","collapsible":true,"collapsed":false,"className":"sidebar-getting-started","description":"Begin your journey with environment setup and n8n basics","items":[{"type":"doc","id":"intro","label":"Workshop Introduction","translatable":true},{"type":"doc","id":"architecture-overview","label":"🏗️ Architecture Overview","translatable":true},{"type":"doc","id":"github-codespaces","label":"GitHub Codespaces Setup","translatable":true},{"type":"doc","id":"prerequisites","label":"Prerequisites & Local Setup","translatable":true},{"type":"doc","id":"n8n-first-run","label":"n8n First Run Experience","translatable":true}]},{"type":"category","label":"⚙️ Setup & Configuration","collapsible":true,"collapsed":false,"className":"sidebar-setup","description":"Configure MongoDB Atlas and Voyage AI for your agent","items":[{"type":"doc","id":"api-architecture","label":"🌐 API Gateway Architecture","translatable":true},{"type":"doc","id":"mongodb-atlas-setup","label":"MongoDB Atlas Setup","translatable":true},{"type":"doc","id":"voyage-ai-setup","label":"Voyage AI Configuration","translatable":true}]},{"type":"category","label":"🔧 Building Workflows","collapsible":true,"collapsed":false,"className":"sidebar-workflows","description":"Create powerful automation workflows step by step","items":[{"type":"doc","id":"pdf-processing-workflow","label":"PDF Processing Workflow","translatable":true},{"type":"doc","id":"vector-search-workflow","label":"Vector Search Implementation","translatable":true},{"type":"doc","id":"ai-agent-workflow","label":"AI Agent with Tool Calling","translatable":true}]},{"type":"category","label":"🧪 Hands-On Exercises","collapsible":true,"collapsed":false,"className":"sidebar-exercises","description":"Structured exercises to build complete AI agents","items":[{"type":"doc","id":"exercise-pdf-rag-agent","label":"🧪 Exercise: Build a PDF RAG Agent","translatable":true},{"type":"doc","id":"exercise-memory-context","label":"🧪 Exercise: Memory & Context","translatable":true},{"type":"doc","id":"exercise-advanced-tools","label":"🧪 Exercise: Advanced Tool Calling","translatable":true}]},{"type":"category","label":"🎯 Advanced Topics","collapsible":true,"collapsed":true,"className":"sidebar-advanced","description":"Take your agent to production with advanced features","items":[{"type":"doc","id":"complete-multimodal-agent","label":"Complete Multimodal Agent","translatable":true},{"type":"doc","id":"mongodb-vector-setup","label":"Production Vector Search","translatable":true},{"type":"doc","id":"upload-interface","label":"Web Upload Interface","translatable":true},{"type":"doc","id":"python-mongodb-approaches","label":"🐍 Python Integration Options","translatable":true},{"type":"doc","id":"approach-comparison","label":"⚖️ n8n vs Python Comparison","translatable":true},{"type":"doc","id":"agent-patterns","label":"🧠 AI Agent Planning Patterns","translatable":true},{"type":"doc","id":"memory-context-patterns","label":"💾 Memory & Context Patterns","translatable":true},{"type":"doc","id":"tool-definition-primer","label":"🛠️ Tool Definition & Function Calling","translatable":true},{"type":"doc","id":"multimodal-image-queries","label":"🖼️ Multimodal Image Queries","translatable":true}]},{"type":"category","label":"📚 Resources & Support","collapsible":true,"collapsed":true,"className":"sidebar-resources","description":"Additional resources, troubleshooting, and community","items":[{"type":"doc","id":"local-setup-tips","label":"Docker Best Practices","translatable":true},{"type":"doc","id":"docker-troubleshooting","label":"Troubleshooting Guide","translatable":true},{"type":"doc","id":"community-resources","label":"Community Resources","translatable":true},{"type":"doc","id":"status-badge-usage-guide","label":"Status Badge Usage Guide","translatable":true},{"type":"doc","id":"summary","label":"🎉 Workshop Summary","translatable":true}]}]}}]}},"docusaurus-plugin-content-blog":{"default":{"blogSidebarTitle":"Recent posts","blogPosts":[],"blogListPaginated":[],"blogTags":{},"blogTagsListPath":"/multimodal-pdf-agent-n8n/blog/tags"}},"docusaurus-plugin-content-pages":{"default":[{"type":"jsx","permalink":"/multimodal-pdf-agent-n8n/helloWorld","source":"@site/src/pages/helloWorld.js"},{"type":"jsx","permalink":"/multimodal-pdf-agent-n8n/","source":"@site/src/pages/index.js"}]},"docusaurus-plugin-debug":{},"docusaurus-plugin-svgr":{},"docusaurus-theme-classic":{},"docusaurus-lunr-search":{},"docusaurus-theme-mermaid":{},"docusaurus-bootstrap-plugin":{},"docusaurus-mdx-fallback-plugin":{}}}
```

# .docusaurus/docusaurus-plugin-google-gtag/default/__plugin.json

```json
{
  "name": "docusaurus-plugin-google-gtag",
  "id": "default"
}
```

# .docusaurus/docusaurus.config.mjs

```mjs
/*
 * AUTOGENERATED - DON'T EDIT
 * Your edits in this file will be overwritten in the next build!
 * Modify the docusaurus.config.js file at your site's root instead.
 */
export default {
  "title": "Build a Multimodal PDF Agent with n8n",
  "tagline": "Process, encode, and search PDFs using MongoDB Vector Search, Voyage AI, and n8n automation",
  "url": "https://multimodal-pdf-agent-n8n.github.io",
  "baseUrl": "/multimodal-pdf-agent-n8n/",
  "projectName": "mongodb-developer.github.io",
  "organizationName": "mongodb-developer",
  "trailingSlash": false,
  "onBrokenLinks": "throw",
  "onBrokenMarkdownLinks": "warn",
  "favicon": "img/favicon.svg",
  "deploymentBranch": "gh-pages",
  "staticDirectories": [
    "static"
  ],
  "i18n": {
    "defaultLocale": "en",
    "locales": [
      "en",
      "es"
    ],
    "path": "i18n",
    "localeConfigs": {}
  },
  "customFields": {
    "startButtonTitle": "Start Building",
    "featureList": [
      {
        "title": "Visual Workflow Building",
        "illustration": "img/n8n-workflow.png",
        "description": "\n        Build complex AI agents using n8n's visual interface - no coding required!\n    "
      },
      {
        "title": "Multimodal Processing",
        "illustration": "img/multimodal.png",
        "description": "\n        Process both text and images from PDFs using Voyage AI's multimodal embeddings.\n    "
      },
      {
        "title": "Production-Ready",
        "illustration": "img/mongodb-atlas.png",
        "description": "\n        Deploy scalable vector search with MongoDB Atlas and n8n's robust automation.\n    "
      }
    ],
    "utmParams": "utm_campaign=devrel&utm_source=workshop&utm_medium=cta&utm_content=multimodal_pdf_agent_n8n&utm_term=michael.lynn"
  },
  "presets": [
    [
      "classic",
      {
        "docs": {
          "sidebarPath": "/Users/michael.lynn/code/ai4/workshop-docs/sidebars.js",
          "editUrl": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/blob/main"
        },
        "theme": {
          "customCss": "/Users/michael.lynn/code/ai4/workshop-docs/src/css/custom.css"
        },
        "gtag": {
          "trackingID": "G-ZJ28V71VTQ",
          "anonymizeIP": true
        }
      }
    ]
  ],
  "plugins": [
    [
      "/Users/michael.lynn/code/ai4/workshop-docs/node_modules/docusaurus-lunr-search/src/index.js",
      {
        "languages": [
          "es",
          "en"
        ]
      }
    ]
  ],
  "themeConfig": {
    "docs": {
      "sidebar": {
        "autoCollapseCategories": true,
        "hideable": true
      },
      "versionPersistence": "localStorage"
    },
    "announcementBar": {
      "id": "feedback_form",
      "content": "This is a demonstration that we can put a pop-up message here! Even <a target=\"_blank\" rel=\"noopener noreferrer\" href=\"#\">links</a>",
      "backgroundColor": "#fafbfc",
      "textColor": "#091E42",
      "isCloseable": true
    },
    "navbar": {
      "title": "Build a Multimodal PDF Agent with n8n",
      "logo": {
        "alt": "MongoDB Logo",
        "src": "img/logo.svg",
        "srcDark": "img/logo-dark.svg",
        "className": "navbar-logo",
        "width": "135px",
        "height": "100%"
      },
      "items": [
        {
          "type": "localeDropdown",
          "position": "right",
          "dropdownItemsBefore": [],
          "dropdownItemsAfter": []
        }
      ],
      "hideOnScroll": false
    },
    "footer": {
      "style": "dark",
      "links": [
        {
          "label": "Try MongoDB Atlas",
          "href": "https://www.mongodb.com/try?utm_campaign=devrel&utm_source=workshop&utm_medium=cta&utm_content=multimodal_pdf_agent_n8n&utm_term=michael.lynn"
        },
        {
          "label": "Forums",
          "href": "https://www.mongodb.com/community/forums?utm_campaign=devrel&utm_source=workshop&utm_medium=cta&utm_content=multimodal_pdf_agent_n8n&utm_term=michael.lynn"
        },
        {
          "label": "Developer Center",
          "href": "https://www.mongodb.com/developer?utm_campaign=devrel&utm_source=workshop&utm_medium=cta&utm_content=multimodal_pdf_agent_n8n&utm_term=michael.lynn"
        },
        {
          "label": "MongoDB University",
          "href": "https://learn.mongodb.com?utm_campaign=devrel&utm_source=workshop&utm_medium=cta&utm_content=multimodal_pdf_agent_n8n&utm_term=michael.lynn"
        },
        {
          "href": "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n",
          "label": "Workshop GitHub (Deployment)"
        }
      ],
      "copyright": "© 2025 MongoDB, Inc."
    },
    "prism": {
      "theme": {
        "plain": {
          "color": "#393A34",
          "backgroundColor": "#f6f8fa"
        },
        "styles": [
          {
            "types": [
              "comment",
              "prolog",
              "doctype",
              "cdata"
            ],
            "style": {
              "color": "#999988",
              "fontStyle": "italic"
            }
          },
          {
            "types": [
              "namespace"
            ],
            "style": {
              "opacity": 0.7
            }
          },
          {
            "types": [
              "string",
              "attr-value"
            ],
            "style": {
              "color": "#e3116c"
            }
          },
          {
            "types": [
              "punctuation",
              "operator"
            ],
            "style": {
              "color": "#393A34"
            }
          },
          {
            "types": [
              "entity",
              "url",
              "symbol",
              "number",
              "boolean",
              "variable",
              "constant",
              "property",
              "regex",
              "inserted"
            ],
            "style": {
              "color": "#36acaa"
            }
          },
          {
            "types": [
              "atrule",
              "keyword",
              "attr-name",
              "selector"
            ],
            "style": {
              "color": "#00a4db"
            }
          },
          {
            "types": [
              "function",
              "deleted",
              "tag"
            ],
            "style": {
              "color": "#d73a49"
            }
          },
          {
            "types": [
              "function-variable"
            ],
            "style": {
              "color": "#6f42c1"
            }
          },
          {
            "types": [
              "tag",
              "selector",
              "keyword"
            ],
            "style": {
              "color": "#00009f"
            }
          }
        ]
      },
      "darkTheme": {
        "plain": {
          "color": "#F8F8F2",
          "backgroundColor": "#282A36"
        },
        "styles": [
          {
            "types": [
              "prolog",
              "constant",
              "builtin"
            ],
            "style": {
              "color": "rgb(189, 147, 249)"
            }
          },
          {
            "types": [
              "inserted",
              "function"
            ],
            "style": {
              "color": "rgb(80, 250, 123)"
            }
          },
          {
            "types": [
              "deleted"
            ],
            "style": {
              "color": "rgb(255, 85, 85)"
            }
          },
          {
            "types": [
              "changed"
            ],
            "style": {
              "color": "rgb(255, 184, 108)"
            }
          },
          {
            "types": [
              "punctuation",
              "symbol"
            ],
            "style": {
              "color": "rgb(248, 248, 242)"
            }
          },
          {
            "types": [
              "string",
              "char",
              "tag",
              "selector"
            ],
            "style": {
              "color": "rgb(255, 121, 198)"
            }
          },
          {
            "types": [
              "keyword",
              "variable"
            ],
            "style": {
              "color": "rgb(189, 147, 249)",
              "fontStyle": "italic"
            }
          },
          {
            "types": [
              "comment"
            ],
            "style": {
              "color": "rgb(98, 114, 164)"
            }
          },
          {
            "types": [
              "attr-name"
            ],
            "style": {
              "color": "rgb(241, 250, 140)"
            }
          }
        ]
      },
      "additionalLanguages": [
        "powershell",
        "swift",
        "kotlin"
      ],
      "magicComments": [
        {
          "className": "theme-code-block-highlighted-line",
          "line": "highlight-next-line",
          "block": {
            "start": "highlight-start",
            "end": "highlight-end"
          }
        }
      ]
    },
    "mermaid": {
      "theme": {
        "light": "neutral",
        "dark": "forest"
      },
      "options": {}
    },
    "colorMode": {
      "defaultMode": "light",
      "disableSwitch": false,
      "respectPrefersColorScheme": false
    },
    "blog": {
      "sidebar": {
        "groupByYear": true
      }
    },
    "metadata": [],
    "tableOfContents": {
      "minHeadingLevel": 2,
      "maxHeadingLevel": 3
    }
  },
  "future": {
    "v4": {
      "removeLegacyPostBuildHeadAttribute": true,
      "useCssCascadeLayers": true
    },
    "experimental_faster": {
      "swcJsLoader": true,
      "swcJsMinimizer": true,
      "swcHtmlMinimizer": true,
      "lightningCssMinimizer": true,
      "mdxCrossCompilerCache": false,
      "rspackBundler": false,
      "rspackPersistentCache": false,
      "ssgWorkerThreads": false
    },
    "experimental_storage": {
      "type": "localStorage",
      "namespace": true
    },
    "experimental_router": "browser"
  },
  "markdown": {
    "mermaid": true,
    "format": "mdx",
    "mdx1Compat": {
      "comments": true,
      "admonitions": true,
      "headingIds": true
    },
    "anchors": {
      "maintainCase": false
    }
  },
  "themes": [
    "@docusaurus/theme-mermaid"
  ],
  "baseUrlIssueBanner": true,
  "onBrokenAnchors": "warn",
  "onDuplicateRoutes": "warn",
  "scripts": [],
  "headTags": [],
  "stylesheets": [],
  "clientModules": [],
  "titleDelimiter": "|",
  "noIndex": false
};

```

# .docusaurus/DONT-EDIT-THIS-FOLDER

```
This folder stores temp files that Docusaurus' client bundler accesses.

DO NOT hand-modify files in this folder because they will be overwritten in the
next build. You can clear all build artifacts (including this folder) with the
`docusaurus clear` command.

```

# .docusaurus/globalData.json

```json
{
  "docusaurus-plugin-content-docs": {
    "default": {
      "path": "/multimodal-pdf-agent-n8n/docs",
      "versions": [
        {
          "name": "current",
          "label": "Next",
          "isLast": true,
          "path": "/multimodal-pdf-agent-n8n/docs",
          "mainDocId": "index",
          "docs": [
            {
              "id": "agent-patterns",
              "path": "/multimodal-pdf-agent-n8n/docs/agent-patterns",
              "sidebar": "tutorialSidebar"
            },
            {
              "id": "ai-agent-workflow",
              "path": "/multimodal-pdf-agent-n8n/docs/ai-agent-workflow",
              "sidebar": "tutorialSidebar"
            },
            {
              "id": "api-architecture",
              "path": "/multimodal-pdf-agent-n8n/docs/api-architecture",
              "sidebar": "tutorialSidebar"
            },
            {
              "id": "approach-comparison",
              "path": "/multimodal-pdf-agent-n8n/docs/approach-comparison",
              "sidebar": "tutorialSidebar"
            },
            {
              "id": "architecture-overview",
              "path": "/multimodal-pdf-agent-n8n/docs/architecture-overview",
              "sidebar": "tutorialSidebar"
            },
            {
              "id": "codebase",
              "path": "/multimodal-pdf-agent-n8n/docs/codebase"
            },
            {
              "id": "community-resources",
              "path": "/multimodal-pdf-agent-n8n/docs/community-resources",
              "sidebar": "tutorialSidebar"
            },
            {
              "id": "complete-multimodal-agent",
              "path": "/multimodal-pdf-agent-n8n/docs/complete-multimodal-agent",
              "sidebar": "tutorialSidebar"
            },
            {
              "id": "docker-troubleshooting",
              "path": "/multimodal-pdf-agent-n8n/docs/docker-troubleshooting",
              "sidebar": "tutorialSidebar"
            },
            {
              "id": "exercise-advanced-tools",
              "path": "/multimodal-pdf-agent-n8n/docs/exercise-advanced-tools",
              "sidebar": "tutorialSidebar"
            },
            {
              "id": "exercise-memory-context",
              "path": "/multimodal-pdf-agent-n8n/docs/exercise-memory-context",
              "sidebar": "tutorialSidebar"
            },
            {
              "id": "exercise-pdf-rag-agent",
              "path": "/multimodal-pdf-agent-n8n/docs/exercise-pdf-rag-agent",
              "sidebar": "tutorialSidebar"
            },
            {
              "id": "github-codespaces",
              "path": "/multimodal-pdf-agent-n8n/docs/github-codespaces",
              "sidebar": "tutorialSidebar"
            },
            {
              "id": "index",
              "path": "/multimodal-pdf-agent-n8n/docs/",
              "sidebar": "tutorialSidebar"
            },
            {
              "id": "intro",
              "path": "/multimodal-pdf-agent-n8n/docs/intro",
              "sidebar": "tutorialSidebar"
            },
            {
              "id": "local-setup-tips",
              "path": "/multimodal-pdf-agent-n8n/docs/local-setup-tips",
              "sidebar": "tutorialSidebar"
            },
            {
              "id": "memory-context-patterns",
              "path": "/multimodal-pdf-agent-n8n/docs/memory-context-patterns",
              "sidebar": "tutorialSidebar"
            },
            {
              "id": "mongodb-atlas-setup",
              "path": "/multimodal-pdf-agent-n8n/docs/mongodb-atlas-setup",
              "sidebar": "tutorialSidebar"
            },
            {
              "id": "mongodb-vector-setup",
              "path": "/multimodal-pdf-agent-n8n/docs/mongodb-vector-setup",
              "sidebar": "tutorialSidebar"
            },
            {
              "id": "multimodal-image-queries",
              "path": "/multimodal-pdf-agent-n8n/docs/multimodal-image-queries",
              "sidebar": "tutorialSidebar"
            },
            {
              "id": "n8n-first-run",
              "path": "/multimodal-pdf-agent-n8n/docs/n8n-first-run",
              "sidebar": "tutorialSidebar"
            },
            {
              "id": "pdf-processing-workflow",
              "path": "/multimodal-pdf-agent-n8n/docs/pdf-processing-workflow",
              "sidebar": "tutorialSidebar"
            },
            {
              "id": "prerequisites",
              "path": "/multimodal-pdf-agent-n8n/docs/prerequisites",
              "sidebar": "tutorialSidebar"
            },
            {
              "id": "python-mongodb-approaches",
              "path": "/multimodal-pdf-agent-n8n/docs/python-mongodb-approaches",
              "sidebar": "tutorialSidebar"
            },
            {
              "id": "status-badge-usage-guide",
              "path": "/multimodal-pdf-agent-n8n/docs/status-badge-usage-guide",
              "sidebar": "tutorialSidebar"
            },
            {
              "id": "summary",
              "path": "/multimodal-pdf-agent-n8n/docs/summary",
              "sidebar": "tutorialSidebar"
            },
            {
              "id": "tool-definition-primer",
              "path": "/multimodal-pdf-agent-n8n/docs/tool-definition-primer",
              "sidebar": "tutorialSidebar"
            },
            {
              "id": "upload-interface",
              "path": "/multimodal-pdf-agent-n8n/docs/upload-interface",
              "sidebar": "tutorialSidebar"
            },
            {
              "id": "vector-search-workflow",
              "path": "/multimodal-pdf-agent-n8n/docs/vector-search-workflow",
              "sidebar": "tutorialSidebar"
            },
            {
              "id": "voyage-ai-setup",
              "path": "/multimodal-pdf-agent-n8n/docs/voyage-ai-setup",
              "sidebar": "tutorialSidebar"
            }
          ],
          "draftIds": [],
          "sidebars": {
            "tutorialSidebar": {
              "link": {
                "path": "/multimodal-pdf-agent-n8n/docs/",
                "label": "🎓 Workshop Overview"
              }
            }
          }
        }
      ],
      "breadcrumbs": true
    }
  },
  "docusaurus-lunr-search": {
    "default": {
      "fileNames": {
        "searchDoc": "search-doc-1753374706266.json",
        "lunrIndex": "lunr-index-1753374706266.json"
      }
    }
  }
}
```

# .docusaurus/i18n.json

```json
{
  "defaultLocale": "en",
  "locales": [
    "en",
    "es"
  ],
  "path": "i18n",
  "currentLocale": "en",
  "localeConfigs": {
    "en": {
      "label": "English",
      "direction": "ltr",
      "htmlLang": "en",
      "calendar": "gregory",
      "path": "en"
    },
    "es": {
      "label": "Español",
      "direction": "ltr",
      "htmlLang": "es",
      "calendar": "gregory",
      "path": "es"
    }
  }
}
```

# .docusaurus/lunr.client.js

```js
// THIS FILE IS AUTOGENERATED
// DO NOT EDIT THIS FILE!

import * as lunr from "lunr";
require("lunr-languages/lunr.stemmer.support")(lunr);
require("lunr-languages/lunr.es")(lunr);
require("lunr-languages/lunr.multi")(lunr);
export default lunr;

```

# .docusaurus/registry.js

```js
export default {
  "__comp---site-src-pages-hello-world-js-72-d-375": [() => import(/* webpackChunkName: "__comp---site-src-pages-hello-world-js-72-d-375" */ "@site/src/pages/helloWorld.js"), "@site/src/pages/helloWorld.js", require.resolveWeak("@site/src/pages/helloWorld.js")],
  "__comp---site-src-pages-index-jsc-4-f-f99": [() => import(/* webpackChunkName: "__comp---site-src-pages-index-jsc-4-f-f99" */ "@site/src/pages/index.js"), "@site/src/pages/index.js", require.resolveWeak("@site/src/pages/index.js")],
  "__comp---theme-debug-config-23-a-2ff": [() => import(/* webpackChunkName: "__comp---theme-debug-config-23-a-2ff" */ "@theme/DebugConfig"), "@theme/DebugConfig", require.resolveWeak("@theme/DebugConfig")],
  "__comp---theme-debug-contentba-8-ce7": [() => import(/* webpackChunkName: "__comp---theme-debug-contentba-8-ce7" */ "@theme/DebugContent"), "@theme/DebugContent", require.resolveWeak("@theme/DebugContent")],
  "__comp---theme-debug-global-dataede-0fa": [() => import(/* webpackChunkName: "__comp---theme-debug-global-dataede-0fa" */ "@theme/DebugGlobalData"), "@theme/DebugGlobalData", require.resolveWeak("@theme/DebugGlobalData")],
  "__comp---theme-debug-registry-679-501": [() => import(/* webpackChunkName: "__comp---theme-debug-registry-679-501" */ "@theme/DebugRegistry"), "@theme/DebugRegistry", require.resolveWeak("@theme/DebugRegistry")],
  "__comp---theme-debug-routes-946-699": [() => import(/* webpackChunkName: "__comp---theme-debug-routes-946-699" */ "@theme/DebugRoutes"), "@theme/DebugRoutes", require.resolveWeak("@theme/DebugRoutes")],
  "__comp---theme-debug-site-metadata-68-e-3d4": [() => import(/* webpackChunkName: "__comp---theme-debug-site-metadata-68-e-3d4" */ "@theme/DebugSiteMetadata"), "@theme/DebugSiteMetadata", require.resolveWeak("@theme/DebugSiteMetadata")],
  "__comp---theme-doc-item-178-a40": [() => import(/* webpackChunkName: "__comp---theme-doc-item-178-a40" */ "@theme/DocItem"), "@theme/DocItem", require.resolveWeak("@theme/DocItem")],
  "__comp---theme-doc-roota-94-67a": [() => import(/* webpackChunkName: "__comp---theme-doc-roota-94-67a" */ "@theme/DocRoot"), "@theme/DocRoot", require.resolveWeak("@theme/DocRoot")],
  "__comp---theme-doc-version-roota-7-b-5de": [() => import(/* webpackChunkName: "__comp---theme-doc-version-roota-7-b-5de" */ "@theme/DocVersionRoot"), "@theme/DocVersionRoot", require.resolveWeak("@theme/DocVersionRoot")],
  "__comp---theme-docs-root-5-e-9-0b6": [() => import(/* webpackChunkName: "__comp---theme-docs-root-5-e-9-0b6" */ "@theme/DocsRoot"), "@theme/DocsRoot", require.resolveWeak("@theme/DocsRoot")],
  "__props---multimodal-pdf-agent-n-8-n-docs-2-ee-9f5": [() => import(/* webpackChunkName: "__props---multimodal-pdf-agent-n-8-n-docs-2-ee-9f5" */ "@generated/docusaurus-plugin-content-docs/default/p/multimodal-pdf-agent-n-8-n-docs-a69.json"), "@generated/docusaurus-plugin-content-docs/default/p/multimodal-pdf-agent-n-8-n-docs-a69.json", require.resolveWeak("@generated/docusaurus-plugin-content-docs/default/p/multimodal-pdf-agent-n-8-n-docs-a69.json")],
  "__props---multimodal-pdf-agent-n-8-n-docusaurus-debug-contenta-00-4cc": [() => import(/* webpackChunkName: "__props---multimodal-pdf-agent-n-8-n-docusaurus-debug-contenta-00-4cc" */ "@generated/docusaurus-plugin-debug/default/p/multimodal-pdf-agent-n-8-n-docusaurus-debug-content-b60.json"), "@generated/docusaurus-plugin-debug/default/p/multimodal-pdf-agent-n-8-n-docusaurus-debug-content-b60.json", require.resolveWeak("@generated/docusaurus-plugin-debug/default/p/multimodal-pdf-agent-n-8-n-docusaurus-debug-content-b60.json")],
  "config---multimodal-pdf-agent-n-8-n-hello-world-5-e-9-00a": [() => import(/* webpackChunkName: "config---multimodal-pdf-agent-n-8-n-hello-world-5-e-9-00a" */ "@generated/docusaurus.config"), "@generated/docusaurus.config", require.resolveWeak("@generated/docusaurus.config")],
  "content---multimodal-pdf-agent-n-8-n-docs-4-ed-86c": [() => import(/* webpackChunkName: "content---multimodal-pdf-agent-n-8-n-docs-4-ed-86c" */ "@site/docs/index.mdx"), "@site/docs/index.mdx", require.resolveWeak("@site/docs/index.mdx")],
  "content---multimodal-pdf-agent-n-8-n-docs-agent-patterns-42-d-320": [() => import(/* webpackChunkName: "content---multimodal-pdf-agent-n-8-n-docs-agent-patterns-42-d-320" */ "@site/docs/65-agent-patterns.mdx"), "@site/docs/65-agent-patterns.mdx", require.resolveWeak("@site/docs/65-agent-patterns.mdx")],
  "content---multimodal-pdf-agent-n-8-n-docs-ai-agent-workflow-600-b25": [() => import(/* webpackChunkName: "content---multimodal-pdf-agent-n-8-n-docs-ai-agent-workflow-600-b25" */ "@site/docs/60-ai-agent-workflow.mdx"), "@site/docs/60-ai-agent-workflow.mdx", require.resolveWeak("@site/docs/60-ai-agent-workflow.mdx")],
  "content---multimodal-pdf-agent-n-8-n-docs-api-architecture-137-674": [() => import(/* webpackChunkName: "content---multimodal-pdf-agent-n-8-n-docs-api-architecture-137-674" */ "@site/docs/api-architecture.mdx"), "@site/docs/api-architecture.mdx", require.resolveWeak("@site/docs/api-architecture.mdx")],
  "content---multimodal-pdf-agent-n-8-n-docs-approach-comparisonabe-8e2": [() => import(/* webpackChunkName: "content---multimodal-pdf-agent-n-8-n-docs-approach-comparisonabe-8e2" */ "@site/docs/90-approach-comparison.mdx"), "@site/docs/90-approach-comparison.mdx", require.resolveWeak("@site/docs/90-approach-comparison.mdx")],
  "content---multimodal-pdf-agent-n-8-n-docs-architecture-overviewad-9-564": [() => import(/* webpackChunkName: "content---multimodal-pdf-agent-n-8-n-docs-architecture-overviewad-9-564" */ "@site/docs/architecture-overview.mdx"), "@site/docs/architecture-overview.mdx", require.resolveWeak("@site/docs/architecture-overview.mdx")],
  "content---multimodal-pdf-agent-n-8-n-docs-codebase-282-bb5": [() => import(/* webpackChunkName: "content---multimodal-pdf-agent-n-8-n-docs-codebase-282-bb5" */ "@site/docs/codebase.md"), "@site/docs/codebase.md", require.resolveWeak("@site/docs/codebase.md")],
  "content---multimodal-pdf-agent-n-8-n-docs-community-resourcesb-5-e-4df": [() => import(/* webpackChunkName: "content---multimodal-pdf-agent-n-8-n-docs-community-resourcesb-5-e-4df" */ "@site/docs/95-community-resources.mdx"), "@site/docs/95-community-resources.mdx", require.resolveWeak("@site/docs/95-community-resources.mdx")],
  "content---multimodal-pdf-agent-n-8-n-docs-complete-multimodal-agent-802-85b": [() => import(/* webpackChunkName: "content---multimodal-pdf-agent-n-8-n-docs-complete-multimodal-agent-802-85b" */ "@site/docs/70-complete-multimodal-agent.mdx"), "@site/docs/70-complete-multimodal-agent.mdx", require.resolveWeak("@site/docs/70-complete-multimodal-agent.mdx")],
  "content---multimodal-pdf-agent-n-8-n-docs-docker-troubleshooting-827-9bb": [() => import(/* webpackChunkName: "content---multimodal-pdf-agent-n-8-n-docs-docker-troubleshooting-827-9bb" */ "@site/docs/95-docker-troubleshooting.mdx"), "@site/docs/95-docker-troubleshooting.mdx", require.resolveWeak("@site/docs/95-docker-troubleshooting.mdx")],
  "content---multimodal-pdf-agent-n-8-n-docs-exercise-advanced-tools-561-f6e": [() => import(/* webpackChunkName: "content---multimodal-pdf-agent-n-8-n-docs-exercise-advanced-tools-561-f6e" */ "@site/docs/exercise-advanced-tools.mdx"), "@site/docs/exercise-advanced-tools.mdx", require.resolveWeak("@site/docs/exercise-advanced-tools.mdx")],
  "content---multimodal-pdf-agent-n-8-n-docs-exercise-memory-contextd-23-91f": [() => import(/* webpackChunkName: "content---multimodal-pdf-agent-n-8-n-docs-exercise-memory-contextd-23-91f" */ "@site/docs/exercise-memory-context.mdx"), "@site/docs/exercise-memory-context.mdx", require.resolveWeak("@site/docs/exercise-memory-context.mdx")],
  "content---multimodal-pdf-agent-n-8-n-docs-exercise-pdf-rag-agentde-6-389": [() => import(/* webpackChunkName: "content---multimodal-pdf-agent-n-8-n-docs-exercise-pdf-rag-agentde-6-389" */ "@site/docs/exercise-pdf-rag-agent.mdx"), "@site/docs/exercise-pdf-rag-agent.mdx", require.resolveWeak("@site/docs/exercise-pdf-rag-agent.mdx")],
  "content---multimodal-pdf-agent-n-8-n-docs-github-codespaceseb-7-bd3": [() => import(/* webpackChunkName: "content---multimodal-pdf-agent-n-8-n-docs-github-codespaceseb-7-bd3" */ "@site/docs/15-github-codespaces.mdx"), "@site/docs/15-github-codespaces.mdx", require.resolveWeak("@site/docs/15-github-codespaces.mdx")],
  "content---multimodal-pdf-agent-n-8-n-docs-intro-317-a69": [() => import(/* webpackChunkName: "content---multimodal-pdf-agent-n-8-n-docs-intro-317-a69" */ "@site/docs/10-intro.mdx"), "@site/docs/10-intro.mdx", require.resolveWeak("@site/docs/10-intro.mdx")],
  "content---multimodal-pdf-agent-n-8-n-docs-local-setup-tips-68-d-8a3": [() => import(/* webpackChunkName: "content---multimodal-pdf-agent-n-8-n-docs-local-setup-tips-68-d-8a3" */ "@site/docs/45-local-setup-tips.mdx"), "@site/docs/45-local-setup-tips.mdx", require.resolveWeak("@site/docs/45-local-setup-tips.mdx")],
  "content---multimodal-pdf-agent-n-8-n-docs-memory-context-patterns-57-a-3d4": [() => import(/* webpackChunkName: "content---multimodal-pdf-agent-n-8-n-docs-memory-context-patterns-57-a-3d4" */ "@site/docs/67-memory-context-patterns.mdx"), "@site/docs/67-memory-context-patterns.mdx", require.resolveWeak("@site/docs/67-memory-context-patterns.mdx")],
  "content---multimodal-pdf-agent-n-8-n-docs-mongodb-atlas-setup-7-fe-90e": [() => import(/* webpackChunkName: "content---multimodal-pdf-agent-n-8-n-docs-mongodb-atlas-setup-7-fe-90e" */ "@site/docs/30-mongodb-atlas-setup.mdx"), "@site/docs/30-mongodb-atlas-setup.mdx", require.resolveWeak("@site/docs/30-mongodb-atlas-setup.mdx")],
  "content---multimodal-pdf-agent-n-8-n-docs-mongodb-vector-setupe-72-fb1": [() => import(/* webpackChunkName: "content---multimodal-pdf-agent-n-8-n-docs-mongodb-vector-setupe-72-fb1" */ "@site/docs/75-mongodb-vector-setup.mdx"), "@site/docs/75-mongodb-vector-setup.mdx", require.resolveWeak("@site/docs/75-mongodb-vector-setup.mdx")],
  "content---multimodal-pdf-agent-n-8-n-docs-multimodal-image-queries-512-486": [() => import(/* webpackChunkName: "content---multimodal-pdf-agent-n-8-n-docs-multimodal-image-queries-512-486" */ "@site/docs/69-multimodal-image-queries.mdx"), "@site/docs/69-multimodal-image-queries.mdx", require.resolveWeak("@site/docs/69-multimodal-image-queries.mdx")],
  "content---multimodal-pdf-agent-n-8-n-docs-n-8-n-first-run-658-d41": [() => import(/* webpackChunkName: "content---multimodal-pdf-agent-n-8-n-docs-n-8-n-first-run-658-d41" */ "@site/docs/25-n8n-first-run.mdx"), "@site/docs/25-n8n-first-run.mdx", require.resolveWeak("@site/docs/25-n8n-first-run.mdx")],
  "content---multimodal-pdf-agent-n-8-n-docs-pdf-processing-workflow-05-e-3b5": [() => import(/* webpackChunkName: "content---multimodal-pdf-agent-n-8-n-docs-pdf-processing-workflow-05-e-3b5" */ "@site/docs/40-pdf-processing-workflow.mdx"), "@site/docs/40-pdf-processing-workflow.mdx", require.resolveWeak("@site/docs/40-pdf-processing-workflow.mdx")],
  "content---multimodal-pdf-agent-n-8-n-docs-prerequisitesb-49-028": [() => import(/* webpackChunkName: "content---multimodal-pdf-agent-n-8-n-docs-prerequisitesb-49-028" */ "@site/docs/20-prerequisites.mdx"), "@site/docs/20-prerequisites.mdx", require.resolveWeak("@site/docs/20-prerequisites.mdx")],
  "content---multimodal-pdf-agent-n-8-n-docs-python-mongodb-approaches-03-a-254": [() => import(/* webpackChunkName: "content---multimodal-pdf-agent-n-8-n-docs-python-mongodb-approaches-03-a-254" */ "@site/docs/85-python-mongodb-approaches.mdx"), "@site/docs/85-python-mongodb-approaches.mdx", require.resolveWeak("@site/docs/85-python-mongodb-approaches.mdx")],
  "content---multimodal-pdf-agent-n-8-n-docs-status-badge-usage-guide-73-d-8c8": [() => import(/* webpackChunkName: "content---multimodal-pdf-agent-n-8-n-docs-status-badge-usage-guide-73-d-8c8" */ "@site/docs/status-badge-usage-guide.mdx"), "@site/docs/status-badge-usage-guide.mdx", require.resolveWeak("@site/docs/status-badge-usage-guide.mdx")],
  "content---multimodal-pdf-agent-n-8-n-docs-summary-3-aa-d8e": [() => import(/* webpackChunkName: "content---multimodal-pdf-agent-n-8-n-docs-summary-3-aa-d8e" */ "@site/docs/summary.mdx"), "@site/docs/summary.mdx", require.resolveWeak("@site/docs/summary.mdx")],
  "content---multimodal-pdf-agent-n-8-n-docs-tool-definition-primerc-74-7e8": [() => import(/* webpackChunkName: "content---multimodal-pdf-agent-n-8-n-docs-tool-definition-primerc-74-7e8" */ "@site/docs/68-tool-definition-primer.mdx"), "@site/docs/68-tool-definition-primer.mdx", require.resolveWeak("@site/docs/68-tool-definition-primer.mdx")],
  "content---multimodal-pdf-agent-n-8-n-docs-upload-interface-442-038": [() => import(/* webpackChunkName: "content---multimodal-pdf-agent-n-8-n-docs-upload-interface-442-038" */ "@site/docs/80-upload-interface.mdx"), "@site/docs/80-upload-interface.mdx", require.resolveWeak("@site/docs/80-upload-interface.mdx")],
  "content---multimodal-pdf-agent-n-8-n-docs-vector-search-workflow-02-d-994": [() => import(/* webpackChunkName: "content---multimodal-pdf-agent-n-8-n-docs-vector-search-workflow-02-d-994" */ "@site/docs/50-vector-search-workflow.mdx"), "@site/docs/50-vector-search-workflow.mdx", require.resolveWeak("@site/docs/50-vector-search-workflow.mdx")],
  "content---multimodal-pdf-agent-n-8-n-docs-voyage-ai-setup-314-16c": [() => import(/* webpackChunkName: "content---multimodal-pdf-agent-n-8-n-docs-voyage-ai-setup-314-16c" */ "@site/docs/35-voyage-ai-setup.mdx"), "@site/docs/35-voyage-ai-setup.mdx", require.resolveWeak("@site/docs/35-voyage-ai-setup.mdx")],
  "plugin---multimodal-pdf-agent-n-8-n-docsaba-485": [() => import(/* webpackChunkName: "plugin---multimodal-pdf-agent-n-8-n-docsaba-485" */ "@generated/docusaurus-plugin-content-docs/default/__plugin.json"), "@generated/docusaurus-plugin-content-docs/default/__plugin.json", require.resolveWeak("@generated/docusaurus-plugin-content-docs/default/__plugin.json")],
  "plugin---multimodal-pdf-agent-n-8-n-docusaurus-debugb-38-6d5": [() => import(/* webpackChunkName: "plugin---multimodal-pdf-agent-n-8-n-docusaurus-debugb-38-6d5" */ "@generated/docusaurus-plugin-debug/default/__plugin.json"), "@generated/docusaurus-plugin-debug/default/__plugin.json", require.resolveWeak("@generated/docusaurus-plugin-debug/default/__plugin.json")],
  "plugin---multimodal-pdf-agent-n-8-n-hello-worlda-74-0eb": [() => import(/* webpackChunkName: "plugin---multimodal-pdf-agent-n-8-n-hello-worlda-74-0eb" */ "@generated/docusaurus-plugin-content-pages/default/__plugin.json"), "@generated/docusaurus-plugin-content-pages/default/__plugin.json", require.resolveWeak("@generated/docusaurus-plugin-content-pages/default/__plugin.json")],};

```

# .docusaurus/routes.js

```js
import React from 'react';
import ComponentCreator from '@docusaurus/ComponentCreator';

export default [
  {
    path: '/multimodal-pdf-agent-n8n/__docusaurus/debug',
    component: ComponentCreator('/multimodal-pdf-agent-n8n/__docusaurus/debug', 'd0b'),
    exact: true
  },
  {
    path: '/multimodal-pdf-agent-n8n/__docusaurus/debug/config',
    component: ComponentCreator('/multimodal-pdf-agent-n8n/__docusaurus/debug/config', '117'),
    exact: true
  },
  {
    path: '/multimodal-pdf-agent-n8n/__docusaurus/debug/content',
    component: ComponentCreator('/multimodal-pdf-agent-n8n/__docusaurus/debug/content', 'c4f'),
    exact: true
  },
  {
    path: '/multimodal-pdf-agent-n8n/__docusaurus/debug/globalData',
    component: ComponentCreator('/multimodal-pdf-agent-n8n/__docusaurus/debug/globalData', '941'),
    exact: true
  },
  {
    path: '/multimodal-pdf-agent-n8n/__docusaurus/debug/metadata',
    component: ComponentCreator('/multimodal-pdf-agent-n8n/__docusaurus/debug/metadata', '814'),
    exact: true
  },
  {
    path: '/multimodal-pdf-agent-n8n/__docusaurus/debug/registry',
    component: ComponentCreator('/multimodal-pdf-agent-n8n/__docusaurus/debug/registry', 'ac4'),
    exact: true
  },
  {
    path: '/multimodal-pdf-agent-n8n/__docusaurus/debug/routes',
    component: ComponentCreator('/multimodal-pdf-agent-n8n/__docusaurus/debug/routes', '904'),
    exact: true
  },
  {
    path: '/multimodal-pdf-agent-n8n/helloWorld',
    component: ComponentCreator('/multimodal-pdf-agent-n8n/helloWorld', '194'),
    exact: true
  },
  {
    path: '/multimodal-pdf-agent-n8n/docs',
    component: ComponentCreator('/multimodal-pdf-agent-n8n/docs', 'df9'),
    routes: [
      {
        path: '/multimodal-pdf-agent-n8n/docs',
        component: ComponentCreator('/multimodal-pdf-agent-n8n/docs', '22a'),
        routes: [
          {
            path: '/multimodal-pdf-agent-n8n/docs',
            component: ComponentCreator('/multimodal-pdf-agent-n8n/docs', 'e3c'),
            routes: [
              {
                path: '/multimodal-pdf-agent-n8n/docs',
                component: ComponentCreator('/multimodal-pdf-agent-n8n/docs', '248'),
                exact: true,
                sidebar: "tutorialSidebar"
              },
              {
                path: '/multimodal-pdf-agent-n8n/docs/agent-patterns',
                component: ComponentCreator('/multimodal-pdf-agent-n8n/docs/agent-patterns', 'abb'),
                exact: true,
                sidebar: "tutorialSidebar"
              },
              {
                path: '/multimodal-pdf-agent-n8n/docs/ai-agent-workflow',
                component: ComponentCreator('/multimodal-pdf-agent-n8n/docs/ai-agent-workflow', '2b2'),
                exact: true,
                sidebar: "tutorialSidebar"
              },
              {
                path: '/multimodal-pdf-agent-n8n/docs/api-architecture',
                component: ComponentCreator('/multimodal-pdf-agent-n8n/docs/api-architecture', '928'),
                exact: true,
                sidebar: "tutorialSidebar"
              },
              {
                path: '/multimodal-pdf-agent-n8n/docs/approach-comparison',
                component: ComponentCreator('/multimodal-pdf-agent-n8n/docs/approach-comparison', '55c'),
                exact: true,
                sidebar: "tutorialSidebar"
              },
              {
                path: '/multimodal-pdf-agent-n8n/docs/architecture-overview',
                component: ComponentCreator('/multimodal-pdf-agent-n8n/docs/architecture-overview', 'e95'),
                exact: true,
                sidebar: "tutorialSidebar"
              },
              {
                path: '/multimodal-pdf-agent-n8n/docs/codebase',
                component: ComponentCreator('/multimodal-pdf-agent-n8n/docs/codebase', '522'),
                exact: true
              },
              {
                path: '/multimodal-pdf-agent-n8n/docs/community-resources',
                component: ComponentCreator('/multimodal-pdf-agent-n8n/docs/community-resources', '96d'),
                exact: true,
                sidebar: "tutorialSidebar"
              },
              {
                path: '/multimodal-pdf-agent-n8n/docs/complete-multimodal-agent',
                component: ComponentCreator('/multimodal-pdf-agent-n8n/docs/complete-multimodal-agent', '4c7'),
                exact: true,
                sidebar: "tutorialSidebar"
              },
              {
                path: '/multimodal-pdf-agent-n8n/docs/docker-troubleshooting',
                component: ComponentCreator('/multimodal-pdf-agent-n8n/docs/docker-troubleshooting', 'd0c'),
                exact: true,
                sidebar: "tutorialSidebar"
              },
              {
                path: '/multimodal-pdf-agent-n8n/docs/exercise-advanced-tools',
                component: ComponentCreator('/multimodal-pdf-agent-n8n/docs/exercise-advanced-tools', '52f'),
                exact: true,
                sidebar: "tutorialSidebar"
              },
              {
                path: '/multimodal-pdf-agent-n8n/docs/exercise-memory-context',
                component: ComponentCreator('/multimodal-pdf-agent-n8n/docs/exercise-memory-context', 'd02'),
                exact: true,
                sidebar: "tutorialSidebar"
              },
              {
                path: '/multimodal-pdf-agent-n8n/docs/exercise-pdf-rag-agent',
                component: ComponentCreator('/multimodal-pdf-agent-n8n/docs/exercise-pdf-rag-agent', '4b6'),
                exact: true,
                sidebar: "tutorialSidebar"
              },
              {
                path: '/multimodal-pdf-agent-n8n/docs/github-codespaces',
                component: ComponentCreator('/multimodal-pdf-agent-n8n/docs/github-codespaces', 'b20'),
                exact: true,
                sidebar: "tutorialSidebar"
              },
              {
                path: '/multimodal-pdf-agent-n8n/docs/intro',
                component: ComponentCreator('/multimodal-pdf-agent-n8n/docs/intro', '2d3'),
                exact: true,
                sidebar: "tutorialSidebar"
              },
              {
                path: '/multimodal-pdf-agent-n8n/docs/local-setup-tips',
                component: ComponentCreator('/multimodal-pdf-agent-n8n/docs/local-setup-tips', '7a9'),
                exact: true,
                sidebar: "tutorialSidebar"
              },
              {
                path: '/multimodal-pdf-agent-n8n/docs/memory-context-patterns',
                component: ComponentCreator('/multimodal-pdf-agent-n8n/docs/memory-context-patterns', 'a9b'),
                exact: true,
                sidebar: "tutorialSidebar"
              },
              {
                path: '/multimodal-pdf-agent-n8n/docs/mongodb-atlas-setup',
                component: ComponentCreator('/multimodal-pdf-agent-n8n/docs/mongodb-atlas-setup', 'baf'),
                exact: true,
                sidebar: "tutorialSidebar"
              },
              {
                path: '/multimodal-pdf-agent-n8n/docs/mongodb-vector-setup',
                component: ComponentCreator('/multimodal-pdf-agent-n8n/docs/mongodb-vector-setup', 'd7a'),
                exact: true,
                sidebar: "tutorialSidebar"
              },
              {
                path: '/multimodal-pdf-agent-n8n/docs/multimodal-image-queries',
                component: ComponentCreator('/multimodal-pdf-agent-n8n/docs/multimodal-image-queries', '0d5'),
                exact: true,
                sidebar: "tutorialSidebar"
              },
              {
                path: '/multimodal-pdf-agent-n8n/docs/n8n-first-run',
                component: ComponentCreator('/multimodal-pdf-agent-n8n/docs/n8n-first-run', '529'),
                exact: true,
                sidebar: "tutorialSidebar"
              },
              {
                path: '/multimodal-pdf-agent-n8n/docs/pdf-processing-workflow',
                component: ComponentCreator('/multimodal-pdf-agent-n8n/docs/pdf-processing-workflow', '808'),
                exact: true,
                sidebar: "tutorialSidebar"
              },
              {
                path: '/multimodal-pdf-agent-n8n/docs/prerequisites',
                component: ComponentCreator('/multimodal-pdf-agent-n8n/docs/prerequisites', '88c'),
                exact: true,
                sidebar: "tutorialSidebar"
              },
              {
                path: '/multimodal-pdf-agent-n8n/docs/python-mongodb-approaches',
                component: ComponentCreator('/multimodal-pdf-agent-n8n/docs/python-mongodb-approaches', '391'),
                exact: true,
                sidebar: "tutorialSidebar"
              },
              {
                path: '/multimodal-pdf-agent-n8n/docs/status-badge-usage-guide',
                component: ComponentCreator('/multimodal-pdf-agent-n8n/docs/status-badge-usage-guide', 'e78'),
                exact: true,
                sidebar: "tutorialSidebar"
              },
              {
                path: '/multimodal-pdf-agent-n8n/docs/summary',
                component: ComponentCreator('/multimodal-pdf-agent-n8n/docs/summary', '6fa'),
                exact: true,
                sidebar: "tutorialSidebar"
              },
              {
                path: '/multimodal-pdf-agent-n8n/docs/tool-definition-primer',
                component: ComponentCreator('/multimodal-pdf-agent-n8n/docs/tool-definition-primer', '3b0'),
                exact: true,
                sidebar: "tutorialSidebar"
              },
              {
                path: '/multimodal-pdf-agent-n8n/docs/upload-interface',
                component: ComponentCreator('/multimodal-pdf-agent-n8n/docs/upload-interface', '8ed'),
                exact: true,
                sidebar: "tutorialSidebar"
              },
              {
                path: '/multimodal-pdf-agent-n8n/docs/vector-search-workflow',
                component: ComponentCreator('/multimodal-pdf-agent-n8n/docs/vector-search-workflow', '5e0'),
                exact: true,
                sidebar: "tutorialSidebar"
              },
              {
                path: '/multimodal-pdf-agent-n8n/docs/voyage-ai-setup',
                component: ComponentCreator('/multimodal-pdf-agent-n8n/docs/voyage-ai-setup', '77a'),
                exact: true,
                sidebar: "tutorialSidebar"
              }
            ]
          }
        ]
      }
    ]
  },
  {
    path: '/multimodal-pdf-agent-n8n/',
    component: ComponentCreator('/multimodal-pdf-agent-n8n/', '7a9'),
    exact: true
  },
  {
    path: '*',
    component: ComponentCreator('*'),
  },
];

```

# .docusaurus/routesChunkNames.json

```json
{
  "/multimodal-pdf-agent-n8n/__docusaurus/debug-d0b": {
    "__comp": "__comp---theme-debug-config-23-a-2ff",
    "__context": {
      "plugin": "plugin---multimodal-pdf-agent-n-8-n-docusaurus-debugb-38-6d5"
    }
  },
  "/multimodal-pdf-agent-n8n/__docusaurus/debug/config-117": {
    "__comp": "__comp---theme-debug-config-23-a-2ff",
    "__context": {
      "plugin": "plugin---multimodal-pdf-agent-n-8-n-docusaurus-debugb-38-6d5"
    }
  },
  "/multimodal-pdf-agent-n8n/__docusaurus/debug/content-c4f": {
    "__comp": "__comp---theme-debug-contentba-8-ce7",
    "__context": {
      "plugin": "plugin---multimodal-pdf-agent-n-8-n-docusaurus-debugb-38-6d5"
    },
    "__props": "__props---multimodal-pdf-agent-n-8-n-docusaurus-debug-contenta-00-4cc"
  },
  "/multimodal-pdf-agent-n8n/__docusaurus/debug/globalData-941": {
    "__comp": "__comp---theme-debug-global-dataede-0fa",
    "__context": {
      "plugin": "plugin---multimodal-pdf-agent-n-8-n-docusaurus-debugb-38-6d5"
    }
  },
  "/multimodal-pdf-agent-n8n/__docusaurus/debug/metadata-814": {
    "__comp": "__comp---theme-debug-site-metadata-68-e-3d4",
    "__context": {
      "plugin": "plugin---multimodal-pdf-agent-n-8-n-docusaurus-debugb-38-6d5"
    }
  },
  "/multimodal-pdf-agent-n8n/__docusaurus/debug/registry-ac4": {
    "__comp": "__comp---theme-debug-registry-679-501",
    "__context": {
      "plugin": "plugin---multimodal-pdf-agent-n-8-n-docusaurus-debugb-38-6d5"
    }
  },
  "/multimodal-pdf-agent-n8n/__docusaurus/debug/routes-904": {
    "__comp": "__comp---theme-debug-routes-946-699",
    "__context": {
      "plugin": "plugin---multimodal-pdf-agent-n-8-n-docusaurus-debugb-38-6d5"
    }
  },
  "/multimodal-pdf-agent-n8n/helloWorld-194": {
    "__comp": "__comp---site-src-pages-hello-world-js-72-d-375",
    "__context": {
      "plugin": "plugin---multimodal-pdf-agent-n-8-n-hello-worlda-74-0eb"
    },
    "config": "config---multimodal-pdf-agent-n-8-n-hello-world-5-e-9-00a"
  },
  "/multimodal-pdf-agent-n8n/docs-df9": {
    "__comp": "__comp---theme-docs-root-5-e-9-0b6",
    "__context": {
      "plugin": "plugin---multimodal-pdf-agent-n-8-n-docsaba-485"
    }
  },
  "/multimodal-pdf-agent-n8n/docs-22a": {
    "__comp": "__comp---theme-doc-version-roota-7-b-5de",
    "__props": "__props---multimodal-pdf-agent-n-8-n-docs-2-ee-9f5"
  },
  "/multimodal-pdf-agent-n8n/docs-e3c": {
    "__comp": "__comp---theme-doc-roota-94-67a"
  },
  "/multimodal-pdf-agent-n8n/docs-248": {
    "__comp": "__comp---theme-doc-item-178-a40",
    "content": "content---multimodal-pdf-agent-n-8-n-docs-4-ed-86c"
  },
  "/multimodal-pdf-agent-n8n/docs/agent-patterns-abb": {
    "__comp": "__comp---theme-doc-item-178-a40",
    "content": "content---multimodal-pdf-agent-n-8-n-docs-agent-patterns-42-d-320"
  },
  "/multimodal-pdf-agent-n8n/docs/ai-agent-workflow-2b2": {
    "__comp": "__comp---theme-doc-item-178-a40",
    "content": "content---multimodal-pdf-agent-n-8-n-docs-ai-agent-workflow-600-b25"
  },
  "/multimodal-pdf-agent-n8n/docs/api-architecture-928": {
    "__comp": "__comp---theme-doc-item-178-a40",
    "content": "content---multimodal-pdf-agent-n-8-n-docs-api-architecture-137-674"
  },
  "/multimodal-pdf-agent-n8n/docs/approach-comparison-55c": {
    "__comp": "__comp---theme-doc-item-178-a40",
    "content": "content---multimodal-pdf-agent-n-8-n-docs-approach-comparisonabe-8e2"
  },
  "/multimodal-pdf-agent-n8n/docs/architecture-overview-e95": {
    "__comp": "__comp---theme-doc-item-178-a40",
    "content": "content---multimodal-pdf-agent-n-8-n-docs-architecture-overviewad-9-564"
  },
  "/multimodal-pdf-agent-n8n/docs/codebase-522": {
    "__comp": "__comp---theme-doc-item-178-a40",
    "content": "content---multimodal-pdf-agent-n-8-n-docs-codebase-282-bb5"
  },
  "/multimodal-pdf-agent-n8n/docs/community-resources-96d": {
    "__comp": "__comp---theme-doc-item-178-a40",
    "content": "content---multimodal-pdf-agent-n-8-n-docs-community-resourcesb-5-e-4df"
  },
  "/multimodal-pdf-agent-n8n/docs/complete-multimodal-agent-4c7": {
    "__comp": "__comp---theme-doc-item-178-a40",
    "content": "content---multimodal-pdf-agent-n-8-n-docs-complete-multimodal-agent-802-85b"
  },
  "/multimodal-pdf-agent-n8n/docs/docker-troubleshooting-d0c": {
    "__comp": "__comp---theme-doc-item-178-a40",
    "content": "content---multimodal-pdf-agent-n-8-n-docs-docker-troubleshooting-827-9bb"
  },
  "/multimodal-pdf-agent-n8n/docs/exercise-advanced-tools-52f": {
    "__comp": "__comp---theme-doc-item-178-a40",
    "content": "content---multimodal-pdf-agent-n-8-n-docs-exercise-advanced-tools-561-f6e"
  },
  "/multimodal-pdf-agent-n8n/docs/exercise-memory-context-d02": {
    "__comp": "__comp---theme-doc-item-178-a40",
    "content": "content---multimodal-pdf-agent-n-8-n-docs-exercise-memory-contextd-23-91f"
  },
  "/multimodal-pdf-agent-n8n/docs/exercise-pdf-rag-agent-4b6": {
    "__comp": "__comp---theme-doc-item-178-a40",
    "content": "content---multimodal-pdf-agent-n-8-n-docs-exercise-pdf-rag-agentde-6-389"
  },
  "/multimodal-pdf-agent-n8n/docs/github-codespaces-b20": {
    "__comp": "__comp---theme-doc-item-178-a40",
    "content": "content---multimodal-pdf-agent-n-8-n-docs-github-codespaceseb-7-bd3"
  },
  "/multimodal-pdf-agent-n8n/docs/intro-2d3": {
    "__comp": "__comp---theme-doc-item-178-a40",
    "content": "content---multimodal-pdf-agent-n-8-n-docs-intro-317-a69"
  },
  "/multimodal-pdf-agent-n8n/docs/local-setup-tips-7a9": {
    "__comp": "__comp---theme-doc-item-178-a40",
    "content": "content---multimodal-pdf-agent-n-8-n-docs-local-setup-tips-68-d-8a3"
  },
  "/multimodal-pdf-agent-n8n/docs/memory-context-patterns-a9b": {
    "__comp": "__comp---theme-doc-item-178-a40",
    "content": "content---multimodal-pdf-agent-n-8-n-docs-memory-context-patterns-57-a-3d4"
  },
  "/multimodal-pdf-agent-n8n/docs/mongodb-atlas-setup-baf": {
    "__comp": "__comp---theme-doc-item-178-a40",
    "content": "content---multimodal-pdf-agent-n-8-n-docs-mongodb-atlas-setup-7-fe-90e"
  },
  "/multimodal-pdf-agent-n8n/docs/mongodb-vector-setup-d7a": {
    "__comp": "__comp---theme-doc-item-178-a40",
    "content": "content---multimodal-pdf-agent-n-8-n-docs-mongodb-vector-setupe-72-fb1"
  },
  "/multimodal-pdf-agent-n8n/docs/multimodal-image-queries-0d5": {
    "__comp": "__comp---theme-doc-item-178-a40",
    "content": "content---multimodal-pdf-agent-n-8-n-docs-multimodal-image-queries-512-486"
  },
  "/multimodal-pdf-agent-n8n/docs/n8n-first-run-529": {
    "__comp": "__comp---theme-doc-item-178-a40",
    "content": "content---multimodal-pdf-agent-n-8-n-docs-n-8-n-first-run-658-d41"
  },
  "/multimodal-pdf-agent-n8n/docs/pdf-processing-workflow-808": {
    "__comp": "__comp---theme-doc-item-178-a40",
    "content": "content---multimodal-pdf-agent-n-8-n-docs-pdf-processing-workflow-05-e-3b5"
  },
  "/multimodal-pdf-agent-n8n/docs/prerequisites-88c": {
    "__comp": "__comp---theme-doc-item-178-a40",
    "content": "content---multimodal-pdf-agent-n-8-n-docs-prerequisitesb-49-028"
  },
  "/multimodal-pdf-agent-n8n/docs/python-mongodb-approaches-391": {
    "__comp": "__comp---theme-doc-item-178-a40",
    "content": "content---multimodal-pdf-agent-n-8-n-docs-python-mongodb-approaches-03-a-254"
  },
  "/multimodal-pdf-agent-n8n/docs/status-badge-usage-guide-e78": {
    "__comp": "__comp---theme-doc-item-178-a40",
    "content": "content---multimodal-pdf-agent-n-8-n-docs-status-badge-usage-guide-73-d-8c8"
  },
  "/multimodal-pdf-agent-n8n/docs/summary-6fa": {
    "__comp": "__comp---theme-doc-item-178-a40",
    "content": "content---multimodal-pdf-agent-n-8-n-docs-summary-3-aa-d8e"
  },
  "/multimodal-pdf-agent-n8n/docs/tool-definition-primer-3b0": {
    "__comp": "__comp---theme-doc-item-178-a40",
    "content": "content---multimodal-pdf-agent-n-8-n-docs-tool-definition-primerc-74-7e8"
  },
  "/multimodal-pdf-agent-n8n/docs/upload-interface-8ed": {
    "__comp": "__comp---theme-doc-item-178-a40",
    "content": "content---multimodal-pdf-agent-n-8-n-docs-upload-interface-442-038"
  },
  "/multimodal-pdf-agent-n8n/docs/vector-search-workflow-5e0": {
    "__comp": "__comp---theme-doc-item-178-a40",
    "content": "content---multimodal-pdf-agent-n-8-n-docs-vector-search-workflow-02-d-994"
  },
  "/multimodal-pdf-agent-n8n/docs/voyage-ai-setup-77a": {
    "__comp": "__comp---theme-doc-item-178-a40",
    "content": "content---multimodal-pdf-agent-n-8-n-docs-voyage-ai-setup-314-16c"
  },
  "/multimodal-pdf-agent-n8n/-7a9": {
    "__comp": "__comp---site-src-pages-index-jsc-4-f-f99",
    "__context": {
      "plugin": "plugin---multimodal-pdf-agent-n-8-n-hello-worlda-74-0eb"
    },
    "config": "config---multimodal-pdf-agent-n-8-n-hello-world-5-e-9-00a"
  }
}
```

# .docusaurus/site-metadata.json

```json
{
  "docusaurusVersion": "3.8.1",
  "siteVersion": "2.3.0",
  "pluginVersions": {
    "docusaurus-plugin-css-cascade-layers": {
      "type": "package",
      "name": "@docusaurus/plugin-css-cascade-layers",
      "version": "3.8.1"
    },
    "docusaurus-plugin-content-docs": {
      "type": "package",
      "name": "@docusaurus/plugin-content-docs",
      "version": "3.8.1"
    },
    "docusaurus-plugin-content-blog": {
      "type": "package",
      "name": "@docusaurus/plugin-content-blog",
      "version": "3.8.1"
    },
    "docusaurus-plugin-content-pages": {
      "type": "package",
      "name": "@docusaurus/plugin-content-pages",
      "version": "3.8.1"
    },
    "docusaurus-plugin-debug": {
      "type": "package",
      "name": "@docusaurus/plugin-debug",
      "version": "3.8.1"
    },
    "docusaurus-plugin-svgr": {
      "type": "package",
      "name": "@docusaurus/plugin-svgr",
      "version": "3.8.1"
    },
    "docusaurus-theme-classic": {
      "type": "package",
      "name": "@docusaurus/theme-classic",
      "version": "3.8.1"
    },
    "docusaurus-lunr-search": {
      "type": "package",
      "name": "docusaurus-lunr-search",
      "version": "3.6.1"
    },
    "docusaurus-theme-mermaid": {
      "type": "package",
      "name": "@docusaurus/theme-mermaid",
      "version": "3.8.1"
    }
  }
}
```

# .docusaurus/site-storage.json

```json
{
  "type": "localStorage",
  "namespace": "-555"
}
```

# .gitignore

```
node_modules
build
dist
.DS_Store
.claude
.docusaurus
.docusaurus/*
.vercel
DOCUMENTATION-UPDATE-PROMPT.md

```

# CLAUDE.md

```md
# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Overview

This is a Docusaurus-based documentation site for a workshop on building multimodal PDF agents with n8n, MongoDB Atlas, and Voyage AI. The site serves as educational content for workshop participants working in GitHub Codespaces.

## Development Commands

### Local Development
\`\`\`bash
npm install          # Install dependencies
npm start           # Start dev server (accessible on 0.0.0.0:3000)
npm run build       # Build for production
npm run serve       # Serve built site (accessible on 0.0.0.0:3000)
\`\`\`

### Workshop-Specific Commands
\`\`\`bash
npm run workshop:setup    # Run setup script from .devcontainer/
npm run workshop:start    # Start Docker services and dev server
npm run workshop:stop     # Stop Docker services
npm run workshop:restart  # Restart Docker services
npm run workshop:logs     # View Docker service logs
npm run workshop:reset    # Reset Docker services (removes volumes)
npm run dev               # Start both docs site and Docker services
npm run test:services     # Test workshop services
\`\`\`

### Other Commands
\`\`\`bash
npm run clear             # Clear Docusaurus cache
npm run deploy           # Deploy to GitHub Pages
npm run swizzle          # Customize Docusaurus components
\`\`\`

## Architecture

### Site Structure
- **docs/** - Workshop tutorial pages (MDX format, auto-generated sidebar)
- **src/components/** - Custom React components (BrowserWindow, Screenshot, Link)
- **src/pages/** - Custom pages (homepage, helloWorld)
- **static/** - Static assets (images, PDFs, upload interface HTML)
- **docusaurus.config.js** - Main site configuration

### Key Configuration
- **Workshop Name**: `multimodal-pdf-agent-n8n`
- **Organization**: `mongodb-developer`
- **Deployment**: Configured for both GitHub Pages and Vercel
- **Features**: Mermaid diagrams, search (Lunr), internationalization (en/es)
- **Codespaces Support**: Dynamic URL configuration for port forwarding

### Content Organization
Tutorial content follows numerical naming (10-intro.mdx, 20-prerequisites.mdx, etc.) for ordered presentation. The sidebar is auto-generated from the docs/ folder structure.

### Deployment Targets
- **Vercel**: Configured via vercel.json with npm build command
- **GitHub Pages**: Configured for gh-pages deployment branch
- **Codespaces**: Dynamic URL handling for development environment

## Custom Components
- **BrowserWindow**: Simulates browser interface for screenshots
- **Screenshot**: Displays workshop screenshots
- **Link**: Enhanced link component
- **MDXComponents**: Custom MDX component mappings
```

# COMPONENT-USAGE-GUIDE.md

```md
# 📖 Workshop Component Usage Guide

This guide explains how to use the custom workshop components throughout your documentation.

## 🎯 Component Overview

### 1. WorkshopTransition
**Purpose**: Bridge between Google Slides presentation and hands-on Docusaurus content.
**Where it's used**: Currently only on the main workshop overview page (`docs/index.mdx`)
**When to use**: At the very beginning of your workshop documentation to welcome attendees transitioning from slides.

### 2. InstructorNotes
**Purpose**: Provide timing, tips, and guidance for workshop instructors.
**Where it's used**: Throughout the documentation (`index.mdx`, `10-intro.mdx`, `25-n8n-first-run.mdx`, `30-mongodb-atlas-setup.mdx`)
**When to use**: At the beginning of each major section or before complex exercises.

### 3. SlideRecap
**Purpose**: Summarize what was covered in the Google Slides before diving into hands-on content.
**Where it's used**: Currently in `10-intro.mdx`
**When to use**: After transitioning from slides to reinforce key concepts.

### 4. QRCodeAccess
**Purpose**: Generate QR codes for easy mobile access to workshop materials.
**Where it's used**: Bottom of `index.mdx`
**When to use**: Anywhere you want attendees to quickly access a URL on their phones.

## 📝 Usage Examples

### WorkshopTransition

\`\`\`jsx
<WorkshopTransition 
  slideTopics={[
    "Workshop overview and learning objectives",
    "Architecture overview", 
    "Technology stack introduction"
  ]}
  instructor="Michael Lynn"
  welcomeMessage="Welcome to the Hands-On Workshop!"
  handsOnUrl="/docs/intro"
/>
\`\`\`

**Best practices:**
- Use only on the main landing page
- List 3-5 key slide topics
- Customize instructor name
- Optional: Override welcome message

### InstructorNotes

\`\`\`jsx
<InstructorNotes 
  timing="MongoDB Atlas Setup (15-20 minutes)"
  notes={[
    "Atlas signup can take a few minutes - start early",
    "Credit card may be required but we'll stay in free tier",
    "Network access setup often confuses first-time users"
  ]}
  tips={[
    "Demo the Atlas setup on screen while attendees follow",
    "Have backup connection strings ready",
    "Consider pair programming for troubleshooting"
  ]}
/>
\`\`\`

**Best practices:**
- Include realistic timing estimates
- Add 3-5 practical notes from experience
- Provide actionable tips
- Place at the beginning of sections

### SlideRecap

\`\`\`jsx
<SlideRecap 
  title="From Presentation to Practice"
  items={[
    {
      icon: "🏗️",
      title: "Architecture Overview",
      description: "We covered how n8n, MongoDB Atlas, and Voyage AI work together"
    },
    {
      icon: "🎯", 
      title: "Learning Objectives",
      description: "Build a production-ready multimodal PDF processing system"
    }
  ]}
  nextSection="Now we'll build this system step by step!"
/>
\`\`\`

**Best practices:**
- Use after transitioning from slides
- Include 3-4 key concepts from slides
- Use relevant emojis for visual appeal
- End with encouraging next step message

### QRCodeAccess

\`\`\`jsx
<QRCodeAccess 
  url={typeof window !== 'undefined' ? window.location.origin + '/docs/' : 'https://workshop.example.com/docs/'}
  title="Share Workshop Materials"
/>
\`\`\`

**Best practices:**
- Use dynamic URL generation when possible
- Provide fallback URL for SSR
- Place where attendees might need mobile access
- Consider adding at section transitions

## 🚀 Where to Add More Components

### Recommended Additions:

1. **InstructorNotes** - Add to every major section:
   - `prerequisites.mdx` - Common setup issues
   - `github-codespaces.mdx` - Port forwarding tips
   - `pdf-processing-workflow.mdx` - Debugging workflow issues
   - `voyage-ai-setup.mdx` - API key management
   - `vector-search-implementation.mdx` - Index creation timing
   - `ai-agent-workflow.mdx` - Model selection guidance
   - `complete-multimodal-agent.mdx` - Integration testing tips

2. **SlideRecap** - Add after major conceptual sections:
   - After prerequisites overview
   - Before starting PDF processing
   - Before vector search implementation

3. **QRCodeAccess** - Add for:
   - External resources (MongoDB Atlas signup)
   - API documentation links
   - Sample file downloads
   - Final deployed application

## 💡 Component Composition

You can combine components for powerful experiences:

\`\`\`jsx
{/* Start of a major section */}
<SlideRecap 
  title="Vector Search Concepts"
  items={[...]}
/>

<InstructorNotes 
  timing="20 minutes"
  notes={["Start MongoDB Atlas setup early"]}
/>

<WorkshopExercise>
  {/* Exercise content */}
</WorkshopExercise>

{/* End with access options */}
<QRCodeAccess 
  url="https://docs.mongodb.com/atlas"
  title="MongoDB Atlas Documentation"
/>
\`\`\`

## 🎨 Styling Guidelines

1. **Consistency**: Use components in similar patterns across sections
2. **Visibility**: InstructorNotes should be at section starts
3. **Context**: SlideRecap should reference actual slide content
4. **Accessibility**: QR codes should include text URLs too

## 📊 Current Usage Statistics

- **WorkshopTransition**: 1 instance (index.mdx)
- **InstructorNotes**: 4 instances across 3 files
- **SlideRecap**: 1 instance (10-intro.mdx)
- **QRCodeAccess**: 1 instance (index.mdx)

## 🔄 Next Steps

1. Add InstructorNotes to remaining sections
2. Create SlideRecap components for major transitions
3. Add QRCodeAccess for external resources
4. Consider creating a WorkshopFeedback component
5. Build a WorkshopResources component for additional materials

## 🛠️ Maintenance

- Review instructor notes after each workshop
- Update timing estimates based on actual experience
- Add new tips discovered during delivery
- Keep slide topics synchronized with actual presentation
```

# docs/10-intro.mdx

```mdx
---
sidebar_position: 10
---

# 📘 Introduction to Multimodal PDF Agents with n8n

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

|Workshop goals|Build a multimodal AI agent that processes PDFs using n8n, MongoDB Atlas, and Voyage AI|
|-|-|
|What you'll learn|Visual workflow automation, vector search, multimodal embeddings, AI agent patterns|
|Prerequisites|n8n installed, MongoDB Atlas account, Voyage AI API key|
|Time to complete|2 hours|

<SlideRecap 
  title="From Presentation to Practice"
  items={[
    {
      icon: "🏗️",
      title: "Architecture Overview",
      description: "We covered how n8n, MongoDB Atlas, and Voyage AI work together"
    },
    {
      icon: "🎯", 
      title: "Learning Objectives",
      description: "Build a production-ready multimodal PDF processing system"
    },
    {
      icon: "⚡",
      title: "Visual Workflows",
      description: "Why n8n's no-code approach makes AI development accessible"
    }
  ]}
  nextSection="Now we'll build this system step by step!"
/>

<ProgressTracker steps={[
  {
    title: "Environment Setup",
    description: "Set up Docker, n8n, and MongoDB Atlas",
    timeEstimate: "15 minutes",
    difficulty: "beginner"
  },
  {
    title: "PDF Processing Workflow", 
    description: "Build workflow to extract and process PDF content",
    timeEstimate: "25 minutes",
    difficulty: "intermediate"
  },
  {
    title: "Vector Search Implementation",
    description: "Configure MongoDB Atlas Vector Search",
    timeEstimate: "20 minutes", 
    difficulty: "intermediate"
  },
  {
    title: "AI Agent Creation",
    description: "Build intelligent agent with tool calling",
    timeEstimate: "30 minutes",
    difficulty: "advanced"
  },
  {
    title: "Memory & Context",
    description: "Add conversation history and context management",
    timeEstimate: "20 minutes",
    difficulty: "advanced"
  },
  {
    title: "Production Deployment",
    description: "Deploy and scale your multimodal agent",
    timeEstimate: "15 minutes",
    difficulty: "intermediate"
  }
]} />

## 🎯 What We're Building

A production-ready system that:
- **Ingests PDFs** and extracts both text and images
- **Generates multimodal embeddings** using Voyage AI
- **Stores in MongoDB Atlas** with vector search capabilities
- **Provides an AI agent** with tool calling via Gemini 2.0
- **Maintains conversation memory** for context
- **Implements ReAct pattern** for intelligent reasoning

## 🏗️ Architecture Overview

\`\`\`mermaid
graph LR
    A[PDF Input] --> B[n8n Workflow]
    B --> C[Page Extraction]
    C --> D[Voyage AI Embeddings]
    D --> E[MongoDB Atlas]
    F[User Query] --> G[AI Agent]
    G --> H[Vector Search]
    H --> E
    G --> I[Gemini Response]
\`\`\`

## 🚀 Why This Approach?

### Visual Development
- No code complexity
- See data flow in real-time
- Easy debugging and modification

### Production Ready
- Built-in error handling
- Scalable architecture
- Enterprise features

### Best-in-Class Tools
- **MongoDB Atlas**: Leading vector database
- **Voyage AI**: State-of-the-art multimodal embeddings
- **n8n**: Powerful workflow automation
- **Gemini 2.0**: Advanced AI capabilities

## 🚀 Choose Your Setup Method

<WorkshopExercise 
  title="Setup Your Development Environment" 
  difficulty="beginner"
  timeEstimate="15 minutes"
  objectives={[
    "Choose between Codespaces or local development",
    "Set up all required services and tools", 
    "Verify your environment is working correctly"
  ]}
>

<Tabs>
  <TabItem value="cloud" label="☁️ GitHub Codespaces (Fastest)" default>

<ExerciseStep stepNumber="1" title="Launch GitHub Codespaces">

**Zero Installation Required!** Everything runs in your browser:

<TerminalCommand 
  command="# Navigate to deployment repository"
  output="Opening: https://github.com/mongodb-developer/multimodal-pdf-agent-n8n"
/>

1. Go to [deployment repository](https://github.com/mongodb-developer/multimodal-pdf-agent-n8n)
2. Click **Code** → **Codespaces** → **Create codespace**  
3. Wait for automatic setup (3-5 minutes first time)
4. All services start automatically

**Requirements:**
- GitHub account (free)
- Web browser
- Internet connection

</ExerciseStep>

<ExerciseValidation 
  title="Verify Codespaces Setup"
  checks={[
    {
      id: "codespace_running",
      description: "Codespace is running and accessible",
      hint: "Check that VS Code opens in your browser"
    },
    {
      id: "ports_forwarded", 
      description: "Ports are automatically forwarded (check Ports tab)",
      hint: "Look for ports 5678 and 3000 in the Ports panel"
    },
    {
      id: "services_healthy",
      description: "All Docker services are running (green status)",
      hint: "Run 'docker-compose ps' in the terminal"
    }
  ]}
/>

👉 **[Continue with Codespaces Setup](./github-codespaces)**

  </TabItem>
  <TabItem value="local" label="🐳 Local Docker">

<ExerciseStep stepNumber="1" title="Clone and Start Services">

**Full control** - Work offline, customize everything:

<CodeBlock language="bash" title="Local Setup Commands">
{`# Clone workshop deployment repo
git clone https://github.com/mongodb-developer/multimodal-pdf-agent-n8n.git
cd multimodal-pdf-agent-n8n

# Start services
cp .env.example .env
docker-compose up -d`}
</CodeBlock>

<ServiceTester 
  serviceName="n8n"
  testUrl="http://localhost:5678"
  testData={{}}
/>

**Requirements:**
- Docker Desktop
- Git
- 8GB RAM

</ExerciseStep>

<ExerciseValidation 
  title="Verify Local Setup"
  checks={[
    {
      id: "docker_running",
      description: "Docker Desktop is running",
      hint: "Check Docker icon in system tray"
    },
    {
      id: "services_up",
      description: "All services are up (docker-compose ps shows 'Up')",
      hint: "Run 'docker-compose ps' to check status"
    },
    {
      id: "n8n_accessible",
      description: "n8n is accessible at http://localhost:5678",
      hint: "Open the URL in your browser"
    },
    {
      id: "mongodb_accessible",
      description: "MongoDB Atlas is configured and ready for vector search",
      hint: "Open the URL in your browser"
    }
  ]}
/>

👉 **[Continue with Local Setup](./prerequisites)**

  </TabItem>
</Tabs>

</WorkshopExercise>

## 📋 Required for Both Methods

✅ **MongoDB Atlas account** (free tier) - [Sign up](https://www.mongodb.com/try)  
✅ **Google AI Studio API key** for Gemini (optional) - [Get key](https://makersuite.google.com/app/apikey)  
✅ **Sample PDFs** for testing  

## 🗺️ Workshop Journey

1. **Environment Setup** → Get all tools configured
2. **PDF Processing** → Build ingestion workflow
3. **Vector Search** → Implement similarity search
4. **AI Agent** → Create intelligent assistant
5. **Memory & Context** → Add conversation history
6. **ReAct Pattern** → Implement reasoning loops
7. **Production Deploy** → Scale your solution

## 💡 Key Concepts

### Multimodal Embeddings
Voyage AI's `voyage-multimodal-3` model processes both text and images into a unified vector space, enabling semantic search across different content types.

### Vector Search
MongoDB Atlas Vector Search provides efficient similarity search at scale, perfect for RAG (Retrieval Augmented Generation) applications.

### Visual Workflows
n8n's node-based interface makes complex integrations intuitive, with built-in error handling and monitoring.

### Agent Patterns
We'll implement industry-standard patterns like tool calling and ReAct (Reasoning and Acting) for intelligent agent behavior.

## 🎓 Learning Outcomes

By the end of this workshop, you'll be able to:

1. **Design and build** visual AI workflows in n8n
2. **Process multimodal content** from PDFs
3. **Implement vector search** with MongoDB Atlas
4. **Create AI agents** with tool calling capabilities
5. **Add memory** to maintain context
6. **Deploy to production** with confidence

## 🐍 Beyond Visual Workflows

While this workshop focuses on n8n's visual approach, we also cover **Python integration options** for developers who want programmatic control:

- **MongoDB Multimodal Search Library** - High-level Python SDK
- **Direct PyMongo Integration** - Maximum performance and control  
- **Hybrid Approaches** - Combine n8n orchestration with Python logic
- **LangChain Integration** - Advanced RAG patterns

These approaches all use the same MongoDB Atlas and Voyage AI foundation you'll learn about in the visual workflows!

## 🚦 Ready to Start?

Let's begin by setting up your development environment and ensuring all prerequisites are in place.

[Get Started with Prerequisites →](./prerequisites)
```

# docs/15-github-codespaces.mdx

```mdx
---
sidebar_position: 15
---

# 🌐 GitHub Codespaces: Zero-Install Workshop

The **fastest way** to start this workshop - no local setup required!

<InstructorNotes 
  timing="GitHub Codespaces Setup (5-8 minutes)"
  notes={[
    "Codespaces can take 3-5 minutes on first launch - warn attendees",
    "Free GitHub accounts get 60 hours/month - more than enough for workshop",
    "Port forwarding is automatic but ports must be made 'Public' for sharing",
    "Some corporate networks block Codespaces - have local setup as backup",
    "Attendees often close browser tab accidentally - show how to reconnect"
  ]}
  tips={[
    "Have attendees start Codespace creation at the very beginning",
    "Show how to check build progress in the terminal",
    "Demonstrate port visibility settings in the Ports tab",
    "Explain that Codespaces persists between sessions for 30 days",
    "Mention Codespaces works on tablets/Chromebooks unlike local setup"
  ]}
/>

## 🚀 What is GitHub Codespaces?

GitHub Codespaces provides a complete, cloud-based development environment that runs in your browser. For this workshop, it means:

- ✅ **No local installation** - Works on any device with a browser
- ✅ **Pre-configured environment** - All services start automatically
- ✅ **Consistent experience** - Same setup for all participants
- ✅ **Built-in VS Code** - Full IDE in your browser

## 🎯 Quick Start (30 Seconds!)

### 1. Launch Codespace

<Screenshot src="/img/codespaces-button.png" alt="GitHub Codespaces Button" />

1. Go to the [workshop deployment repository](https://github.com/mongodb-developer/multimodal-pdf-agent-n8n)

<QRCodeAccess 
  url="https://github.com/mongodb-developer/multimodal-pdf-agent-n8n"
  title="Workshop Repository"
/>

2. Click the green **Code** button
3. Select **Codespaces** tab
4. Click **Create codespace on main**

### 2. Wait for Setup (3-5 minutes)

The first time takes a few minutes as it:
- Builds the Docker environment
- Installs all dependencies
- Starts all services
- Configures port forwarding

<Screenshot src="/img/codespaces-building.png" alt="Codespaces Building" />

### 3. Services Auto-Start

Once ready, you'll see:
- Terminal showing service status
- Ports automatically forwarded
- Pop-up notifications for available services

## 🌟 Accessing Workshop Services

### Automatic Port Forwarding

GitHub Codespaces automatically forwards all ports with secure URLs:

| Service | Local Port | Codespaces URL | Access |
|---------|------------|----------------|--------|
| **n8n Editor** | 5678 | `https://<name>-5678.preview.app.github.dev` | Auto-opens |
| **Documentation** | 3000 | `https://<name>-3000.preview.app.github.dev` | Auto-opens |

### Finding Your URLs

1. Click **Ports** tab in the terminal panel
2. Hover over any port
3. Click the globe icon to open

<Screenshot src="/img/codespaces-ports.png" alt="Codespaces Ports Panel" />

## 📋 Codespaces vs Local Docker

| Feature | GitHub Codespaces | Local Docker |
|---------|------------------|--------------|
| **Setup Time** | 30 seconds | 10-15 minutes |
| **Prerequisites** | GitHub account | Docker Desktop |
| **Performance** | Cloud-based | Local machine |
| **Cost** | Free tier (60 hrs/month) | Free |
| **Persistence** | While active | Permanent |
| **Offline Work** | ❌ | ✅ |

## 🔧 Codespaces Features

### Pre-installed Extensions

Your Codespace includes:
- MongoDB for VS Code
- Python & Pylance
- YAML support
- Docker tools
- Prettier formatter

### Terminal Commands

All workshop commands work identically:

\`\`\`bash
# Check service status
docker-compose ps

# View logs
docker-compose logs -f n8n

# Restart services
docker-compose restart

# Run documentation
npm start
\`\`\`

### File Persistence

- Files are saved automatically
- Changes persist between sessions
- Export important workflows before stopping

## 💡 Pro Tips for Codespaces

### 1. Keep It Running

Codespaces auto-suspend after 30 minutes of inactivity:
- Keep the browser tab open
- Interact periodically
- Or adjust timeout in settings

### 2. Resource Management

Default Codespace has:
- 2 CPU cores
- 4 GB RAM
- 32 GB storage

For better performance:
1. Go to repository settings
2. Select "Change machine type"
3. Choose 4-core option

### 3. Multiple Windows

- **Split Terminal**: Drag terminal tabs
- **Preview Side-by-Side**: Right-click tabs → "Split Right"
- **Multiple Browser Tabs**: Open services in separate tabs

## 🛠️ Troubleshooting Codespaces

### Services Not Starting

\`\`\`bash
# Restart all services
docker-compose down
docker-compose up -d

# Check logs
docker-compose logs
\`\`\`

### Port Not Accessible

1. Check **Ports** tab
2. Ensure port visibility is "Public" or "Private"
3. Click globe icon to open

### Performance Issues

- Close unused browser tabs
- Upgrade to larger machine type
- Stop unused services

## 🔒 Security & Privacy

### Port Visibility

By default, ports are private to you. The workshop sets:
- Documentation (3000): Public
- n8n (5678): Private
- MongoDB Atlas: Cloud-based

### Data Security

- All data stays in your Codespace
- Encrypted in transit
- Deleted when Codespace is deleted

## 📊 Managing Your Codespace

### View Active Codespaces

1. Go to [github.com/codespaces](https://github.com/codespaces)
2. See all your active Codespaces
3. Monitor usage and billing

### Stop vs Delete

- **Stop**: Preserves state, can resume later
- **Delete**: Removes everything permanently

\`\`\`bash
# Export workflows before deleting
docker-compose exec n8n n8n export:workflow --all
\`\`\`

## 🎓 Workshop-Specific Setup

**Important**: Launch Codespaces from the [deployment repository](https://github.com/mongodb-developer/multimodal-pdf-agent-n8n), not this documentation site!

Our devcontainer automatically:

1. **Installs Dependencies**
   - Node.js 22 (for n8n)
   - Python 3.11 (for AI libraries)
   - MongoDB tools

2. **Starts Services**
   - n8n workflow engine
   - Documentation site

3. **Configures Environment**
   - Copies `.env.example` to `.env`
   - Sets up workshop directories
   - Initializes sample data

## 🚀 Ready to Start?

With Codespaces, you can:
- Start the workshop in seconds
- Work from any device
- Share your environment easily
- Focus on learning, not setup

### Next Steps

1. ✅ Launch Codespace from [deployment repository](https://github.com/mongodb-developer/multimodal-pdf-agent-n8n)
2. ✅ Services are accessible
3. ✅ Ready to build workflows

Continue to [n8n First Run →](./n8n-first-run)

---

**Tip**: Bookmark your Codespace URL for quick access!
```

# docs/20-prerequisites.mdx

```mdx
---
sidebar_position: 20
---

# 🛠️ Prerequisites & Setup

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

Before we start building, let's get all the tools and accounts you'll need.

<InstructorNotes 
  timing="Prerequisites Setup (10-15 minutes)"
  notes={[
    "This is where most workshops get derailed - allocate extra time",
    "Docker Desktop issues are the #1 problem on Windows/Mac",
    "Have attendees start MongoDB Atlas signup early (email verification takes time)",
    "Codespaces users often forget to make ports public",
    "Local setup varies significantly - recommend Codespaces for mixed groups"
  ]}
  tips={[
    "Poll the room: who has Docker already running?",
    "Share your screen showing successful docker-compose ps output",
    "Have backup plan ready for attendees with setup issues",
    "Consider pairing experienced developers with beginners",
    "Emphasize that Codespaces 'just works' if local setup fails"
  ]}
/>

## 🐳 Docker-Based Workshop Setup

This workshop uses Docker to provide a consistent, pre-configured environment. No need to install n8n or worry about Node.js versions!

### ⚠️ Prerequisites Overview

**Required:**
- Docker Desktop (includes Docker and Docker Compose)
- Git (for cloning the workshop)
- Text editor (VS Code recommended)
- MongoDB Atlas account (free tier)

**Optional:**
- Voyage AI API key (workshop provides serverless endpoint)
- Google AI Studio API key (for Gemini features)

## 🚀 Setup Instructions

<Tabs>
  <TabItem value="codespaces" label="GitHub Codespaces" default>

### Instant Cloud Setup

1. **Open in Codespaces**
   \`\`\`
   Repository → Code → Codespaces → Create codespace on main
   \`\`\`

2. **Automatic Configuration**
   - All services start automatically
   - Ports are forwarded with secure URLs
   - VS Code opens in your browser

3. **Access Services**
   - Click **Ports** tab in terminal
   - Click globe icon next to each service
   - Or wait for pop-up notifications

<Screenshot src="/img/n8n-3.png" alt="Ensure Ports are Public, and Open in Browser" />


🎉 **That's it! Skip to [MongoDB Atlas Setup](./mongodb-atlas-setup)**

  </TabItem>
  <TabItem value="mac" label="macOS (Local)">

### Step 1: Install Docker Desktop

\`\`\`bash
# Download Docker Desktop for Mac
# Visit: https://www.docker.com/products/docker-desktop/
# Choose Apple Silicon (M1/M2) or Intel version

# After installation, verify Docker is running:
docker --version
docker-compose --version
\`\`\`

### Step 2: Clone the Workshop

\`\`\`bash
# Clone the workshop deployment repository
git clone https://github.com/mongodb-developer/multimodal-pdf-agent-n8n.git
cd multimodal-pdf-agent-n8n

# Copy environment template
cp .env.example .env
\`\`\`

### Step 3: Start Workshop Services

\`\`\`bash
# Start all services with one command
docker-compose up -d

# Services will be available at:
# n8n: http://localhost:5678
# MongoDB Atlas: Ready for vector search
# Documentation: Run 'npm start' separately
\`\`\`

:::tip Why Docker?
We use Docker to avoid Node.js version conflicts and provide a consistent environment. Everything is pre-configured and ready to go!
:::

  </TabItem>
  <TabItem value="windows" label="Windows">

### Step 1: Install Docker Desktop

\`\`\`powershell
# Download Docker Desktop for Windows
# Visit: https://www.docker.com/products/docker-desktop/
# Download the installer and run it

# After installation, verify Docker is running:
docker --version
docker-compose --version
\`\`\`

### Step 2: Clone the Workshop

\`\`\`powershell
# Clone the workshop deployment repository
git clone https://github.com/mongodb-developer/multimodal-pdf-agent-n8n.git
cd multimodal-pdf-agent-n8n

# Copy environment template
copy .env.example .env
\`\`\`

### Step 3: Start Workshop Services

\`\`\`powershell
# Start all services with one command
docker-compose up -d

# Services will be available at:
# n8n: http://localhost:5678
# MongoDB Atlas: Ready for vector search
# Documentation: Run 'npm start' separately
\`\`\`

:::tip Windows Docker Setup
- Ensure WSL 2 is enabled for better performance
- Docker Desktop handles this automatically during installation
- You may need to restart after installing Docker Desktop
:::

  </TabItem>
  <TabItem value="linux" label="Linux">

### Step 1: Install Docker

**Ubuntu/Debian:**
\`\`\`bash
# Update package index
sudo apt update

# Install Docker
sudo apt install docker.io docker-compose

# Add your user to docker group (logout/login required)
sudo usermod -aG docker $USER

# Verify installation
docker --version
docker-compose --version
\`\`\`

**Fedora/RHEL/CentOS:**
\`\`\`bash
# Install Docker
sudo dnf install docker docker-compose

# Start Docker service
sudo systemctl start docker
sudo systemctl enable docker

# Add user to docker group
sudo usermod -aG docker $USER
\`\`\`

### Step 2: Clone the Workshop

\`\`\`bash
# Clone the workshop deployment repository
git clone https://github.com/mongodb-developer/multimodal-pdf-agent-n8n.git
cd multimodal-pdf-agent-n8n

# Copy environment template
cp .env.example .env
\`\`\`

### Step 3: Start Workshop Services

\`\`\`bash
# Start all services with one command
docker-compose up -d

# Services will be available at:
# n8n: http://localhost:5678
# MongoDB Atlas: Ready for vector search
# Documentation: Run 'npm start' separately
\`\`\`

:::tip Linux Docker Permissions
If you get "permission denied" errors, logout and login again after adding yourself to the docker group.
:::

  </TabItem>
</Tabs>

## 🐳 Understanding the Docker Setup

Our workshop uses Docker Compose to manage all services:

### Services Included

1. **n8n** (port 5678)
   - Pre-configured workflow automation platform
   - Connected to MongoDB for data persistence
   - All necessary environment variables set

2. **MongoDB Atlas** (cloud database)
   - Vector database for storing workflows and embeddings
   - Managed service with built-in security
   - Vector Search indexes for semantic similarity

### Starting Services

\`\`\`bash
# Start all services
docker-compose up -d

# Check service status
docker-compose ps

# View logs
docker-compose logs -f

# Stop services
docker-compose down
\`\`\`

:::tip Container Management
The `-d` flag runs containers in detached mode (background). Remove it to see logs in real-time.
:::

## 📦 Workshop Files & Structure

\`\`\`
multimodal-pdf-agent-n8n/           # Deployment repository
├── docker-compose.yml              # Service definitions
├── .env.example                   # Environment template
├── .env                           # Your configuration (create from .env.example)
├── .devcontainer/                 # GitHub Codespaces configuration
├── init/
│   ├── mongodb/                  # Database initialization
│   ├── workflows/                # Sample n8n workflows
│   └── sample-data/              # Test PDFs
├── files/                        # File uploads directory
├── scripts/                      # Testing and management scripts
└── workshop-embedding-api/       # Serverless embedding endpoint
\`\`\`

## 🔐 n8n Account Setup

### Community Edition Features

When you first access n8n:

1. **Create Account**: Enter your email address
2. **Community Edition**: You start with the free community edition
3. **Unlock Features**: Get advanced features free forever!

### Getting Your Free License Key

1. Go to **Settings** → **Usage and Plan**
2. Click **"Unlock selected paid features for free"**
3. Features you'll get:
    - ✅ Workflow history
    - ✅ Advanced debugging
    - ✅ Execution search and tagging
    - ✅ Folder organization
4. Click **"Send me a free license key"**
5. Check your email immediately
6. Click the activation link in the email

:::info Activation Tip
The activation link in your email automatically applies your license key - no need to copy/paste!
:::

## Understanding n8n's Interface

### Key Areas to Explore

1. **Workflows**: Your automation canvas
2. **Credentials**: Store API keys securely
3. **Executions**: View run history
4. **Settings**: Personal, instance, and community nodes

### Community Nodes

n8n has a rich ecosystem of community-contributed nodes:

1. Go to **Settings** → **Community Nodes**
2. Click **"Browse"** to see available nodes
3. Popular nodes include:
    - DeepSeek AI integration
    - MCP (Model Context Protocol) nodes
    - Custom database connectors
    - Specialized AI tools

:::tip For Our Workshop
We'll use the built-in MongoDB and HTTP Request nodes, but feel free to explore community nodes for extended functionality!
:::

## 🔧 Docker Troubleshooting

<details>
<summary>Docker services won't start</summary>

\`\`\`bash
# Check if Docker is running
docker info

# If not, start Docker Desktop (GUI) or:
sudo systemctl start docker  # Linux

# Check for errors in logs
docker-compose logs

# Rebuild if needed
docker-compose build --no-cache
docker-compose up -d
\`\`\`

</details>

<details>
<summary>Port 5678 already in use</summary>

Another service is using the port:

<Tabs>
  <TabItem value="mac" label="macOS" default>

\`\`\`bash
# Find what's using port 5678
lsof -i :5678

# Kill the process (replace PID with actual process ID)
kill -9 <PID>

# Or use different port:
n8n start --port=5679
\`\`\`

</TabItem>
<TabItem value="windows" label="Windows">

\`\`\`powershell
# Find what's using port 5678
netstat -ano | findstr :5678

# Kill the process (replace PID with actual process ID)
taskkill /PID <PID> /F

# Or use different port:
n8n start --port=5679
\`\`\`

</TabItem>
<TabItem value="linux" label="Linux">

\`\`\`bash
# Find what's using port 5678
lsof -i :5678
# or
netstat -tulpn | grep :5678

# Kill the process (replace PID with actual process ID)
kill -9 <PID>

# Or use different port:
n8n start --port=5679
\`\`\`

</TabItem>
</Tabs>

</details>

<details>
<summary>Permission/Installation Errors</summary>

<Tabs>
  <TabItem value="mac" label="macOS" default>

\`\`\`bash
# Don't use: brew install n8n (package may be broken)
# Use npm instead: npm install -g n8n

# If permission errors:
sudo npm install -g n8n

# Better: Configure npm to avoid sudo
mkdir ~/.npm-global
npm config set prefix '~/.npm-global'
echo 'export PATH=~/.npm-global/bin:$PATH' >> ~/.zshrc
source ~/.zshrc
npm install -g n8n
\`\`\`

</TabItem>
<TabItem value="windows" label="Windows">

\`\`\`powershell
# Make sure you're running PowerShell as Administrator

# If execution policy errors:
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser

# Clear npm cache if needed:
npm cache clean --force

# Reinstall n8n:
npm install -g n8n
\`\`\`

</TabItem>
<TabItem value="linux" label="Linux">

\`\`\`bash
# If permission errors with system npm:
sudo npm install -g n8n

# Better: Use nvm (no sudo needed):
# First install nvm if not already installed
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh | bash
source ~/.bashrc
nvm install 22
nvm use 22
npm install -g n8n
\`\`\`

</TabItem>
</Tabs>

</details>

## MongoDB Atlas Setup

### Create Your Atlas Account

1. Go to [MongoDB Atlas](https://www.mongodb.com/try)
2. Sign up with your email
3. Create a new project
4. Build your first cluster (free tier)

### Configure Database Access

1. **Database Access**: Create a user
   - Username: `n8n-user`
   - Password: Generate secure password
   - Database User Privileges: Read and write to any database

2. **Network Access**: Add IP addresses
   - Add your current IP
   - For development: Allow access from anywhere (0.0.0.0/0)

### Get Connection String

1. Click **Connect** on your cluster
2. Choose **Connect your application**
3. Copy the connection string
4. Replace `<password>` with your user password

## Workshop Embedding Service

For this workshop, we'll use a serverless endpoint that handles embeddings without requiring API key management.

### Test the Workshop Service

\`\`\`bash
curl -X POST "https://ai4-workshop-embeddings.vercel.app/api/embed" \
  -H "Content-Type: application/json" \
  -d '{
    "input": "Test document",
    "input_type": "document"
  }'
\`\`\`

This endpoint provides:
- ✅ Voyage AI multimodal embeddings
- ✅ No API key required
- ✅ Workshop-optimized rate limits
- ✅ Built-in error handling

## ✅ Pre-Workshop Checklist

Complete these BEFORE the workshop:

- [ ] Install Docker Desktop
- [ ] Clone workshop deployment repository
- [ ] Copy `.env.example` to `.env`
- [ ] Run `docker-compose up -d`
- [ ] Verify n8n service at http://localhost:5678
- [ ] Create MongoDB Atlas account (free tier)
- [ ] Have a test PDF ready

## 🚨 Common Docker Issues & Solutions

1. **Docker not running**: Start Docker Desktop first
2. **Port conflicts**: Check `lsof -i :5678` (Mac/Linux) or `netstat -ano | findstr :5678` (Windows)
3. **Permission denied**: Add user to docker group (Linux)
4. **Services won't start**: Check `docker-compose logs` for errors
5. **Can't connect to services**: Ensure using `http://` not `https://`

## 🎯 Quick Reference

| Service | URL | Purpose |
|---------|-----|---------|
| n8n Editor | http://localhost:5678 | Build workflows |
| Documentation | http://localhost:3000 | Workshop guide |
| MongoDB Atlas | Via connection string | Vector database |

Ready to build your multimodal PDF agent! →
```

# docs/25-n8n-first-run.mdx

```mdx
---
sidebar_position: 25
---

# 🚀 n8n First Run Experience

<StepIndicator current={1} total={6} titles={[
  "Environment Setup", 
  "n8n First Run", 
  "MongoDB Atlas", 
  "PDF Processing", 
  "Vector Search", 
  "AI Agent"
]} />

Let's walk through your first n8n experience and set up the foundation for our multimodal PDF agent.

<InstructorNotes 
  timing="n8n First Run section (10-15 minutes)"
  notes={[
    "This is often where attendees encounter their first issues",
    "Common problems: Docker not running, ports in use, browser cache",
    "Have attendees confirm they can access n8n before proceeding",
    "License activation email sometimes goes to spam folder"
  ]}
  tips={[
    "Share your own n8n screen to show what success looks like",
    "Encourage attendees to help each other with setup issues",
    "Keep a few minutes buffer for troubleshooting",
    "Consider setting up a backup n8n instance for demos"
  ]}
/>

<WorkshopExercise 
  title="Launch and Configure n8n" 
  difficulty="beginner"
  timeEstimate="10 minutes"
  objectives={[
    "Verify n8n is running and accessible",
    "Complete initial setup wizard",
    "Unlock premium features for free",
    "Explore the n8n interface"
  ]}
>

<ExerciseStep stepNumber="1" title="Verify n8n Service">

With our Docker setup, n8n should already be running! Let's verify:

<TerminalCommand 
  command="docker-compose ps"
  output={`NAME           IMAGE              STATUS       PORTS
n8n-workshop   n8nio/n8n:latest   Up 2 mins    0.0.0.0:5678->5678/tcp
n8n-workshop   n8nio/n8n:latest   Up 2 mins    0.0.0.0:5678->5678/tcp`}
/>

If n8n isn't running, start the services:

<CodeBlock language="bash" title="Start All Services">
{`# Start all services
docker-compose up -d

# Wait 10-15 seconds for services to initialize
# Then check logs
docker-compose logs n8n`}
</CodeBlock>

<ServiceTester 
  serviceName="n8n" 
  testUrl="http://localhost:5678"
  testData={{}}
/>

</ExerciseStep>

<ExerciseStep stepNumber="2" title="Complete Initial Setup Wizard">

Navigate to `http://localhost:5678` in your browser:

**Account Creation:**
- Enter your email address
- Create a secure password  
- You're automatically on the Community Edition (perfect for learning!)

<Screenshot src="/img/n8n-1.png" alt="n8n Initial Setup" />

</ExerciseStep>

<ExerciseStep stepNumber="3" title="Unlock Premium Features (Free!)">

Don't skip this step! Get premium features at no cost:

<InteractiveDemo 
  title="Unlock n8n Premium Features"
  description="Follow these steps to get advanced features free forever"
  steps={[
    {
      title: "Navigate to Settings",
      content: (
        <div>
          <p>1. Click the **Settings** (gear icon) in the left sidebar</p>
          <p>2. Look for the **Usage and Plan** section</p>
        </div>
      ),
      timeEstimate: "1 minute"
    },
    {
      title: "Request Free License",
      content: (
        <div>
          <p>3. Click **"Get paid features for free forever"**</p>
          <p>4. Enter your email when prompted</p>
          <p>5. Check your email inbox immediately</p>
        </div>
      ),
      timeEstimate: "2 minutes"
    },
    {
      title: "Activate License",
      content: (
        <div>
          <p>6. Click the activation link in your email</p>
          <p>7. Your license will be automatically applied</p>
          <p>✅ You now have access to premium features!</p>
        </div>
      ),
      timeEstimate: "1 minute"
    }
  ]}
/>

**Premium Features You'll Get:**
- ✅ Workflow history and versioning
- ✅ Advanced debugging tools
- ✅ Execution search and tagging
- ✅ Folder organization
- ✅ Enhanced performance monitoring

</ExerciseStep>

<ExerciseStep stepNumber="4" title="Configure Your Workspace">

Let's customize n8n for our workshop:

**Theme Selection:**
- Navigate to **Settings** → **Personal**
- Choose Light or Dark theme (instructor prefers light theme 😎)

**Community Nodes (Optional):**
- Go to **Settings** → **Community Nodes**
- Browse available extensions
- We'll install specific nodes as needed during the workshop

</ExerciseStep>

<ExerciseValidation 
  title="Verify n8n Setup Complete"
  checks={[
    {
      id: "account_created",
      description: "Successfully created n8n account and logged in",
      hint: "You should see the n8n dashboard with your email in the top right"
    },
    {
      id: "license_activated",
      description: "Premium features unlocked (check Settings → Usage and Plan)",
      hint: "Look for 'Premium features activated' or similar message"
    },
    {
      id: "interface_accessible",
      description: "Can navigate through different sections (Workflows, Credentials, Settings)",
      hint: "Click through the left sidebar menu items"
    }
  ]}
/>

</WorkshopExercise>

## Understanding the n8n Interface

### Main Navigation

<Screenshot src="/img/n8n-1.png" alt="n8n Overview Dashboard" />

### Workflow Canvas

When you create a new workflow:

1. **Canvas**: Main work area
2. **Node Panel**: Click + to add nodes
3. **Node Search**: Type to find nodes
4. **Execution Panel**: See run results

<Screenshot src="/img/n8n-2.png" alt="n8n Overview Dashboard" />

## Your First Test

Let's verify everything works:

### 1. Create Test Workflow

1. Click **Create New Workflow** or select **Start from Scratch** in the center of the Overview panel.
2. You'll see a blank canvas with "Start" node

<Screenshot src="/img/blank-workspace.png" alt="n8n Blank Workspace" />


### 2. Add a Simple Node

1. Click the **+** button next to the trigger node
2. In the search field at the top, type "Set"
3. Look for **"Edit Fields (Set)"** option (has a pencil icon)
4. Click on it to add the node
5. The node will be automatically connected to your trigger
6. Configure the Set node:
   - Click on the Set node to open its settings
   - You'll see fields to add data
   - Add a field with:
     - Name: `test`
     - Value: `Hello n8n!`
   - Add another field:
     - Name: `timestamp`
     - Value: `{{ new Date().toISOString() }}`
    

### 3. Execute

1. Click **Execute Workflow**
2. You should see output with your test data

## Pro Tips from the Field

### 💡 Installation Tips

Based on real experience:

1. **Always use Node 22** - v24 doesn't work
2. **Use npm, not Homebrew** for n8n install
3. **Activate free license immediately** for better features
4. **Start simple** - test basic nodes first

### 🎯 Workflow Development Tips

1. **Name your workflows** clearly
2. **Use folders** to organize (with free license)
3. **Test incrementally** - node by node
4. **Save often** - use Ctrl/Cmd+S

### 🔧 Useful Settings

Enable these for better experience:

1. **Settings** → **Workflow Defaults**
    - Save execution progress: ON
    - Save manual executions: ON
2. **Settings** → **Personal**
    - Execution timeout: 5 minutes (for our workshop)

## Common First-Time Issues

### "Site can't be reached"

- Make sure n8n is running in terminal
- Check [http://localhost:5678](http://localhost:5678/) (not https)
- Verify no firewall blocking

### "Invalid Node Version"

\`\`\`bash
# Quick fix:
nvm use 22
n8n
\`\`\`

### "License Key Not Working"

- Click the link in email (don't copy/paste)
- Check spam folder
- Request new key if needed

## Next Steps

Now that n8n is running:

✅ n8n installed and running  
✅ Account created  
✅ Free license activated  
✅ Interface explored  
✅ First test workflow created

Ready to build our PDF system! →
```

# docs/30-mongodb-atlas-setup.mdx

```mdx
---
sidebar_position: 30
---

# 🗄️ MongoDB Atlas Setup for Vector Search

This workshop uses MongoDB Atlas for vector search capabilities.

**Note**: MongoDB Vector Search is only available in MongoDB Atlas, not in local MongoDB instances.

<SlideRecap 
  title="Database Foundation for Vector Search"
  items={[
    {
      icon: "🗄️",
      title: "MongoDB Atlas Vector Search",
      description: "Why we chose MongoDB Atlas for production-grade vector similarity search"
    },
    {
      icon: "🔍", 
      title: "Vector Indexes & Embeddings",
      description: "How 1024-dimensional vectors enable semantic search across multimodal content"
    },
    {
      icon: "⚡",
      title: "Scalability & Performance",
      description: "From prototype to production with MongoDB's managed vector database"
    }
  ]}
  nextSection="Let's set up your vector database now!"
/>

<InstructorNotes 
  timing="MongoDB Atlas Setup (15-20 minutes)"
  notes={[
    "Atlas signup can take a few minutes - start this section early",
    "Credit card may be required but we'll stay within free tier limits",
    "Network access setup often confuses first-time users",
    "Connection string formatting is a common source of errors"
  ]}
  tips={[
    "Demo the Atlas setup process on screen while attendees follow",
    "Emphasize the importance of saving connection strings securely",
    "Show how to test connections before moving to workflows",
    "Have backup connection strings ready for troubleshooting"
  ]}
/>

## ☁️ MongoDB Atlas Setup

MongoDB Atlas provides managed vector search capabilities that are essential for our multimodal PDF agent.

## Create Your Vector Database

### 1. Atlas Account Setup

If you don't have an account yet:

1. Visit [MongoDB Atlas](https://www.mongodb.com/try?utm_campaign=devrel&utm_source=workshop&utm_medium=cta&utm_content=multimodal_pdf_agent_n8n&utm_term=michael.lynn)

<QRCodeAccess 
  url="https://www.mongodb.com/try?utm_campaign=devrel&utm_source=workshop&utm_medium=cta&utm_content=multimodal_pdf_agent_n8n&utm_term=michael.lynn"
  title="MongoDB Atlas Signup"
/>
2. Sign up with your email
3. Verify your email address
4. Complete the onboarding questions

### 2. Create a Cluster

1. Click **"Build a Database"**
2. Choose **M0 Free Tier** (perfect for our workshop)
3. Select your preferred cloud provider and region
4. Name your cluster: `multimodal-workshop`
5. Click **"Create"** and wait for deployment (~2 minutes)

:::tip Cluster Location
Choose a region close to you for better performance during the workshop.
:::

### 3. Database Configuration

Once your cluster is ready:

1. Click **"Browse Collections"**
2. Click **"Add My Own Data"**
3. Create database and collection:
   \`\`\`
   Database: multimodal_workshop
   Collection: pdf_documents
   \`\`\`
4. Click **"Create"**

## 4. Create Vector Search Index

Navigate to **Atlas Search** → **Create Index**:

1. Click **"Create Search Index"**
2. Select **"JSON Editor"**
3. Choose **"Atlas Vector Search"** as the index type
4. Choose your database: `multimodal_workshop`
5. Choose your collection: `pdf_documents`
6. Name your index: `vector_index`
7. Paste this configuration:

\`\`\`json
{
  "fields": [
    {
      "type": "vector",
      "path": "embedding",
      "numDimensions": 1024,
      "similarity": "cosine"
    },
    {
      "type": "filter",
      "path": "filename"
    },
    {
      "type": "filter",
      "path": "page_number"
    },
    {
      "type": "filter",
      "path": "content_type"
    },
    {
      "type": "filter",
      "path": "metadata.source_url"
    }
  ]
}
\`\`\`

:::info Vector Search Configuration
- **Vector Field**: `embedding` with 1024 dimensions for Voyage AI's `voyage-multimodal-3` model
- **Similarity Function**: `cosine` for normalized vectors (recommended for most embedding models)
- **Filter Fields**: Additional fields for pre-filtering search results by filename, page, content type, and source
:::

### Understanding the Index Configuration

**Vector Field Configuration:**
- `type: "vector"` - Specifies this field contains vector embeddings
- `path: "embedding"` - The field name in your documents containing the vector
- `numDimensions: 1024` - Must match your embedding model's output dimensions
- `similarity: "cosine"` - Similarity function for comparing vectors

**Filter Field Configuration:**
- `type: "filter"` - Allows pre-filtering documents before vector search
- `path: "field_name"` - The document field to enable filtering on

**Available Similarity Functions:**
- `cosine` - Measures angle between vectors (recommended for normalized embeddings)
- `euclidean` - Measures distance between vector endpoints
- `dotProduct` - Like cosine but considers magnitude (requires normalized vectors)

### Alternative Index Configurations

#### Minimal Vector-Only Index
If you only need basic vector search without filtering:

\`\`\`json
{
  "fields": [
    {
      "type": "vector",
      "path": "embedding",
      "numDimensions": 1024,
      "similarity": "cosine"
    }
  ]
}
\`\`\`

#### Performance-Optimized Index with Quantization
For large-scale deployments, enable scalar quantization to reduce memory usage:

\`\`\`json
{
  "fields": [
    {
      "type": "vector",
      "path": "embedding",
      "numDimensions": 1024,
      "similarity": "cosine",
      "quantization": "scalar"
    },
    {
      "type": "filter",
      "path": "filename"
    }
  ]
}
\`\`\`

:::tip Performance Optimization
- **Scalar Quantization**: Reduces memory usage by ~75% with minimal accuracy loss
- **Filter Fields**: Only add fields you'll actually filter on to avoid unnecessary indexing overhead
- **Similarity Function**: Choose based on your embedding model's training method
:::

### Index Creation via MongoDB Drivers

You can also create the index programmatically using MongoDB drivers:

\`\`\`javascript
// Example using MongoDB Node.js driver
const indexDefinition = {
  fields: [
    {
      type: "vector",
      path: "embedding", 
      numDimensions: 1024,
      similarity: "cosine"
    }
  ]
};

await collection.createSearchIndex({
  name: "vector_index",
  type: "vectorSearch", 
  definition: indexDefinition
});
\`\`\`

## Connection in n8n

### 1. Get Your Connection String

1. In Atlas, click **"Connect"** on your cluster
2. Choose **"Connect your application"**
3. Select **"Node.js"** as driver
4. Copy the connection string:
   \`\`\`
   mongodb+srv://<username>:<password>@multimodal-workshop.xxxxx.mongodb.net/
   \`\`\`

### 2. Add MongoDB Credentials in n8n

1. In n8n, go to **Credentials** → **New**
2. Search for **"MongoDB"**
3. Configure:
   - **Credential Name**: `MongoDB Atlas Workshop`
   - **Connection String**: Paste your connection string
   - **Database Name**: `multimodal_workshop`
   - Replace `<username>` and `<password>` with your actual credentials

### 3. Test Connection

Create a test workflow to verify:

1. Add a **Manual Trigger** node
2. Add a **MongoDB** node
3. Configure MongoDB node:
   - **Credential**: Select `MongoDB Atlas Workshop`
   - **Operation**: Find
   - **Collection**: `pdf_documents`
4. Execute the workflow

You should see an empty result (no documents yet) - this confirms the connection works!

## Document Schema

Our PDF documents will follow this schema:

\`\`\`javascript
{
  "_id": ObjectId("..."),
  "filename": "sample.pdf",
  "page_number": 1,
  "content_type": "image", // or "text"
  "embedding": [0.123, -0.456, ...], // 1024 dimensions
  "metadata": {
    "source_url": "https://example.com/sample.pdf",
    "processed_at": "2024-01-20T10:30:00Z",
    "total_pages": 10,
    "file_size": 2048576
  },
  "text_content": "Extracted text from page...", // if applicable
  "image_data": {
    "width": 1920,
    "height": 1080,
    "format": "png"
  }
}
\`\`\`

## Best Practices

### 1. Security

- **Never** commit connection strings to version control
- Use n8n's credential management system
- Enable IP whitelisting in production

### 2. Indexing

- Create indexes on frequently queried fields
- Monitor index performance in Atlas UI
- Consider compound indexes for complex queries

### 3. Data Management

- Set up automatic backups (available in Atlas)
- Monitor storage usage (512MB free tier limit)
- Implement data retention policies

## Troubleshooting

### Connection Issues

If you can't connect from n8n:

1. **Check Network Access**:
   - Atlas → Security → Network Access
   - Add your IP or `0.0.0.0/0` for development
   
2. **Verify Credentials**:
   - Ensure username/password are correct
   - Check database user has read/write permissions

3. **Connection String Format**:
   - Must include `mongodb+srv://` prefix
   - Replace placeholder values completely

### Index Creation Errors

- Ensure collection exists before creating index
- Check JSON syntax in index definition
- Verify field names match your schema

## 🧠 Knowledge Check

<Quiz 
  title="MongoDB Atlas & Vector Search Fundamentals"
  passingScore={75}
  questions={[
    {
      question: "What is the primary purpose of MongoDB Atlas Vector Search in our multimodal PDF agent?",
      options: [
        "To store PDF files directly in the database",
        "To enable semantic similarity search across document embeddings", 
        "To compress PDF documents for faster loading",
        "To convert PDFs to HTML format"
      ],
      correctAnswer: 1,
      explanation: "Vector Search enables semantic similarity search by comparing embedding vectors, allowing us to find relevant content based on meaning rather than exact keyword matches."
    },
    {
      question: "In our vector search index, what does 'numDimensions: 1024' specify?",
      options: [
        "The maximum number of documents that can be stored",
        "The size of each embedding vector from Voyage AI",
        "The number of PDF pages that can be processed",
        "The maximum file size in kilobytes"
      ],
      correctAnswer: 1,
      explanation: "numDimensions must match the embedding model's output size. Voyage AI's multimodal model produces 1024-dimensional vectors."
    },
    {
      question: "Why do we use cosine similarity for our vector search index?",
      options: [
        "It's the fastest similarity metric available",
        "It works well for high-dimensional embeddings and focuses on vector direction",
        "It requires less storage space than other metrics", 
        "It's the only metric supported by MongoDB Atlas"
      ],
      correctAnswer: 1,
      explanation: "Cosine similarity measures the angle between vectors, making it ideal for high-dimensional embeddings where direction matters more than magnitude."
    },
    {
      question: "What happens if you create a vector search index before the collection exists?",
      options: [
        "The index will be created successfully and wait for the collection",
        "MongoDB will automatically create the collection",
        "You'll get an error - the collection must exist first",
        "The index will be created in a different database"
      ],
      correctAnswer: 2,
      explanation: "Collections must exist before you can create search indexes on them. Always ensure your collection is created first."
    },
    {
      question: "What is the benefit of adding filter fields to a vector search index?",
      options: [
        "It makes the index smaller and faster to build",
        "It allows you to combine vector similarity with metadata filtering",
        "It automatically optimizes the embedding dimensions",
        "It enables real-time updates to the search results"
      ],
      correctAnswer: 1,
      explanation: "Filter fields enable hybrid search - you can find semantically similar content AND filter by metadata like filename, date, or document type."
    }
  ]}
/>

<QuickCheck 
  question="True or False: Scalar quantization in vector indexes reduces memory usage by approximately 75%?"
  options={["True", "False"]}
  correctAnswer={0}
  explanation="Scalar quantization reduces memory usage by ~75% with minimal accuracy loss, making it ideal for large-scale deployments."
/>

## Next Steps

With MongoDB Atlas configured:

✅ Cluster created and running  
✅ Database and collection ready  
✅ Vector search index configured  
✅ n8n connection established  
✅ **Knowledge validated** with quiz completion

You're ready to start ingesting PDFs! Let's set up Voyage AI next.

[Continue to Voyage AI Setup →](./voyage-ai-setup)
```

# docs/35-voyage-ai-setup.mdx

```mdx
---
sidebar_position: 35
---

# 🚢 Voyage AI Embedding Service Setup

Configure access to multimodal embeddings that process both text and images using our workshop serverless endpoint.

<InstructorNotes 
  timing="Voyage AI Setup (8-12 minutes)"
  notes={[
    "This section moves quickly since we provide the API endpoint",
    "Attendees often ask why we don't use their own Voyage API keys",
    "Common confusion: difference between voyage-2 and voyage-3 models",
    "The EmbeddingTester component is crucial for verifying connectivity",
    "Some attendees will want to explore other embedding providers"
  ]}
  tips={[
    "Demo the EmbeddingTester component live - show expected output format",
    "Explain workshop endpoint handles rate limiting and error handling",
    "Mention this serverless approach works for other embedding APIs too",
    "Keep this section brief - the real learning happens in workflows",
    "Have sample text ready for testing (complex multi-sentence examples work best)"
  ]}
/>

## Workshop Serverless Endpoint

For this workshop, we'll use a pre-configured serverless endpoint that handles Voyage AI embeddings without requiring you to manage API keys.

### 1. Endpoint Configuration

**Workshop Embedding Service URL**: `https://workshop-embedding-api.vercel.app/api/embed`

This endpoint provides:
- ✅ Voyage AI `voyage-3` model access
- ✅ 1024-dimensional embeddings
- ✅ Support for text inputs
- ✅ Rate limiting and error handling
- ✅ No API key management required

### 2. Using in n8n HTTP Request Nodes

The workshop embedding API is designed to work directly with n8n's **HTTP Request** node without requiring special credentials:

**HTTP Request Node Configuration:**
1. **Method**: `POST`
2. **URL**: `https://workshop-embedding-api.vercel.app/api/embed`
3. **Authentication**: None (leave empty)
4. **Send Headers**: Toggle ON
5. **Header Parameters**: 
   - Name: `Content-Type`
   - Value: `application/json`
6. **Send Body**: Toggle ON
7. **Body Content Type**: `JSON`
8. **Specify Body**: Select `Using JSON`
9. **JSON**: Enter this exactly:
   \`\`\`json
   {
     "text": "actual text to embed here",
     "model": "voyage-3"
   }
   \`\`\`

   For dynamic content from previous nodes:
   \`\`\`json
   {
     "text": {{ JSON.stringify($json.textContent) }},
     "model": "voyage-3"
   }
   \`\`\`

:::warning Required Field
The `text` field is required! Make sure to include the actual text you want to embed. In workflows, this usually comes from a previous node using `{{ $json.textContent }}` or similar.
:::

### 3. Interactive API Testing

Test the embedding API directly from this documentation before building your n8n workflow:

<EmbeddingTester />

### 4. Testing in n8n

To test if the API is working in n8n, create a simple workflow:

1. **Manual Trigger** node
2. **Set** node with test data:
   \`\`\`json
   {
     "textContent": "This is a test document about artificial intelligence and machine learning."
   }
   \`\`\`
3. **HTTP Request** node configured as above
4. **Execute** the workflow

**Expected Response:**
\`\`\`json
{
  "embeddings": [[0.123, -0.456, ...]], // 1024-dimensional array
  "model": "voyage-3",
  "usage": {
    "total_tokens": 12
  }
}
\`\`\`

### 5. Troubleshooting

**Error: "Invalid character in header content"**
- This indicates an issue with the API key configuration on the server
- The instructor needs to check the Vercel environment variables
- Ensure no extra spaces or special characters in the API key

**Error: "The service was not able to process your request"**
- Check that the `text` field contains actual text (not empty)
- Ensure the JSON is properly formatted without extra quotes
- Verify the API URL is correct

**Test with cURL:**
\`\`\`bash
curl -X POST https://workshop-embedding-api.vercel.app/api/embed \
  -H "Content-Type: application/json" \
  -d '{"text": "test embedding", "model": "voyage-3"}'
\`\`\`

### 6. Alternative: Mock Embeddings for Testing

If the API is temporarily unavailable, you can use a **Code** node in n8n to generate mock embeddings:

\`\`\`javascript
// Mock embedding generator
const text = $json.textContent || "test";
const embedding = new Array(1024).fill(0).map((_, i) => 
  Math.sin(i * 0.1) * Math.cos(text.length * 0.01)
);

return [{
  json: {
    embeddings: [embedding],
    model: "mock-voyage-3",
    usage: { total_tokens: text.split(' ').length }
  }
}];
\`\`\`

:::tip No Credentials Required
The workshop API is publicly accessible and doesn't require authentication. Simply use the HTTP Request node with the configuration above.
:::

:::tip Workshop Benefits
Using the serverless endpoint means:
- No need to sign up for Voyage AI accounts
- No API key management
- Consistent workshop experience
- Built-in rate limiting and error handling
:::

## Understanding Multimodal Embeddings

### What Makes Voyage AI Special?

The `voyage-multimodal-3` model:
- **Unified Vector Space**: Text and images in the same 1024-dimensional space
- **Semantic Understanding**: Finds conceptual similarities across modalities
- **Optimized for RAG**: Built specifically for retrieval tasks
- **High Performance**: Fast inference with excellent accuracy

### API Endpoints

**Workshop Endpoint**: `https://ai4-workshop-embeddings.vercel.app/api/embed`

**Method**: POST

**Headers**:
\`\`\`json
{
  "Content-Type": "application/json"
}
\`\`\`

### Request Format

The workshop endpoint accepts a simplified format that handles both text and images:

For text embeddings:
\`\`\`json
{
  "input": "Your text content here",
  "input_type": "document"
}
\`\`\`

For image embeddings:
\`\`\`json
{
  "input": "data:image/png;base64,iVBORw0KGgo...",
  "input_type": "document"
}
\`\`\`

For search queries:
\`\`\`json
{
  "input": "search query",
  "input_type": "query"
}
\`\`\`

**Response Format**:
\`\`\`json
{
  "success": true,
  "embedding": [0.123, -0.456, ...],
  "dimensions": 1024,
  "model": "voyage-multimodal-3"
}
\`\`\`

:::info Input Types
- Use `"document"` for content being indexed
- Use `"query"` for search queries
- This distinction optimizes embeddings for their purpose
:::

## Testing Your Setup

### Quick Test with cURL

Test the workshop endpoint:

\`\`\`bash
curl -X POST "https://ai4-workshop-embeddings.vercel.app/api/embed" \
  -H "Content-Type: application/json" \
  -d '{
    "input": "Hello, multimodal world!",
    "input_type": "document"
  }'
\`\`\`

Expected response:
\`\`\`json
{
  "success": true,
  "embedding": [0.123, -0.456, ...],
  "dimensions": 1024,
  "model": "voyage-multimodal-3"
}
\`\`\`

### Test in n8n

Create a test workflow:

1. Add **Manual Trigger** node
2. Add **HTTP Request** node
3. Configure HTTP Request:
   - **Method**: POST
   - **URL**: `https://ai4-workshop-embeddings.vercel.app/api/embed`
   - **Authentication**: Select your `Workshop Embedding Service` credential
   - **Body Content Type**: JSON
   - **Body**:
     \`\`\`json
     {
       "input": "Test embedding for workshop",
       "input_type": "document"
     }
     \`\`\`
4. Execute and verify you get a response with `embedding` array

## Usage Limits & Workshop Policies

### Workshop Endpoint Limits
- Rate limit: 100 requests/minute per IP
- Max concurrent requests: 10
- Request timeout: 30 seconds
- Perfect for workshop activities

### Usage Guidelines
- Use the endpoint responsibly during the workshop
- Text processing: ~100ms average response time
- Image processing: ~200ms average response time
- Designed to handle workshop load comfortably

## Best Practices

### 1. Image Preparation

Before sending images:
- Convert to base64 format
- Resize large images (max 2048x2048 recommended)
- Use PNG or JPEG format
- Include proper data URI prefix

### 2. Batch Processing

Maximize efficiency:
\`\`\`json
{
  "input": [
    "First document",
    "Second document",
    "data:image/png;base64,...",
    "Fourth document"
  ],
  "model": "voyage-multimodal-3",
  "input_type": "document"
}
\`\`\`

### 3. Error Handling

Common errors and solutions:

| Error | Solution |
|-------|----------|
| 401 Unauthorized | Check API key format and validity |
| 429 Rate Limited | Implement retry logic with backoff |
| 413 Payload Too Large | Reduce image size or batch size |
| 400 Invalid Input | Check base64 encoding and format |

## Integration Tips for n8n

### Code Node Template

Here's a reusable template for the workshop embedding service in n8n:

\`\`\`javascript
// Helper function for workshop embeddings
async function getEmbedding(input, inputType = 'document') {
  const response = await $http.request({
    method: 'POST',
    url: 'https://ai4-workshop-embeddings.vercel.app/api/embed',
    headers: {
      'Content-Type': 'application/json'
    },
    body: {
      input: input,
      input_type: inputType
    }
  });
  
  if (!response.success) {
    throw new Error(`Embedding failed: ${response.error}`);
  }
  
  return response.embedding;
}

// Usage examples:
// Text embedding
const textEmbedding = await getEmbedding("Sample text");

// Image embedding (base64 encoded)
const imageEmbedding = await getEmbedding(`data:image/png;base64,${base64Data}`);

// Query embedding
const queryEmbedding = await getEmbedding("search query", "query");
\`\`\`

### Error Handling

\`\`\`javascript
try {
  const embedding = await getEmbedding(inputText);
  return [{ json: { embedding: embedding } }];
} catch (error) {
  // Fallback or retry logic
  console.error('Embedding generation failed:', error);
  return [{ json: { error: error.message, embedding: null } }];
}
\`\`\`

## Troubleshooting

### Common Issues

**Endpoint Not Responding**
- Check your internet connection
- Verify the URL is correct
- Workshop endpoint may be temporarily unavailable

**Rate Limiting**
- Reduce request frequency
- Add delays between requests
- Implement retry logic with backoff

**Large Image Errors**
- Resize images to max 2048x2048
- Use JPEG compression for large files
- Ensure base64 encoding is correct

### Performance Tips
- Keep images reasonably sized (< 2MB)
- Cache embeddings locally when possible
- Use batch processing where appropriate

### Getting Help
- Check workshop chat for real-time support
- Verify your network allows HTTPS requests
- Try the cURL test command first

## Next Steps

With the workshop embedding service configured:

✅ Serverless endpoint access configured  
✅ Credentials set up in n8n  
✅ Test embeddings working  
✅ Ready for multimodal processing  
✅ No API key management required  

Now let's build the PDF processing workflow!

[Continue to PDF Processing →](./pdf-processing-workflow)
```

# docs/40-pdf-processing-workflow.mdx

```mdx
---
sidebar_position: 40
---

# 📄 PDF Processing Workflow

Build your first n8n workflow to process PDFs into searchable multimodal embeddings.

<SlideRecap 
  title="From Documents to Intelligent Data"
  items={[
    {
      icon: "📄",
      title: "PDF Ingestion Pipeline",
      description: "How to automatically process documents and extract both text and visual content"
    },
    {
      icon: "🎨", 
      title: "Multimodal Understanding",
      description: "Why processing images and text together creates richer, more accurate search"
    },
    {
      icon: "🔄",
      title: "n8n Visual Workflows",
      description: "Building complex data pipelines with visual, no-code automation"
    }
  ]}
  nextSection="Time to build your first multimodal processing pipeline!"
/>

<InstructorNotes 
  timing="PDF Processing Workflow (25-30 minutes)"
  notes={[
    "This is the heart of the workshop - expect debugging time",
    "PDF download node often fails due to CORS or authentication issues",
    "PDF toolkit node can be memory intensive with large files",
    "Embedding generation is the slowest step - use smaller PDFs for demos",
    "MongoDB connection issues surface here if Atlas wasn't configured properly"
  ]}
  tips={[
    "Start with a simple 1-2 page PDF for initial testing",
    "Use the sample PDFs provided in the workshop repo",
    "Show attendees how to use the debug panel to inspect data flow",
    "Expect 5-10 minutes for first successful workflow execution",
    "Have attendees save workflow frequently - crashes can happen",
    "Demonstrate error handling patterns they'll need later"
  ]}
/>

## Workflow Overview

\`\`\`mermaid
graph LR
    A[Webhook Trigger] --> B[Download PDF]
    B --> C[Extract Pages]
    C --> D[Convert to Images]
    D --> E[Generate Embeddings]
    E --> F[Store in MongoDB]
\`\`\`

## Step 1: Create the Webhook Trigger

### Add Webhook Node

1. Create a new workflow in n8n
2. Click the **+** button to add a node
3. Search for **"Webhook"**
4. Configure:
   - **HTTP Method**: POST
   - **Path**: `/process-pdf`
   - **Response Mode**: Immediately respond
   - **Response Code**: 200
   - **Response Data**: `{"status": "processing"}`

### Copy the Webhook URL

1. Click on the Webhook node
2. Copy the **Test URL** (for development)
3. It will look like: `http://localhost:5678/webhook-test/process-pdf`

:::tip Production URLs
In production, use the Production URL instead of Test URL.
:::

## Step 2: Download PDF

### Add HTTP Request Node

1. Add **HTTP Request** node
2. Connect it to the Webhook node
3. Configure:
   - **Method**: GET
   - **URL**: `{{ $json.pdf_url }}`
   - **Response Format**: File
   - **Binary Property**: data

### Test Data Structure

Your webhook should receive:
\`\`\`json
{
  "pdf_url": "https://example.com/sample.pdf",
  "metadata": {
    "source": "user_upload",
    "tags": ["ai", "workshop"]
  }
}
\`\`\`

## Step 3: Extract PDF Pages

### Add Read PDF Node

1. Add **Read PDF** node (from community nodes if needed)
2. Connect to HTTP Request node
3. Configure:
   - **Operation**: Extract Pages as Images
   - **Binary Property**: data
   - **Output Format**: Separate Items
   - **Image Format**: PNG
   - **DPI**: 150 (balance quality/size)

:::info Alternative Approach
If Read PDF node isn't available, use a Code node with pdf-parse library.
:::

### Code Node Alternative

\`\`\`javascript
const PDFParser = require('pdf-parse');
const { createCanvas } = require('canvas');
const items = [];

// Get PDF buffer
const pdfBuffer = $binary.data.buffer;

// Parse PDF
const pdfData = await PDFParser(pdfBuffer);

// Extract text pages
for (let i = 0; i < pdfData.numpages; i++) {
  items.push({
    json: {
      page_number: i + 1,
      text: pdfData.text, // Simplified - real implementation would get page text
      total_pages: pdfData.numpages
    }
  });
}

return items;
\`\`\`

## Step 4: Generate Embeddings

Before building the embedding code, let's verify our API is working:

<QuickEmbeddingTest 
  text="This is sample PDF content that will be processed by our workflow"
  label="Test Embedding API"
/>

### Add Code Node for Voyage AI

1. Add **Code** node
2. Connect to PDF extraction node
3. Add this code:

\`\`\`javascript
const items = [];

for (const item of $input.all()) {
  try {
    // Get image data
    const imageBuffer = await item.binary.data.buffer;
    const base64Image = imageBuffer.toString('base64');
    
    // Prepare input based on content type
    const input = item.json.content_type === 'image' 
      ? `data:image/png;base64,${base64Image}`
      : item.json.text_content;
    
    // Call Workshop Embedding Service
    const response = await $http.request({
      method: 'POST',
      url: 'https://workshop-embedding-api.vercel.app/api/embed',
      headers: {
        'Content-Type': 'application/json'
      },
      body: {
        text: input,
        model: 'voyage-3'
      }
    });
    
    // Prepare document for MongoDB
    items.push({
      json: {
        filename: $('Webhook').item.json.metadata.filename || 'unknown.pdf',
        page_number: item.json.page_number,
        content_type: item.json.content_type || 'image',
        embedding: response.embeddings[0],
        metadata: {
          source_url: $('Webhook').item.json.pdf_url,
          processed_at: new Date().toISOString(),
          total_pages: item.json.total_pages,
          ...$('Webhook').item.json.metadata
        },
        text_content: item.json.text_content || null,
        image_data: {
          width: item.json.width || null,
          height: item.json.height || null,
          format: 'png'
        }
      }
    });
    
  } catch (error) {
    console.error(`Error processing page ${item.json.page_number}:`, error);
    // Continue with other pages
  }
}

return items;
\`\`\`

## Step 5: Store in MongoDB

### Add MongoDB Node

1. Add **MongoDB** node
2. Connect to Code node
3. Configure:
   - **Credential**: Select your MongoDB Atlas credential
   - **Operation**: Insert
   - **Collection**: `pdf_documents`
   - **Options**:
     - **Multiple Documents**: Toggle ON

## Complete Workflow

Your workflow should now look like:

\`\`\`
[Webhook] → [HTTP Request] → [Extract PDF] → [Generate Embeddings] → [MongoDB]
\`\`\`

## Testing the Workflow

### 1. Activate the Workflow

Click **"Execute Workflow"** to activate test mode.

### 2. Send Test Request

Use cURL or Postman:

\`\`\`bash
curl -X POST http://localhost:5678/webhook-test/process-pdf \
  -H "Content-Type: application/json" \
  -d '{
    "pdf_url": "https://example.com/sample.pdf",
    "metadata": {
      "filename": "ai-workshop.pdf",
      "source": "workshop_test"
    }
  }'
\`\`\`

### 3. Monitor Execution

1. Check each node for green checkmarks
2. Click nodes to see output data
3. Verify documents in MongoDB Atlas

## Error Handling

### Add Error Workflow

1. Create new workflow: "PDF Processing Error Handler"
2. Add **Error Trigger** node
3. Add **MongoDB** node to log errors:
   \`\`\`javascript
   {
     collection: "processing_errors",
     error: $json.error,
     workflow: $json.workflow,
     timestamp: new Date()
   }
   \`\`\`

### Link Error Handler

1. Go to main workflow settings
2. Set **Error Workflow** to your error handler
3. Errors will now be logged

## Performance Optimization

### Batch Processing

For multiple PDFs, modify the workflow:

1. Use **Split In Batches** node after webhook
2. Process 5 PDFs at a time
3. Add delay between batches

### Caching Strategy

Add a check before processing:

\`\`\`javascript
// Check if already processed
const existing = await $mongodb.find({
  filename: filename,
  page_number: pageNumber
});

if (existing.length > 0) {
  return [{json: {skipped: true, reason: 'Already processed'}}];
}
\`\`\`

## Monitoring & Logging

### Add Logging Node

Create a simple logger:

\`\`\`javascript
const logEntry = {
  workflow_id: $workflow.id,
  execution_id: $execution.id,
  timestamp: new Date(),
  status: 'completed',
  stats: {
    pages_processed: items.length,
    pdf_url: $('Webhook').item.json.pdf_url,
    processing_time: Date.now() - $execution.startedAt
  }
};

// Log to MongoDB
await $mongodb.insert('workflow_logs', logEntry);
\`\`\`

## Next Steps

Your PDF processing pipeline is ready! You can now:

✅ Accept PDF URLs via webhook  
✅ Extract pages as images  
✅ Generate multimodal embeddings  
✅ Store in MongoDB with vector search  

Let's build the search functionality next!

[Continue to Vector Search →](./vector-search-workflow)
```

# docs/45-local-setup-tips.mdx

```mdx
---
sidebar_position: 45
---

# 💻 Docker Development Best Practices

Based on real-world experience, here's how to optimize your Docker-based n8n development environment.

<InstructorNotes 
  timing="Docker Best Practices (Optional - 10 minutes)"
  notes={[
    "This is reference material - don't spend workshop time here unless issues arise",
    "Most useful for attendees doing local development vs Codespaces",
    "Docker memory issues are common on older machines with 8GB RAM",
    "Volume persistence problems cause workflow loss - emphasize backup",
    "Network connectivity issues surface with corporate firewalls"
  ]}
  tips={[
    "Point attendees here when they encounter Docker issues during workshop",
    "Use as troubleshooting reference rather than sequential content",
    "Emphasize that Codespaces avoids most of these complications",
    "Have this page bookmarked for quick access during debugging",
    "Consider this advanced material for post-workshop exploration"
  ]}
/>

## 🐳 Docker Environment Management

### Project Structure

\`\`\`
multimodal-pdf-agent-n8n/          # Deployment repository
├── docker-compose.yml              # Main services configuration
├── docker-compose.dev.yml          # Development overrides (optional)
├── .env                            # Environment variables
├── .devcontainer/                  # GitHub Codespaces configuration
├── volumes/
│   ├── n8n/                       # n8n data persistence
│   ├── mongodb/                   # MongoDB data
│   └── files/                     # Uploaded files
├── init/
│   ├── workflows/                 # Sample n8n workflows
│   ├── sample-data/               # Test PDFs
│   └── mongodb/                   # Database initialization
├── scripts/                       # Testing and management scripts
├── workshop-embedding-api/        # Serverless embedding endpoint
└── logs/                          # Container logs (if configured)
\`\`\`

### Environment Configuration

Create a comprehensive `.env` file:

\`\`\`bash
# Docker Configuration
COMPOSE_PROJECT_NAME=n8n-workshop

# n8n Configuration
N8N_PORT=5678
N8N_PROTOCOL=http
N8N_HOST=localhost
N8N_LOG_LEVEL=info
N8N_METRICS=false
N8N_VERSION=1.103.2

# MongoDB Configuration
MONGO_VERSION=7.0
MONGO_USERNAME=workshop
MONGO_PASSWORD=secure_password_here
MONGO_DATABASE=pdf_workshop

# Resource Limits
N8N_MEMORY_LIMIT=2g
MONGODB_MEMORY_LIMIT=1g

# Development Settings
DEBUG_MODE=true
ENABLE_HOT_RELOAD=true
\`\`\`

## 🔄 Service Management

### Starting Services

\`\`\`bash
# Start all services
docker-compose up -d

# Start specific service
docker-compose up -d n8n

# Start with logs visible
docker-compose up n8n

# Use development configuration
docker-compose -f docker-compose.yml -f docker-compose.dev.yml up
\`\`\`

### Monitoring Services

\`\`\`bash
# Check status
docker-compose ps

# View logs
docker-compose logs -f n8n

# Monitor resource usage
docker stats

# Access container shell
docker-compose exec n8n sh
\`\`\`

## 📁 Data Persistence

### Volume Management

\`\`\`yaml
# docker-compose.yml
volumes:
  n8n_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./volumes/n8n
  
  mongodb_data:
    driver: local
    driver_opts:
      type: none
      o: bind
      device: ./volumes/mongodb
\`\`\`

### Backup Strategy

Create automated backup script:

\`\`\`bash
#!/bin/bash
# backup.sh

DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="./backups/$DATE"

echo "Creating backup: $BACKUP_DIR"
mkdir -p "$BACKUP_DIR"

# Backup n8n workflows
docker-compose exec n8n n8n export:workflow --all \
  --output=/home/node/backups/workflows_$DATE.json

# Backup n8n workflows
docker-compose exec n8n n8n export:workflow --all \
  --output=/home/node/backups/workflows_$DATE.json

# Copy files
cp -r ./volumes/files "$BACKUP_DIR/"

echo "Backup complete!"
\`\`\`

## 🚀 Performance Optimization

### Docker Resource Configuration

\`\`\`yaml
# docker-compose.yml
services:
  n8n:
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '1'
          memory: 1G
\`\`\`

### Container Health Checks

\`\`\`yaml
services:
  n8n:
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:5678/healthz"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
\`\`\`

## 🔧 Development Workflow

### Hot Reload for Custom Nodes

\`\`\`yaml
# docker-compose.dev.yml
services:
  n8n:
    volumes:
      - ./custom-nodes:/home/node/.n8n/custom
      - ./packages:/home/node/packages
    environment:
      - N8N_CUSTOM_EXTENSIONS=/home/node/custom-nodes
\`\`\`

### Debugging Configuration

\`\`\`yaml
services:
  n8n:
    environment:
      - NODE_ENV=development
      - N8N_LOG_LEVEL=debug
      - DEBUG=n8n:*
    ports:
      - "9229:9229"  # Node.js debugger
\`\`\`

## 🌐 Network Configuration

### Service Communication

\`\`\`yaml
# docker-compose.yml
networks:
  n8n-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.20.0.0/16
\`\`\`

### External Service Access

\`\`\`bash
# MongoDB Atlas is accessed via connection string from Atlas UI
# No local MongoDB instances are used in this workshop
\`\`\`

## 📊 Monitoring & Logging

### Centralized Logging

\`\`\`yaml
# docker-compose.yml
services:
  n8n:
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
\`\`\`

### Log Analysis

\`\`\`bash
# Search logs
docker-compose logs n8n | grep ERROR

# Export logs
docker-compose logs > workshop_logs_$(date +%Y%m%d).log

# Real-time monitoring
watch docker-compose ps
\`\`\`

## 🛡️ Security Best Practices

### Secrets Management

\`\`\`bash
# Use Docker secrets
echo "your-api-key" | docker secret create voyage_api_key -

# Reference in docker-compose.yml
secrets:
  voyage_api_key:
    external: true
\`\`\`

### Network Isolation

\`\`\`yaml
services:
  n8n:
    networks:
      - frontend
      - backend
  
  mongodb:
    networks:
      - backend
\`\`\`

## 🎯 Common Tasks

### Rebuild Services

\`\`\`bash
# Rebuild single service
docker-compose build n8n

# Rebuild all services
docker-compose build

# Force rebuild without cache
docker-compose build --no-cache
\`\`\`

### Clean Up

\`\`\`bash
# Stop and remove containers
docker-compose down

# Remove volumes too
docker-compose down -v

# Clean Docker system
docker system prune -a
\`\`\`

## 💡 Pro Tips

1. **Use Docker Compose profiles** for different environments:
   \`\`\`yaml
   services:
     voyage-mock:
       profiles: ["testing"]
   \`\`\`

2. **Implement health checks** for all services

3. **Use named volumes** for better data management

4. **Set resource limits** to prevent container runaway

5. **Regular backups** of workflows and data

6. **Monitor disk space** - Docker can consume significant space

## 🚨 Troubleshooting

### Container Won't Start

\`\`\`bash
# Check logs
docker-compose logs n8n

# Inspect container
docker-compose ps
docker inspect n8n-workshop

# Reset everything
docker-compose down -v
docker-compose up -d
\`\`\`

### Performance Issues

\`\`\`bash
# Check resource usage
docker stats

# Increase memory limits
docker-compose down
# Edit docker-compose.yml to increase limits
docker-compose up -d
\`\`\`

### Network Problems

\`\`\`bash
# Test connectivity
curl http://localhost:5678/healthz

# Check network configuration
docker network ls
docker network inspect workshop_n8n-network
\`\`\`

Ready to build production-ready workflows! →
```

# docs/50-vector-search-workflow.mdx

```mdx
---
sidebar_position: 50
---

# 🔍 Vector Search Workflow

Create a search endpoint that uses MongoDB Atlas Vector Search to find relevant PDF content.

<InstructorNotes 
  timing="Vector Search Implementation (20-25 minutes)"
  notes={[
    "Vector search index creation can take 5-10 minutes - start this early",
    "Common error: querying before index is built ('index not found')",
    "MongoDB aggregation pipeline syntax trips up SQL developers",
    "Search quality depends heavily on having enough documents ingested",
    "Similarity scores need explanation - attendees expect exact matches"
  ]}
  tips={[
    "Create the vector index immediately after PDF ingestion finishes",
    "Use MongoDB Atlas UI to monitor index building progress",
    "Test with queries that should return obvious matches first",
    "Explain that cosine similarity scores range from 0-1 (higher = more similar)",
    "Have 3-5 test queries ready that demonstrate different search capabilities",
    "Show attendees how to interpret search results and similarity scores"
  ]}
/>

## Search Workflow Structure

\`\`\`mermaid
graph LR
    A[Webhook - Search Query] --> B[Generate Query Embedding]
    B --> C[MongoDB Vector Search]
    C --> D[Format Results]
    D --> E[Return Response]
\`\`\`

## Implementation Steps

### 1. Search Webhook

Add a new **Webhook** node:

1. **HTTP Method**: POST
2. **Path**: `/search`
3. **Response Mode**: Last Node
4. **Response Code**: 200

Expected request format:
\`\`\`json
{
  "query": "What is machine learning?",
  "limit": 5,
  "filters": {
    "source": "workshop_pdfs"
  }
}
\`\`\`

### 2. Query Embedding Generation

Add a **Code** node to generate query embeddings:

\`\`\`javascript
const query = $json.query;

if (!query || query.trim() === '') {
  throw new Error('Query cannot be empty');
}

// Call Workshop Embedding Service with query input type
const response = await $http.request({
  method: 'POST',
  url: 'https://ai4-workshop-embeddings.vercel.app/api/embed',
  headers: {
    'Content-Type': 'application/json'
  },
  body: {
    input: query,
    input_type: 'query' // Important: use 'query' for search
  }
});

return [{
  json: {
    query: query,
    embedding: response.embedding,
    limit: $json.limit || 5,
    filters: $json.filters || {}
  }
}];
\`\`\`

### 3. MongoDB Vector Search

Add a **MongoDB** node with aggregation pipeline:

1. **Operation**: Aggregate
2. **Collection**: `pdf_documents`
3. **Pipeline**:

\`\`\`javascript
[
  {
    "$vectorSearch": {
      "index": "vector_index",
      "path": "embedding",
      "queryVector": $json.embedding,
      "numCandidates": 100,
      "limit": $json.limit || 5
    }
  },
  {
    "$project": {
      "_id": 1,
      "filename": 1,
      "page_number": 1,
      "content_type": 1,
      "text_content": 1,
      "metadata": 1,
      "score": { "$meta": "vectorSearchScore" }
    }
  }
]
\`\`\`

:::tip Vector Search Parameters
- **queryVector**: The embedding vector to search for
- **numCandidates**: Number of candidates to consider (should be >= limit)
- **limit**: Final number of results to return
- **index**: Must match your Atlas Vector Search index name
:::

### 4. Format Results

Add a **Code** node to format the response:

\`\`\`javascript
const results = $json;
const query = $('Webhook').item.json.query;

// Format results for easy consumption
const formattedResults = results.map((doc, index) => ({
  rank: index + 1,
  score: doc.score,
  filename: doc.filename,
  page_number: doc.page_number,
  content_type: doc.content_type,
  preview: doc.text_content ? 
    doc.text_content.substring(0, 200) + '...' : 
    'Image content',
  metadata: doc.metadata
}));

return [{
  json: {
    query: query,
    total_results: formattedResults.length,
    results: formattedResults,
    search_timestamp: new Date().toISOString()
  }
}];
\`\`\`

## Advanced Search Features

### Hybrid Search (Text + Image)

Modify your search to handle both text queries and image queries:

\`\`\`javascript
// Detect if input is image or text
const input = $json.query;
let searchInput;
let inputType = 'query';

if (input.startsWith('data:image')) {
  // Image search
  searchInput = input;
} else {
  // Text search
  searchInput = input;
}

// Generate embedding
const embedding = await getVoyageEmbedding(searchInput, inputType);
\`\`\`

### Semantic + Metadata Filtering

Combine vector search with metadata filters:

\`\`\`javascript
[
  {
    "$vectorSearch": {
      "index": "vector_index",
      "path": "embedding",
      "queryVector": $json.embedding,
      "numCandidates": 100,
      "limit": 20,
      "filter": {
        "metadata.tags": { "$in": ["ai", "ml"] }
      }
    }
  },
  {
    "$limit": $json.limit || 5
  }
]
\`\`\`

### Vector Search with Pre-Filtering

Use the filter fields defined in your index:

\`\`\`javascript
[
  {
    "$vectorSearch": {
      "index": "vector_index",
      "path": "embedding", 
      "queryVector": $json.embedding,
      "numCandidates": 100,
      "limit": $json.limit || 5,
      "filter": {
        "$and": [
          { "content_type": { "$eq": "image" } },
          { "filename": { "$regex": "^ml_", "$options": "i" } }
        ]
      }
    }
  },
  {
    "$project": {
      "_id": 1,
      "filename": 1,
      "page_number": 1,
      "content_type": 1,
      "text_content": 1,
      "metadata": 1,
      "score": { "$meta": "vectorSearchScore" }
    }
  }
]
\`\`\`

:::tip Filter Performance
- Only use fields that are indexed as `"type": "filter"` in your vector search index
- Complex filters may impact search performance
- Pre-filtering reduces the candidate set before vector similarity calculation
:::

### Multi-Stage Search

Implement a two-stage search for better relevance:

\`\`\`javascript
// Stage 1: Initial broad search
const initialResults = await vectorSearch(embedding, 20);

// Stage 2: Rerank using additional criteria
const rerankedResults = initialResults
  .map(doc => ({
    ...doc,
    relevanceScore: calculateRelevance(doc, query)
  }))
  .sort((a, b) => b.relevanceScore - a.relevanceScore)
  .slice(0, limit);
\`\`\`

## Testing Your Search

### Test Queries

Create test requests:

\`\`\`bash
# Text search
curl -X POST http://localhost:5678/webhook/search \
  -H "Content-Type: application/json" \
  -d '{
    "query": "machine learning algorithms",
    "limit": 3
  }'

# Search with filters
curl -X POST http://localhost:5678/webhook/search \
  -H "Content-Type: application/json" \
  -d '{
    "query": "neural networks",
    "limit": 5,
    "filters": {
      "source": "workshop_pdfs"
    }
  }'
\`\`\`

### Expected Response

\`\`\`json
{
  "query": "machine learning algorithms",
  "total_results": 3,
  "results": [
    {
      "rank": 1,
      "score": 0.92,
      "filename": "ml-basics.pdf",
      "page_number": 5,
      "content_type": "image",
      "preview": "Image content",
      "metadata": {
        "source_url": "https://example.com/ml-basics.pdf",
        "processed_at": "2024-01-20T10:30:00Z"
      }
    }
  ],
  "search_timestamp": "2024-01-20T11:00:00Z"
}
\`\`\`

## Performance Optimization

### 1. Caching Layer

Add Redis caching for frequent queries:

\`\`\`javascript
// Check cache first
const cacheKey = `search:${query}:${limit}`;
const cached = await redis.get(cacheKey);
if (cached) {
  return JSON.parse(cached);
}

// Perform search
const results = await performVectorSearch(query);

// Cache results (5 minute TTL)
await redis.setex(cacheKey, 300, JSON.stringify(results));
\`\`\`

### 2. Query Expansion

Improve recall with query expansion:

\`\`\`javascript
// Generate variations of the query
const expandedQueries = [
  query,
  await generateSynonyms(query),
  await generateRelatedTerms(query)
];

// Get embeddings for all variations
const embeddings = await Promise.all(
  expandedQueries.map(q => getVoyageEmbedding(q))
);

// Average the embeddings
const avgEmbedding = averageVectors(embeddings);
\`\`\`

### 3. Result Deduplication

Remove duplicate content:

\`\`\`javascript
const uniqueResults = results.reduce((acc, current) => {
  const isDuplicate = acc.find(item => 
    item.filename === current.filename && 
    Math.abs(item.page_number - current.page_number) <= 1
  );
  
  if (!isDuplicate) {
    acc.push(current);
  }
  
  return acc;
}, []);
\`\`\`

## Error Handling

### Add Error Boundaries

\`\`\`javascript
try {
  // Main search logic
  const results = await performSearch();
  
  if (!results || results.length === 0) {
    return [{
      json: {
        query: query,
        total_results: 0,
        results: [],
        message: "No results found. Try different keywords."
      }
    }];
  }
  
  return formatResults(results);
  
} catch (error) {
  console.error('Search error:', error);
  
  // Return graceful error response
  return [{
    json: {
      error: true,
      message: "Search temporarily unavailable",
      query: query,
      timestamp: new Date().toISOString()
    }
  }];
}
\`\`\`

## Monitoring Search Quality

### Log Search Analytics

\`\`\`javascript
// Log search metrics
const searchMetrics = {
  query: query,
  results_count: results.length,
  top_score: results[0]?.score || 0,
  response_time: Date.now() - startTime,
  has_results: results.length > 0,
  timestamp: new Date()
};

await $mongodb.insert('search_analytics', searchMetrics);
\`\`\`

## Next Steps

Your vector search is now operational! You can:

✅ Accept search queries via API  
✅ Generate query embeddings  
✅ Perform similarity search  
✅ Return formatted results  

Let's add AI intelligence to create a conversational agent!

[Continue to AI Agent →](./ai-agent-workflow)
```

# docs/60-ai-agent-workflow.mdx

```mdx
---
sidebar_position: 60
---

# 🤖 AI Agent with Function Calling

Build an intelligent agent using Gemini 2.0 Flash and n8n's powerful workflow capabilities.

<SlideRecap 
  title="AI Agents & Intelligent Reasoning"
  items={[
    {
      icon: "🤖",
      title: "Function Calling & Tool Use",
      description: "How modern AI agents decide when and how to use external tools for better answers"
    },
    {
      icon: "🧠", 
      title: "ReAct Pattern",
      description: "Reasoning and Acting - the industry-standard pattern for intelligent agent behavior"
    },
    {
      icon: "⚡",
      title: "Gemini 2.0 Integration",
      description: "Leveraging Google's latest multimodal AI model for sophisticated agent capabilities"
    }
  ]}
  nextSection="Let's build your intelligent agent step by step!"
/>

<InstructorNotes 
  timing="AI Agent Creation (30-35 minutes)"
  notes={[
    "This is the most complex section - expect questions about function calling",
    "Gemini API key signup requires Google account (some attendees may not have)",
    "Function calling syntax in n8n is different from OpenAI - emphasize this",
    "Tool selection logic often needs multiple iterations to get right",
    "Response formatting is crucial for good user experience"
  ]}
  tips={[
    "Demo the difference between simple chat and function calling first",
    "Show how to test function definitions before building full agent",
    "Use clear, simple test queries that obviously need search",
    "Explain the ReAct pattern (reason, act, observe) conceptually",
    "Have backup Gemini API key ready in case attendees hit rate limits",
    "Demonstrate debugging failed function calls step by step"
  ]}
/>

## Agent Architecture

\`\`\`mermaid
graph TD
    A[User Query] --> B{Tool Selection}
    B -->|Need Search| C[Vector Search Tool]
    B -->|Direct Answer| D[Generate Response]
    C --> E[Retrieve Documents]
    E --> D
    D --> F[Return Answer]
\`\`\`

## Gemini Integration Setup

### 1. Get Gemini API Key

1. Visit [Google AI Studio](https://makersuite.google.com/app/apikey)

<QRCodeAccess 
  url="https://makersuite.google.com/app/apikey"
  title="Get Gemini API Key"
/>

2. Click **"Create API Key"**
3. Copy the key for n8n

### 2. Add Gemini Credentials in n8n

1. **Credentials** → **New**
2. Search for **"Header Auth"**
3. Configure:
   - **Name**: `Gemini AI`
   - **Header Auth**:
     - **Name**: `x-goog-api-key`
     - **Value**: Your API key

## Building the AI Agent Workflow

### 1. Agent Webhook

Create a new workflow with **Webhook** node:
- **Path**: `/agent`
- **Method**: POST
- **Response**: Last Node

Expected input:
\`\`\`json
{
  "message": "What does the PDF say about neural networks?",
  "session_id": "user-123",
  "context": []
}
\`\`\`

### 2. Function Calling Implementation

Add a **Code** node for tool selection:

\`\`\`javascript
const userMessage = $json.message;
const sessionId = $json.session_id || 'default';

// Define available tools
const tools = [{
  type: "function",
  function: {
    name: "search_documents",
    description: "Search through PDF documents for relevant information",
    parameters: {
      type: "object",
      properties: {
        query: {
          type: "string",
          description: "Search query to find relevant documents"
        },
        limit: {
          type: "number",
          description: "Number of results to return (default: 5)"
        }
      },
      required: ["query"]
    }
  }
}, {
  type: "function", 
  function: {
    name: "get_document_details",
    description: "Get detailed information about a specific document",
    parameters: {
      type: "object",
      properties: {
        filename: {
          type: "string",
          description: "Name of the PDF file"
        },
        page_number: {
          type: "number",
          description: "Specific page number"
        }
      },
      required: ["filename"]
    }
  }
}];

// Prepare messages for Gemini
const messages = [
  {
    role: "system",
    content: `You are an AI assistant with access to a PDF document search system. 
    You can search through documents to answer questions. 
    Always search for relevant information before answering.
    Be helpful and provide detailed answers based on the documents.`
  },
  {
    role: "user",
    content: userMessage
  }
];

// Call Gemini with function calling
const response = await $http.request({
  method: 'POST',
  url: 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent',
  headers: {
    'Content-Type': 'application/json',
    'x-goog-api-key': await $credentials.get('gemini', 'apiKey')
  },
  body: {
    contents: messages.map(m => ({
      role: m.role === 'system' ? 'user' : m.role,
      parts: [{ text: m.content }]
    })),
    tools: tools,
    generationConfig: {
      temperature: 0.7,
      maxOutputTokens: 2048
    }
  }
});

// Extract function call if present
const candidate = response.candidates[0];
const content = candidate.content;

if (content.parts[0].functionCall) {
  const functionCall = content.parts[0].functionCall;
  return [{
    json: {
      action: 'function_call',
      function_name: functionCall.name,
      arguments: functionCall.args,
      original_message: userMessage,
      session_id: sessionId
    }
  }];
} else {
  return [{
    json: {
      action: 'direct_response',
      response: content.parts[0].text,
      original_message: userMessage,
      session_id: sessionId
    }
  }];
}
\`\`\`

### 3. Router Node

Add an **IF** node to route based on action:
- **Condition**: `{{ $json.action === 'function_call' }}`
- **True**: Route to function execution
- **False**: Route to response formatting

### 4. Function Execution Branch

#### Search Documents Function

Add **HTTP Request** node to call your search endpoint:

\`\`\`javascript
// In a Code node before HTTP Request
const functionName = $json.function_name;
const args = $json.arguments;

if (functionName === 'search_documents') {
  return [{
    json: {
      method: 'POST',
      url: 'http://localhost:5678/webhook/search',
      body: {
        query: args.query,
        limit: args.limit || 5
      },
      original_data: $json
    }
  }];
}
\`\`\`

#### Process Search Results

Add **Code** node after search:

\`\`\`javascript
const searchResults = $json.results || [];
const originalData = $('Router').item.json;

// Format results for Gemini
const formattedResults = searchResults.map(doc => ({
  filename: doc.filename,
  page: doc.page_number,
  relevance: doc.score,
  content: doc.preview,
  type: doc.content_type
}));

// Prepare function response
const functionResponse = {
  role: "function",
  name: originalData.function_name,
  content: JSON.stringify({
    results: formattedResults,
    total_found: searchResults.length
  })
};

return [{
  json: {
    function_response: functionResponse,
    original_message: originalData.original_message,
    session_id: originalData.session_id,
    search_performed: true
  }
}];
\`\`\`

### 5. Generate Final Response

Add **Code** node to generate final answer:

\`\`\`javascript
const functionResponse = $json.function_response;
const originalMessage = $json.original_message;
const searchPerformed = $json.search_performed || false;

// Build conversation with function results
const messages = [
  {
    role: "user",
    content: originalMessage
  }
];

if (searchPerformed && functionResponse) {
  messages.push({
    role: "model",
    content: "",
    parts: [{
      functionCall: {
        name: functionResponse.name,
        args: JSON.parse(functionResponse.content).query
      }
    }]
  });
  messages.push(functionResponse);
}

// Call Gemini again with function results
const response = await $http.request({
  method: 'POST',
  url: 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent',
  headers: {
    'Content-Type': 'application/json',
    'x-goog-api-key': await $credentials.get('gemini', 'apiKey')
  },
  body: {
    contents: messages.map(m => ({
      role: m.role,
      parts: m.parts || [{ text: m.content }]
    })),
    generationConfig: {
      temperature: 0.7,
      maxOutputTokens: 2048
    }
  }
});

const answer = response.candidates[0].content.parts[0].text;

return [{
  json: {
    response: answer,
    sources: searchPerformed ? JSON.parse(functionResponse.content).results : [],
    session_id: $json.session_id,
    timestamp: new Date().toISOString()
  }
}];
\`\`\`

## Testing the Agent

### Simple Query Test

\`\`\`bash
curl -X POST http://localhost:5678/webhook/agent \
  -H "Content-Type: application/json" \
  -d '{
    "message": "What machine learning concepts are covered in the PDFs?"
  }'
\`\`\`

### Complex Query Test

\`\`\`bash
curl -X POST http://localhost:5678/webhook/agent \
  -H "Content-Type: application/json" \
  -d '{
    "message": "Compare the different neural network architectures mentioned across all documents"
  }'
\`\`\`

## Advanced Agent Features

### Multi-Tool Support

Extend your agent with more tools:

\`\`\`javascript
const additionalTools = [{
  type: "function",
  function: {
    name: "summarize_document",
    description: "Generate a summary of a specific document",
    parameters: {
      type: "object",
      properties: {
        filename: { type: "string" }
      }
    }
  }
}, {
  type: "function",
  function: {
    name: "extract_tables",
    description: "Extract tabular data from PDFs",
    parameters: {
      type: "object",
      properties: {
        topic: { type: "string" }
      }
    }
  }
}];
\`\`\`

### Streaming Responses

For better UX, implement streaming:

\`\`\`javascript
// In webhook configuration
{
  "Response Mode": "When Last Node Finishes",
  "Response Headers": {
    "Content-Type": "text/event-stream",
    "Cache-Control": "no-cache"
  }
}

// Stream events
const streamEvent = (data) => {
  return `data: ${JSON.stringify(data)}\n\n`;
};
\`\`\`

### Error Recovery

Add intelligent error handling:

\`\`\`javascript
try {
  // Main agent logic
} catch (error) {
  // Fallback to direct response
  const fallbackResponse = await generateFallbackResponse(
    userMessage,
    error.message
  );
  
  return [{
    json: {
      response: fallbackResponse,
      error_occurred: true,
      fallback_used: true
    }
  }];
}
\`\`\`

## Agent Optimization

### Response Caching

Cache common queries:

\`\`\`javascript
const cacheKey = `agent:${hashMessage(userMessage)}`;
const cached = await getCache(cacheKey);

if (cached && !forceRefresh) {
  return [{
    json: {
      ...cached,
      from_cache: true
    }
  }];
}
\`\`\`

### Token Management

Monitor and optimize token usage:

\`\`\`javascript
const tokenEstimate = estimateTokens(userMessage + JSON.stringify(tools));

if (tokenEstimate > 3000) {
  // Reduce context or tool descriptions
  tools = tools.slice(0, 2); // Limit tools
}
\`\`\`

## Next Steps

Your AI agent is now functional! It can:

✅ Understand natural language queries  
✅ Decide when to search documents  
✅ Retrieve relevant information  
✅ Generate contextual responses  

You've built a powerful AI agent system! 

[View Workshop Summary →](./summary)
```

# docs/65-agent-patterns.mdx

```mdx
---
sidebar_position: 65
---

# 🧠 AI Agent Planning Patterns

Understanding how AI agents reason, plan, and act is crucial for building effective multimodal systems. This section covers the key planning patterns that power modern AI agents.

<InstructorNotes 
  timing="Agent Planning Patterns (20-25 minutes)"
  notes={[
    "This bridges the gap between simple prompting and true agent behavior",
    "ReAct pattern is the foundation for our tool-calling implementation",
    "Show concrete examples of each pattern in action",
    "Emphasize that these patterns can be combined",
    "Connect back to the n8n visual workflows they've built"
  ]}
  tips={[
    "Start with simple examples and build complexity",
    "Use the workshop's PDF agent as a running example",
    "Show how n8n's AI Agent node implements these patterns",
    "Demonstrate failures when patterns aren't used correctly",
    "Have attendees identify which pattern fits their use case"
  ]}
/>

<SlideRecap 
  title="From Theory to Implementation"
  items={[
    {
      icon: "🎯",
      title: "AI Agents vs Simple LLMs",
      description: "Agents reason, plan, and act using tools and memory - not just respond"
    },
    {
      icon: "🔄", 
      title: "Planning Patterns",
      description: "Zero-shot, Few-shot, Chain-of-Thought, ReAct, and Reflection patterns"
    },
    {
      icon: "🛠️",
      title: "Practical Implementation",
      description: "How these patterns map to n8n nodes and workflows"
    }
  ]}
  nextSection="Let's explore each planning pattern with real examples!"
/>

## 🎯 What Makes an AI Agent?

Before diving into patterns, let's clarify what distinguishes an AI agent from simpler approaches:

| Approach | Capabilities | Example |
|----------|-------------|---------|
| **Simple Prompting** | Single response, no context | "What is MongoDB?" |
| **RAG (Retrieval)** | Retrieves context, then responds | "Search docs, then answer about MongoDB" |
| **AI Agent** | Reasons, plans, acts, remembers | "Research MongoDB, create examples, test them, refine" |

AI agents are characterized by:
- **Reasoning** about how to approach a task
- **Planning** multi-step solutions
- **Acting** by calling tools and APIs
- **Learning** from results and feedback
- **Remembering** context across interactions

## 📋 Planning Pattern Overview

\`\`\`mermaid
graph TD
    A[User Query] --> B{Planning Pattern}
    B --> C[Zero-Shot]
    B --> D[Few-Shot]
    B --> E[Chain-of-Thought]
    B --> F[ReAct]
    B --> G[Reflection]
    
    C --> H[Direct Answer]
    D --> I[Example-Based Answer]
    E --> J[Step-by-Step Reasoning]
    F --> K[Reason → Act → Observe]
    G --> L[Answer → Critique → Refine]
\`\`\`

## 🎲 Pattern 1: Zero-Shot Planning

The agent attempts to solve a problem without any examples, relying purely on its training.

### When to Use
- Simple, well-defined tasks
- When speed is critical
- Clear, unambiguous queries

### Implementation in n8n

\`\`\`javascript
{
  "systemPrompt": "You are a helpful AI assistant that answers questions directly.",
  "userPrompt": "{{$json.query}}",
  "temperature": 0.3
}
\`\`\`

### Example
**Query**: "What is the capital of France?"
**Response**: "The capital of France is Paris."

### Limitations
- May miss nuanced requirements
- No guarantee of format compliance
- Limited for complex multi-step tasks

## 🎯 Pattern 2: Few-Shot Planning

Provide examples to guide the agent's behavior and output format.

### When to Use
- Need specific output formats
- Complex domain-specific tasks
- Ensuring consistent behavior

### Implementation in n8n

\`\`\`javascript
{
  "systemPrompt": `You extract key information from documents.
  
  Example 1:
  Input: "MongoDB Atlas is a cloud database service."
  Output: {"service": "MongoDB Atlas", "type": "cloud database"}
  
  Example 2:
  Input: "Voyage AI provides multimodal embeddings."
  Output: {"service": "Voyage AI", "type": "multimodal embeddings"}`,
  
  "userPrompt": "Extract: {{$json.text}}",
  "temperature": 0.2
}
\`\`\`

### Workshop Example
\`\`\`javascript
// Few-shot for PDF metadata extraction
const examples = [
  {
    input: "Invoice #12345 dated 2024-01-15",
    output: {
      documentType: "invoice",
      documentId: "12345",
      date: "2024-01-15"
    }
  },
  {
    input: "Contract Agreement between Company A and Company B",
    output: {
      documentType: "contract",
      parties: ["Company A", "Company B"]
    }
  }
];
\`\`\`

## 🧠 Pattern 3: Chain-of-Thought (CoT)

Guide the agent to show its reasoning process step-by-step.

### When to Use
- Complex reasoning tasks
- Mathematical or logical problems
- When transparency is important
- Debugging agent decisions

### Implementation Approaches

#### Basic CoT
\`\`\`javascript
{
  "systemPrompt": "Think through problems step by step before answering.",
  "userPrompt": "{{$json.query}}\n\nLet's think about this step by step:"
}
\`\`\`

#### Structured CoT
\`\`\`javascript
{
  "systemPrompt": `When answering questions:
  1. First, identify what information is needed
  2. Then, break down the problem into steps
  3. Work through each step methodically
  4. Finally, synthesize the answer
  
  Show your reasoning at each step.`,
  "userPrompt": "{{$json.query}}"
}
\`\`\`

### Workshop Example: PDF Analysis CoT

\`\`\`javascript
// Chain-of-Thought for document analysis
const cotPrompt = `
Analyze this PDF content step by step:

Step 1: Identify document type
- Look for keywords like "invoice", "contract", "report"
- Check formatting and structure

Step 2: Extract key entities
- Find names, dates, amounts
- Identify relationships between entities

Step 3: Determine document purpose
- What action does this document require?
- Who are the stakeholders?

Step 4: Summarize findings
- Combine insights from previous steps
- Highlight critical information

Document content: {{$json.pdfText}}
`;
\`\`\`

## 🔄 Pattern 4: ReAct (Reasoning + Acting)

The cornerstone pattern for tool-using agents. Combines reasoning with action in a loop.

### The ReAct Loop

\`\`\`mermaid
graph LR
    A[Thought] --> B[Action]
    B --> C[Observation]
    C --> D{Goal Achieved?}
    D -->|No| A
    D -->|Yes| E[Final Answer]
\`\`\`

### When to Use
- Tasks requiring external tools
- Multi-step problem solving
- When agent needs to gather information
- Interactive workflows

### ReAct Format

\`\`\`
Thought: I need to find information about MongoDB vector search
Action: search_documents
Action Input: {"query": "MongoDB Atlas vector search setup"}
Observation: Found 3 documents about vector search configuration...

Thought: Now I need to extract the specific index configuration
Action: extract_content
Action Input: {"document_id": "doc_123", "section": "index_config"}
Observation: Vector index requires fields specification...

Thought: I have enough information to answer the question
Action: generate_answer
Action Input: {"context": "...", "query": "..."}
Final Answer: To set up MongoDB Atlas vector search...
\`\`\`

### Implementation in n8n AI Agent

<WorkshopExercise 
  title="Implement ReAct Pattern in n8n" 
  difficulty="intermediate"
  timeEstimate="15 minutes"
  objectives={[
    "Configure AI Agent node with ReAct pattern",
    "Define tools for the agent to use",
    "Test the reasoning loop with a real query"
  ]}
>

<ExerciseStep stepNumber="1" title="Configure AI Agent Node">

In your n8n workflow:

1. Add **AI Agent** node
2. Configure with Gemini model
3. Set system message:

\`\`\`javascript
You are a helpful AI assistant that uses the ReAct pattern.
For each user query:
1. Think about what you need to do
2. Use available tools to gather information
3. Observe the results
4. Repeat until you can answer fully
5. Provide a comprehensive final answer

Always show your reasoning process.
\`\`\`

</ExerciseStep>

<ExerciseStep stepNumber="2" title="Define Agent Tools">

Configure these tools for your agent:

\`\`\`javascript
// Tool 1: Vector Search
{
  name: "search_documents",
  description: "Search for relevant documents using vector similarity",
  properties: {
    query: {
      type: "string",
      description: "Search query"
    },
    limit: {
      type: "number",
      description: "Number of results",
      default: 5
    }
  }
}

// Tool 2: Extract PDF Content
{
  name: "extract_pdf_section",
  description: "Extract specific section from a PDF document",
  properties: {
    document_id: {
      type: "string",
      description: "Document ID from search results"
    },
    page_number: {
      type: "number",
      description: "Page to extract"
    }
  }
}

// Tool 3: Analyze Image
{
  name: "analyze_image",
  description: "Analyze image content from PDF",
  properties: {
    image_url: {
      type: "string",
      description: "URL of image to analyze"
    },
    question: {
      type: "string",
      description: "What to look for in the image"
    }
  }
}
\`\`\`

</ExerciseStep>

<ExerciseStep stepNumber="3" title="Test the ReAct Loop">

Test with this query:
\`\`\`
"Find the MongoDB vector index configuration in our documentation 
and explain how to set it up for 1024-dimensional embeddings"
\`\`\`

Expected ReAct behavior:
1. **Thought**: Need to search for vector index documentation
2. **Action**: search_documents with "MongoDB vector index configuration"
3. **Observation**: Found relevant documents
4. **Thought**: Extract specific configuration details
5. **Action**: extract_pdf_section for detailed setup
6. **Final Answer**: Complete setup instructions

</ExerciseStep>

</WorkshopExercise>

### ReAct Best Practices

1. **Clear Tool Descriptions**: Agents rely on descriptions to choose tools
2. **Observation Formatting**: Structure tool outputs for easy parsing
3. **Loop Limits**: Set maximum iterations to prevent infinite loops
4. **Error Handling**: Gracefully handle tool failures

## 🔍 Pattern 5: Reflection

The agent critiques and improves its own outputs through self-evaluation.

### When to Use
- Quality-critical outputs
- Complex document generation
- Learning from mistakes
- Iterative improvement needed

### Reflection Process

\`\`\`mermaid
graph TD
    A[Initial Answer] --> B[Self-Critique]
    B --> C{Satisfactory?}
    C -->|No| D[Identify Issues]
    D --> E[Generate Improvements]
    E --> F[Revised Answer]
    F --> B
    C -->|Yes| G[Final Answer]
\`\`\`

### Implementation Example

\`\`\`javascript
const reflectionPrompt = `
Task: {{$json.task}}

My initial answer: {{$json.initial_answer}}

Now, let me critically evaluate this answer:
1. Is it complete and accurate?
2. Does it address all aspects of the question?
3. Is the reasoning sound?
4. Are there any errors or omissions?

Based on this reflection, here's my improved answer:
`;
\`\`\`

### Workshop Example: PDF Summary Reflection

\`\`\`javascript
// Two-stage reflection for document summarization
const stage1 = {
  prompt: "Summarize this PDF document",
  output: "Initial summary..."
};

const stage2 = {
  prompt: `Review this summary for:
    - Completeness: Are all key points covered?
    - Accuracy: Any misinterpretations?
    - Clarity: Is it easy to understand?
    - Relevance: Focus on what matters?
    
    Original: {{pdfContent}}
    Summary: {{stage1.output}}
    
    Provide an improved summary:`,
  output: "Refined summary..."
};
\`\`\`

## 🎨 Combining Patterns

Real-world agents often combine multiple patterns:

### ReAct + CoT
\`\`\`javascript
{
  systemPrompt: `Use ReAct pattern with chain-of-thought reasoning.
  
  For each step:
  Thought: [Explain your reasoning step by step]
  Action: [What tool to use and why]
  Observation: [What you learned]
  
  Continue until you can provide a complete answer.`
}
\`\`\`

### Few-Shot + Reflection
\`\`\`javascript
{
  systemPrompt: `Here are examples of good document analyses:
  [Examples...]
  
  After generating your analysis:
  1. Compare it to the examples
  2. Identify improvements
  3. Provide refined version`
}
\`\`\`

## 🚀 Practical Implementation Tips

### 1. Pattern Selection Guide

<Quiz 
  title="Which Planning Pattern Should You Use?"
  passingScore={80}
  questions={[
    {
      question: "You need to extract specific fields from invoices in a consistent format. Which pattern?",
      options: [
        "Zero-shot - It's straightforward",
        "Few-shot - Provide format examples", 
        "ReAct - Need to search for fields",
        "Reflection - Improve extraction quality"
      ],
      correctAnswer: 1,
      explanation: "Few-shot is ideal when you need consistent output formats. Provide examples of correctly extracted invoices."
    },
    {
      question: "Your agent needs to research a topic across multiple PDFs and synthesize findings. Which pattern?",
      options: [
        "Zero-shot - Let it figure out the approach",
        "Chain-of-Thought - Show reasoning",
        "ReAct - Search, read, synthesize iteratively",
        "Few-shot - Show research examples"
      ],
      correctAnswer: 2,
      explanation: "ReAct is perfect for multi-step research tasks requiring tool use for searching and reading documents."
    },
    {
      question: "You want to ensure high-quality document summaries. Which pattern?",
      options: [
        "Zero-shot with high temperature",
        "Few-shot with summary examples",
        "Chain-of-Thought for transparency",
        "Reflection for iterative improvement"
      ],
      correctAnswer: 3,
      explanation: "Reflection pattern allows the agent to critique and improve its summaries iteratively."
    }
  ]}
/>

### 2. n8n Workflow Patterns

Map planning patterns to n8n nodes:

| Pattern | n8n Implementation |
|---------|-------------------|
| Zero-shot | Basic AI node with simple prompt |
| Few-shot | AI node with examples in system prompt |
| CoT | AI node with reasoning instructions |
| ReAct | AI Agent node with tools |
| Reflection | Sequential AI nodes with critique loop |

### 3. Performance Considerations

- **Zero-shot**: Fastest, least reliable
- **Few-shot**: Fast, more reliable
- **CoT**: Slower, transparent
- **ReAct**: Variable (depends on tool calls)
- **Reflection**: Slowest, highest quality

## 🎯 Workshop Challenge

<WorkshopExercise 
  title="Implement Multi-Pattern PDF Agent" 
  difficulty="advanced"
  timeEstimate="20 minutes"
  objectives={[
    "Combine multiple planning patterns",
    "Create a sophisticated PDF analysis workflow",
    "Compare results with single-pattern approaches"
  ]}
>

Create an n8n workflow that:
1. Uses **Few-shot** for document type classification
2. Applies **ReAct** for information extraction
3. Employs **CoT** for complex analysis
4. Implements **Reflection** for summary quality

Compare the results with your original simple workflow!

</WorkshopExercise>

## 📚 Next Steps

Now that you understand planning patterns:
- [Implement Memory Patterns →](./memory-context-patterns)
- [Define Custom Tools →](./tool-definition-primer)
- **Advanced Agent Techniques** - Coming soon!

These patterns are the building blocks of sophisticated AI agents. Master them, and you'll be able to create agents that truly reason, plan, and act intelligently! 🚀
```

# docs/67-memory-context-patterns.mdx

```mdx
---
sidebar_position: 67
---

# 🧠 Memory & Context Patterns

Real AI agents need memory to maintain context across conversations and learn from interactions. This section shows how to implement different memory patterns using MongoDB and n8n workflows.

<InstructorNotes 
  timing="Memory & Context Patterns (20-25 minutes)"
  notes={[
    "Memory is what separates true agents from simple chatbots",
    "MongoDB collections work perfectly for different memory types",
    "Show how to balance memory size vs performance",
    "Explain when to summarize vs store full context",
    "Connect to the agent patterns from previous section"
  ]}
  tips={[
    "Start with simple session memory, then build complexity",
    "Show real examples of memory retrieval and updates",
    "Demonstrate how memory affects agent behavior",
    "Use the workshop's PDF agent to show memory in action",
    "Address memory privacy and data retention concerns"
  ]}
/>

<SlideRecap 
  title="Memory Makes Agents Smart"
  items={[
    {
      icon: "🧠",
      title: "Short-term Memory",
      description: "Current conversation context and working memory for multi-step tasks"
    },
    {
      icon: "💾", 
      title: "Long-term Memory",
      description: "User preferences, learned patterns, and historical interactions"
    },
    {
      icon: "⚡",
      title: "Implementation Patterns",
      description: "MongoDB collections, summarization, and context management strategies"
    }
  ]}
  nextSection="Let's build memory systems that make agents truly intelligent!"
/>

## 🎯 Types of AI Agent Memory

Understanding different memory types helps you choose the right implementation pattern:

| Memory Type | Purpose | Storage Duration | MongoDB Implementation |
|-------------|---------|------------------|----------------------|
| **Working Memory** | Current task context | Minutes to hours | Session collection with TTL |
| **Episodic Memory** | Conversation history | Days to weeks | Conversation collection |
| **Semantic Memory** | Learned facts/patterns | Permanent | Knowledge collection |
| **Procedural Memory** | Learned skills/procedures | Permanent | Workflow templates |

\`\`\`mermaid
graph TD
    A[User Input] --> B[Working Memory]
    B --> C[Process & Reason]
    C --> D[Access Long-term Memory]
    D --> E[Generate Response]
    E --> F[Update All Memory Types]
    F --> G[Store for Future Use]
\`\`\`

## 💭 Working Memory (Short-term)

Working memory maintains context for the current conversation or task.

### MongoDB Schema

\`\`\`javascript
// Collection: agent_working_memory
{
  "_id": ObjectId("..."),
  "session_id": "user_123_session_456",
  "user_id": "user_123",
  "context": {
    "current_task": "pdf_analysis",
    "documents_processed": ["doc_1", "doc_2"],
    "last_query": "What are the key findings?",
    "reasoning_state": {
      "step": 3,
      "thoughts": ["Analyzed first document", "Found key metrics"],
      "next_actions": ["Compare with second document"]
    }
  },
  "created_at": ISODate("2024-01-20T10:30:00Z"),
  "expires_at": ISODate("2024-01-20T14:30:00Z") // 4-hour TTL
}
\`\`\`

### n8n Implementation

<WorkshopExercise 
  title="Implement Working Memory" 
  difficulty="intermediate"
  timeEstimate="15 minutes"
  objectives={[
    "Create working memory storage workflow",
    "Implement context retrieval and updates",
    "Test memory persistence across interactions"
  ]}
>

<ExerciseStep stepNumber="1" title="Create Memory Storage Workflow">

Add these nodes to your agent workflow:

**1. Retrieve Working Memory:**
\`\`\`javascript
// MongoDB node - Find working memory
{
  "operation": "Find",
  "collection": "agent_working_memory",
  "query": {
    "session_id": "{{$json.session_id}}",
    "expires_at": {"$gt": new Date()}
  },
  "limit": 1,
  "sort": {"created_at": -1}
}
\`\`\`

**2. Initialize if Empty:**
\`\`\`javascript
// If node - Check if memory exists
{
  "conditions": {
    "boolean": [
      {
        "value1": "{{$json.length}}",
        "operation": "equal",
        "value2": 0
      }
    ]
  }
}

// MongoDB node - Create new memory
{
  "operation": "Insert One",
  "collection": "agent_working_memory",
  "document": {
    "session_id": "{{$json.session_id}}",
    "user_id": "{{$json.user_id}}",
    "context": {
      "current_task": null,
      "conversation_history": [],
      "reasoning_state": {}
    },
    "created_at": new Date(),
    "expires_at": new Date(Date.now() + 4*60*60*1000) // 4 hours
  }
}
\`\`\`

</ExerciseStep>

<ExerciseStep stepNumber="2" title="Context-Aware Agent Processing">

Modify your AI Agent node to use working memory:

\`\`\`javascript
// System prompt with memory context
const systemPrompt = `
You are an AI assistant with access to your working memory.

Current Context:
{{#if $json.memory.context.current_task}}
Task: {{$json.memory.context.current_task}}
{{/if}}

{{#if $json.memory.context.conversation_history}}
Recent conversation:
{{#each $json.memory.context.conversation_history}}
- {{this.role}}: {{this.message}}
{{/each}}
{{/if}}

{{#if $json.memory.context.reasoning_state}}
Previous reasoning:
{{#each $json.memory.context.reasoning_state.thoughts}}
- {{this}}
{{/each}}
{{/if}}

Use this context to provide coherent, consistent responses.
`;
\`\`\`

</ExerciseStep>

<ExerciseStep stepNumber="3" title="Update Memory After Processing">

Add memory update after agent response:

\`\`\`javascript
// MongoDB node - Update working memory
{
  "operation": "Update One",
  "collection": "agent_working_memory",
  "query": {"session_id": "{{$json.session_id}}"},
  "updateDocument": {
    "$push": {
      "context.conversation_history": {
        "$each": [
          {
            "role": "user",
            "message": "{{$json.user_query}}",
            "timestamp": new Date()
          },
          {
            "role": "assistant", 
            "message": "{{$json.agent_response}}",
            "timestamp": new Date()
          }
        ],
        "$slice": -10 // Keep only last 10 exchanges
      }
    },
    "$set": {
      "context.last_interaction": new Date(),
      "expires_at": new Date(Date.now() + 4*60*60*1000)
    }
  }
}
\`\`\`

</ExerciseStep>

</WorkshopExercise>

## 📚 Episodic Memory (Conversation History)

Episodic memory stores complete conversation histories for learning and reference.

### Advanced Schema Design

\`\`\`javascript
// Collection: agent_episodic_memory
{
  "_id": ObjectId("..."),
  "user_id": "user_123",
  "conversation_id": "conv_456",
  "episode": {
    "title": "PDF Analysis Discussion",
    "summary": "User asked about extracting financial data from quarterly reports",
    "tags": ["pdf_analysis", "financial_data", "quarterly_reports"],
    "outcome": "successful_extraction",
    "satisfaction_score": 4.5
  },
  "interactions": [
    {
      "timestamp": ISODate("2024-01-20T10:00:00Z"),
      "role": "user",
      "content": "Can you help me extract revenue data from these PDFs?",
      "attachments": ["doc_123.pdf", "doc_124.pdf"]
    },
    {
      "timestamp": ISODate("2024-01-20T10:02:00Z"),
      "role": "assistant",
      "content": "I'll analyze these PDFs for revenue data...",
      "reasoning": ["Identified financial documents", "Located revenue sections"],
      "tools_used": ["pdf_extract", "financial_parser"],
      "confidence": 0.92
    }
  ],
  "created_at": ISODate("2024-01-20T10:00:00Z"),
  "last_updated": ISODate("2024-01-20T10:30:00Z")
}
\`\`\`

### Implementation Pattern

\`\`\`javascript
// Smart conversation summarization
const summarizeConversation = {
  systemPrompt: `Summarize this conversation in a structured way:

  Title: Brief descriptive title
  Summary: 2-3 sentence overview
  Key Topics: List of main topics discussed
  Outcome: What was accomplished
  Learning: What the agent learned for future use
  
  Conversation:
  {{$json.conversation_history}}`,
  
  temperature: 0.3
};
\`\`\`

## 🧠 Semantic Memory (Knowledge Base)

Semantic memory stores learned facts, patterns, and domain knowledge.

### Knowledge Extraction Pattern

\`\`\`javascript
// Collection: agent_semantic_memory
{
  "_id": ObjectId("..."),
  "knowledge_type": "document_pattern",
  "domain": "financial_documents",
  "pattern": {
    "trigger_conditions": ["document_type:invoice", "has_tables:true"],
    "extraction_strategy": "table_parsing",
    "success_rate": 0.87,
    "learned_from": ["conv_123", "conv_456", "conv_789"]
  },
  "knowledge": {
    "fact": "Financial documents with tables require different parsing",
    "procedure": "Use table detection before text extraction",
    "examples": ["invoice_table_parse.json"],
    "confidence": 0.89
  },
  "embeddings": [0.123, -0.456, ...], // For semantic search
  "created_at": ISODate("2024-01-20T08:00:00Z"),
  "last_reinforced": ISODate("2024-01-22T14:30:00Z"),
  "usage_count": 15
}
\`\`\`

### Learning Workflow

<WorkshopExercise 
  title="Implement Semantic Learning" 
  difficulty="advanced"
  timeEstimate="20 minutes"
  objectives={[
    "Extract knowledge from successful interactions",
    "Store learnings in semantic memory",
    "Retrieve relevant knowledge for new tasks"
  ]}
>

<ExerciseStep stepNumber="1" title="Knowledge Extraction">

Create a workflow that runs after successful interactions:

\`\`\`javascript
// AI node - Extract learnings
{
  systemPrompt: `Analyze this successful interaction and extract learnable knowledge:

  1. What pattern or strategy worked well?
  2. What conditions made this approach successful?
  3. How could this knowledge help with future similar tasks?
  4. What procedure should be documented?

  Format as structured knowledge for future reference.
  
  Interaction: {{$json.successful_interaction}}`,
  
  temperature: 0.2
}
\`\`\`

</ExerciseStep>

<ExerciseStep stepNumber="2" title="Knowledge Storage">

Store extracted knowledge with embeddings:

\`\`\`javascript
// Generate embeddings for semantic search
{
  "url": "https://workshop-embedding-api.vercel.app/api/embed",
  "method": "POST",
  "body": {
    "text": "{{$json.extracted_knowledge}}",
    "model": "voyage-3"
  }
}

// Store in semantic memory
{
  "operation": "Insert One",
  "collection": "agent_semantic_memory",
  "document": {
    "knowledge_type": "{{$json.knowledge_type}}",
    "domain": "{{$json.domain}}",
    "knowledge": "{{$json.extracted_knowledge}}",
    "embeddings": "{{$json.embedding_vector}}",
    "learned_from": "{{$json.conversation_id}}",
    "confidence": "{{$json.confidence_score}}",
    "created_at": new Date()
  }
}
\`\`\`

</ExerciseStep>

<ExerciseStep stepNumber="3" title="Knowledge Retrieval">

Before processing new requests, search for relevant knowledge:

\`\`\`javascript
// Vector search for relevant knowledge
{
  "operation": "Aggregate",
  "collection": "agent_semantic_memory",
  "pipeline": [
    {
      "$vectorSearch": {
        "index": "semantic_knowledge_index",
        "path": "embeddings",
        "queryVector": "{{$json.query_embedding}}",
        "numCandidates": 50,
        "limit": 5,
        "filter": {
          "domain": "{{$json.task_domain}}",
          "confidence": {"$gte": 0.7}
        }
      }
    },
    {
      "$project": {
        "knowledge": 1,
        "confidence": 1,
        "score": {"$meta": "vectorSearchScore"}
      }
    }
  ]
}
\`\`\`

</ExerciseStep>

</WorkshopExercise>

## 🔄 Memory Management Patterns

### 1. Memory Hierarchy

\`\`\`mermaid
graph TD
    A[New Information] --> B{Importance Level}
    B -->|High| C[Immediate Working Memory]
    B -->|Medium| D[Session Context]
    B -->|Low| E[Temporary Buffer]
    
    C --> F[Episodic Memory]
    D --> F
    F --> G{Should Extract Knowledge?}
    G -->|Yes| H[Semantic Memory]
    G -->|No| I[Archive]
\`\`\`

### 2. Context Window Management

\`\`\`javascript
// Smart context truncation
const manageContextWindow = {
  systemPrompt: `You have limited context window. Prioritize:
  1. Current user query (highest priority)
  2. Recent conversation (last 3 exchanges)
  3. Relevant semantic knowledge
  4. Working memory state
  5. Historical context (summarized)
  
  Summarize older context to fit within limits.`,
  
  maxTokens: 4000 // Adjust based on model limits
};
\`\`\`

### 3. Memory Consolidation

\`\`\`javascript
// Periodic memory consolidation workflow
const consolidateMemory = {
  schedule: "0 2 * * *", // Daily at 2 AM
  
  operations: [
    // Summarize old conversations
    {
      collection: "agent_episodic_memory",
      operation: "summarize_old_conversations",
      criteria: {"created_at": {"$lt": new Date(Date.now() - 7*24*60*60*1000)}}
    },
    
    // Extract patterns from recent interactions
    {
      collection: "agent_semantic_memory", 
      operation: "extract_new_patterns",
      criteria: {"usage_count": {"$gte": 3}}
    },
    
    // Clean up expired working memory
    {
      collection: "agent_working_memory",
      operation: "deleteMany",
      criteria: {"expires_at": {"$lt": new Date()}}
    }
  ]
};
\`\`\`

## 🎯 Memory-Driven Agent Behavior

### Personalization Through Memory

\`\`\`javascript
// Retrieve user preferences and history
const personalizedSystemPrompt = `
You are an AI assistant with memory of this user.

User Profile:
- Preferred communication style: {{$json.user_profile.communication_style}}
- Domain expertise: {{$json.user_profile.expertise_level}}
- Common tasks: {{$json.user_profile.frequent_tasks}}

Recent successful interactions:
{{#each $json.successful_patterns}}
- {{this.description}}: {{this.success_rate}}% success rate
{{/each}}

User preferences learned:
{{#each $json.learned_preferences}}
- {{this.preference}}: {{this.confidence}} confidence
{{/each}}

Adapt your response style and approach accordingly.
`;
\`\`\`

### Adaptive Learning

\`\`\`javascript
// Update knowledge based on feedback
const adaptiveLearning = {
  onUserFeedback: {
    positive: {
      operation: "increment",
      fields: ["confidence", "usage_count", "success_rate"]
    },
    negative: {
      operation: "decrement", 
      fields: ["confidence", "success_rate"],
      action: "require_validation"
    }
  }
};
\`\`\`

## 📊 Memory Performance Optimization

### 1. Indexing Strategy

\`\`\`javascript
// MongoDB indexes for memory collections
db.agent_working_memory.createIndex(
  {"session_id": 1, "expires_at": 1}
);

db.agent_episodic_memory.createIndex(
  {"user_id": 1, "created_at": -1}
);

db.agent_semantic_memory.createIndex([
  {"domain": 1},
  {"knowledge_type": 1},
  {"confidence": -1}
]);

// Vector search index for semantic memory
db.agent_semantic_memory.createSearchIndex(
  "semantic_knowledge_index",
  {
    "fields": [
      {
        "type": "vector",
        "path": "embeddings",
        "numDimensions": 1024,
        "similarity": "cosine"
      }
    ]
  }
);
\`\`\`

### 2. Memory Size Limits

\`\`\`javascript
// Implement memory size limits
const memoryLimits = {
  working_memory: {
    max_context_length: 10000, // tokens
    max_conversation_history: 10, // exchanges
    ttl_hours: 4
  },
  episodic_memory: {
    max_conversations_per_user: 100,
    auto_summarize_after_days: 7,
    archive_after_months: 6
  },
  semantic_memory: {
    max_knowledge_items: 1000,
    min_confidence_threshold: 0.6,
    cleanup_unused_after_days: 30
  }
};
\`\`\`

## 🔒 Memory Privacy & Security

### Data Retention Policies

\`\`\`javascript
// Privacy-compliant memory management
const privacyRules = {
  user_data_retention: {
    working_memory: "4 hours",
    episodic_memory: "90 days", 
    semantic_memory: "anonymized, permanent"
  },
  
  anonymization: {
    remove_fields: ["user_id", "personal_identifiers"],
    hash_fields: ["session_id"],
    generalize_content: true
  },
  
  user_deletion: {
    on_user_request: "delete_all_memories",
    cascade_delete: true,
    backup_semantic_knowledge: "anonymized_only"
  }
};
\`\`\`

## 🚀 Advanced Memory Patterns

### Multi-Agent Memory Sharing

\`\`\`javascript
// Shared knowledge between agent instances
{
  "_id": ObjectId("..."),
  "knowledge_type": "shared_pattern",
  "sharing_scope": "all_agents", // or "domain_specific"
  "access_level": "read_only",
  "knowledge": {
    "pattern": "PDF table extraction technique",
    "success_conditions": ["table_detected", "structured_data"],
    "failure_modes": ["rotated_tables", "merged_cells"]
  },
  "contributed_by": ["agent_instance_1", "agent_instance_2"],
  "validated_by": 5, // Number of agents that confirmed
  "global_confidence": 0.91
}
\`\`\`

### Temporal Memory Patterns

\`\`\`javascript
// Time-aware memory retrieval
const temporalMemory = {
  recent_context: {
    weight: 1.0,
    decay_factor: 0.9, // Daily decay
    max_age_hours: 24
  },
  
  seasonal_patterns: {
    weight: 0.7,
    match_timeframe: "same_month_previous_years",
    relevance_boost: 0.3
  },
  
  trending_topics: {
    weight: 0.8,
    recency_boost: 0.5,
    popularity_threshold: 0.6
  }
};
\`\`\`

## 🎯 Testing Memory Systems

<Quiz 
  title="Memory Pattern Selection"
  passingScore={75}  
  questions={[
    {
      question: "Your agent needs to remember user preferences across multiple sessions. Which memory type?",
      options: [
        "Working memory - stores current context",
        "Episodic memory - stores conversation history", 
        "Semantic memory - stores learned knowledge",
        "All types working together"
      ],
      correctAnswer: 2,
      explanation: "User preferences are learned knowledge that should persist across sessions, making semantic memory the primary choice."
    },
    {
      question: "What's the best strategy for managing context window limits?",
      options: [
        "Truncate oldest messages first",
        "Keep only the last user message",
        "Prioritize: current query, recent context, relevant knowledge, summarized history",
        "Use only working memory"
      ],
      correctAnswer: 2,
      explanation: "Intelligent prioritization maintains the most relevant context while respecting model limits."
    },
    {
      question: "When should you consolidate memory?",
      options: [
        "After every interaction",
        "When memory collections get too large",
        "Periodically (daily/weekly) during low usage",
        "Only when users complain about performance"
      ],
      correctAnswer: 2,
      explanation: "Scheduled consolidation during low usage periods maintains performance without impacting user experience."
    }
  ]}
/>

Memory transforms simple AI models into intelligent agents that learn, adapt, and provide increasingly personalized experiences. Master these patterns, and your agents will truly understand and remember their users! 🧠✨

## 📚 Next Steps

- [Define Custom Tools →](./tool-definition-primer)  
- [Build Multimodal Workflows →](./multimodal-image-queries)
- **Agent Reflection** - Coming soon!
```

# docs/68-tool-definition-primer.mdx

```mdx
---
sidebar_position: 68
---

# 🛠️ Tool Definition & Function Calling Primer

Tools are what transform AI models from conversational interfaces into capable agents that can interact with the world. This section covers how to define, configure, and optimize tools for your multimodal PDF agent.

<InstructorNotes 
  timing="Tool Definition & Function Calling (25-30 minutes)"
  notes={[
    "Tools are the 'hands' of AI agents - crucial concept to emphasize",
    "Schema definition quality directly impacts agent performance",
    "Show both n8n visual tools and conceptual @tool decorators",
    "Common mistake: vague tool descriptions lead to poor tool selection",
    "Error handling in tools is critical for robust agents"
  ]}
  tips={[
    "Start with simple tools, then show complex examples",
    "Demonstrate what happens when tool descriptions are poor",
    "Show the connection between n8n nodes and function calling",
    "Use real examples from the workshop's PDF processing workflow",
    "Address security considerations for tool access"
  ]}
/>

<SlideRecap 
  title="From Static to Interactive Agents"
  items={[
    {
      icon: "🛠️",
      title: "Tool Definition",
      description: "How to describe functions so AI agents can understand and use them effectively"
    },
    {
      icon: "🔗", 
      title: "Function Calling",
      description: "The mechanism that allows agents to execute tools and process results"
    },
    {
      icon: "⚡",
      title: "n8n Implementation",
      description: "How visual workflows translate to tool calling in practice"
    }
  ]}
  nextSection="Let's build tools that make agents truly capable!"
/>

## 🎯 What Are AI Agent Tools?

Tools are functions that AI agents can call to:
- 🔍 **Retrieve information** (search, databases, APIs)
- 🔧 **Process data** (calculations, transformations, analysis)
- 📤 **Take actions** (send emails, create files, trigger workflows)
- 🧠 **Extend capabilities** (specialized algorithms, external services)

### Tool vs. Simple Function

| Aspect | Simple Function | AI Agent Tool |
|--------|----------------|---------------|
| **Caller** | Developer (hardcoded) | AI Agent (dynamic) |
| **Selection** | Explicit function call | Agent reasoning |
| **Description** | Comments for humans | Schema for AI |
| **Error Handling** | Developer responsibility | Must guide agent |
| **Parameters** | Known at compile time | Dynamically generated |

## 📋 Tool Definition Fundamentals

### The @tool Decorator Concept

While n8n uses visual workflows, understanding the conceptual `@tool` decorator helps design better tools:

\`\`\`python
from typing import List, Optional
from pydantic import BaseModel, Field

@tool
def search_documents(
    query: str = Field(..., description="Natural language search query"),
    limit: int = Field(5, description="Maximum number of results to return"),
    filters: Optional[dict] = Field(None, description="Additional search filters")
) -> List[dict]:
    """
    Search through PDF documents using vector similarity.
    
    This tool finds relevant documents based on semantic similarity
    to the user's query. Use when you need to find information
    across multiple documents.
    
    Returns a list of matching documents with content and metadata.
    """
    # Implementation would go here
    pass
\`\`\`

### Key Components of Tool Definitions

1. **Name**: Clear, descriptive function name
2. **Description**: What the tool does and when to use it
3. **Parameters**: Input schema with types and descriptions
4. **Return Type**: What the tool returns
5. **Error Conditions**: How failures are communicated

## 🔧 n8n Tool Implementation

### 1. HTTP Request Tools

The most flexible tool type in n8n:

<WorkshopExercise 
  title="Create a Document Search Tool" 
  difficulty="intermediate"
  timeEstimate="15 minutes"
  objectives={[
    "Define a search tool using HTTP Request node",
    "Configure proper tool schema for AI Agent",
    "Test tool calling with different queries"
  ]}
>

<ExerciseStep stepNumber="1" title="Create HTTP Request Tool">

Add an **HTTP Request** node with these settings:

\`\`\`javascript
// HTTP Request Configuration
{
  "method": "POST",
  "url": "http://localhost:3001/api/search",
  "authentication": "none",
  "sendHeaders": true,
  "headerParameters": {
    "parameters": [
      {
        "name": "Content-Type",
        "value": "application/json"
      }
    ]
  },
  "sendBody": true,
  "bodyContentType": "json",
  "jsonParameters": {
    "parameters": [
      {
        "name": "query",
        "value": "={{ $json.query }}"
      },
      {
        "name": "limit", 
        "value": "={{ $json.limit || 5 }}"
      },
      {
        "name": "filters",
        "value": "={{ $json.filters || {} }}"
      }
    ]
  }
}
\`\`\`

</ExerciseStep>

<ExerciseStep stepNumber="2" title="Define Tool Schema for AI Agent">

In your **AI Agent** node, define the tool schema:

\`\`\`javascript
// Tool Definition in AI Agent
{
  "name": "search_documents",
  "description": "Search through PDF documents using semantic similarity. Use this when you need to find information across multiple documents or when the user asks questions that require searching through content.",
  "parameters": {
    "type": "object",
    "properties": {
      "query": {
        "type": "string",
        "description": "The search query in natural language. Be specific about what you're looking for."
      },
      "limit": {
        "type": "integer",
        "description": "Maximum number of documents to return (default: 5, max: 20)",
        "minimum": 1,
        "maximum": 20,
        "default": 5
      },
      "filters": {
        "type": "object",
        "description": "Optional filters to narrow search results",
        "properties": {
          "document_type": {
            "type": "string",
            "enum": ["invoice", "contract", "report", "manual"]
          },
          "date_range": {
            "type": "object",
            "properties": {
              "start": {"type": "string", "format": "date"},
              "end": {"type": "string", "format": "date"}
            }
          }
        }
      }
    },
    "required": ["query"]
  }
}
\`\`\`

</ExerciseStep>

<ExerciseStep stepNumber="3" title="Test Tool Calling">

Test with these queries to see how the agent chooses tools:

1. **Should trigger search**: "What do our financial reports say about Q3 revenue?"
2. **Should not trigger search**: "What is MongoDB?"
3. **Should use filters**: "Find invoices from December 2023"

</ExerciseStep>

</WorkshopExercise>

### 2. MongoDB Tools

Direct database operations as tools:

\`\`\`javascript
// MongoDB Vector Search Tool
{
  "name": "vector_search_documents",
  "description": "Perform advanced vector search with custom scoring and filtering. Use when you need precise control over search parameters or when semantic search needs fine-tuning.",
  "parameters": {
    "type": "object",
    "properties": {
      "embedding_vector": {
        "type": "array",
        "items": {"type": "number"},
        "description": "Pre-computed embedding vector for search"
      },
      "search_options": {
        "type": "object",
        "properties": {
          "numCandidates": {
            "type": "integer",
            "description": "Number of candidate documents for search",
            "default": 50
          },
          "limit": {
            "type": "integer", 
            "description": "Final number of results to return",
            "default": 5
          },
          "filter": {
            "type": "object",
            "description": "MongoDB query filter"
          }
        }
      }
    },
    "required": ["embedding_vector"]
  }
}

// MongoDB Insert Tool
{
  "name": "store_document_analysis",
  "description": "Store analysis results or extracted insights for future reference. Use when you've processed a document and want to save the insights.",
  "parameters": {
    "type": "object", 
    "properties": {
      "document_id": {
        "type": "string",
        "description": "ID of the analyzed document"
      },
      "analysis": {
        "type": "object",
        "properties": {
          "summary": {"type": "string"},
          "key_findings": {"type": "array", "items": {"type": "string"}},
          "metadata": {"type": "object"}
        }
      }
    },
    "required": ["document_id", "analysis"]
  }
}
\`\`\`

### 3. Data Processing Tools

Custom processing workflows as tools:

\`\`\`javascript
// PDF Analysis Tool
{
  "name": "analyze_pdf_structure",
  "description": "Analyze the structure and content of a PDF document. Use when you need to understand document layout, extract tables, or identify document sections.",
  "parameters": {
    "type": "object",
    "properties": {
      "document_url": {
        "type": "string",
        "format": "uri",  
        "description": "URL or path to the PDF document"
      },
      "analysis_type": {
        "type": "string",
        "enum": ["structure", "tables", "images", "text", "full"],
        "description": "Type of analysis to perform"
      },
      "page_range": {
        "type": "object",
        "properties": {
          "start": {"type": "integer", "minimum": 1},
          "end": {"type": "integer", "minimum": 1}
        },
        "description": "Specific page range to analyze (optional)"
      }
    },
    "required": ["document_url", "analysis_type"]
  }
}

// Image Analysis Tool  
{
  "name": "analyze_document_image",
  "description": "Analyze images, charts, or diagrams from documents. Use when you need to understand visual content like graphs, diagrams, or photo content in PDFs.",
  "parameters": {
    "type": "object",
    "properties": {
      "image_url": {
        "type": "string",
        "format": "uri",
        "description": "URL to the image to analyze"
      },
      "analysis_focus": {
        "type": "string",
        "enum": ["charts", "text_ocr", "objects", "general"],
        "description": "What to focus on in the image analysis"
      },
      "context": {
        "type": "string",
        "description": "Additional context about what you're looking for in the image"
      }
    },
    "required": ["image_url"]
  }
}
\`\`\`

## 🎨 Advanced Tool Patterns

### 1. Conditional Tool Access

\`\`\`javascript
// Tool that checks permissions before execution
{
  "name": "access_sensitive_document",
  "description": "Access documents marked as sensitive. Only use when explicitly requested and user has appropriate permissions.",
  "parameters": {
    "type": "object",
    "properties": {
      "document_id": {
        "type": "string",
        "description": "ID of the sensitive document"
      },
      "access_reason": {
        "type": "string", 
        "description": "Reason for accessing this sensitive document"
      },
      "user_confirmation": {
        "type": "boolean",
        "description": "Has the user explicitly confirmed they want to access this sensitive document?"
      }
    },
    "required": ["document_id", "access_reason", "user_confirmation"]
  }
}
\`\`\`

### 2. Multi-Step Tool Workflows

\`\`\`javascript
// Tool that orchestrates multiple operations
{
  "name": "comprehensive_document_analysis",
  "description": "Perform a complete analysis of a document including content extraction, entity recognition, and summarization. Use for thorough document review.",
  "parameters": {
    "type": "object",
    "properties": {
      "document_id": {
        "type": "string",
        "description": "Document to analyze completely"
      },
      "analysis_depth": {
        "type": "string",
        "enum": ["quick", "standard", "comprehensive"],
        "description": "Depth of analysis to perform"
      },
      "include_sections": {
        "type": "array",
        "items": {
          "type": "string",
          "enum": ["summary", "entities", "sentiment", "topics", "structure"]
        },
        "description": "Which analysis sections to include"
      }
    },
    "required": ["document_id"]
  }
}
\`\`\`

### 3. Error-Resilient Tools

\`\`\`javascript
// Tool with comprehensive error handling
{
  "name": "robust_document_processor",
  "description": "Process documents with automatic retry and fallback mechanisms. Use when document processing reliability is critical.",
  "parameters": {
    "type": "object",
    "properties": {
      "document_source": {
        "type": "string",
        "description": "Source of the document (URL, file path, or ID)"
      },
      "processing_options": {
        "type": "object",
        "properties": {
          "retry_count": {
            "type": "integer",
            "minimum": 0,
            "maximum": 3,
            "default": 1,
            "description": "Number of retries if processing fails"
          },
          "fallback_method": {
            "type": "string",
            "enum": ["ocr", "text_only", "metadata_only"],
            "description": "Fallback method if primary processing fails"
          },
          "timeout_seconds": {
            "type": "integer",
            "minimum": 10,
            "maximum": 300,
            "default": 60,
            "description": "Maximum time to wait for processing"
          }
        }
      }
    },
    "required": ["document_source"]
  }
}
\`\`\`

## 🧪 Tool Testing & Validation

### 1. Tool Response Validation

\`\`\`javascript
// Add validation logic to tool responses
const validateToolResponse = {
  systemPrompt: `Always validate tool responses before using them:

  1. Check if the response format matches expectations
  2. Verify required fields are present  
  3. Validate data types and ranges
  4. Look for error indicators in the response
  
  If a tool response seems invalid:
  - Explain what's wrong
  - Try a different approach or tool
  - Ask for clarification if needed
  
  Tool Response: {{$json.tool_response}}
  Expected Format: {{$json.expected_format}}`,
  
  temperature: 0.2
};
\`\`\`

### 2. Tool Performance Monitoring

<WorkshopExercise 
  title="Implement Tool Performance Tracking" 
  difficulty="intermediate"
  timeEstimate="10 minutes"
  objectives={[
    "Add performance metrics to tool calls",
    "Track success/failure rates",
    "Identify optimization opportunities"
  ]}
>

<ExerciseStep stepNumber="1" title="Add Performance Tracking">

Wrap your tools with performance tracking:

\`\`\`javascript
// Before tool execution
{
  "startTime": "={{ new Date().toISOString() }}",
  "toolName": "search_documents",
  "inputParams": "={{ $json }}"
}

// After tool execution  
{
  "endTime": "={{ new Date().toISOString() }}",
  "executionTime": "={{ Date.parse($json.endTime) - Date.parse($json.startTime) }}",
  "success": "={{ $json.error ? false : true }}",
  "resultCount": "={{ $json.results ? $json.results.length : 0 }}"
}

// Store metrics in MongoDB
{
  "operation": "Insert One",
  "collection": "tool_performance_metrics",
  "document": {
    "tool_name": "={{ $json.toolName }}",
    "execution_time_ms": "={{ $json.executionTime }}",
    "success": "={{ $json.success }}",
    "input_size": "={{ JSON.stringify($json.inputParams).length }}",
    "output_size": "={{ JSON.stringify($json.results).length }}",
    "timestamp": "={{ new Date() }}",
    "session_id": "={{ $json.session_id }}"
  }
}
\`\`\`

</ExerciseStep>

</WorkshopExercise>

## 🔒 Tool Security & Best Practices

### 1. Access Control

\`\`\`javascript
// Implement role-based tool access
const toolAccessControl = {
  tools: {
    "search_documents": {
      required_roles: ["user", "admin"],
      rate_limit": "100/hour"
    },
    "delete_document": {
      required_roles: ["admin"],
      rate_limit": "10/hour",
      requires_confirmation: true
    },
    "access_sensitive_data": {
      required_roles: ["admin", "analyst"],
      rate_limit: "20/hour", 
      audit_log: true,
      requires_justification: true
    }
  }
};
\`\`\`

### 2. Input Sanitization

\`\`\`javascript
// Sanitize tool inputs before execution
const sanitizeInputs = {
  systemPrompt: `Before calling any tool, validate and sanitize inputs:

  1. Check for injection attempts (SQL, code, etc.)
  2. Validate data types match schema
  3. Ensure required parameters are present
  4. Sanitize string inputs (remove dangerous characters)
  5. Validate file paths and URLs
  
  If inputs seem suspicious, reject the tool call and explain why.`,
  
  validationRules: {
    "no_script_tags": "/<script|javascript:/i",
    "no_sql_injection": "/union|select|drop|delete|insert/i",
    "safe_file_paths": "/^[a-zA-Z0-9._/-]+$/",
    "valid_urls": "https?://"
  }
};
\`\`\`

### 3. Error Handling Patterns

\`\`\`javascript
// Comprehensive error handling for tools
const toolErrorHandling = {
  errorTypes: {
    "network_error": {
      retry: true,
      max_retries: 3,
      backoff: "exponential",
      user_message: "Network connection issue. Retrying..."
    },
    "permission_denied": {
      retry: false,
      user_message: "Access denied. Please check permissions.",
      escalate: true
    },
    "invalid_input": {
      retry: false,
      user_message: "Invalid input provided. Please check parameters.",
      suggest_fix: true
    },
    "resource_not_found": {
      retry: false,
      user_message: "Requested resource not found.",
      suggest_alternatives: true
    }
  }
};
\`\`\`

## 📊 Tool Optimization Strategies

### 1. Tool Selection Optimization

\`\`\`javascript
// Improve tool selection through better descriptions
const optimizedToolDescriptions = {
  "search_documents": {
    // ❌ Poor description
    bad: "Search documents",
    
    // ✅ Good description  
    good: "Search through PDF documents using semantic similarity. Use this when you need to find information across multiple documents, answer questions about document content, or when the user asks about specific topics that might be mentioned in the uploaded documents. This tool works best with specific, detailed queries rather than general questions."
  },
  
  "extract_pdf_text": {
    // ❌ Poor description
    bad: "Extract text from PDF",
    
    // ✅ Good description
    good: "Extract raw text content from specific pages of a PDF document. Use this when you need the exact text content from a document, want to analyze specific sections, or need to process text for further analysis. Specify page numbers when possible to get targeted content."
  }
};
\`\`\`

### 2. Tool Chaining Patterns

\`\`\`javascript
// Design tools that work well together
const toolChaining = {
  analysis_workflow: [
    {
      tool: "search_documents",
      purpose: "Find relevant documents",
      output_feeds: ["extract_pdf_text", "analyze_document_image"]
    },
    {
      tool: "extract_pdf_text", 
      purpose: "Get detailed text content",
      output_feeds: ["analyze_sentiment", "extract_entities"]
    },
    {
      tool: "analyze_document_image",
      purpose: "Process visual content",
      output_feeds: ["ocr_text", "chart_analysis"]
    },
    {
      tool: "synthesize_findings",
      purpose: "Combine all analysis results",
      inputs: ["text_analysis", "image_analysis", "entities"]
    }
  ]
};
\`\`\`

## 🎯 Tool Design Workshop Challenge

<WorkshopExercise 
  title="Design Your Own Tool Suite" 
  difficulty="advanced"
  timeEstimate="25 minutes"
  objectives={[
    "Design a custom tool for your specific use case",
    "Implement proper schema and error handling",
    "Test tool integration with AI agent"
  ]}
>

Design tools for a specific scenario:

**Scenario**: Legal document review system
**Required Tools**:
1. **Contract analyzer** - Find specific clauses
2. **Risk assessor** - Identify potential legal risks  
3. **Compliance checker** - Verify regulatory compliance
4. **Clause extractor** - Extract specific contract terms

For each tool, define:
- Clear name and description
- Comprehensive parameter schema
- Error handling approach
- Expected output format
- Integration with other tools

</WorkshopExercise>

## 🎭 Common Tool Design Antipatterns

### ❌ Antipattern 1: Vague Tool Descriptions
\`\`\`javascript
// Bad
{
  "name": "process_document",
  "description": "Does something with documents"
}

// Good  
{
  "name": "extract_financial_data",
  "description": "Extract financial information (revenue, expenses, profit) from financial documents like income statements, balance sheets, and financial reports. Returns structured data with amounts, dates, and categories."
}
\`\`\`

### ❌ Antipattern 2: Overly Complex Tools
\`\`\`javascript
// Bad - Tool that does everything
{
  "name": "analyze_everything",
  "parameters": {
    "do_text_analysis": {"type": "boolean"},
    "do_image_analysis": {"type": "boolean"}, 
    "extract_entities": {"type": "boolean"},
    "create_summary": {"type": "boolean"}
    // ... 20 more parameters
  }
}

// Good - Focused, single-purpose tools
{
  "name": "extract_document_entities",
  "description": "Extract named entities (people, organizations, locations, dates) from document text"
}
\`\`\`

### ❌ Antipattern 3: Poor Error Messages
\`\`\`javascript
// Bad
{
  "error": "Something went wrong"
}

// Good
{
  "error": "Document not found: The specified document ID 'doc_123' does not exist in the system. Please verify the document ID or search for available documents first.",
  "error_code": "DOCUMENT_NOT_FOUND",
  "suggested_action": "Use search_documents tool to find available documents"
}
\`\`\`

## 🚀 Next Steps

With well-designed tools, your AI agents can:
- 🔍 Search and analyze any type of content
- 🛠️ Process data with precision and reliability  
- 🔗 Chain operations for complex workflows
- 🧠 Learn from tool usage patterns
- 🔒 Operate securely within defined boundaries

Tools are the bridge between AI reasoning and real-world capabilities. Master tool design, and you'll build agents that can truly act on their insights!

<Quiz 
  title="Tool Design Mastery Check"
  passingScore={75}
  questions={[
    {
      question: "What's the most important aspect of a tool description?",
      options: [
        "Being as short as possible",
        "Clearly explaining when and why to use the tool",
        "Listing all possible parameters",
        "Including technical implementation details"
      ],
      correctAnswer: 1,
      explanation: "AI agents rely on descriptions to choose the right tool. Clear guidance on when and why to use each tool is crucial for proper tool selection."
    },
    {
      question: "How should you handle tool errors?",
      options: [
        "Return generic error messages",
        "Crash the workflow to alert users",
        "Provide specific error details and suggested actions",
        "Ignore errors and continue processing"
      ],
      correctAnswer: 2,
      explanation: "Good error handling provides specific information about what went wrong and guides the agent (or user) on how to resolve the issue."
    },
    {
      question: "What makes a tool 'chainable' with other tools?",
      options: [
        "Having many parameters",
        "Producing output that other tools can consume as input",
        "Being the fastest tool available",
        "Having no dependencies"
      ],
      correctAnswer: 1,
      explanation: "Chainable tools produce structured output that can be consumed by other tools, enabling sophisticated multi-step workflows."
    }
  ]}
/>

## 📚 Continue Learning

- [Build Multimodal Image Queries →](./multimodal-image-queries)
- **Advanced Agent Patterns** - Coming soon!
- **Production Tool Deployment** - Coming soon!
```

# docs/69-multimodal-image-queries.mdx

```mdx
---
sidebar_position: 69
---

# 🖼️ Multimodal Image Queries & Visual Understanding

"Screenshots are all you need" - this powerful concept from multimodal AI means agents can understand and analyze visual content just as well as text. Let's build workflows that handle image queries and visual document analysis.

<InstructorNotes 
  timing="Multimodal Image Queries (25-30 minutes)"
  notes={[
    "This is where the 'multimodal' aspect really shines",
    "Screenshots of interfaces, diagrams, charts are common use cases",
    "Voyage AI's multimodal model handles both text and images in unified vector space",
    "Visual question answering often surprises attendees with accuracy",
    "Common issue: image quality affects analysis results significantly"
  ]}
  tips={[
    "Use clear, high-resolution example images for demonstrations",
    "Show both simple image questions and complex visual analysis",
    "Emphasize that this works with any image content, not just PDFs",
    "Demonstrate combining text and image queries for better results",
    "Address privacy considerations when processing visual content"
  ]}
/>

<SlideRecap 
  title="Visual Intelligence in Action"
  items={[
    {
      icon: "👁️",
      title: "Visual Understanding", 
      description: "How AI models process and comprehend visual content like humans"
    },
    {
      icon: "🔗", 
      title: "Multimodal Fusion",
      description: "Combining text and image understanding in a unified approach"
    },
    {
      icon: "📊",
      title: "Practical Applications",
      description: "Real-world use cases from document analysis to interface understanding"
    }
  ]}
  nextSection="Let's build workflows that see and understand visual content!"
/>

## 🎯 Multimodal Understanding Fundamentals

### What Makes Content "Multimodal"?

Modern AI agents can process multiple modalities simultaneously:

| Modality | Examples | Use Cases |
|----------|----------|-----------|
| **Text** | Documents, emails, code | Traditional NLP tasks |
| **Images** | Photos, diagrams, charts | Visual analysis, OCR |
| **Combined** | PDFs with images, web pages | Document understanding |
| **Structured** | Tables, forms, layouts | Data extraction |

### Voyage AI Multimodal Model

The `voyage-multimodal-3` model creates unified embeddings for both text and images:

\`\`\`mermaid
graph TD
    A[Text Content] --> C[Multimodal Encoder]
    B[Image Content] --> C
    C --> D[1024-dim Vector]
    D --> E[Vector Search]
    E --> F[Unified Results]
\`\`\`

## 🖼️ Image Processing Workflow

### Basic Image Analysis Setup

<WorkshopExercise 
  title="Build Image Analysis Workflow" 
  difficulty="intermediate"
  timeEstimate="20 minutes"
  objectives={[
    "Create image upload and processing workflow",
    "Implement multimodal embedding generation",
    "Build image-based question answering system"
  ]}
>

<ExerciseStep stepNumber="1" title="Image Upload Handler">

Create a webhook to handle image uploads:

\`\`\`javascript
// Webhook node configuration
{
  "httpMethod": "POST",
  "path": "/analyze-image",
  "responseMode": "lastNode",
  "options": {}
}

// Expected request format:
{
  "image_url": "https://example.com/image.jpg",
  "question": "What does this chart show?",
  "context": "This is from a financial report"
}
\`\`\`

</ExerciseStep>

<ExerciseStep stepNumber="2" title="Image Processing Pipeline">

Build the processing workflow:

**1. Download and Validate Image:**
\`\`\`javascript
// HTTP Request node - Download image
{
  "method": "GET", 
  "url": "{{ $json.image_url }}",
  "responseFormat": "file",
  "options": {
    "timeout": 30000,
    "followRedirects": true
  }
}

// Function node - Validate image
{
  "code": `
    const supportedFormats = ['image/jpeg', 'image/png', 'image/gif', 'image/webp'];
    const contentType = $input.first().binary.mimeType;
    
    if (!supportedFormats.includes(contentType)) {
      throw new Error(\`Unsupported image format: \${contentType}\`);
    }
    
    // Check file size (max 10MB)
    const fileSize = $input.first().binary.data.length;
    if (fileSize > 10 * 1024 * 1024) {
      throw new Error('Image too large. Maximum size: 10MB');
    }
    
    return {
      image_data: $input.first().binary.data,
      content_type: contentType,
      file_size: fileSize,
      question: $('Webhook').first().json.question,
      context: $('Webhook').first().json.context || ''
    };
  `
}
\`\`\`

**2. Generate Multimodal Embedding:**
\`\`\`javascript
// HTTP Request node - Voyage AI multimodal embedding
{
  "method": "POST",
  "url": "https://workshop-embedding-api.vercel.app/api/embed",
  "headers": {
    "Content-Type": "application/json"
  },
  "body": {
    "content": {
      "image": "{{ $json.image_data }}", // Base64 encoded
      "text": "{{ $json.question }}{{ $json.context ? ' Context: ' + $json.context : '' }}"
    },
    "model": "voyage-multimodal-3",
    "input_type": "multimodal"
  }
}
\`\`\`

</ExerciseStep>

<ExerciseStep stepNumber="3" title="Visual Question Answering">

Implement the Q&A system:

**Search Similar Visual Content:**
\`\`\`javascript
// MongoDB node - Vector search for similar images/content
{
  "operation": "Aggregate",
  "collection": "multimodal_content",
  "pipeline": [
    {
      "$vectorSearch": {
        "index": "multimodal_vector_index",
        "path": "embedding",
        "queryVector": "{{ $json.embedding }}",
        "numCandidates": 50,  
        "limit": 5,
        "filter": {
          "content_type": {"$in": ["image", "multimodal"]}
        }
      }
    },
    {
      "$project": {
        "content": 1,
        "metadata": 1,
        "image_analysis": 1,
        "score": {"$meta": "vectorSearchScore"}
      }
    }
  ]
}
\`\`\`

**AI Agent for Visual Analysis:**
\`\`\`javascript
// AI Agent node configuration
{
  "model": "gemini-2.0-flash-exp",
  "systemMessage": `You are a visual analysis expert. Analyze images and answer questions about their content.

Available context from similar images:
{{ #each $json.similar_content }}
- {{ this.metadata.description }}: {{ this.image_analysis.summary }}
{{ /each }}

When analyzing images, consider:
1. Visual elements (objects, text, colors, layout)
2. Charts/graphs (data, trends, relationships)  
3. Documents (structure, content, formatting)
4. Interface elements (buttons, menus, forms)
5. Context clues and relationships

Provide detailed, accurate analysis based on what you can see.`,
  
  "tools": [
    {
      "name": "extract_text_from_image",
      "description": "Extract and transcribe text visible in the image using OCR",
      "parameters": {
        "type": "object",
        "properties": {
          "image_region": {
            "type": "string",
            "description": "Specific region to focus OCR on (optional)"
          }
        }
      }
    },
    {
      "name": "analyze_chart_data", 
      "description": "Analyze charts, graphs, or data visualizations in the image",
      "parameters": {
        "type": "object",
        "properties": {
          "chart_type": {
            "type": "string",
            "enum": ["bar", "line", "pie", "scatter", "table", "other"]
          },
          "extract_data": {
            "type": "boolean",
            "description": "Whether to extract numerical data points"
          }
        }
      }
    },
    {
      "name": "identify_ui_elements",
      "description": "Identify and describe user interface elements in screenshots",
      "parameters": {
        "type": "object", 
        "properties": {
          "element_types": {
            "type": "array",
            "items": {
              "type": "string",
              "enum": ["buttons", "forms", "menus", "text", "images"]
            }
          }
        }
      }
    }
  ]
}
\`\`\`

</ExerciseStep>

</WorkshopExercise>

## 📊 Visual Content Analysis Patterns

### 1. Chart and Graph Analysis

\`\`\`javascript
// Specialized chart analysis workflow
const chartAnalysisPrompt = `
Analyze this chart/graph systematically:

1. **Chart Type**: Identify the type (bar, line, pie, scatter, etc.)
2. **Axes & Labels**: Read axis labels, titles, and units
3. **Data Points**: Extract key data points and values
4. **Trends**: Identify patterns, trends, or anomalies
5. **Context**: Relate findings to the user's question

User Question: {{ $json.question }}
Additional Context: {{ $json.context }}

Provide both a summary and detailed data extraction.
`;

// Example responses for different chart types
const chartResponses = {
  bar_chart: {
    summary: "Revenue comparison across quarters showing 15% growth",
    data_points: [
      {"quarter": "Q1", "revenue": 2.3, "unit": "million"},
      {"quarter": "Q2", "revenue": 2.7, "unit": "million"}
    ],
    trends: ["Consistent upward trend", "Q2 shows acceleration"]
  },
  
  pie_chart: {
    summary: "Budget allocation across departments",
    data_points: [
      {"category": "Engineering", "percentage": 45, "amount": "1.8M"},
      {"category": "Marketing", "percentage": 30, "amount": "1.2M"}
    ],
    insights: ["Engineering dominates budget", "Marketing is second priority"]
  }
};
\`\`\`

### 2. Document Layout Analysis

\`\`\`javascript
// Document structure recognition
const documentAnalysisPrompt = `
Analyze this document image for:

1. **Document Type**: Invoice, contract, report, form, etc.
2. **Layout Structure**: Headers, sections, tables, signatures
3. **Key Information**: Important fields, values, dates
4. **Text Quality**: Readability, scan quality, completeness
5. **Processing Recommendations**: Best extraction approach

Focus on: {{ $json.analysis_focus }}
Question: {{ $json.question }}
`;

// MongoDB schema for document layout analysis
const documentLayoutSchema = {
  document_id: "doc_456",
  analysis_type: "layout_structure",
  visual_elements: {
    headers: [
      {
        text: "INVOICE #12345",
        position: {x: 100, y: 50},
        confidence: 0.95
      }
    ],
    tables: [
      {
        rows: 5,
        columns: 4,
        position: {x: 50, y: 200, width: 500, height: 200},  
        content_type: "itemized_charges"
      }
    ],
    signatures: [
      {
        position: {x: 400, y: 600},
        type: "handwritten",
        confidence: 0.87
      }
    ]
  },
  extraction_recommendations: [
    "Use table parsing for itemized charges",
    "OCR quality sufficient for text extraction",
    "Signature detection successful"
  ]
};
\`\`\`

### 3. Interface Screenshot Analysis

\`\`\`javascript
// UI/UX analysis for screenshots
const interfaceAnalysisPrompt = `
Analyze this interface screenshot:

1. **Interface Type**: Web page, mobile app, desktop application, etc.
2. **Navigation Elements**: Menus, buttons, links, breadcrumbs
3. **Content Areas**: Main content, sidebars, headers, footers
4. **Interactive Elements**: Forms, buttons, input fields
5. **Visual Hierarchy**: Layout, typography, color usage
6. **User Experience**: Clarity, accessibility, usability

Question: {{ $json.question }}
Focus Area: {{ $json.focus_area }}
`;

// Example UI element detection
const uiElementsDetected = {
  navigation: {
    primary_menu: ["Home", "Products", "About", "Contact"],
    breadcrumb: "Home > Products > Category",
    search_bar: {present: true, placeholder: "Search products..."}
  },
  content: {
    main_heading: "Product Catalog",
    product_grid: {
      items_visible: 12,
      layout: "3x4 grid",
      pagination: true
    }
  },
  interactive: {
    buttons: ["Add to Cart", "View Details", "Compare"],
    forms: ["Newsletter signup", "Product filter"],
    calls_to_action: 3
  }
};
\`\`\`

## 🔄 Multimodal Search Implementation

### Enhanced Vector Search with Image Context

<WorkshopExercise 
  title="Build Multimodal Search System" 
  difficulty="advanced"
  timeEstimate="25 minutes"
  objectives={[
    "Implement combined text + image search",
    "Create weighted multimodal queries",
    "Build visual similarity clustering"
  ]}
>

<ExerciseStep stepNumber="1" title="Multimodal Index Creation">

Create a comprehensive vector index:

\`\`\`javascript
// MongoDB vector search index for multimodal content
{
  "fields": [
    {
      "type": "vector",
      "path": "text_embedding",
      "numDimensions": 1024,
      "similarity": "cosine"
    },
    {
      "type": "vector", 
      "path": "image_embedding",
      "numDimensions": 1024,
      "similarity": "cosine"
    },
    {
      "type": "vector",
      "path": "multimodal_embedding", 
      "numDimensions": 1024,
      "similarity": "cosine"
    },
    {
      "type": "filter",
      "path": "content_type"
    },
    {
      "type": "filter",
      "path": "visual_features.has_charts"
    },
    {
      "type": "filter", 
      "path": "visual_features.has_tables"
    }
  ]
}
\`\`\`

</ExerciseStep>

<ExerciseStep stepNumber="2" title="Weighted Multimodal Search">

Implement search that combines multiple modalities:

\`\`\`javascript
// Function node - Calculate weighted search
{
  "code": `
    const query = $input.first().json;
    const weights = {
      text: query.text_weight || 0.6,
      image: query.image_weight || 0.4,
      multimodal: query.multimodal_weight || 1.0
    };
    
    // Generate embeddings for each modality
    const searches = [];
    
    if (query.text_query && weights.text > 0) {
      searches.push({
        type: 'text',
        weight: weights.text,
        embedding_path: 'text_embedding',
        query: query.text_query
      });
    }
    
    if (query.image_query && weights.image > 0) {
      searches.push({
        type: 'image', 
        weight: weights.image,
        embedding_path: 'image_embedding',
        query: query.image_query
      });
    }
    
    if (query.combined_query && weights.multimodal > 0) {
      searches.push({
        type: 'multimodal',
        weight: weights.multimodal,
        embedding_path: 'multimodal_embedding', 
        query: query.combined_query
      });
    }
    
    return { searches, query };
  `
}

// MongoDB aggregation for combined search
{
  "operation": "Aggregate",
  "collection": "multimodal_content", 
  "pipeline": [
    {
      "$search": {
        "compound": {
          "should": [
            {
              "$vectorSearch": {
                "index": "multimodal_index",
                "path": "text_embedding",
                "queryVector": "{{ $json.text_embedding }}",
                "numCandidates": 50,
                "boost": "{{ $json.searches[0].weight }}"
              }
            },
            {
              "$vectorSearch": {
                "index": "multimodal_index", 
                "path": "image_embedding",
                "queryVector": "{{ $json.image_embedding }}",
                "numCandidates": 50,
                "boost": "{{ $json.searches[1].weight }}"
              }
            }
          ]
        }
      }
    },
    {
      "$limit": 10
    },
    {
      "$project": {
        "content": 1,
        "metadata": 1,
        "visual_features": 1,
        "combined_score": {"$meta": "searchScore"}
      }
    }
  ]
}
\`\`\`

</ExerciseStep>

<ExerciseStep stepNumber="3" title="Visual Similarity Clustering">

Group similar visual content:

\`\`\`javascript
// Function node - Cluster similar images
{
  "code": `
    const results = $input.first().json.results;
    const clusters = [];
    const threshold = 0.85; // Similarity threshold
    
    results.forEach((item, index) => {
      let assigned = false;
      
      // Check if item belongs to existing cluster
      for (let cluster of clusters) {
        const similarity = calculateCosineSimilarity(
          item.image_embedding, 
          cluster.centroid_embedding
        );
        
        if (similarity > threshold) {
          cluster.items.push(item);
          cluster.centroid_embedding = updateCentroid(cluster.items);
          assigned = true;
          break;
        }
      }
      
      // Create new cluster if not assigned
      if (!assigned) {
        clusters.push({
          id: clusters.length,
          items: [item],
          centroid_embedding: item.image_embedding,
          representative_item: item
        });
      }
    });
    
    return { clusters, total_items: results.length };
  `
}
\`\`\`

</ExerciseStep>

</WorkshopExercise>

## 🎨 Advanced Visual Analysis Patterns

### 1. Multi-Image Comparison

\`\`\`javascript
// Compare multiple images in a single query
const multiImageComparison = {
  prompt: `Compare these images and identify:
  
  1. **Similarities**: What do they have in common?
  2. **Differences**: How do they differ?
  3. **Patterns**: Any recurring themes or elements?
  4. **Quality**: Which image is clearer/more informative?
  5. **Context**: How do they relate to each other?
  
  Images: {{ $json.image_urls }}
  Question: {{ $json.comparison_question }}`,
  
  implementation: {
    process_images: "parallel",
    generate_embeddings: "batch", 
    compare_vectors: "pairwise",
    synthesize_results: "llm_analysis"
  }
};
\`\`\`

### 2. Progressive Visual Analysis

\`\`\`javascript
// Multi-step visual analysis workflow
const progressiveAnalysis = {
  steps: [
    {
      name: "initial_scan",
      prompt: "What type of visual content is this? Provide a brief overview.",
      confidence_threshold: 0.8
    },
    {
      name: "detailed_analysis", 
      prompt: "Based on the content type, perform detailed analysis of key elements.",
      depends_on: "initial_scan"
    },
    {
      name: "data_extraction",
      prompt: "Extract specific data points, text, or measurements as requested.",
      depends_on: "detailed_analysis",
      tools: ["ocr_extraction", "chart_parser"]
    },
    {
      name: "synthesis",
      prompt: "Combine all findings to answer the user's question comprehensively.",
      depends_on: ["initial_scan", "detailed_analysis", "data_extraction"]
    }
  ]
};
\`\`\`

### 3. Visual Context Enhancement

\`\`\`javascript
// Enhance image understanding with metadata context
const contextEnhancement = {
  image_metadata: {
    source: "financial_report_q3_2024.pdf",
    page: 15,
    section: "revenue_analysis",
    surrounding_text: "The following chart shows quarterly revenue trends...",
    document_type: "financial_report"
  },
  
  enhanced_prompt: `Analyze this image with additional context:
  
  Source: {{ metadata.source }}
  Document Section: {{ metadata.section }}
  Surrounding Text: "{{ metadata.surrounding_text }}"
  
  Use this context to provide more accurate and relevant analysis.
  
  User Question: {{ $json.question }}`
};
\`\`\`

## 📱 Real-World Use Cases

### 1. Technical Documentation Analysis

\`\`\`javascript
// Analyze software documentation screenshots
const techDocAnalysis = {
  use_cases: [
    "API documentation with code examples",
    "Software interface tutorials", 
    "Configuration screenshots",
    "Error message analysis",
    "Installation step verification"
  ],
  
  specialized_prompts: {
    api_docs: "Extract API endpoints, parameters, and example responses from this documentation screenshot.",
    ui_tutorial: "Describe the UI elements and steps shown in this tutorial screenshot.",
    error_analysis: "Identify the error message and suggest potential solutions based on the screenshot."
  }
};
\`\`\`

### 2. Business Process Documentation

\`\`\`javascript
// Analyze workflow diagrams and process charts
const processDocAnalysis = {
  diagram_types: [
    "flowcharts",
    "organizational_charts", 
    "process_diagrams",
    "network_diagrams",
    "architecture_diagrams"
  ],
  
  analysis_framework: {
    structure: "Identify main components and their relationships",
    flow: "Trace the process flow and decision points",
    bottlenecks: "Identify potential bottlenecks or inefficiencies",
    compliance: "Check for regulatory or best practice compliance"
  }
};
\`\`\`

### 3. Educational Content Analysis

\`\`\`javascript
// Analyze educational materials and presentations
const educationalAnalysis = {
  content_types: [
    "presentation_slides",
    "textbook_diagrams",
    "lab_procedures",
    "exam_questions",
    "interactive_exercises"
  ],
  
  learning_objectives: {
    comprehension: "Assess understanding of key concepts",
    application: "Identify practical applications",
    analysis: "Break down complex information",
    synthesis: "Combine information from multiple sources"
  }
};
\`\`\`

## 🔍 Visual Search Optimization

### Image Quality Preprocessing

\`\`\`javascript
// Optimize images for better analysis
const imagePreprocessing = {
  quality_checks: [
    {
      metric: "resolution",
      minimum: "800x600",
      recommendation: "Resize if too small, compress if too large"
    },
    {
      metric: "contrast",
      threshold: 0.7,
      enhancement: "Auto-contrast adjustment"
    },
    {
      metric: "text_clarity",
      ocr_confidence: 0.8,
      action: "Sharpen text regions"
    }
  ],
  
  preprocessing_pipeline: [
    "noise_reduction",
    "contrast_enhancement", 
    "text_region_detection",
    "orientation_correction",
    "format_standardization"
  ]
};
\`\`\`

## 🎯 Testing Visual Understanding

<Quiz 
  title="Multimodal AI Concepts"
  passingScore={80}
  questions={[
    {
      question: "What makes an embedding 'multimodal'?",
      options: [
        "It processes multiple files at once",
        "It combines different types of content (text, images) in a unified vector space",
        "It runs on multiple servers simultaneously", 
        "It supports multiple languages"
      ],
      correctAnswer: 1,
      explanation: "Multimodal embeddings create unified representations where text and images exist in the same vector space, enabling cross-modal search and understanding."
    },
    {
      question: "When should you use weighted multimodal search?",
      options: [
        "When you have both text and visual queries with different importance",
        "When your database is very large",
        "When you need faster search results",
        "When you have multiple users searching simultaneously"
      ],
      correctAnswer: 0,
      explanation: "Weighted search allows you to emphasize different modalities based on your query - prioritizing text for factual questions or images for visual similarity."
    },
    {
      question: "What's the key advantage of progressive visual analysis?",
      options: [
        "It's faster than single-step analysis",
        "It builds understanding incrementally, allowing for more accurate and detailed results",
        "It uses less computational resources",
        "It works with lower quality images"
      ],
      correctAnswer: 1,
      explanation: "Progressive analysis mimics human visual understanding - starting with general recognition and building to detailed analysis based on what's discovered."
    }
  ]}
/>

## 🚀 Advanced Challenge

<WorkshopExercise 
  title="Build a Complete Visual Document Assistant" 
  difficulty="expert"
  timeEstimate="30 minutes"
  objectives={[
    "Create end-to-end visual document processing",
    "Implement multi-step visual analysis", 
    "Build intelligent visual question answering"
  ]}
>

Create a system that can:
1. **Accept** various image inputs (photos, screenshots, scanned docs)
2. **Analyze** content type and quality automatically
3. **Extract** relevant information based on content type
4. **Answer** complex questions about visual content
5. **Learn** from interactions to improve future analysis

Test with:
- Financial charts and graphs
- Software interface screenshots  
- Scanned legal documents
- Technical diagrams
- Mixed content presentations

</WorkshopExercise>

Visual understanding transforms AI agents from text-only systems into comprehensive intelligent assistants. With multimodal capabilities, your agents can truly see and understand the world as humans do! 👁️🧠

## 📚 Next Steps

- **Advanced Agent Techniques** - Coming soon!
- **Production Visual Systems** - Coming soon!
- **Computer Vision Integration** - Coming soon!
```

# docs/70-complete-multimodal-agent.mdx

```mdx
---
sidebar_position: 70
---

# 🧠 Complete Multimodal PDF Agent

Build a complete multimodal AI agent that can process PDFs, understand both text and images, and answer questions using MongoDB Vector Search and Voyage AI.

<InstructorNotes 
  timing="Complete Agent Integration (25-30 minutes)"
  notes={[
    "This section integrates everything - expect integration issues to surface",
    "Memory management becomes important with large PDFs and long conversations",
    "Error handling is crucial - workflows are now complex enough to fail in multiple ways",
    "Performance optimization discussions often come up here",
    "Attendees want to test with their own PDFs - have guidelines ready"
  ]}
  tips={[
    "Start with end-to-end demo showing complete workflow",
    "Emphasize testing each component individually before integration",
    "Show monitoring and logging strategies for production workflows",
    "Discuss scaling considerations (rate limits, memory, storage)",
    "Have sample questions ready that showcase multimodal capabilities",
    "Address common production concerns (security, cost, reliability)"
  ]}
/>

## Agent Capabilities

Your finished agent will:
- ✅ **Accept PDF uploads** via web interface
- ✅ **Extract text and images** from PDF pages
- ✅ **Generate multimodal embeddings** using Voyage AI
- ✅ **Store in MongoDB** with vector search index
- ✅ **Answer questions** about PDF content
- ✅ **Understand images** and visual content
- ✅ **Maintain conversation** context

## Architecture Overview

\`\`\`mermaid
graph TD
    A[PDF Upload] --> B[Extract Pages]
    B --> C[Text Extraction]
    B --> D[Image Extraction]
    C --> E[Generate Text Embeddings]
    D --> F[Generate Image Embeddings]
    E --> G[Store in MongoDB]
    F --> G
    H[User Question] --> I[Generate Query Embedding]
    I --> J[Vector Search]
    J --> K[Retrieve Context]
    K --> L[Generate Response]
    L --> M[Return Answer]
\`\`\`

## Complete Workflow Implementation

### 1. PDF Processing Pipeline

**Workflow Name**: `Multimodal PDF Processor`

#### Trigger: File Upload Webhook
\`\`\`json
{
  "path": "/upload-pdf",
  "method": "POST",
  "response_mode": "lastNode"
}
\`\`\`

#### Node 1: Validate Upload
\`\`\`javascript
// JavaScript node to validate PDF
const files = $input.all();
if (!files.length || !files[0].binary) {
  throw new Error('No PDF file uploaded');
}

const filename = files[0].binary.data.fileName;
if (!filename.toLowerCase().endsWith('.pdf')) {
  throw new Error('Only PDF files are supported');
}

return [{
  json: {
    filename: filename,
    fileSize: files[0].binary.data.fileSize,
    timestamp: new Date().toISOString()
  },
  binary: files[0].binary
}];
\`\`\`

#### Node 2: Convert PDF to Images
\`\`\`javascript
// Using PDF-lib or similar
// This extracts each page as an image for multimodal processing
const pdfBuffer = Buffer.from($binary.data, 'base64');
const pages = await extractPagesAsImages(pdfBuffer);

return pages.map((page, index) => ({
  json: {
    filename: $json.filename,
    pageNumber: index + 1,
    totalPages: pages.length
  },
  binary: {
    data: page.buffer,
    mimeType: 'image/png',
    fileName: `${$json.filename}_page_${index + 1}.png`
  }
}));
\`\`\`

#### Node 3: Extract Text Content
\`\`\`javascript
// Extract text from each page
const textContent = await extractTextFromPDF($binary.data);
return [{
  json: {
    filename: $json.filename,
    textContent: textContent,
    wordCount: textContent.split(' ').length
  }
}];
\`\`\`

#### Node 4: Generate Multimodal Embeddings
**HTTP Request Node** to your embedding API:
\`\`\`json
{
  "url": "https://workshop-embedding-api.vercel.app/api/embed",
  "method": "POST",
  "headers": {
    "Content-Type": "application/json"
  },
  "body": {
    "text": "={{ $json.textContent }}",
    "model": "voyage-3"
  }
}
\`\`\`

#### Node 5: Store in MongoDB
\`\`\`javascript
// MongoDB node configuration
{
  "collection": "pdf_documents",
  "operation": "insertOne",
  "document": {
    "filename": "={{ $json.filename }}",
    "pageNumber": "={{ $json.pageNumber }}",
    "textContent": "={{ $json.textContent }}",
    "embedding": "={{ $json.embeddings[0] }}",
    "metadata": {
      "uploadedAt": "={{ $json.timestamp }}",
      "wordCount": "={{ $json.wordCount }}",
      "fileSize": "={{ $json.fileSize }}"
    }
  }
}
\`\`\`

### 2. Conversational Agent Interface

**Workflow Name**: `Multimodal PDF Agent`

#### Trigger: Chat Webhook
\`\`\`json
{
  "path": "/chat",
  "method": "POST",
  "response_mode": "lastNode"
}
\`\`\`

Expected input:
\`\`\`json
{
  "message": "What is discussed about AI in the uploaded document?",
  "filename": "research_paper.pdf",
  "conversation_id": "unique-id"
}
\`\`\`

#### Node 1: Generate Query Embedding
**HTTP Request** to embedding API:
\`\`\`json
{
  "url": "https://workshop-embedding-api.vercel.app/api/embed",
  "method": "POST",
  "body": {
    "text": "={{ $json.message }}",
    "model": "voyage-3"
  }
}
\`\`\`

#### Node 2: Vector Search in MongoDB
\`\`\`javascript
// MongoDB Aggregate operation
[
  {
    $vectorSearch: {
      index: "vector_index",
      path: "embedding",
      queryVector: $json.embeddings[0],
      numCandidates: 50,
      limit: 5,
      filter: {
        filename: $json.filename
      }
    }
  },
  {
    $project: {
      textContent: 1,
      pageNumber: 1,
      score: { $meta: "vectorSearchScore" },
      filename: 1
    }
  }
]
\`\`\`

#### Node 3: Build Context
\`\`\`javascript
// Combine search results into context
const searchResults = $input.all();
const context = searchResults
  .map(result => `Page ${result.json.pageNumber}: ${result.json.textContent}`)
  .join('\n\n');

return [{
  json: {
    query: $('Node 1').first().json.message,
    context: context,
    relevantPages: searchResults.map(r => r.json.pageNumber),
    filename: $json.filename
  }
}];
\`\`\`

#### Node 4: Generate AI Response
**HTTP Request** to AI service (Gemini/OpenAI):
\`\`\`json
{
  "url": "https://api.openai.com/v1/chat/completions",
  "method": "POST",
  "headers": {
    "Authorization": "Bearer YOUR_API_KEY",
    "Content-Type": "application/json"
  },
  "body": {
    "model": "gpt-4",
    "messages": [
      {
        "role": "system",
        "content": "You are a helpful AI assistant that answers questions about PDF documents. Use the provided context to answer questions accurately. If the context doesn't contain relevant information, say so."
      },
      {
        "role": "user",
        "content": "Question: {{ $json.query }}\n\nContext from {{ $json.filename }}:\n{{ $json.context }}\n\nPlease answer the question based on the context provided."
      }
    ]
  }
}
\`\`\`

#### Node 5: Format Response
\`\`\`javascript
return [{
  json: {
    response: $json.choices[0].message.content,
    sources: {
      filename: $json.filename,
      relevantPages: $json.relevantPages
    },
    timestamp: new Date().toISOString(),
    conversationId: $json.conversation_id
  }
}];
\`\`\`

## Testing Your Agent

### 1. Upload a PDF
\`\`\`bash
curl -X POST http://localhost:5678/webhook/upload-pdf \
  -F "file=@sample.pdf"
\`\`\`

### 2. Ask Questions
\`\`\`bash
curl -X POST http://localhost:5678/webhook/chat \
  -H "Content-Type: application/json" \
  -d '{
    "message": "What are the main findings in this research?",
    "filename": "sample.pdf",
    "conversation_id": "test-123"
  }'
\`\`\`

## Advanced Features

### Image Understanding
For multimodal capabilities, enhance the embedding generation:

\`\`\`javascript
// Process images with Voyage AI multimodal
const imageEmbedding = await generateEmbedding({
  image: $binary.data, // Base64 image
  text: `Image from page ${$json.pageNumber} of ${$json.filename}`,
  model: "voyage-multimodal-3"
});
\`\`\`

### Conversation Memory
Store conversation history in MongoDB:

\`\`\`javascript
{
  "collection": "conversations",
  "operation": "updateOne",
  "filter": { "conversationId": "={{ $json.conversation_id }}" },
  "update": {
    "$push": {
      "messages": {
        "timestamp": "={{ $json.timestamp }}",
        "question": "={{ $json.query }}",
        "response": "={{ $json.response }}",
        "sources": "={{ $json.sources }}"
      }
    }
  },
  "upsert": true
}
\`\`\`

## Web Interface (Optional)

Create a simple HTML interface:

\`\`\`html
<!DOCTYPE html>
<html>
<head>
    <title>Multimodal PDF Agent</title>
</head>
<body>
    <div id="upload-section">
        <h2>Upload PDF</h2>
        <input type="file" id="pdfFile" accept=".pdf">
        <button onclick="uploadPDF()">Upload</button>
    </div>
    
    <div id="chat-section">
        <h2>Ask Questions</h2>
        <input type="text" id="question" placeholder="Ask about your PDF...">
        <button onclick="askQuestion()">Ask</button>
        <div id="response"></div>
    </div>

    <script>
        async function uploadPDF() {
            const file = document.getElementById('pdfFile').files[0];
            const formData = new FormData();
            formData.append('file', file);
            
            const response = await fetch('/webhook/upload-pdf', {
                method: 'POST',
                body: formData
            });
            
            const result = await response.json();
            console.log('Upload result:', result);
        }
        
        async function askQuestion() {
            const question = document.getElementById('question').value;
            const response = await fetch('/webhook/chat', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    message: question,
                    filename: 'uploaded.pdf',
                    conversation_id: 'web-session'
                })
            });
            
            const result = await response.json();
            document.getElementById('response').innerHTML = result.response;
        }
    </script>
</body>
</html>
\`\`\`

## Success Metrics

Your agent is working when you can:
- ✅ Upload a PDF and see it processed
- ✅ Ask questions about the content
- ✅ Get relevant answers with page references
- ✅ Handle both text and visual content
- ✅ Maintain conversation context

## Next Steps

1. **Enhance with function calling** for complex queries
2. **Add support for multiple file formats**
3. **Implement user authentication**
4. **Add real-time chat interface**
5. **Deploy to production**

Your multimodal PDF agent is now complete and ready for real-world use!
```

# docs/75-mongodb-vector-setup.mdx

```mdx
---
sidebar_position: 75
---

# 🗄️ MongoDB Vector Search Setup

Configure MongoDB for real vector search capabilities in your multimodal PDF agent.

## MongoDB Atlas Vector Search Setup

**Important**: This workshop requires MongoDB Atlas for vector search capabilities. Local MongoDB instances do not support vector search indexing.

### 1. Create the Vector Search Index in Atlas

In MongoDB Atlas, create a vector search index with this configuration:

\`\`\`json
{
  "fields": [
    {
      "type": "vector",
      "path": "embedding",
      "numDimensions": 1024,
      "similarity": "cosine"
    }
  ]
}
\`\`\`

### 2. Atlas Search Index Alternative

You can also create a traditional Atlas Search index for text-based search:

\`\`\`json
{
  "mappings": {
    "dynamic": true,
    "fields": {
      "textContent": {
        "type": "string"
      },
      "metadata": {
        "type": "document"
      }
    }
  }
}
\`\`\`

## Setting Up n8n Credentials

### 1. MongoDB Atlas Connection

1. In n8n, go to **Credentials** → **New**
2. Search for **MongoDB**
3. Configure:
   - **Connection String**: Your MongoDB Atlas connection string
   - **Database**: `multimodal_workshop`

### 2. Voyage AI API (for embeddings)

1. **Credentials** → **New** → **HTTP Request**
2. Configure for Voyage AI API
3. Name it: `Voyage AI Workshop`

## Testing Your Setup

### 1. Test MongoDB Atlas Connection

Use the MongoDB Atlas UI or a MongoDB client to test the connection and insert a test document:

\`\`\`javascript
{
  "filename": "test.pdf",
  "textContent": "Test document",
  "embedding": /* 1024-dimensional array from Voyage AI */
}
\`\`\`

### 2. Test Vector Search

Use this aggregation pipeline to test vector search:

\`\`\`javascript
[
  {
    "$vectorSearch": {
      "index": "vector_index",
      "path": "embedding",
      "queryVector": [/* 1024-dimensional query vector */],
      "numCandidates": 100,
      "limit": 5
    }
  }
]
\`\`\`

## Import the Real Workflow

1. In n8n, import: `/workspaces/multimodal-pdf-agent-n8n/init/workflows/05-real-multimodal-agent.json`
2. Update credentials:
   - MongoDB connection
   - OpenAI API key
3. Test the webhooks!

## Using the Real Agent

### Upload a PDF
\`\`\`bash
curl -X POST http://localhost:5678/webhook/pdf-upload \
  -F "file=@your-document.pdf"
\`\`\`

### Ask Questions
\`\`\`bash
curl -X POST http://localhost:5678/webhook/ask \
  -H "Content-Type: application/json" \
  -d '{
    "question": "What does the document say about AI?"
  }'
\`\`\`

## Troubleshooting

### "Index not found"
- Ensure you created the vector index with the exact name: `vector_index`
- Check index exists: `db.pdf_documents.getIndexes()`

### "Dimension mismatch"
- Voyage AI multimodal model produces 1024 dimensions
- Ensure your index matches this dimension count

### "Connection refused"
- Check network access settings in MongoDB Atlas
- Verify connection string includes the full Atlas connection string with credentials

Your real multimodal PDF agent is now ready!
```

# docs/80-upload-interface.mdx

```mdx
---
sidebar_position: 80
---

# 🌐 Web Upload Interface

A complete web interface for uploading PDFs and chatting with your multimodal agent.

## Accessing the Interface

### Option 1: Via Docusaurus (Recommended)

The upload interface is available at:
\`\`\`
http://localhost:3000/upload-interface.html
\`\`\`

### Option 2: Direct File Access

Open the file directly in your browser:
\`\`\`
/workspaces/multimodal-pdf-agent-n8n-docs/static/upload-interface.html
\`\`\`
(Note: The upload interface is in the documentation repository)

## Features

### 📤 PDF Upload
- **Drag & Drop** support
- **Click to browse** file selection
- **Automatic validation** (PDF files only)
- **Progress feedback** during processing

### 💬 Chat Interface
- **Real-time Q&A** about uploaded PDFs
- **Conversation history** display
- **Loading indicators** for responses
- **Error handling** with clear messages

## Setup Requirements

### 1. Import the Workflow

First, import the real multimodal agent workflow:
\`\`\`
/workspaces/multimodal-pdf-agent-n8n/init/workflows/06-real-voyage-multimodal.json
\`\`\`

### 2. Configure Webhook URLs

The interface expects these webhook endpoints:
- **Upload**: `http://localhost:5678/webhook/pdf-upload`
- **Chat**: `http://localhost:5678/webhook/ask`

### 3. Start the Workflow

1. Open the imported workflow in n8n
2. Click **"Active"** toggle to enable
3. The webhooks are now ready to receive requests

## Using the Interface

### Step 1: Upload a PDF

1. **Drag a PDF** onto the upload area, or
2. **Click "Choose PDF File"** to browse
3. Wait for "Successfully processed" message
4. The chat interface will appear automatically

### Step 2: Ask Questions

1. Type your question in the input field
2. Press **Enter** or click **Ask**
3. Watch the AI analyze your PDF and respond
4. Continue the conversation with follow-up questions

## Example Questions

Try these types of questions:
- "What is the main topic of this document?"
- "Summarize the key findings"
- "What does it say about [specific topic]?"
- "List the main recommendations"

## Customization

### Modify the Interface

Edit `/static/upload-interface.html` (in the docs repository) to:
- Change colors and styling
- Add additional features
- Modify the layout

### Update Webhook URLs

If using different ports or paths:
\`\`\`javascript
const UPLOAD_URL = 'http://localhost:5678/webhook/pdf-upload';
const ASK_URL = 'http://localhost:5678/webhook/ask';
\`\`\`

## Troubleshooting

### "Failed to fetch" Error
- Ensure n8n workflow is active
- Check webhook URLs match your setup
- Verify MongoDB is running

### "No file uploaded" Error
- Ensure file is a valid PDF
- Check file size (keep under 10MB for testing)
- Verify binary data handling in webhook

### Chat Not Appearing
- Check browser console for errors
- Ensure PDF was processed successfully
- Verify MongoDB stored the document

## Production Deployment

For production use:
1. Update URLs to use HTTPS
2. Add authentication/security
3. Implement rate limiting
4. Add file size restrictions
5. Enable CORS properly

Your complete multimodal PDF agent is now accessible via a user-friendly web interface!
```

# docs/85-python-mongodb-approaches.mdx

```mdx
---
sidebar_position: 85
---

# 🐍 Python Approaches to MongoDB Vector Search

While n8n provides an excellent visual workflow approach, developers often need programmatic control. Let's explore different ways to interact with MongoDB vector search and Voyage AI using Python.

<InstructorNotes 
  timing="Python Integration Overview (15-20 minutes)"
  notes={[
    "This section complements the n8n approach - not a replacement",
    "Great for developers who want to understand what's happening 'under the hood'",
    "Python examples help attendees bridge visual workflows to code",
    "MongoDB's new multimodal search library simplifies a lot of complexity",
    "Some attendees may prefer Python for production systems"
  ]}
  tips={[
    "Emphasize that both approaches (n8n and Python) can coexist",
    "Show how n8n workflows can call Python scripts via HTTP",
    "Demonstrate the MongoDB multimodal search library live if time permits",
    "Point out that the concepts learned in n8n transfer directly to Python",
    "Consider this section optional if workshop is running behind schedule"
  ]}
/>

<SlideRecap 
  title="From Visual to Programmatic"
  items={[
    {
      icon: "🔄",
      title: "Multiple Interfaces",
      description: "n8n workflows, Python SDKs, and direct MongoDB drivers all access the same powerful vector search"
    },
    {
      icon: "🐍", 
      title: "Python Ecosystem",
      description: "Rich libraries for document processing, ML model integration, and data analysis"
    },
    {
      icon: "⚡",
      title: "Best of Both Worlds",
      description: "Use n8n for rapid prototyping, Python for custom logic and production systems"
    }
  ]}
  nextSection="Let's explore the different Python approaches available!"
/>

## 🎯 Comparison: n8n vs Python Approaches

| Aspect | n8n Visual Workflows | Python Programming |
|--------|---------------------|-------------------|
| **Learning Curve** | Low - visual interface | Medium - requires Python knowledge |
| **Development Speed** | Fast prototyping | Slower initial setup |
| **Customization** | Limited to available nodes | Unlimited flexibility |
| **Debugging** | Visual execution flow | Traditional debugging tools |
| **Integration** | 400+ pre-built integrations | Vast Python ecosystem |
| **Production** | Enterprise-ready | Full control over deployment |
| **Team Collaboration** | Non-technical team friendly | Requires developer skills |

## 🚀 MongoDB Multimodal Search Library

MongoDB's new Python library simplifies multimodal vector search with a clean, intuitive API.

### Installation

\`\`\`python
pip install mongodb-multimodal-search
\`\`\`

### Basic Setup

\`\`\`python
from mongodb_multimodal_search import MultimodalSearch
from pymongo import MongoClient

# Initialize MongoDB connection
client = MongoClient("your-mongodb-connection-string")
db = client["multimodal_workshop"]
collection = db["pdf_documents"]

# Initialize multimodal search
search = MultimodalSearch(
    collection=collection,
    embedding_provider="voyage",  # or "openai", "cohere"
    embedding_model="voyage-multimodal-3",
    api_key="your-voyage-api-key"
)
\`\`\`

### Document Ingestion

\`\`\`python
# Process a PDF document
document_results = await search.ingest_document(
    file_path="sample.pdf",
    document_metadata={
        "source": "workshop",
        "category": "tutorial",
        "processed_date": datetime.now()
    },
    chunk_size=1000,  # Text chunk size
    overlap=200       # Chunk overlap
)

print(f"Processed {document_results.total_chunks} chunks")
print(f"Generated {document_results.total_embeddings} embeddings")
\`\`\`

### Vector Search

\`\`\`python
# Perform semantic search
results = await search.semantic_search(
    query="How do I create a vector index?",
    limit=5,
    filters={
        "metadata.category": "tutorial"
    },
    include_scores=True
)

for result in results:
    print(f"Score: {result.score:.3f}")
    print(f"Content: {result.content[:200]}...")
    print(f"Metadata: {result.metadata}")
    print("---")
\`\`\`

### Multimodal Queries

\`\`\`python
# Search with both text and image
from PIL import Image

image = Image.open("query_image.png")

results = await search.multimodal_search(
    text_query="architectural diagrams",
    image_query=image,
    limit=3,
    combine_strategy="weighted",  # "text_priority", "image_priority", "balanced"
    weights={"text": 0.6, "image": 0.4}
)
\`\`\`

## 🔧 Direct PyMongo Approach

For maximum control, you can interact directly with MongoDB using PyMongo and handle embeddings manually.

### Vector Search Pipeline

\`\`\`python
from pymongo import MongoClient
import requests

class VectorSearchClient:
    def __init__(self, connection_string, database, collection):
        self.client = MongoClient(connection_string)
        self.db = self.client[database]
        self.collection = self.db[collection]
    
    async def generate_embedding(self, content, content_type="text"):
        """Generate embeddings using Voyage AI API"""
        response = requests.post(
            "https://api.voyageai.com/v1/embeddings",
            headers={
                "Authorization": f"Bearer {voyage_api_key}",
                "Content-Type": "application/json"
            },
            json={
                "input": content,
                "model": "voyage-multimodal-3",
                "input_type": content_type
            }
        )
        return response.json()["data"][0]["embedding"]
    
    async def vector_search(self, query_text, limit=5):
        """Perform vector search using MongoDB aggregation"""
        # Generate query embedding
        query_embedding = await self.generate_embedding(query_text)
        
        # MongoDB vector search pipeline
        pipeline = [
            {
                "$vectorSearch": {
                    "index": "vector_index",
                    "path": "embedding",
                    "queryVector": query_embedding,
                    "numCandidates": limit * 10,
                    "limit": limit
                }
            },
            {
                "$project": {
                    "content": 1,
                    "metadata": 1,
                    "score": {"$meta": "vectorSearchScore"}
                }
            }
        ]
        
        return list(self.collection.aggregate(pipeline))

# Usage
search_client = VectorSearchClient(
    connection_string="mongodb+srv://...",
    database="multimodal_workshop",
    collection="pdf_documents"
)

results = await search_client.vector_search("machine learning concepts")
\`\`\`

### Advanced Filtering

\`\`\`python
# Hybrid search with metadata filtering
pipeline = [
    {
        "$vectorSearch": {
            "index": "vector_index",
            "path": "embedding", 
            "queryVector": query_embedding,
            "numCandidates": 100,
            "limit": 20,
            "filter": {
                "metadata.document_type": {"$eq": "technical"},
                "metadata.date": {"$gte": datetime(2024, 1, 1)}
            }
        }
    },
    {
        "$match": {
            "score": {"$gte": 0.7}  # Minimum similarity threshold
        }
    },
    {
        "$lookup": {
            "from": "document_metadata",
            "localField": "document_id",
            "foreignField": "_id",
            "as": "full_metadata"
        }
    }
]
\`\`\`

## 🌐 LangChain Integration

Integrate MongoDB vector search with LangChain for advanced RAG applications.

### Setup

\`\`\`python
from langchain.vectorstores import MongoDBAtlasVectorSearch
from langchain.embeddings import VoyageAIEmbeddings
from langchain.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter

# Initialize embeddings
embeddings = VoyageAIEmbeddings(
    voyage_api_key="your-api-key",
    model="voyage-multimodal-3"
)

# Setup vector store
vector_store = MongoDBAtlasVectorSearch(
    collection=collection,
    embedding=embeddings,
    index_name="vector_index"
)
\`\`\`

### RAG Chain

\`\`\`python
from langchain.chains import RetrievalQA
from langchain.llms import GoogleGenerativeAI

# Setup retrieval chain
qa_chain = RetrievalQA.from_chain_type(
    llm=GoogleGenerativeAI(model="gemini-2.0-flash-exp"),
    chain_type="stuff",
    retriever=vector_store.as_retriever(
        search_kwargs={"k": 5, "score_threshold": 0.7}
    ),
    return_source_documents=True
)

# Ask questions
result = qa_chain.invoke({
    "query": "How do I optimize vector search performance?"
})

print(f"Answer: {result['result']}")
print(f"Sources: {len(result['source_documents'])} documents")
\`\`\`

## 🔄 Hybrid n8n + Python Approach

Combine the best of both worlds by using n8n for orchestration and Python for custom logic.

### Python Microservice

\`\`\`python
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()

class SearchRequest(BaseModel):
    query: str
    filters: dict = {}
    limit: int = 5

@app.post("/advanced-search")
async def advanced_search(request: SearchRequest):
    """Custom search logic called from n8n"""
    
    # Custom preprocessing
    processed_query = preprocess_query(request.query)
    
    # Advanced search logic
    results = await custom_vector_search(
        query=processed_query,
        filters=request.filters,
        limit=request.limit
    )
    
    # Post-processing
    enhanced_results = enhance_results(results)
    
    return {
        "results": enhanced_results,
        "total": len(enhanced_results),
        "query_processed": processed_query
    }

# Custom functions
def preprocess_query(query: str) -> str:
    # Query expansion, spell check, etc.
    return enhanced_query

async def custom_vector_search(query, filters, limit):
    # Your custom search logic
    pass

def enhance_results(results):
    # Add custom scoring, ranking, metadata
    return enhanced_results
\`\`\`

### n8n HTTP Request Node

\`\`\`json
{
  "method": "POST",
  "url": "http://your-python-service/advanced-search",
  "body": {
    "query": "{{ $json.user_query }}",
    "filters": {
      "document_type": "{{ $json.doc_type }}",
      "date_range": "{{ $json.date_filter }}"
    },
    "limit": 10
  }
}
\`\`\`

## 📊 Performance Comparison

| Approach | Setup Time | Development Speed | Performance | Scalability |
|----------|------------|------------------|-------------|-------------|
| **MongoDB Multimodal Library** | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐ |
| **Direct PyMongo** | ⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ |
| **LangChain Integration** | ⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐ |
| **n8n Visual Workflows** | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐⭐ |

## 🎯 When to Choose Which Approach

### Use **n8n Visual Workflows** when:
- ✅ Rapid prototyping and testing
- ✅ Non-technical team members involved
- ✅ Standard workflow patterns
- ✅ Need many integrations quickly

### Use **MongoDB Multimodal Library** when:
- ✅ Python-first development approach
- ✅ Need multimodal capabilities out-of-the-box
- ✅ Want MongoDB best practices built-in
- ✅ Balancing simplicity with control

### Use **Direct PyMongo** when:
- ✅ Maximum performance requirements
- ✅ Complex custom logic needed
- ✅ Fine-grained control over queries
- ✅ Existing MongoDB infrastructure

### Use **Hybrid Approach** when:
- ✅ Team has mixed skill levels
- ✅ Need both visual workflows and custom logic
- ✅ Want to leverage existing n8n infrastructure
- ✅ Iterative development process

## 🔗 Code Examples Repository

All Python examples from this section are available in the workshop repository:

<QRCodeAccess 
  url="https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/tree/main/python-examples"
  title="Python Examples Repository"
/>

\`\`\`bash
# Clone and explore Python examples
git clone https://github.com/mongodb-developer/multimodal-pdf-agent-n8n.git
cd multimodal-pdf-agent-n8n/python-examples

# Install dependencies
pip install -r requirements.txt

# Run examples
python multimodal_search_example.py
python direct_pymongo_example.py
python langchain_integration_example.py
\`\`\`

## 🚀 Next Steps

1. **Try the MongoDB Multimodal Library** - Start with the high-level API
2. **Experiment with Hybrid Approaches** - Combine n8n with Python microservices  
3. **Optimize for Your Use Case** - Choose the right tool for each task
4. **Join the Community** - Share your Python integration patterns

The power of MongoDB vector search is that it works seamlessly across all these approaches - choose the one that fits your team and project best!

<WorkshopResources 
  title="Python Integration Resources"
  categories={{
    "MongoDB Python Libraries": [
      {
        title: "MongoDB Multimodal Search Library",
        url: "https://github.com/mongodb-labs/multimodal-search-python",
        description: "High-level Python library for multimodal vector search",
        icon: "🐍"
      },
      {
        title: "PyMongo Documentation", 
        url: "https://pymongo.readthedocs.io/",
        description: "Official MongoDB Python driver documentation",
        icon: "📚"
      },
      {
        title: "Motor (Async MongoDB)",
        url: "https://motor.readthedocs.io/",
        description: "Asynchronous Python driver for MongoDB",
        icon: "⚡"
      }
    ],
    "ML/AI Integration": [
      {
        title: "LangChain MongoDB Integration",
        url: "https://python.langchain.com/docs/integrations/vectorstores/mongodb_atlas",
        description: "LangChain vector store integration",
        icon: "🦜"
      },
      {
        title: "Voyage AI Python SDK",
        url: "https://docs.voyageai.com/docs/python-sdk",
        description: "Official Python SDK for Voyage AI embeddings",
        icon: "🚢"
      },
      {
        title: "Hugging Face Transformers",
        url: "https://huggingface.co/docs/transformers/",
        description: "Alternative embedding and model options",
        icon: "🤗"
      }
    ],
    "Development Tools": [
      {
        title: "Jupyter Notebooks Examples",
        url: "https://github.com/mongodb-developer/vector-search-examples",
        description: "Interactive Python examples and tutorials",
        icon: "📓"
      },
      {
        title: "FastAPI Documentation",
        url: "https://fastapi.tiangolo.com/",
        description: "For building Python microservices",
        icon: "🚀"
      },
      {
        title: "Streamlit",
        url: "https://streamlit.io/",
        description: "Rapid Python web app development",
        icon: "🎨"
      }
    ]
  }}
/>
```

# docs/90-approach-comparison.mdx

```mdx
---
sidebar_position: 90
---

# ⚖️ n8n vs Python: Choosing Your Development Approach

Now that you've seen both visual workflows and programmatic approaches, let's dive deep into when and why to choose each method for your multimodal PDF agent projects.

<InstructorNotes 
  timing="Approach Comparison (10-15 minutes)"
  notes={[
    "This section helps attendees make informed decisions for their own projects",
    "Many developers want to know 'what should I use in production?'",
    "Emphasize that both approaches can coexist in the same system",
    "Real-world examples resonate more than abstract comparisons",
    "Some attendees may want to rewrite everything in Python after seeing examples"
  ]}
  tips={[
    "Share your own experience with both approaches",
    "Ask attendees about their team's technical background",
    "Demonstrate how to migrate from n8n to Python gradually",
    "Show specific examples from production systems if possible",
    "Address concerns about vendor lock-in with visual workflow tools"
  ]}
/>

## 🎯 Decision Framework

Use this framework to choose the right approach for your specific situation:

### Team & Skills Assessment

<WorkshopExercise 
  title="Assess Your Development Context" 
  difficulty="beginner"
  timeEstimate="5 minutes"
  objectives={[
    "Evaluate your team's technical capabilities",
    "Identify project requirements and constraints",
    "Choose the most appropriate development approach"
  ]}
>

<ExerciseStep stepNumber="1" title="Team Skills Matrix">

Rate your team's capabilities (1-5 scale):

| Skill Area | Rating | n8n Advantage | Python Advantage |
|------------|--------|---------------|------------------|
| **Visual Thinking** | ___/5 | ✅ Drag-and-drop workflows | ❌ Abstract code concepts |
| **Python Programming** | ___/5 | ❌ Limited to available nodes | ✅ Unlimited flexibility |
| **API Integration** | ___/5 | ✅ 400+ pre-built connectors | ⚠️ Manual integration work |
| **Debugging Skills** | ___/5 | ✅ Visual execution flow | ✅ Traditional debugging tools |
| **DevOps/Deployment** | ___/5 | ⚠️ n8n infrastructure required | ✅ Standard containerization |

</ExerciseStep>

<ExerciseStep stepNumber="2" title="Project Requirements Analysis">

Check all that apply to your project:

**Business Requirements:**
- [ ] Rapid prototyping needed
- [ ] Non-technical stakeholders involved
- [ ] Frequent workflow changes expected
- [ ] Complex business logic required
- [ ] High-performance requirements
- [ ] Regulatory compliance needed

**Technical Requirements:**
- [ ] Custom ML model integration
- [ ] Complex data transformations
- [ ] Real-time processing (less than 100ms)
- [ ] Batch processing (over 1M documents)
- [ ] Multi-language support
- [ ] Advanced error handling

</ExerciseStep>

<ExerciseValidation 
  title="Approach Recommendation"
  checks={[
    {
      id: "skills_assessed",
      description: "Completed team skills assessment",
      hint: "Be honest about current capabilities vs aspirational goals"
    },
    {
      id: "requirements_analyzed",
      description: "Identified key project requirements",
      hint: "Focus on must-have features, not nice-to-have ones"
    },
    {
      id: "approach_selected",
      description: "Selected primary development approach based on analysis",
      hint: "Remember you can always start with one and migrate later"
    }
  ]}
/>

</WorkshopExercise>

## 🏗️ Architecture Patterns

### Pattern 1: Pure n8n Visual Workflows

**Best for:** Rapid prototyping, business user involvement, standard use cases

\`\`\`mermaid
graph TD
    A[PDF Upload] --> B[n8n Webhook]
    B --> C[n8n PDF Processing]
    C --> D[n8n Voyage AI]
    D --> E[n8n MongoDB]
    E --> F[n8n Gemini Agent]
    F --> G[Response]
    
    style B fill:#667eea
    style C fill:#667eea
    style D fill:#667eea
    style E fill:#667eea
    style F fill:#667eea
\`\`\`

**Implementation Time:** 2-4 hours
**Maintenance:** Low
**Customization:** Limited to available nodes

### Pattern 2: Pure Python Development

**Best for:** Maximum control, complex logic, performance optimization

\`\`\`mermaid
graph TD
    A[PDF Upload] --> B[FastAPI Endpoint]
    B --> C[Python PDF Parser]
    C --> D[Voyage AI SDK]
    D --> E[MongoDB PyMongo]
    E --> F[Gemini API]
    F --> G[Response]
    
    style B fill:#10b981
    style C fill:#10b981
    style D fill:#10b981
    style E fill:#10b981
    style F fill:#10b981
\`\`\`

**Implementation Time:** 1-2 weeks
**Maintenance:** Medium-High
**Customization:** Unlimited

### Pattern 3: Hybrid Architecture

**Best for:** Team with mixed skills, gradual migration, leveraging strengths

\`\`\`mermaid
graph TD
    A[PDF Upload] --> B[n8n Orchestration]
    B --> C[Python Microservice<br/>PDF Processing]
    B --> D[n8n Voyage AI]
    D --> E[Python Microservice<br/>Vector Search]
    E --> F[n8n Gemini Agent]
    F --> G[Response]
    
    style B fill:#667eea
    style D fill:#667eea
    style F fill:#667eea
    style C fill:#10b981
    style E fill:#10b981
\`\`\`

**Implementation Time:** 1 week
**Maintenance:** Medium
**Customization:** High where needed

## 📊 Real-World Performance Comparison

Based on production deployments:

### Processing Speed (1000 PDF pages)

| Approach | Setup | Processing | Query Response | Total |
|----------|-------|------------|----------------|--------|
| **n8n Visual** | 5 min | 45 min | 200ms | ~50 min |
| **Python SDK** | 30 min | 35 min | 150ms | ~65 min |
| **PyMongo Direct** | 60 min | 25 min | 100ms | ~85 min |
| **Hybrid** | 20 min | 40 min | 120ms | ~60 min |

### Cost Analysis (Monthly, 10K queries)

| Component | n8n | Python | Hybrid |
|-----------|-----|--------|--------|
| **Compute** | $50 (n8n Cloud) | $30 (AWS/GCP) | $40 |
| **Development** | $500 (2 days) | $2000 (8 days) | $1000 (4 days) |
| **Maintenance** | $200/month | $800/month | $400/month |
| **First Year Total** | $3,400 | $13,600 | $7,800 |

## 🎯 Migration Strategies

### Strategy 1: Start Visual, Migrate Gradually

**Phase 1: n8n Prototype (Week 1)**
\`\`\`javascript
// n8n workflow handles everything
Webhook → PDF → Embeddings → MongoDB → Agent
\`\`\`

**Phase 2: Extract Custom Logic (Week 2-3)**
\`\`\`javascript
// Move complex processing to Python
Webhook → [Python Service] → n8n Embeddings → MongoDB → Agent
\`\`\`

**Phase 3: Full Migration (Month 2-3)**
\`\`\`python
# Full Python implementation
FastAPI → Custom Processing → MongoDB → Custom Agent
\`\`\`

### Strategy 2: Hybrid from Start

**Core n8n Orchestration:**
\`\`\`json
{
  "nodes": [
    {
      "type": "webhook",
      "name": "PDF Upload"
    },
    {
      "type": "http-request", 
      "name": "Python PDF Processor",
      "url": "http://pdf-service/process"
    },
    {
      "type": "voyage-ai",
      "name": "Generate Embeddings" 
    },
    {
      "type": "http-request",
      "name": "Custom Vector Search",
      "url": "http://search-service/query"
    }
  ]
}
\`\`\`

**Python Microservices:**
\`\`\`python
# pdf-service/main.py
@app.post("/process")
async def process_pdf(file: UploadFile):
    # Custom PDF processing logic
    return {"pages": processed_pages}

# search-service/main.py  
@app.post("/query")
async def vector_search(query: SearchQuery):
    # Custom search logic
    return {"results": search_results}
\`\`\`

## 🚀 Production Deployment Patterns

### n8n Production Deployment

\`\`\`yaml
# docker-compose.production.yml
version: '3.8'
services:
  n8n:
    image: n8nio/n8n
    environment:
      - N8N_HOST=your-domain.com
      - N8N_PROTOCOL=https
      - N8N_ENCRYPTION_KEY=${ENCRYPTION_KEY}
    volumes:
      - n8n_data:/home/node/.n8n
    networks:
      - n8n-network
      
  traefik:
    image: traefik:v2.9
    command:
      - "--providers.docker=true"
      - "--entrypoints.web.address=:80"
      - "--certificatesresolvers.letsencrypt.acme.httpchallenge=true"
\`\`\`

### Python Production Deployment

\`\`\`python
# kubernetes/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: multimodal-agent
spec:
  replicas: 3
  selector:
    matchLabels:
      app: multimodal-agent
  template:
    spec:
      containers:
      - name: agent
        image: your-registry/multimodal-agent:latest
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi" 
            cpu: "500m"
        env:
        - name: MONGODB_URI
          valueFrom:
            secretKeyRef:
              name: mongo-secret
              key: connection-string
\`\`\`

### Monitoring & Observability

**n8n Monitoring:**
\`\`\`javascript
// n8n webhook for monitoring
{
  "webhook_url": "https://hooks.slack.com/...",
  "on_error": "notify_team",
  "on_success": "log_metrics",
  "execution_timeout": "5m"
}
\`\`\`

**Python Monitoring:**
\`\`\`python
from prometheus_client import Counter, Histogram
import logging

# Metrics
REQUESTS_TOTAL = Counter('requests_total', 'Total requests')
REQUEST_DURATION = Histogram('request_duration_seconds', 'Request duration')

@app.middleware("http")
async def monitor_requests(request: Request, call_next):
    start_time = time.time()
    REQUESTS_TOTAL.inc()
    
    response = await call_next(request)
    
    REQUEST_DURATION.observe(time.time() - start_time)
    return response
\`\`\`

## 📈 Success Stories & Case Studies

### Case Study 1: Legal Document Analysis (n8n)

**Company:** Mid-size law firm  
**Challenge:** Process 1000+ legal documents daily  
**Solution:** Pure n8n workflow  
**Results:**
- ✅ 3-day implementation
- ✅ 90% time savings
- ✅ Non-technical staff can modify workflows
- ✅ $50K annual savings

**Architecture:**
\`\`\`
Legal Docs → n8n → Text Extraction → Voyage AI → MongoDB → Legal AI Agent
\`\`\`

### Case Study 2: Medical Research Platform (Python)

**Company:** Healthcare research institute  
**Challenge:** Complex multimodal analysis of medical literature  
**Solution:** Custom Python application  
**Results:**
- ✅ 40% better accuracy vs standard tools
- ✅ Custom medical entity recognition
- ✅ Integration with existing Python ML pipeline
- ✅ HIPAA compliance controls

**Architecture:**
\`\`\`python
Medical PDFs → Custom Parser → BioBERT + Voyage → MongoDB → Research Agent
\`\`\`

### Case Study 3: Corporate Knowledge Base (Hybrid)

**Company:** Fortune 500 consulting firm  
**Challenge:** Mixed team skills, rapid iteration needed  
**Solution:** n8n + Python microservices  
**Results:**
- ✅ Fast prototyping with n8n
- ✅ Custom logic where needed
- ✅ Easy stakeholder demos
- ✅ Scalable architecture

**Architecture:**
\`\`\`
Documents → n8n Orchestration → Python Processing → n8n Workflows → Custom Agent
\`\`\`

## 🎯 Decision Matrix

Use this scoring system (1-5) to evaluate approaches for your project:

| Criteria | Weight | n8n | Python | Hybrid |
|----------|--------|-----|--------|--------|
| **Team Python Skills** | 20% | 2 | 5 | 4 |
| **Development Speed** | 25% | 5 | 2 | 4 |
| **Customization Needs** | 20% | 2 | 5 | 4 |
| **Maintenance Burden** | 15% | 5 | 2 | 3 |
| **Performance Requirements** | 10% | 3 | 5 | 4 |
| **Budget Constraints** | 10% | 4 | 3 | 3 |

**Calculate your score:**
\`\`\`python
def calculate_approach_score(weights, ratings):
    return sum(w * r for w, r in zip(weights, ratings)) / sum(weights)

# Example calculation
n8n_score = calculate_approach_score(
    weights=[0.2, 0.25, 0.2, 0.15, 0.1, 0.1],
    ratings=[2, 5, 2, 5, 3, 4]
)  # Result: 3.45
\`\`\`

## 🔄 Evolution Path

**Month 1-2: Proof of Concept**
- Start with n8n for rapid validation
- Test core functionality
- Get stakeholder buy-in

**Month 3-6: Production MVP**
- Decide on approach based on learnings
- Implement core features
- Basic monitoring and error handling

**Month 6-12: Scale & Optimize**
- Performance optimization
- Advanced features
- Comprehensive monitoring

**Year 2+: Advanced Features**
- ML model improvements
- Multi-language support
- Advanced analytics

## 🎉 Making Your Choice

The "best" approach is the one that:
1. **Matches your team's skills** and comfort level
2. **Meets your performance requirements** adequately
3. **Fits your timeline** and budget constraints
4. **Allows for future growth** and changes

Remember: You can always start with one approach and evolve. Many successful projects begin with n8n prototypes and gradually introduce Python components as needs become more sophisticated.

<Quiz 
  title="Approach Selection Quiz"
  passingScore={80}
  questions={[
    {
      question: "Your team has strong Python skills but tight deadlines. What's the best initial approach?",
      options: [
        "Pure Python - leverage existing skills",
        "Pure n8n - fastest time to market", 
        "Hybrid - Python for core logic, n8n for orchestration",
        "Wait and hire n8n specialists"
      ],
      correctAnswer: 1,
      explanation: "With tight deadlines, n8n's visual workflows provide the fastest path to a working prototype, even for Python-skilled teams."
    },
    {
      question: "You need sub-100ms query responses and complex custom scoring. Which approach?",
      options: [
        "n8n visual workflows",
        "MongoDB Multimodal Search Library",
        "Direct PyMongo with custom optimizations",
        "LangChain integration"
      ],
      correctAnswer: 2,
      explanation: "For maximum performance and custom logic, direct PyMongo gives you complete control over queries and optimizations."
    },
    {
      question: "Your business users want to modify workflows themselves. Best choice?",
      options: [
        "Python with configuration files",
        "n8n visual workflows", 
        "Hybrid with n8n frontend",
        "LangChain with YAML configs"
      ],
      correctAnswer: 1,
      explanation: "n8n's visual interface allows non-technical users to understand and modify workflows without coding."
    }
  ]}
/>

The power of modern vector search is that your choice of development approach doesn't limit your capabilities - MongoDB Atlas, Voyage AI, and Gemini work seamlessly across all these patterns! 🚀
```

# docs/95-community-resources.mdx

```mdx
---
sidebar_position: 95
---

# 🌐 Community Nodes & Extensions

Extend your PDF analysis system with community contributions!

## What Are Community Nodes?

Community nodes are extensions created by n8n users that add new integrations and capabilities.

## Installing Community Nodes

### 1. Access Community Nodes
1. Go to **Settings** → **Community Nodes**
2. Click **Install a community node**
3. Enter the npm package name

### 2. Browse Available Nodes
Click **Browse** to see popular nodes:

- 🤖 **AI/ML Nodes**: DeepSeek, Claude, Local LLMs
- 📊 **Database Nodes**: Specialized connectors
- 🔧 **Utility Nodes**: Advanced processors
- 🌐 **API Nodes**: Service integrations

## Recommended Nodes for PDF Enhancement

### 1. n8n-nodes-deepseek
For alternative AI processing:

\`\`\`bash
npm install n8n-nodes-deepseek
\`\`\`

Use cases:
- Cost-effective alternative to OpenAI
- Specialized reasoning tasks
- Multi-language support

### 2. n8n-nodes-mcp

Model Context Protocol integration:

\`\`\`bash
npm install n8n-nodes-mcp
\`\`\`

Use cases:
- Advanced context management
- Multi-model orchestration
- Tool use capabilities

### 3. n8n-nodes-ocr-advanced

Enhanced OCR capabilities:

\`\`\`bash
npm install n8n-nodes-ocr-advanced
\`\`\`

Use cases:
- Extract text from images
- Handle scanned PDFs
- Multi-language OCR

## Creating Your Own Node

### Basic Structure

\`\`\`typescript
import {
  IExecuteFunctions,
  INodeExecutionData,
  INodeType,
  INodeTypeDescription,
} from 'n8n-workflow';

export class MyPdfNode implements INodeType {
  description: INodeTypeDescription = {
    displayName: 'My PDF Processor',
    name: 'myPdfProcessor',
    group: ['transform'],
    version: 1,
    description: 'Custom PDF processing',
    defaults: {
      name: 'My PDF Processor',
    },
    inputs: ['main'],
    outputs: ['main'],
    properties: [
      // Node properties
    ],
  };

  async execute(this: IExecuteFunctions): Promise<INodeExecutionData[][]> {
    // Your logic here
    return this.prepareOutputData(items);
  }
}
\`\`\`

### Publishing Your Node

1. Create npm package
2. Follow n8n node structure
3. Publish to npm
4. Share with community!

## Integration Ideas

### 1. Language Detection Node

\`\`\`javascript
// Detect PDF language and route accordingly
const language = await detectLanguage(pdfText);
switch(language) {
  case 'es': // Route to Spanish workflow
  case 'en': // Route to English workflow
  // etc.
}
\`\`\`

### 2. Image Enhancement Node

\`\`\`javascript
// Enhance images before embedding
const enhanced = await enhanceImage(imageBuffer);
// Better OCR results
// Clearer embeddings
\`\`\`

### 3. Compliance Check Node

\`\`\`javascript
// Check for sensitive information
const compliance = await checkCompliance(pdfContent);
if (compliance.hasPII) {
  // Redact or flag
}
\`\`\`

## Community Resources

### n8n Community Forum

- [https://community.n8n.io](https://community.n8n.io/)
- Share workflows
- Get help
- Find nodes

### Node Development

- [n8n Node Development Guide](https://docs.n8n.io/integrations/creating-nodes/)
- [Example Nodes](https://github.com/n8n-io/n8n/tree/master/packages/nodes-base/nodes)
- [Community Node Template](https://github.com/n8n-io/n8n-nodes-starter)

## Best Practices

### 1. Verify Node Quality

- Check npm downloads
- Review source code
- Test in development first

### 2. Security Considerations

- Audit node code
- Use specific versions
- Monitor for updates

### 3. Performance Impact

- Test with your workload
- Monitor execution time
- Consider caching

## Workshop Challenge

### Create a Custom Node

Try creating a simple node that:

1. Accepts PDF metadata
2. Adds custom fields
3. Formats for your use case

Example:

\`\`\`javascript
// Add reading level analysis
const readingLevel = analyzeReadingLevel(text);
item.json.readingLevel = readingLevel;
item.json.complexity = calculateComplexity(text);
\`\`\`

Share your nodes with the community!
```

# docs/95-docker-troubleshooting.mdx

```mdx
---
sidebar_position: 95
---

# 🐳 Docker Troubleshooting Guide

Common issues and solutions when running the workshop with Docker.

## 🚨 Service Won't Start

### Docker Desktop Not Running

**Symptoms:**
\`\`\`
Cannot connect to the Docker daemon at unix:///var/run/docker.sock
\`\`\`

**Solution:**
\`\`\`bash
# macOS
open -a Docker

# Windows
# Start Docker Desktop from Start Menu

# Linux
sudo systemctl start docker
\`\`\`

### Port Already in Use

**Symptoms:**
\`\`\`
Error: bind: address already in use
\`\`\`

**Solution:**
\`\`\`bash
# Find what's using the port
lsof -i :5678    # macOS/Linux
netstat -ano | findstr :5678  # Windows

# Kill the process
kill -9 <PID>    # macOS/Linux
taskkill /PID <PID> /F  # Windows

# Or change the port in docker-compose.yml
ports:
  - "5679:5678"  # Use 5679 instead
\`\`\`

## 🔧 Container Issues

### n8n Container Keeps Restarting

**Check logs:**
\`\`\`bash
docker-compose logs n8n
\`\`\`

**Common causes:**
1. **MongoDB not ready**
   \`\`\`bash
   # Restart in correct order
   docker-compose down
   docker-compose up -d n8n
   sleep 10
   docker-compose up -d n8n
   \`\`\`

2. **Invalid environment variables**
   \`\`\`bash
   # Check .env file
   cat .env
   # Ensure no spaces around = signs
   \`\`\`

### Cannot Connect to Services

**Verify containers are running:**
\`\`\`bash
docker-compose ps
\`\`\`

**Check container health:**
\`\`\`bash
docker-compose ps | grep healthy
\`\`\`

**Test connectivity:**
\`\`\`bash
# From host
curl http://localhost:5678
curl http://localhost:5678

# From inside container
docker-compose exec n8n wget -O- http://localhost:5678
\`\`\`

## 💾 Data & Volume Issues

### Lost Workflows After Restart

**Ensure volumes are properly mounted:**
\`\`\`bash
# Check volumes
docker volume ls | grep workshop

# Inspect volume
docker volume inspect workshop_n8n_data
\`\`\`

**Fix permission issues:**
\`\`\`bash
# Linux/macOS
sudo chown -R $(whoami):$(whoami) ./volumes

# Create directories if missing
mkdir -p volumes/n8n volumes/mongodb
\`\`\`

### MongoDB Connection Failed

**From n8n container:**
\`\`\`bash
# Test MongoDB connection
docker-compose exec n8n sh
ping mongodb  # Should resolve
exit
\`\`\`

**Check MongoDB logs:**
\`\`\`bash
docker-compose logs n8n | grep -i error
\`\`\`

## 🌐 Network Problems

### Services Can't Communicate

**Verify network exists:**
\`\`\`bash
docker network ls | grep workshop
\`\`\`

**Recreate network:**
\`\`\`bash
docker-compose down
docker network prune
docker-compose up -d
\`\`\`

### External API Calls Failing

**Check DNS from container:**
\`\`\`bash
docker-compose exec n8n nslookup google.com
\`\`\`

**Proxy issues:**
\`\`\`bash
# Add to docker-compose.yml
environment:
  - HTTP_PROXY=${HTTP_PROXY}
  - HTTPS_PROXY=${HTTPS_PROXY}
  - NO_PROXY=localhost
\`\`\`

## 🧹 Clean Slate Reset

### Complete Reset

\`\`\`bash
# Stop everything
docker-compose down -v

# Remove all workshop containers
docker ps -a | grep workshop | awk '{print $1}' | xargs docker rm -f

# Remove all workshop images
docker images | grep workshop | awk '{print $3}' | xargs docker rmi -f

# Remove all workshop volumes
docker volume ls | grep workshop | awk '{print $2}' | xargs docker volume rm

# Start fresh
docker-compose up -d
\`\`\`

## 📊 Performance Issues

### Containers Running Slowly

**Check resource usage:**
\`\`\`bash
docker stats
\`\`\`

**Increase memory limits:**
\`\`\`yaml
# docker-compose.yml
services:
  n8n:
    deploy:
      resources:
        limits:
          memory: 4G  # Increase from 2G
\`\`\`

**Clean up Docker:**
\`\`\`bash
# Remove unused data
docker system prune -a

# Check disk space
df -h
\`\`\`

## 🔍 Debugging Tips

### Enable Debug Logging

\`\`\`yaml
# docker-compose.yml
services:
  n8n:
    environment:
      - N8N_LOG_LEVEL=debug
      - DEBUG=n8n:*
\`\`\`

### Access Container Shell

\`\`\`bash
# n8n container
docker-compose exec n8n sh

# n8n container
docker-compose exec n8n sh
\`\`\`

### Export Logs

\`\`\`bash
# Save all logs
docker-compose logs > workshop_debug_$(date +%Y%m%d_%H%M%S).log

# Follow specific service logs
docker-compose logs -f n8n
\`\`\`

## 🆘 Emergency Commands

### When Nothing Else Works

\`\`\`bash
# 1. Stop Docker Desktop completely
# 2. Restart your computer
# 3. Start Docker Desktop
# 4. Run these commands:

cd workshop
docker system prune -a --volumes
docker-compose build --no-cache
docker-compose up -d
\`\`\`

## 📝 Checklist Before Asking for Help

1. ✅ Docker Desktop is running
2. ✅ You're in the correct directory
3. ✅ .env file exists and is configured
4. ✅ Checked `docker-compose logs`
5. ✅ Tried the clean slate reset
6. ✅ Collected error messages

### Information to Provide

\`\`\`bash
# System info
docker version
docker-compose version
uname -a  # or systeminfo on Windows

# Workshop status
docker-compose ps
docker-compose logs --tail 50

# Environment
cat .env | grep -v PASSWORD
\`\`\`

---

Still having issues? Check the workshop repository issues or ask in the workshop chat!
```

# docs/api-architecture.mdx

```mdx
---
sidebar_position: 20
---

# 🌐 API Gateway Architecture: The Workshop Proxy System

The workshop API gateway serves as both an educational tool and practical infrastructure. Let's explore why it exists, how it works, and how it compares to production systems.

<InstructorNotes 
  timing="API Gateway Architecture (15-20 minutes)"
  notes={[
    "This demystifies the 'black box' proxy for attendees",
    "Many developers want to understand what's happening behind the scenes",
    "Address security concerns about data privacy early",
    "Explain the educational value of controlled failure scenarios",
    "Show the GitHub source code to build trust and transparency"
  ]}
  tips={[
    "Start with why the proxy exists before explaining how it works",
    "Use the live API endpoints to demonstrate concepts",
    "Show both successful calls and simulated failures",
    "Explain rate limiting with concrete examples",
    "Address the workshop vs production architecture differences clearly"
  ]}
/>

<LiveStatusBadge />

## 🎯 Why Does the Workshop Use a Proxy?

Before diving into the technical details, let's understand the educational and practical reasons for the API gateway approach:

### The Problem Without a Proxy

\`\`\`mermaid
graph TD
    A[Attendee 1] --> D[Voyage AI API]
    B[Attendee 2] --> D
    C[Attendee 3] --> D
    E[Attendee 4] --> D
    
    F[API Key Management] --> G[Security Risk]
    H[Rate Limiting Chaos] --> I[Workshop Disruptions]
    J[Cost Control Issues] --> K[Budget Overruns]
    
    style G fill:#ffebee
    style I fill:#ffebee
    style K fill:#ffebee
\`\`\`

**Common Workshop Problems:**
- 🔑 **API Key Distribution** - Sharing keys in chat/email (security risk)
- 💰 **Cost Explosions** - Uncontrolled usage across many attendees
- 🚫 **Rate Limit Chaos** - Some attendees get blocked while others work fine
- 🐛 **Configuration Issues** - Time spent on setup vs learning concepts
- 📊 **No Usage Analytics** - Can't optimize workshop experience

### The Solution: Workshop API Gateway

\`\`\`mermaid
graph TD
    A[Attendee 1] --> E[Workshop Gateway]
    B[Attendee 2] --> E
    C[Attendee 3] --> E
    D[Attendee 4] --> E
    
    E --> F[Rate Limiting]
    E --> G[Cost Control]
    E --> H[Security Layer]
    E --> I[Usage Analytics]
    
    F --> J[Voyage AI API]
    F --> K[Google Gemini API]
    
    style E fill:#e8f5e8
    style F fill:#e3f2fd
    style G fill:#e8f5e8
    style H fill:#fff3e0
\`\`\`

**Workshop Benefits:**
- ✅ **Zero Setup** - No API keys needed
- ✅ **Fair Resource Sharing** - Intelligent rate limiting across all attendees
- ✅ **Cost Predictability** - Workshop organizer controls spending
- ✅ **Educational Features** - Simulated failures, monitoring, analytics
- ✅ **Focus on Learning** - Time spent on concepts, not configuration

## 🏗️ Gateway Architecture Deep Dive

### Core Components

<StatusDot system="Workshop Gateway" endpoint="https://workshop-embedding-api.vercel.app/api/health" />

\`\`\`javascript
// Simplified gateway architecture
const gatewayComponents = {
  proxy_layer: {
    purpose: "Route requests to appropriate AI services",
    technology: "Node.js + Express",
    deployment: "Vercel serverless functions"
  },
  
  rate_limiting: {
    purpose: "Fair usage across workshop attendees", 
    strategy: "Token bucket with attendee identification",
    limits: "100 requests/hour per IP, 1000/hour total"
  },
  
  authentication: {
    purpose: "Secure access without exposing real API keys",
    approach: "IP-based + referrer checking",
    production_difference: "Would use JWT tokens or API keys"
  },
  
  monitoring: {
    purpose: "Track usage and optimize workshop experience",
    metrics: ["request_count", "response_time", "error_rate", "cost_per_attendee"],
    alerts: "Slack notifications for rate limit breaches"
  }
};
\`\`\`

### Request Flow Analysis

<WorkshopExercise 
  title="Trace an API Request Through the Gateway" 
  difficulty="intermediate"
  timeEstimate="15 minutes"
  objectives={[
    "Understand each step in request processing",
    "See how rate limiting and security work",
    "Compare workshop vs production approaches"
  ]}
>

<ExerciseStep stepNumber="1" title="Initial Request Processing">

**n8n HTTP Request → Workshop Gateway:**

\`\`\`javascript
// What your n8n sends
POST https://workshop-embedding-api.vercel.app/api/embed
Content-Type: application/json

{
  "text": "Analyze this financial document for key insights",
  "model": "voyage-3"
}
\`\`\`

**Gateway Processing:**
\`\`\`javascript
// Simplified gateway logic
async function handleEmbeddingRequest(req, res) {
  // 1. Security check
  const security = await validateRequest(req);
  if (!security.valid) {
    return res.status(403).json({error: "Access denied"});
  }
  
  // 2. Rate limiting
  const rateLimit = await checkRateLimit(req.ip);
  if (rateLimit.exceeded) {
    return res.status(429).json({
      error: "Rate limit exceeded",
      retry_after: rateLimit.reset_time
    });
  }
  
  // 3. Request transformation
  const voyageRequest = transformToVoyageFormat(req.body);
  
  // 4. Forward to Voyage AI
  const response = await callVoyageAPI(voyageRequest);
  
  // 5. Response transformation and analytics
  await logUsage(req, response);
  return res.json(transformResponse(response));
}
\`\`\`

</ExerciseStep>

<ExerciseStep stepNumber="2" title="Rate Limiting Logic">

**Token Bucket Implementation:**
\`\`\`javascript
// Rate limiting strategy
const rateLimiter = {
  global_bucket: {
    capacity: 1000,      // Total requests per hour
    refill_rate: 16.67,  // Tokens per minute (1000/60)
    current_tokens: 950
  },
  
  per_ip_buckets: {
    "192.168.1.1": {
      capacity: 100,     // Per attendee limit
      refill_rate: 1.67, // 100/60 minutes
      current_tokens: 45
    }
  },
  
  checkLimit: async (ip) => {
    const global = checkGlobalBucket();
    const individual = checkIPBucket(ip);
    
    return {
      allowed: global.allowed && individual.allowed,
      global_remaining: global.tokens,
      individual_remaining: individual.tokens,
      reset_time: Math.max(global.reset, individual.reset)
    };
  }
};
\`\`\`

**What happens when limits are hit:**
\`\`\`javascript
// Rate limit response
{
  "error": "Rate limit exceeded",
  "message": "Too many requests. Please wait before trying again.",
  "retry_after": 1800, // seconds until reset
  "limits": {
    "individual_limit": 100,
    "individual_remaining": 0,
    "global_limit": 1000,
    "global_remaining": 234
  },
  "workshop_info": "This helps ensure fair access for all attendees"
}
\`\`\`

</ExerciseStep>

<ExerciseStep stepNumber="3" title="Cost Control & Analytics">

**Usage Tracking:**
\`\`\`javascript
// Analytics and cost tracking
const usageAnalytics = {
  track_request: async (req, response) => {
    const usage = {
      timestamp: new Date(),
      endpoint: req.path,
      ip_hash: hashIP(req.ip),
      input_tokens: calculateTokens(req.body),
      output_tokens: response.usage?.total_tokens || 0,
      cost_estimate: calculateCost(response),
      response_time: response.timing.total,
      success: response.status === 'ok'
    };
    
    await storeAnalytics(usage);
    await updateRealTimeDashboard(usage);
  },
  
  cost_calculation: {
    voyage_embedding: 0.00002, // per 1K tokens
    gemini_input: 0.000125,    // per 1K tokens  
    gemini_output: 0.000375,   // per 1K tokens
    mongodb_operations: 0.0001 // per operation
  }
};
\`\`\`

</ExerciseStep>

</WorkshopExercise>

## 🔧 Available API Endpoints

### Production Endpoints

| Endpoint | Purpose | Rate Limit | Workshop Cost |
|----------|---------|------------|---------------|
| `POST /api/embed` | Generate embeddings | 100/hour/IP | ~$0.02/request |
| `POST /api/chat` | Gemini chat completion | 50/hour/IP | ~$0.05/request |
| `GET /api/health` | System health check | 1000/hour/IP | Free |
| `GET /api/usage` | Current usage stats | 20/hour/IP | Free |

### Educational Endpoints

| Endpoint | Purpose | Use Case |
|----------|---------|----------|
| `POST /api/embed?fail=429` | Simulate rate limiting | Error handling practice |
| `POST /api/embed?fail=500` | Simulate server errors | Resilience testing |
| `POST /api/embed?delay=5000` | Simulate slow responses | Timeout handling |
| `GET /api/debug` | Show request details | Debugging workshop |

### Health Check System

<WorkshopExercise 
  title="Build a Health Check Monitor" 
  difficulty="beginner"
  timeEstimate="10 minutes"
  objectives={[
    "Test the health check endpoint",
    "Build a simple monitoring workflow",
    "Understand system status reporting"
  ]}
>

**Create an n8n health check workflow:**

\`\`\`javascript
// 1. Schedule Node - Every 5 minutes
{
  "rule": {
    "interval": [
      {
        "field": "minutes",
        "secundesInterval": 5
      }
    ]
  }
}

// 2. HTTP Request Node - Check health
{
  "method": "GET",
  "url": "https://workshop-embedding-api.vercel.app/api/health",
  "options": {
    "timeout": 10000
  }
}

// 3. Function Node - Process response
{
  "code": `
    const health = $input.first().json;
    const isHealthy = health.status === 'ok' && 
                     health.response_time < 2000 &&
                     health.services.every(s => s.status === 'ok');
    
    return {
      timestamp: new Date().toISOString(),
      overall_status: isHealthy ? 'healthy' : 'degraded',
      details: health,
      alert_needed: !isHealthy
    };
  `
}

// 4. IF Node - Alert on issues
{
  "conditions": {
    "boolean": [
      {
        "value1": "={{$json.alert_needed}}",
        "operation": "equal",
        "value2": true
      }
    ]
  }
}
\`\`\`

**Expected health response:**
\`\`\`json
{
  "status": "ok",
  "timestamp": "2024-01-20T10:30:00Z",
  "response_time": 234,
  "services": [
    {
      "name": "voyage_ai",
      "status": "ok",
      "response_time": 145
    },
    {
      "name": "gemini",
      "status": "ok", 
      "response_time": 200
    },
    {
      "name": "rate_limiter",
      "status": "ok",
      "current_load": 0.34
    }
  ],
  "rate_limits": {
    "global_remaining": 756,
    "average_per_ip": 67
  }
}
\`\`\`

</WorkshopExercise>

## 🔒 Security Model

### Workshop Security (Current)

\`\`\`javascript
const workshopSecurity = {
  authentication: {
    approach: "IP-based allowlisting + referrer checking",
    implementation: "Codespace IPs and docs domain verified",
    limitations: "Not suitable for production use"
  },
  
  api_key_protection: {
    real_keys: "Stored in Vercel environment variables", 
    attendee_access: "No access to real credentials",
    rotation: "Keys rotated after each workshop"
  },
  
  data_privacy: {
    logging: "Only metadata logged, no content stored",
    retention: "Analytics data purged after 30 days",
    compliance: "GDPR-friendly by design"
  },
  
  abuse_prevention: {
    rate_limiting: "Per-IP and global limits enforced",
    content_filtering: "Basic validation of request payloads",
    monitoring: "Real-time alerts for unusual patterns"
  }
};
\`\`\`

### Production Security (What You'd Implement)

\`\`\`javascript
const productionSecurity = {
  authentication: {
    approach: "JWT tokens or API key authentication",
    implementation: "OAuth 2.0 / OpenID Connect integration",
    features: "User roles, permissions, token expiration"
  },
  
  api_key_management: {
    storage: "AWS Secrets Manager / Azure Key Vault",
    rotation: "Automated key rotation every 90 days",
    access_control: "Principle of least privilege"
  },
  
  data_protection: {
    encryption_at_rest: "AES-256 encryption for stored data",
    encryption_in_transit: "TLS 1.3 for all communications",
    compliance: "SOC 2, HIPAA, or industry-specific requirements"
  },
  
  network_security: {
    vpc_isolation: "Private networks for internal communication",
    firewall_rules: "Strict ingress/egress controls",
    ddos_protection: "CDN-based DDoS mitigation"
  }
};
\`\`\`

## 🎭 Simulated Failures: Learning from Errors

### Error Simulation Features

The workshop includes intentional failure modes to teach resilience:

<WorkshopExercise 
  title="Master Error Handling with Simulated Failures" 
  difficulty="intermediate"
  timeEstimate="20 minutes"
  objectives={[
    "Experience different failure modes",
    "Build robust error handling in n8n",
    "Understand production error patterns"
  ]}
>

<ExerciseStep stepNumber="1" title="Test Rate Limiting">

**Trigger a 429 error:**
\`\`\`javascript
// HTTP Request Node
{
  "method": "POST",
  "url": "https://workshop-embedding-api.vercel.app/api/embed?fail=429",
  "body": {
    "text": "This will trigger a rate limit error",
    "model": "voyage-3"
  }
}
\`\`\`

**Expected response:**
\`\`\`json
{
  "error": "Rate limit exceeded",
  "code": "RATE_LIMIT_EXCEEDED",
  "message": "Too many requests. This is a simulated error for workshop learning.",
  "retry_after": 60,
  "workshop_note": "In production, implement exponential backoff retry logic"
}
\`\`\`

**Add error handling in n8n:**
\`\`\`javascript
// Error handling workflow
[HTTP Request] → [Error Handler] → {
  IF (error.code === 'RATE_LIMIT_EXCEEDED') → [Wait Node] → [Retry]
  ELSE → [Log Error] → [User Notification]
}
\`\`\`

</ExerciseStep>

<ExerciseStep stepNumber="2" title="Handle Server Errors">

**Simulate 500 errors:**
\`\`\`javascript
// Test server error handling
{
  "url": "https://workshop-embedding-api.vercel.app/api/embed?fail=500",
  "retry_logic": {
    "max_attempts": 3,
    "backoff_strategy": "exponential",
    "base_delay": 1000
  }
}
\`\`\`

**Robust retry implementation:**
\`\`\`javascript
// Function Node - Retry logic
{
  "code": `
    const maxRetries = 3;
    const baseDelay = 1000;
    const attempt = $json.attempt || 1;
    
    if (attempt > maxRetries) {
      throw new Error('Max retries exceeded');
    }
    
    const delay = baseDelay * Math.pow(2, attempt - 1);
    
    return {
      ...input,
      attempt: attempt + 1,
      delay: delay,
      should_retry: attempt <= maxRetries
    };
  `
}
\`\`\`

</ExerciseStep>

<ExerciseStep stepNumber="3" title="Timeout Handling">

**Test slow response handling:**
\`\`\`javascript
// Simulate slow API response
{
  "url": "https://workshop-embedding-api.vercel.app/api/embed?delay=8000",
  "timeout": 5000, // Will timeout after 5 seconds
  "onTimeout": "fallback_to_cached_response"
}
\`\`\`

</ExerciseStep>

</WorkshopExercise>

## 🔄 Workshop vs Production Comparison

### API Gateway Comparison

| Feature | Workshop Proxy | Production Gateway |
|---------|---------------|-------------------|
| **Authentication** | IP + referrer checking | JWT tokens, API keys, OAuth |
| **Rate Limiting** | Shared pool across attendees | Per-customer limits |
| **Cost Management** | Workshop absorbs costs | Customer billing integration |
| **Error Handling** | Educational failures | Real error scenarios |
| **Monitoring** | Basic usage analytics | Full observability stack |
| **Scaling** | Serverless (Vercel) | Auto-scaling infrastructure |
| **Security** | Basic protection | Enterprise security |

### Migration Path: Workshop → Production

\`\`\`mermaid
graph TD
    A[Workshop Experience] --> B[Development Phase]
    B --> C[Staging Environment] 
    C --> D[Production Deployment]
    
    A1[Shared Proxy] --> B1[Your API Keys]
    B1 --> C1[Staging Gateway]
    C1 --> D1[Production Gateway]
    
    A2[Basic Monitoring] --> B2[Enhanced Logging]
    B2 --> C2[Full Observability]
    C2 --> D2[Enterprise Monitoring]
\`\`\`

**Phase 1: Development (Post-Workshop)**
\`\`\`javascript
// Switch to direct API access
const developmentConfig = {
  voyage_api_key: process.env.VOYAGE_API_KEY,
  gemini_api_key: process.env.GEMINI_API_KEY,
  mongodb_uri: process.env.MONGODB_ATLAS_URI,
  
  // Remove workshop proxy
  use_workshop_proxy: false,
  direct_api_calls: true
};
\`\`\`

**Phase 2: Production Gateway**
\`\`\`javascript
// Implement your own gateway
const productionGateway = {
  authentication: "JWT-based user authentication",
  rate_limiting: "Per-customer quotas with overage billing",
  monitoring: "Comprehensive metrics and alerting",
  security: "WAF, DDoS protection, audit logging",
  scaling: "Auto-scaling based on demand"
};
\`\`\`

## 📊 Real-Time Monitoring

### Usage Dashboard

The workshop includes a real-time usage dashboard:

\`\`\`javascript
// Usage metrics available
const metricsEndpoints = {
  current_usage: "GET /api/usage",
  historical_data: "GET /api/usage/history", 
  per_ip_breakdown: "GET /api/usage/by-ip",
  cost_analysis: "GET /api/usage/costs",
  error_rates: "GET /api/usage/errors"
};

// Example usage response
{
  "current_hour": {
    "total_requests": 1247,
    "unique_ips": 28,
    "avg_response_time": 234,
    "error_rate": 0.023,
    "estimated_cost": 4.56
  },
  "rate_limits": {
    "global_utilization": 0.62,
    "ips_approaching_limit": 3,
    "reset_time": "2024-01-20T11:00:00Z"
  },
  "service_health": {
    "voyage_ai": "healthy",
    "gemini": "healthy", 
    "gateway": "healthy"
  }
}
\`\`\`

## 🚀 Advanced Usage Patterns

### Batch Processing

\`\`\`javascript
// Efficient batch embedding generation
const batchEmbedding = {
  endpoint: "POST /api/embed/batch",
  max_items: 100,
  
  request: {
    "items": [
      {"text": "Document 1 content", "id": "doc_1"},
      {"text": "Document 2 content", "id": "doc_2"}
      // ... up to 100 items
    ],
    "model": "voyage-3"
  },
  
  response: {
    "embeddings": [
      {"id": "doc_1", "embedding": [0.123, -0.456, ...]},
      {"id": "doc_2", "embedding": [0.789, -0.234, ...]}
    ],
    "usage": {"total_tokens": 1500},
    "batch_cost": 0.03
  }
};
\`\`\`

### Caching Strategy

\`\`\`javascript
// Smart caching for workshop efficiency
const cachingLogic = {
  cache_key: (request) => {
    return hashSHA256(JSON.stringify({
      text: request.text,
      model: request.model,
      // Exclude timestamp and user-specific data
    }));
  },
  
  cache_duration: "1 hour", // Balance freshness vs performance
  cache_hit_rate: 0.73,     // ~73% of requests served from cache
  
  benefits: {
    reduced_api_calls: "27% fewer calls to underlying services",
    faster_responses: "Cache hits return in ~50ms vs 500ms+",
    cost_savings: "Significant reduction in AI service costs"
  }
};
\`\`\`

## 🎯 Key Takeaways

The workshop API gateway demonstrates:

1. **Abstraction Benefits** - Hide complexity while teaching concepts
2. **Security by Design** - Protect credentials without limiting learning
3. **Fair Resource Sharing** - Ensure all attendees have good experience
4. **Educational Value** - Turn infrastructure into teaching tool
5. **Production Readiness** - Show real-world patterns and considerations

Understanding this architecture prepares you to:
- **Design your own API gateways** for production systems
- **Implement proper error handling** and resilience patterns
- **Plan for scaling** from prototype to production
- **Consider security** at every layer of your system

## 📚 Next Steps

- **Error Simulation** - Coming soon in advanced topics
- **Direct API Access** - Available in advanced configuration
- [**Build Your First Agent →**](./exercise-pdf-rag-agent)
- **Production Deployment** - Coming soon!

The API gateway bridges workshop learning with production reality. Master these patterns and you'll build robust, scalable AI systems! 🌐
```

# docs/architecture-overview.mdx

```mdx
---
sidebar_position: 0
---

# 🏗️ Architecture Overview: Multimodal AI Agent Workshop

Understanding the complete system architecture helps you see how all components work together to create intelligent, multimodal AI agents. Let's explore the full stack from your browser to the AI models.

<InstructorNotes 
  timing="Architecture Overview (15-20 minutes)"
  notes={[
    "This is foundational - spend time here to prevent confusion later",
    "Use the visual diagrams to show data flow clearly",
    "Emphasize the workshop proxy vs production architecture differences",
    "Many attendees get confused about local vs cloud components",
    "Address security questions about API keys and data flow early"
  ]}
  tips={[
    "Start with the big picture, then zoom into each component",
    "Use the live status badges to show real-time system health",
    "Explain why we chose each technology (n8n, MongoDB, Voyage AI)",
    "Show how this architecture scales to production systems",
    "Have attendees identify which components run where"
  ]}
/>

<LiveStatusBadge showDetails={true} />

## 🎯 Complete System Architecture

\`\`\`mermaid
graph TB
    subgraph "Your Environment"
        A[Browser/Docs] --> B[GitHub Codespaces]
        B --> C[n8n Workflows]
    end
    
    subgraph "Workshop Infrastructure"
        E[Workshop API Gateway]
        F[Rate Limiting & Auth]
        G[Error Simulation]
    end
    
    subgraph "AI Services"
        H[Voyage AI Embeddings]
        I[Google Gemini 2.0]
        J[MongoDB Atlas Vector Search]
    end
    
    subgraph "Production Alternative"
        K[Your API Keys]
        L[Direct Service Access]
    end
    
    C --> E
    E --> F
    F --> H
    F --> I
    C --> J
    
    C -.->|Advanced Option| K
    K -.->|Direct Access| L
    L -.->|No Proxy| H
    L -.->|No Proxy| I
    
    style A fill:#e1f5fe
    style C fill:#f3e5f5
    style E fill:#fff3e0
    style J fill:#e8f5e8
\`\`\`

## 🧩 Component Breakdown

### 1. **Frontend Layer: Browser & Documentation**

| Component | Purpose | Technology |
|-----------|---------|------------|
| **Docusaurus Site** | Interactive workshop guide | React, MDX |
| **Live Status Badges** | Real-time system health | Custom React components |
| **Interactive Exercises** | Hands-on learning | Workshop components |

**What runs here:**
- This documentation you're reading
- Status monitoring and health checks
- Progress tracking and validation

### 2. **Development Environment: GitHub Codespaces**

\`\`\`mermaid
graph LR
    subgraph "Codespace Container"
        A[VS Code] --> B[Docker Environment]
        B --> C[n8n:5678]
        B --> D[Documentation:3000]
    end
\`\`\`

**Why Codespaces?**
- ✅ **Zero setup** - Everything pre-configured
- ✅ **Consistent environment** - Same setup for all attendees
- ✅ **Resource isolation** - Each attendee gets their own instance
- ✅ **Automatic port forwarding** - Access services through secure URLs

**Container Configuration:**
\`\`\`dockerfile
# Simplified .devcontainer setup
FROM node:18

# Install Docker and Docker Compose
RUN apt-get update && apt-get install -y docker.io docker-compose

# Setup n8n and documentation services
COPY docker-compose.yml .
COPY .env.example .env

# Start all services automatically
CMD ["docker-compose", "up", "-d"]
\`\`\`

### 3. **Workflow Engine: n8n Visual Automation**

<WorkshopExercise 
  title="Understanding n8n in the Architecture" 
  difficulty="beginner"
  timeEstimate="10 minutes"
  objectives={[
    "Identify n8n's role as the orchestration layer",
    "Understand how n8n connects different services",
    "See the visual workflow representation of agent logic"
  ]}
>

n8n serves as the **orchestration layer** where:

**Visual Workflows = Agent Logic**
\`\`\`javascript
// Traditional code approach
async function processDocument(pdfUrl) {
  const pdf = await downloadPdf(pdfUrl);
  const pages = await extractPages(pdf);
  const embeddings = await generateEmbeddings(pages);
  const result = await storeInMongoDB(embeddings);
  return result;
}

// n8n visual approach
[Webhook] → [HTTP Download] → [PDF Extract] → [Voyage AI] → [MongoDB] → [Response]
\`\`\`

**Key Advantages:**
- **Visual debugging** - See data flow in real-time
- **Non-technical accessibility** - Business users can modify workflows
- **Built-in integrations** - 400+ pre-built connectors
- **Error handling** - Visual representation of failure paths

</WorkshopExercise>

### 4. **Workshop API Gateway: Simplifying Access**

The workshop includes a **custom API gateway** that acts as a proxy and educational tool:

\`\`\`mermaid
graph TD
    A[n8n HTTP Request] --> B[Workshop Gateway]
    B --> C{Route Request}
    C -->|/api/embed| D[Voyage AI Proxy]
    C -->|/api/chat| E[Gemini Proxy]
    C -->|/api/health| F[Health Checks]
    C -->|/api/simulate| G[Error Simulation]
    
    D --> H[Voyage AI API]
    E --> I[Google Gemini API]
    
    style B fill:#fff3e0
    style D fill:#e8f5e8
    style E fill:#e3f2fd
\`\`\`

**Why Use a Proxy?**

| Benefit | Workshop | Production |
|---------|----------|------------|
| **API Key Management** | Hidden from attendees | Your keys, your control |
| **Rate Limiting** | Shared limits managed | Your limits, your rules |
| **Error Simulation** | Teaching tool for resilience | Real errors only |
| **Cost Control** | Workshop covers costs | You control spending |
| **Security** | No key exposure risk | Full security control |

### 5. **Data Layer: MongoDB Atlas**

**Cloud-First Database Strategy:**

\`\`\`mermaid
graph LR
    subgraph "Production Vector Search"
        A[n8n Workflows] --> B[MongoDB Atlas]
        B --> C[Vector Search Index]
        B --> D[Distributed Storage]
        B --> E[Production Scaling]
    end
\`\`\`

**MongoDB Atlas (Cloud):**
- ✅ **Vector search** - Native multimodal embeddings (1024-dimensional)
- ✅ **Production ready** - Managed, scalable, secure
- ✅ **Advanced features** - Full-text search, analytics, real-time sync
- ✅ **Free tier available** - M0 Sandbox perfect for workshop learning
- ⚠️ **Network dependent** - Requires internet connection

### 6. **AI Services: The Intelligence Layer**

**Voyage AI: Multimodal Embeddings**
\`\`\`javascript
// Single API call handles both text and images
{
  "input": {
    "text": "Financial report summary",
    "image": "base64_encoded_chart_image"
  },
  "model": "voyage-multimodal-3",
  "output_dimensions": 1024
}

// Returns unified vector representation
{
  "embeddings": [0.123, -0.456, 0.789, ...], // 1024 dimensions
  "usage": {"input_tokens": 15, "total_tokens": 15}
}
\`\`\`

**Google Gemini 2.0: Agent Intelligence**
\`\`\`javascript
// Function calling configuration
{
  "model": "gemini-2.0-flash-exp",
  "tools": [
    {
      "function": {
        "name": "search_documents",
        "description": "Search PDF documents using vector similarity",
        "parameters": {
          "type": "object",
          "properties": {
            "query": {"type": "string"},
            "limit": {"type": "integer"}
          }
        }
      }
    }
  ],
  "messages": [
    {"role": "user", "content": "What does the financial report say about Q3 revenue?"}
  ]
}
\`\`\`

## 🔄 Data Flow: Request to Response

Let's trace a complete request through the system:

<WorkshopExercise 
  title="Trace a Complete Request" 
  difficulty="intermediate"
  timeEstimate="15 minutes"
  objectives={[
    "Follow data flow from user input to AI response",
    "Understand each transformation step",
    "Identify potential failure points and optimizations"
  ]}
>

### Example: "What are the key findings in document.pdf?"

**Step 1: User Input**
\`\`\`
Browser → Codespace n8n → Webhook Trigger
Data: {"query": "What are the key findings in document.pdf?"}
\`\`\`

**Step 2: Document Search**
\`\`\`
n8n → MongoDB Atlas Vector Search
Query: Generate embedding for "key findings" → Search similar content
Result: [doc1, doc2, doc3] with similarity scores
\`\`\`

**Step 3: Context Preparation**
\`\`\`
n8n → Function Node
Process: Combine search results into context
Data: "Context: [Document excerpts...] Question: What are the key findings?"
\`\`\`

**Step 4: AI Agent Processing**
\`\`\`
n8n → Workshop API Gateway → Google Gemini
Tools Available: [search_documents, extract_text, analyze_chart]
Processing: ReAct pattern - Reason → Act → Observe → Respond
\`\`\`

**Step 5: Response Generation**
\`\`\`
Gemini → Workshop Gateway → n8n → User
Response: "Based on the documents, the key findings are: 1) Revenue increased 15%, 2) New market expansion successful, 3) Cost optimization saved $2M"
\`\`\`

**Performance Metrics:**
- **Total Time**: ~3-8 seconds
- **Bottlenecks**: Vector search (1-2s), AI processing (2-5s)
- **Optimization Opportunities**: Caching, batch processing, parallel requests

</WorkshopExercise>

## 🏭 Workshop vs Production Architecture

### Workshop Architecture (What You're Using)

\`\`\`mermaid
graph TB
    subgraph "Simplified for Learning"
        A[Codespace] --> B[Workshop Proxy]
        B --> C[Shared AI Services]
        A --> D[MongoDB Atlas Free Tier]
    end
    
    style A fill:#e8f5e8
    style B fill:#fff3e0
\`\`\`

**Characteristics:**
- **Shared resources** - All attendees use same proxy
- **Simplified auth** - No API key management
- **Rate limiting** - Shared quotas across workshop
- **Error simulation** - Intentional failures for learning
- **Cost optimization** - Workshop covers all AI service costs

### Production Architecture (What You'd Deploy)

\`\`\`mermaid
graph TB
    subgraph "Production Ready"
        A[Load Balancer] --> B[n8n Cluster]
        B --> C[Your API Keys]
        C --> D[Direct AI Services]
        B --> E[MongoDB Atlas Production]
        B --> F[Redis Cache]
        B --> G[Monitoring & Alerts]
    end
    
    style B fill:#f3e5f5
    style E fill:#e8f5e8
\`\`\`

**Characteristics:**
- **Dedicated resources** - Your infrastructure, your control
- **Direct API access** - Your keys, full rate limits
- **Advanced monitoring** - Custom alerts and dashboards
- **High availability** - Multi-region deployment
- **Security hardening** - VPCs, encryption, access controls

## 🛡️ Security & Privacy Considerations

### Workshop Security Model

| Component | Security Approach | Why |
|-----------|------------------|-----|
| **API Gateway** | Proxy with hidden keys | Protects real credentials |
| **Codespaces** | Isolated containers | Each user gets private environment |
| **MongoDB** | Atlas with network restrictions | Limited access to workshop data only |
| **Data Processing** | Ephemeral processing | No persistent storage of sensitive data |

### Production Security Checklist

\`\`\`javascript
// Production security considerations
const productionSecurity = {
  authentication: {
    api_keys: "Rotate regularly, use key management service",
    user_auth: "Implement OAuth 2.0 or similar", 
    service_auth: "mTLS between services"
  },
  
  data_protection: {
    encryption_at_rest: "MongoDB encryption enabled",
    encryption_in_transit: "TLS 1.3 for all connections",
    data_classification: "Classify and handle PII appropriately"
  },
  
  network_security: {
    vpc_isolation: "Private networks for internal communication",
    firewall_rules: "Whitelist only necessary ports and IPs",
    ddos_protection: "Rate limiting and DDoS mitigation"
  },
  
  monitoring: {
    audit_logs: "Track all API calls and data access",
    anomaly_detection: "Monitor for unusual patterns",
    incident_response: "Automated alerts and response procedures"
  }
};
\`\`\`

## 📊 Performance & Scalability

### Current Workshop Performance

| Metric | Typical Range | Factors |
|--------|---------------|---------|
| **PDF Processing** | 10-30 seconds | File size, page count, complexity |
| **Vector Search** | 100-500ms | Collection size, query complexity |
| **AI Response** | 2-8 seconds | Model complexity, context length |
| **Total Request** | 5-15 seconds | Network latency, queue time |

### Scaling Strategies

\`\`\`mermaid
graph TD
    A[Single User] --> B[Multiple Users]
    B --> C[High Load]
    
    A1[Simple n8n] --> B1[n8n with Redis Queue]
    B1 --> C1[Distributed n8n Cluster]
    
    A2[Development] --> B2[MongoDB Atlas]
    B2 --> C2[Sharded MongoDB Cluster]
    
    A3[Workshop Proxy] --> B3[Your API Keys]
    B3 --> C3[Multiple AI Service Providers]
\`\`\`

**Scaling Bottlenecks:**
1. **AI Service Rate Limits** - Upgrade tiers or multiple providers
2. **Vector Search Performance** - Index optimization, sharding
3. **n8n Throughput** - Queue systems, horizontal scaling
4. **Memory Usage** - Optimize embeddings, implement caching

## 🎯 Architecture Decision Records

### Why n8n Over Traditional Code?

| Decision Factor | n8n | Traditional Code | Winner |
|----------------|-----|------------------|--------|
| **Learning Curve** | Visual, intuitive | Requires programming skills | n8n |
| **Rapid Prototyping** | Drag-and-drop fast | Longer development cycle | n8n |
| **Team Collaboration** | Non-technical can contribute | Developer-only | n8n |
| **Debugging** | Visual execution flow | Code debugging tools | Tie |
| **Production Scale** | Good for most use cases | Maximum flexibility | Code |
| **Maintenance** | Visual workflows self-document | Requires documentation | n8n |

### Why MongoDB Atlas for Vector Search?

| Decision Factor | MongoDB Atlas | Alternatives | Winner |
|----------------|---------------|--------------|--------|
| **Developer Experience** | Unified document + vector DB | Separate systems | MongoDB |
| **Query Flexibility** | Rich filtering + vector search | Vector-only search | MongoDB |
| **Scaling** | Managed, automatic | Manual configuration | MongoDB |
| **Ecosystem** | Integrated with existing tools | New toolchain needed | MongoDB |
| **Cost** | Pay for what you use | Complex pricing models | MongoDB |

### Why Workshop Proxy?

| Decision Factor | Workshop Proxy | Direct API Access | Winner |
|----------------|----------------|-------------------|--------|
| **Workshop Setup Time** | Zero configuration | API key setup required | Proxy |
| **Security** | No key exposure | Keys in environment | Proxy |
| **Cost Control** | Workshop covers costs | Individual responsibility | Proxy |
| **Learning Focus** | Focus on concepts | Focus on configuration | Proxy |
| **Production Readiness** | Teaching only | Real-world experience | Direct |

## 🚀 Next Steps

Understanding this architecture prepares you for:

1. **[Setting Up Your Environment →](./github-codespaces)** - Get everything running
2. **[n8n Workflow Basics →](./n8n-first-run)** - Master the orchestration layer  
3. **[API Gateway Deep Dive →](./api-architecture)** - Understand the proxy system
4. **[Building Your First Agent →](./exercise-pdf-rag-agent)** - Put it all together

The architecture you've learned here scales from workshop prototype to production system. Every component has a clear purpose, and every design decision optimizes for learning while maintaining production relevance.

Ready to start building? Let's launch your development environment! 🛠️
```

# docs/exercise-advanced-tools.mdx

```mdx
---
sidebar_position: 32
---

# 🧪 Exercise: Advanced Tool Calling & Function Integration

<InstructorNotes 
  timing="Advanced Tools Exercise (40-50 minutes)"
  notes={[
    "This is the most technical exercise - ensure strong foundation from previous exercises",
    "Focus on real-world tool integration patterns",
    "Show debugging techniques for function calling failures",
    "Demonstrate error handling and fallback strategies",
    "Address security considerations for external tool access",
    "Show both simple and complex tool orchestration examples"
  ]}
  tips={[
    "Start with simple tools (calculator, date) before complex APIs",
    "Show the JSON schema validation in action",
    "Demonstrate parallel vs sequential tool calling",
    "Use concrete business examples (not abstract demos)",
    "Show tool calling from both n8n and direct Gemini approaches"
  ]}
/>

## 🧪 Objective

Transform your PDF RAG agent into a sophisticated AI assistant that can execute complex tasks using external tools, APIs, and services through intelligent function calling.

<LiveStatusBadge />

## 🛠️ Setup

### Prerequisites
1. **Complete Exercises 30 & 31** - RAG agent with memory capabilities
2. **API Access** - Various external services for tool integration
3. **Security Planning** - API key management and access controls

### Tool Architecture Overview
\`\`\`mermaid
graph TB
    A[User Query] --> B[Intent Analysis]
    B --> C[Tool Selection]
    C --> D[Parameter Extraction]
    D --> E[Tool Execution]
    E --> F[Result Processing]
    F --> G[Response Generation]
    
    C --> H[Search Tools]
    C --> I[Data Tools]  
    C --> J[Communication Tools]
    C --> K[Analysis Tools]
    
    H --> L[Document Search]
    H --> M[Web Search]
    I --> N[Database Query]
    I --> O[API Calls]
    J --> P[Email/Slack]
    J --> Q[Notifications]
    K --> R[Data Analysis]
    K --> S[Chart Generation]
\`\`\`

## 🧠 Key Concepts

### Function Calling Fundamentals

**Tool Definition Schema:**
\`\`\`javascript
{
  "name": "search_financial_data",
  "description": "Search for financial metrics and data in company documents",
  "parameters": {
    "type": "object",
    "properties": {
      "metric_type": {
        "type": "string",
        "enum": ["revenue", "profit", "expenses", "growth"],
        "description": "Type of financial metric to search for"
      },
      "time_period": {
        "type": "string", 
        "description": "Time period (e.g., 'Q3 2024', 'last quarter')"
      },
      "company_division": {
        "type": "string",
        "description": "Specific division or department (optional)"
      }
    },
    "required": ["metric_type", "time_period"]
  }
}
\`\`\`

### Tool Categories

| Category | Purpose | Examples | Complexity |
|----------|---------|----------|------------|
| **Search Tools** | Information retrieval | Document search, web search, database queries | Low |
| **Data Tools** | Data processing | Calculations, transformations, analysis | Medium |
| **Communication** | External communication | Email, Slack, notifications | Medium |
| **Action Tools** | System actions | File operations, workflow triggers | High |

## ✅ Success Criteria

Your advanced tool-enabled agent should:

### Core Tool Functions
- [ ] **Tool Discovery** - Dynamically select appropriate tools for tasks
- [ ] **Parameter Extraction** - Extract correct parameters from natural language
- [ ] **Error Handling** - Gracefully handle tool failures and retries
- [ ] **Result Integration** - Combine tool outputs into coherent responses
- [ ] **Security** - Validate inputs and secure external communications

### Advanced Capabilities  
- [ ] **Multi-Tool Workflows** - Chain multiple tools for complex tasks
- [ ] **Parallel Execution** - Run independent tools simultaneously
- [ ] **Context Preservation** - Maintain context across tool calls
- [ ] **Learning** - Improve tool selection based on success patterns

## 🏗️ Implementation Steps

### Phase 1: Core Tool Infrastructure

<WorkshopExercise 
  title="Build Tool Registry & Execution Engine" 
  difficulty="advanced"
  timeEstimate="20 minutes"
  objectives={[
    "Create a flexible tool registry system",
    "Implement secure tool execution",
    "Build parameter validation and error handling"
  ]}
>

**Create tool infrastructure:**

1. **Tool Registry System**
   \`\`\`javascript
   // Function node: Tool registry
   const toolRegistry = {
     "search_documents": {
       name: "search_documents",
       description: "Search through uploaded PDF documents for specific information",
       parameters: {
         type: "object",
         properties: {
           query: {type: "string", description: "Search query"},
           document_filter: {type: "string", description: "Optional document name filter"},
           max_results: {type: "integer", default: 5, minimum: 1, maximum: 20}
         },
         required: ["query"]
       },
       endpoint: "/search-docs",
       security_level: "low"
     },
     
     "calculate_metrics": {
       name: "calculate_metrics", 
       description: "Perform financial calculations and metric analysis",
       parameters: {
         type: "object",
         properties: {
           operation: {type: "string", enum: ["sum", "average", "growth_rate", "percentage"]},
           values: {type: "array", items: {type: "number"}},
           time_periods: {type: "array", items: {type: "string"}}
         },
         required: ["operation", "values"]
       },
       endpoint: "/calculate",
       security_level: "low"
     },
     
     "send_notification": {
       name: "send_notification",
       description: "Send notifications via email or Slack",
       parameters: {
         type: "object",
         properties: {
           channel: {type: "string", enum: ["email", "slack"]},
           recipient: {type: "string"},
           message: {type: "string"},
           priority: {type: "string", enum: ["low", "medium", "high"], default: "medium"}
         },
         required: ["channel", "recipient", "message"]
       },
       endpoint: "/notify",
       security_level: "high"
     }
   };
   
   return { available_tools: Object.values(toolRegistry) };
   \`\`\`

2. **Parameter Validation Engine**
   \`\`\`javascript
   // Function node: Validate tool parameters
   function validateToolCall(toolName, parameters, toolRegistry) {
     const tool = toolRegistry[toolName];
     if (!tool) {
       throw new Error(`Tool '${toolName}' not found in registry`);
     }
     
     const schema = tool.parameters;
     const required = schema.required || [];
     
     // Check required parameters
     for (const param of required) {
       if (!(param in parameters)) {
         throw new Error(`Missing required parameter: ${param}`);
       }
     }
     
     // Validate parameter types and constraints
     for (const [param, value] of Object.entries(parameters)) {
       const paramSchema = schema.properties[param];
       if (!paramSchema) continue;
       
       if (paramSchema.type === "string" && paramSchema.enum) {
         if (!paramSchema.enum.includes(value)) {
           throw new Error(`Invalid value for ${param}: ${value}`);
         }
       }
       
       if (paramSchema.type === "integer") {
         if (paramSchema.minimum && value < paramSchema.minimum) {
           throw new Error(`${param} must be >= ${paramSchema.minimum}`);
         }
         if (paramSchema.maximum && value > paramSchema.maximum) {
           throw new Error(`${param} must be <= ${paramSchema.maximum}`);
         }
       }
     }
     
     return { valid: true, tool: tool };
   }
   
   const validation = validateToolCall(
     $json.tool_name, 
     $json.parameters, 
     $json.tool_registry
   );
   
   return validation;
   \`\`\`

3. **Secure Tool Execution**
   \`\`\`javascript
   // Function node: Execute tool with security checks
   async function executeToolSecurely(toolCall, userContext) {
     const { tool_name, parameters, validation } = toolCall;
     const tool = validation.tool;
     
     // Security checks
     if (tool.security_level === "high" && !userContext.admin_privileges) {
       throw new Error("Insufficient privileges for this tool");
     }
     
     // Rate limiting check
     const rateLimitKey = `${userContext.session_id}:${tool_name}`;
     const recentCalls = await checkRateLimit(rateLimitKey, 10, 60000); // 10 calls per minute
     
     if (recentCalls.exceeded) {
       throw new Error("Rate limit exceeded for this tool");
     }
     
     // Execute the tool
     try {
       const startTime = Date.now();
       const result = await callToolEndpoint(tool.endpoint, parameters);
       const executionTime = Date.now() - startTime;
       
       // Log successful execution
       await logToolExecution({
         tool_name,
         parameters,
         execution_time: executionTime,
         success: true,
         user_session: userContext.session_id
       });
       
       return {
         success: true,
         result: result,
         execution_time: executionTime,
         tool_name: tool_name
       };
       
     } catch (error) {
       // Log failed execution
       await logToolExecution({
         tool_name,
         parameters,
         error: error.message,
         success: false,
         user_session: userContext.session_id
       });
       
       throw error;
     }
   }
   \`\`\`

</WorkshopExercise>

### Phase 2: Intelligent Tool Selection

<WorkshopExercise 
  title="Implement Smart Tool Selection" 
  difficulty="advanced"
  timeEstimate="15 minutes"
  objectives={[
    "Analyze user queries to determine needed tools",
    "Select optimal tool combinations",
    "Handle ambiguous tool selection scenarios"
  ]}
>

**Build tool selection intelligence:**

1. **Intent Analysis with Gemini**
   \`\`\`javascript
   // HTTP Request: Analyze query for tool needs
   {
     "method": "POST",
     "url": "https://workshop-embedding-api.vercel.app/api/chat",
     "body": {
       "model": "gemini-2.0-flash-exp",
       "messages": [
         {
           "role": "system",
           "content": "You are a tool selection specialist. Analyze user queries and determine which tools are needed to fulfill the request. Consider the available tools and their capabilities."
         },
         {
           "role": "user",
           "content": "Available tools: {{$json.available_tools}}\n\nUser query: {{$json.user_query}}\n\nDetermine which tools to use and in what order."
         }
       ],
       "tools": [
         {
           "function": {
             "name": "select_tools",
             "description": "Select tools needed for the user's request",
             "parameters": {
               "type": "object",
               "properties": {
                 "tool_sequence": {
                   "type": "array",
                   "items": {
                     "type": "object",
                     "properties": {
                       "tool_name": {"type": "string"},
                       "reason": {"type": "string"},
                       "parameters": {"type": "object"},
                       "depends_on": {"type": "array", "items": {"type": "string"}},
                       "execution_order": {"type": "integer"}
                     }
                   }
                 },
                 "execution_strategy": {"type": "string", "enum": ["sequential", "parallel", "mixed"]},
                 "confidence": {"type": "number", "minimum": 0, "maximum": 1}
               }
             }
           }
         }
       ]
     }
   }
   \`\`\`

2. **Tool Orchestration Engine**
   \`\`\`javascript
   // Function node: Orchestrate tool execution
   async function orchestrateTools(toolSequence, executionStrategy) {
     const results = {};
     const errors = [];
     
     if (executionStrategy === "sequential") {
       // Execute tools one by one
       for (const toolCall of toolSequence.sort((a, b) => a.execution_order - b.execution_order)) {
         try {
           // Resolve parameter dependencies
           const resolvedParams = resolveDependencies(toolCall.parameters, results);
           
           const result = await executeToolSecurely({
             tool_name: toolCall.tool_name,
             parameters: resolvedParams,
             validation: await validateToolCall(toolCall.tool_name, resolvedParams)
           }, userContext);
           
           results[toolCall.tool_name] = result;
           
         } catch (error) {
           errors.push({
             tool: toolCall.tool_name,
             error: error.message,
             timestamp: new Date()
           });
           
           // Decide whether to continue or stop
           if (toolCall.critical) {
             throw new Error(`Critical tool ${toolCall.tool_name} failed: ${error.message}`);
           }
         }
       }
       
     } else if (executionStrategy === "parallel") {
       // Execute independent tools in parallel
       const independentTools = toolSequence.filter(t => !t.depends_on || t.depends_on.length === 0);
       
       const parallelPromises = independentTools.map(async (toolCall) => {
         try {
           const result = await executeToolSecurely({
             tool_name: toolCall.tool_name,
             parameters: toolCall.parameters,
             validation: await validateToolCall(toolCall.tool_name, toolCall.parameters)
           }, userContext);
           
           return { tool: toolCall.tool_name, result: result };
         } catch (error) {
           return { tool: toolCall.tool_name, error: error.message };
         }
       });
       
       const parallelResults = await Promise.all(parallelPromises);
       
       parallelResults.forEach(pr => {
         if (pr.result) {
           results[pr.tool] = pr.result;
         } else {
           errors.push({ tool: pr.tool, error: pr.error, timestamp: new Date() });
         }
       });
     }
     
     return {
       results: results,
       errors: errors,
       execution_summary: {
         total_tools: toolSequence.length,
         successful_tools: Object.keys(results).length,
         failed_tools: errors.length,
         execution_strategy: executionStrategy
       }
     };
   }
   \`\`\`

</WorkshopExercise>

### Phase 3: Specialized Tool Implementations

<WorkshopExercise 
  title="Build Specialized Business Tools" 
  difficulty="advanced"
  timeEstimate="25 minutes"
  objectives={[
    "Create domain-specific tools for business use cases",
    "Implement complex data processing tools",
    "Build communication and notification tools"
  ]}
>

**Implement business-specific tools:**

1. **Advanced Document Search Tool**
   \`\`\`javascript
   // HTTP Request node: Enhanced document search
   {
     "method": "POST",
     "url": "https://workshop-embedding-api.vercel.app/api/search-documents",
     "body": {
       "query": "{{$json.search_query}}",
       "filters": {
         "document_type": "{{$json.document_filter}}",
         "date_range": {
           "start": "{{$json.date_start}}",
           "end": "{{$json.date_end}}"
         },
         "metadata": "{{$json.metadata_filters}}"
       },
       "search_options": {
         "semantic_search": true,
         "keyword_search": true,
         "image_search": true,
         "hybrid_ranking": true
       },
       "result_options": {
         "max_results": "{{$json.max_results}}",
         "include_snippets": true,
         "include_images": true,
         "similarity_threshold": 0.7
       }
     }
   }
   \`\`\`

2. **Financial Analysis Tool**
   \`\`\`javascript
   // Function node: Financial calculations and analysis
   function performFinancialAnalysis(operation, data, options = {}) {
     const calculations = {
       growth_rate: (current, previous) => ((current - previous) / previous) * 100,
       
       compound_annual_growth_rate: (ending_value, beginning_value, years) => 
         (Math.pow(ending_value / beginning_value, 1 / years) - 1) * 100,
       
       moving_average: (values, period) => {
         const results = [];
         for (let i = period - 1; i < values.length; i++) {
           const sum = values.slice(i - period + 1, i + 1).reduce((a, b) => a + b, 0);
           results.push(sum / period);
         }
         return results;
       },
       
       trend_analysis: (values) => {
         const n = values.length;
         const x_mean = (n - 1) / 2;
         const y_mean = values.reduce((a, b) => a + b, 0) / n;
         
         let numerator = 0;
         let denominator = 0;
         
         for (let i = 0; i < n; i++) {
           numerator += (i - x_mean) * (values[i] - y_mean);
           denominator += Math.pow(i - x_mean, 2);
         }
         
         const slope = numerator / denominator;
         const direction = slope > 0 ? "increasing" : slope < 0 ? "decreasing" : "stable";
         
         return { slope, direction, confidence: Math.abs(slope) };
       },
       
       variance_analysis: (actual, budget) => {
         const variance = actual - budget;
         const variance_percentage = (variance / budget) * 100;
         
         return {
           absolute_variance: variance,
           percentage_variance: variance_percentage,
           status: variance >= 0 ? "favorable" : "unfavorable",
           significance: Math.abs(variance_percentage) > 10 ? "significant" : "minor"
         };
       }
     };
     
     const result = calculations[operation](data.values, data.secondary_values, data.periods);
     
     return {
       operation: operation,
       result: result,
       metadata: {
         calculation_date: new Date(),
         data_points: data.values?.length || 0,
         confidence_level: options.confidence_level || 0.95
       }
     };
   }
   
   const analysis = performFinancialAnalysis(
     $json.operation,
     $json.financial_data,
     $json.options
   );
   
   return analysis;
   \`\`\`

3. **Smart Notification Tool**
   \`\`\`javascript
   // Function node: Intelligent notification system
   async function sendSmartNotification(notification) {
     const { channel, recipient, message, priority, context } = notification;
     
     // Analyze message content for optimal delivery
     const messageAnalysis = await analyzeMessage(message);
     
     // Determine optimal timing
     const deliveryTiming = calculateOptimalTiming(recipient, priority, context);
     
     // Format message for channel
     const formattedMessage = formatMessageForChannel(message, channel, messageAnalysis);
     
     // Delivery options based on channel
     const deliveryMethods = {
       email: async (recipient, message) => {
         return await sendEmail({
           to: recipient,
           subject: generateSmartSubject(message),
           body: message,
           priority: priority,
           delivery_time: deliveryTiming.optimal_time
         });
       },
       
       slack: async (recipient, message) => {
         return await sendSlackMessage({
           channel: recipient,
           text: message,
           blocks: generateSlackBlocks(messageAnalysis),
           priority: priority
         });
       },
       
       sms: async (recipient, message) => {
         return await sendSMS({
           to: recipient,
           message: truncateForSMS(message),
           priority: priority
         });
       }
     };
     
     try {
       const deliveryResult = await deliveryMethods[channel](recipient, formattedMessage);
       
       // Log successful delivery
       await logNotification({
         channel,
         recipient,
         message_id: deliveryResult.id,
         delivered_at: new Date(),
         success: true,
         analysis: messageAnalysis
       });
       
       return {
         success: true,
         delivery_id: deliveryResult.id,
         channel: channel,
         estimated_read_time: deliveryTiming.estimated_read_time
       };
       
     } catch (error) {
       // Try fallback channel if available
       if (context.fallback_channel && context.fallback_channel !== channel) {
         return await sendSmartNotification({
           ...notification,
           channel: context.fallback_channel
         });
       }
       
       throw error;
     }
   }
   \`\`\`

</WorkshopExercise>

### Phase 4: Multi-Tool Workflows

<WorkshopExercise 
  title="Create Complex Multi-Tool Workflows" 
  difficulty="expert"
  timeEstimate="20 minutes"
  objectives={[
    "Chain multiple tools for complex business processes",
    "Handle tool dependencies and data flow",
    "Implement error recovery and fallback strategies"
  ]}
>

**Build sophisticated workflows:**

1. **Business Report Generation Workflow**
   \`\`\`javascript
   // Complex workflow: Generate comprehensive business report
   const reportWorkflow = {
     name: "generate_business_report",
     description: "Generate comprehensive business report with data analysis and insights",
     
     steps: [
       {
         step: 1,
         tool: "search_documents",
         parameters: {
           query: "{{$json.report_topic}}",
           document_filter: "financial_reports",
           max_results: 10
         },
         output_name: "source_documents"
       },
       
       {
         step: 2,
         tool: "calculate_metrics",
         parameters: {
           operation: "trend_analysis",
           values: "{{steps.source_documents.financial_data}}"
         },
         depends_on: ["source_documents"],
         output_name: "trend_analysis"
       },
       
       {
         step: 3,
         tool: "calculate_metrics", 
         parameters: {
           operation: "variance_analysis",
           values: "{{steps.source_documents.actual_values}}",
           secondary_values: "{{steps.source_documents.budget_values}}"
         },
         depends_on: ["source_documents"],
         output_name: "variance_analysis",
         parallel_with: [2] // Can run parallel with step 2
       },
       
       {
         step: 4,
         tool: "generate_insights",
         parameters: {
           trend_data: "{{steps.trend_analysis.result}}",
           variance_data: "{{steps.variance_analysis.result}}",
           source_context: "{{steps.source_documents.context}}"
         },
         depends_on: ["trend_analysis", "variance_analysis"],
         output_name: "business_insights"
       },
       
       {
         step: 5,
         tool: "create_visualization",
         parameters: {
           chart_type: "dashboard",
           data_sources: [
             "{{steps.trend_analysis.result}}",
             "{{steps.variance_analysis.result}}"
           ]
         },
         depends_on: ["trend_analysis", "variance_analysis"],
         output_name: "visualizations",
         parallel_with: [4]
       },
       
       {
         step: 6,
         tool: "generate_report",
         parameters: {
           insights: "{{steps.business_insights.result}}",
           charts: "{{steps.visualizations.result}}",
           template: "executive_summary"
         },
         depends_on: ["business_insights", "visualizations"],
         output_name: "final_report"
       },
       
       {
         step: 7,
         tool: "send_notification",
         parameters: {
           channel: "email",
           recipient: "{{$json.report_recipient}}",
           message: "Business report ready: {{steps.final_report.summary}}",
           priority: "medium"
         },
         depends_on: ["final_report"],
         optional: true // Don't fail workflow if notification fails
       }
     ],
     
     error_handling: {
       retry_failed_steps: true,
       max_retries: 2,
       fallback_strategy: "partial_completion",
       notify_on_failure: true
     }
   };
   
   return { workflow: reportWorkflow };
   \`\`\`

2. **Workflow Execution Engine**
   \`\`\`javascript
   // Function node: Execute complex multi-tool workflow
   async function executeWorkflow(workflow, inputData, userContext) {
     const executionPlan = analyzeWorkflowDependencies(workflow.steps);
     const stepResults = {};
     const errors = [];
     
     // Execute workflow in optimal order
     for (const phase of executionPlan.execution_phases) {
       const phasePromises = [];
       
       for (const step of phase.parallel_steps) {
         const promise = executeWorkflowStep(step, stepResults, inputData, userContext)
           .then(result => {
             stepResults[step.output_name] = result;
             return { step: step.step, success: true, result };
           })
           .catch(error => {
             errors.push({ step: step.step, error: error.message, timestamp: new Date() });
             
             if (workflow.error_handling.retry_failed_steps && step.retry_count < workflow.error_handling.max_retries) {
               step.retry_count = (step.retry_count || 0) + 1;
               return executeWorkflowStep(step, stepResults, inputData, userContext);
             }
             
             return { step: step.step, success: false, error: error.message };
           });
         
         phasePromises.push(promise);
       }
       
       const phaseResults = await Promise.all(phasePromises);
       
       // Check if critical steps failed
       const criticalFailures = phaseResults.filter(r => !r.success && !r.optional);
       if (criticalFailures.length > 0 && workflow.error_handling.fallback_strategy !== "partial_completion") {
         throw new Error(`Critical workflow steps failed: ${criticalFailures.map(f => f.step).join(', ')}`);
       }
     }
     
     return {
       success: errors.length === 0,
       results: stepResults,
       errors: errors,
       execution_summary: {
         total_steps: workflow.steps.length,
         successful_steps: Object.keys(stepResults).length,
         failed_steps: errors.length,
         execution_time: Date.now() - startTime
       }
     };
   }
   \`\`\`

</WorkshopExercise>

## 🧩 Advanced Tool Patterns

### Error Recovery Strategies
- **Graceful Degradation** - Continue with reduced functionality when tools fail
- **Retry Logic** - Exponential backoff for transient failures
- **Circuit Breakers** - Prevent cascading failures from external services

### Performance Optimization
- **Tool Caching** - Cache results from expensive tool operations
- **Batch Processing** - Combine multiple tool calls for efficiency
- **Async Execution** - Non-blocking tool execution where possible

### Security & Governance
- **Tool Permissions** - Role-based access to different tool categories
- **Audit Logging** - Complete audit trail of all tool executions
- **Data Validation** - Strict validation of all tool inputs and outputs

## 🔧 Testing Your Tool System

### Tool Integration Tests
1. **Individual Tool Tests** - Verify each tool works in isolation
2. **Parameter Validation** - Test edge cases and invalid inputs
3. **Error Handling** - Verify graceful failure handling
4. **Performance Tests** - Measure tool execution times under load

### Workflow Tests
1. **Simple Chains** - Test 2-3 tool sequences
2. **Complex Workflows** - Test full business process automation
3. **Parallel Execution** - Verify concurrent tool execution
4. **Failure Recovery** - Test error scenarios and recovery

## 📋 Advanced Tools Checklist

- [ ] **Tool Registry** - Dynamic tool discovery and registration
- [ ] **Parameter Validation** - Robust input validation and error handling
- [ ] **Security Controls** - Authentication, authorization, and rate limiting
- [ ] **Execution Engine** - Parallel and sequential tool orchestration
- [ ] **Error Recovery** - Retry logic and fallback strategies
- [ ] **Performance** - Caching, batching, and optimization
- [ ] **Monitoring** - Logging, metrics, and alerting
- [ ] **Documentation** - Clear tool schemas and usage examples

## 🎯 Key Takeaways

This exercise demonstrates:

1. **Tool Architecture** - Scalable, secure tool integration patterns
2. **Workflow Orchestration** - Complex business process automation
3. **Error Resilience** - Robust handling of real-world failures
4. **Security** - Enterprise-grade security and governance

## 📚 Next Steps

Ready for production deployment?

- **Production Architecture** - Coming soon!
- **Scaling & Performance** - Coming soon!
- **Security & Governance** - Coming soon!

You've built a sophisticated AI agent capable of complex task execution - the foundation of true business automation! 🛠️
```

# docs/exercise-memory-context.mdx

```mdx
---
sidebar_position: 31
---

# 🧪 Exercise: Memory & Context Management

<InstructorNotes 
  timing="Memory & Context Exercise (30-40 minutes)"
  notes={[
    "This builds on the RAG agent - ensure attendees completed Exercise 30 first",
    "Focus on different memory types and when to use each",
    "Show how memory improves agent responses over time",
    "Demonstrate the difference between stateless and stateful agents",
    "Address privacy concerns around storing conversation data",
    "Show MongoDB TTL indexes for automatic cleanup"
  ]}
  tips={[
    "Start with working memory (easiest to understand)",
    "Use concrete examples: 'Remember my name is John'",
    "Show the MongoDB collections filling up with memory data",
    "Demonstrate memory retrieval in action during conversations",
    "Explain when to clear vs persist different memory types"
  ]}
/>

## 🧪 Objective

Enhance your PDF RAG agent with sophisticated memory capabilities, enabling it to remember conversations, learn from interactions, and maintain context across multiple queries.

<LiveStatusBadge />

## 🛠️ Setup

### Prerequisites
1. **Complete Exercise 30** - Your PDF RAG agent should be working
2. **MongoDB Collections** - Ensure you have write access to create new collections
3. **Session Management** - We'll add user session tracking to your workflows

### Memory Architecture Overview
\`\`\`mermaid
graph TB
    A[User Query] --> B[Memory Retrieval]
    B --> C[Context Assembly]
    C --> D[Agent Processing]
    D --> E[Response Generation]
    E --> F[Memory Storage]
    
    B --> G[(Working Memory)]
    B --> H[(Episodic Memory)]
    B --> I[(Semantic Memory)]
    B --> J[(Procedural Memory)]
    
    G --> K[Session Data]
    H --> L[Conversation History]
    I --> M[Learned Facts]
    J --> N[Task Patterns]
\`\`\`

## 🧠 Key Concepts

### Memory Types in AI Agents

| Memory Type | Purpose | Duration | Example |
|-------------|---------|----------|---------|
| **Working Memory** | Current session context | Session only | "User's name is Sarah, working on Q3 report" |
| **Episodic Memory** | Conversation history | Days/weeks | "Last week asked about revenue trends" |
| **Semantic Memory** | Learned knowledge | Permanent | "Company fiscal year ends in March" |
| **Procedural Memory** | Task patterns | Permanent | "When user asks for summary, include key metrics" |

### Memory Storage Strategy
- **MongoDB Collections** - Separate collections for each memory type
- **TTL Indexes** - Automatic cleanup for temporary memories
- **Vector Embeddings** - Enable semantic memory search
- **Session Tracking** - Link memories to user sessions

## ✅ Success Criteria

Your memory-enhanced agent should:

### Core Memory Functions
- [ ] **Session Persistence** - Remember context within a conversation
- [ ] **Cross-Session Learning** - Recall information from previous sessions
- [ ] **Context Assembly** - Combine relevant memories for better responses
- [ ] **Memory Updates** - Learn new facts and preferences from interactions
- [ ] **Selective Recall** - Retrieve only relevant memories for each query

### Quality Indicators
- [ ] **Consistency** - Maintains consistent information across conversations
- [ ] **Personalization** - Adapts responses based on user history
- [ ] **Efficiency** - Fast memory retrieval doesn't slow responses
- [ ] **Privacy** - Respects data retention and cleanup policies

## 🏗️ Implementation Steps

### Phase 1: Working Memory (Session Context)

<WorkshopExercise 
  title="Implement Session-Based Working Memory" 
  difficulty="intermediate"
  timeEstimate="15 minutes"
  objectives={[
    "Track user sessions across multiple queries",
    "Store and retrieve session context",
    "Handle session expiration automatically"
  ]}
>

**Build session management:**

1. **Session Initialization**
   \`\`\`javascript
   // Function node: Generate or retrieve session ID
   const sessionId = $input.first().json.session_id || 
                    `session_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
   
   return {
     session_id: sessionId,
     timestamp: new Date(),
     user_query: $input.first().json.query,
     context: {}
   };
   \`\`\`

2. **Working Memory Storage**
   \`\`\`javascript
   // MongoDB node: Store session context
   {
     "operation": "findOneAndUpdate",
     "collection": "working_memory",
     "filter": {
       "session_id": "{{$json.session_id}}"
     },
     "update": {
       "$set": {
         "session_id": "{{$json.session_id}}",
         "last_activity": "{{$now}}",
         "context": "{{$json.context}}",
         "query_count": {"$inc": 1}
       }
     },
     "options": {
       "upsert": true,
       "returnDocument": "after"
     }
   }
   \`\`\`

3. **TTL Index Setup** (MongoDB Atlas):
   \`\`\`javascript
   // Create TTL index for automatic cleanup
   db.working_memory.createIndex(
     { "last_activity": 1 }, 
     { expireAfterSeconds: 3600 } // 1 hour session timeout
   );
   \`\`\`

4. **Context Retrieval**
   \`\`\`javascript
   // Function node: Load session context
   const session = await $input.first().json;
   
   // Combine current query with session context
   const enrichedContext = {
     current_query: session.user_query,
     session_history: session.context.previous_queries || [],
     user_preferences: session.context.preferences || {},
     document_context: session.context.current_document || null
   };
   
   return { enriched_context: enrichedContext };
   \`\`\`

</WorkshopExercise>

### Phase 2: Episodic Memory (Conversation History)

<WorkshopExercise 
  title="Build Conversational Memory" 
  difficulty="intermediate"
  timeEstimate="15 minutes"
  objectives={[
    "Store conversation turns with context",
    "Retrieve relevant conversation history",
    "Enable multi-turn dialogue understanding"
  ]}
>

**Create conversation tracking:**

1. **Conversation Storage Schema**
   \`\`\`javascript
   // MongoDB document structure
   {
     "conversation_id": "conv_12345",
     "session_id": "session_67890", 
     "user_id": "user_abc", // Optional for personalization
     "turns": [
       {
         "turn_number": 1,
         "timestamp": "2024-01-20T10:30:00Z",
         "user_query": "What are the main findings in the Q3 report?",
         "agent_response": "The Q3 report shows...",
         "context_used": ["page_5", "page_12"],
         "confidence": 0.89
       }
     ],
     "topics": ["financial_report", "q3_analysis"],
     "document_references": ["q3_report.pdf"],
     "created_at": "2024-01-20T10:30:00Z",
     "updated_at": "2024-01-20T10:45:00Z"
   }
   \`\`\`

2. **Conversation Update Node**
   \`\`\`javascript
   // Function node: Add conversation turn
   const currentTurn = {
     turn_number: ($json.conversation?.turns?.length || 0) + 1,
     timestamp: new Date(),
     user_query: $json.user_query,
     agent_response: $json.agent_response,
     context_used: $json.context_pages || [],
     confidence: $json.confidence_score || 0.8
   };
   
   return {
     conversation_id: $json.conversation_id,
     new_turn: currentTurn,
     topics: extractTopics($json.user_query), // Extract key topics
     document_refs: $json.document_references || []
   };
   \`\`\`

3. **History Retrieval with Relevance**
   \`\`\`javascript
   // MongoDB aggregation: Find relevant conversation history
   [
     {
       "$match": {
         "session_id": "{{$json.session_id}}",
         "topics": {"$in": ["{{$json.current_topics}}"]}
       }
     },
     {
       "$unwind": "$turns"
     },
     {
       "$match": {
         "turns.timestamp": {
           "$gte": "{{$json.time_window_start}}"
         }
       }
     },
     {
       "$sort": {"turns.timestamp": -1}
     },
     {
       "$limit": 5
     },
     {
       "$project": {
         "query": "$turns.user_query",
         "response": "$turns.agent_response", 
         "timestamp": "$turns.timestamp",
         "relevance_score": 1
       }
     }
   ]
   \`\`\`

</WorkshopExercise>

### Phase 3: Semantic Memory (Learned Knowledge)

<WorkshopExercise 
  title="Implement Knowledge Learning" 
  difficulty="advanced"
  timeEstimate="20 minutes"
  objectives={[
    "Extract and store factual information from conversations",
    "Build a knowledge base from user interactions",
    "Enable semantic search across learned facts"
  ]}
>

**Build knowledge extraction:**

1. **Fact Extraction with Gemini**
   \`\`\`javascript
   // HTTP Request: Extract facts from conversation
   {
     "method": "POST",
     "url": "https://workshop-embedding-api.vercel.app/api/chat",
     "body": {
       "model": "gemini-2.0-flash-exp",
       "messages": [
         {
           "role": "system",
           "content": "Extract factual information and user preferences from this conversation. Return as structured JSON."
         },
         {
           "role": "user",
           "content": "Conversation: {{$json.conversation_text}}"
         }
       ],
       "tools": [
         {
           "function": {
             "name": "store_fact",
             "description": "Store a learned fact or preference",
             "parameters": {
               "type": "object",
               "properties": {
                 "fact_type": {"type": "string", "enum": ["user_preference", "domain_knowledge", "process_info"]},
                 "subject": {"type": "string"},
                 "predicate": {"type": "string"},
                 "object": {"type": "string"},
                 "confidence": {"type": "number"},
                 "source": {"type": "string"}
               }
             }
           }
         }
       ]
     }
   }
   \`\`\`

2. **Semantic Memory Storage**
   \`\`\`javascript
   // MongoDB node: Store extracted facts
   {
     "operation": "insertMany",
     "collection": "semantic_memory",
     "documents": [
       {
         "fact_id": "{{$json.fact_id}}",
         "type": "{{$json.fact_type}}",
         "subject": "{{$json.subject}}",
         "predicate": "{{$json.predicate}}", 
         "object": "{{$json.object}}",
         "confidence": "{{$json.confidence}}",
         "source_conversation": "{{$json.conversation_id}}",
         "embedding": "{{$json.fact_embedding}}", // For semantic search
         "created_at": "{{$now}}",
         "verified": false,
         "usage_count": 0
       }
     ]
   }
   \`\`\`

3. **Knowledge Retrieval Pipeline**
   \`\`\`javascript
   // Function node: Query semantic memory
   const queryEmbedding = await generateEmbedding($json.user_query);
   
   // Vector search for relevant facts
   const relevantFacts = await mongodbVectorSearch({
     collection: "semantic_memory",
     index: "semantic_vector_index",
     queryVector: queryEmbedding,
     filter: {
       confidence: {$gte: 0.7},
       verified: true
     },
     limit: 10
   });
   
   return {
     relevant_knowledge: relevantFacts,
     knowledge_context: relevantFacts.map(f => 
       `${f.subject} ${f.predicate} ${f.object}`
     ).join('. ')
   };
   \`\`\`

</WorkshopExercise>

### Phase 4: Procedural Memory (Task Patterns)

<WorkshopExercise 
  title="Learn User Task Patterns" 
  difficulty="advanced"
  timeEstimate="15 minutes"
  objectives={[
    "Identify recurring user task patterns",
    "Optimize workflows based on usage patterns",
    "Provide proactive suggestions"
  ]}
>

**Implement pattern learning:**

1. **Task Pattern Recognition**
   \`\`\`javascript
   // Function node: Analyze user behavior patterns
   const userSessions = $input.all();
   const patterns = {};
   
   userSessions.forEach(session => {
     const queryTypes = session.queries.map(q => classifyQuery(q));
     const sequence = queryTypes.join(' -> ');
     
     patterns[sequence] = (patterns[sequence] || 0) + 1;
   });
   
   // Find common patterns
   const commonPatterns = Object.entries(patterns)
     .filter(([_, count]) => count >= 3)
     .sort(([_, a], [__, b]) => b - a)
     .slice(0, 10);
   
   return { 
     task_patterns: commonPatterns,
     recommendations: generateRecommendations(commonPatterns)
   };
   \`\`\`

2. **Pattern-Based Suggestions**
   \`\`\`javascript
   // HTTP Request: Generate proactive suggestions
   {
     "method": "POST",
     "url": "https://workshop-embedding-api.vercel.app/api/chat",
     "body": {
       "model": "gemini-2.0-flash-exp",
       "messages": [
         {
           "role": "system",
           "content": "Based on user patterns, suggest helpful follow-up questions or actions."
         },
         {
           "role": "user",
           "content": "User query: {{$json.current_query}}\nCommon patterns: {{$json.user_patterns}}\nCurrent context: {{$json.context}}"
         }
       ]
     }
   }
   \`\`\`

</WorkshopExercise>

## 🧩 Advanced Memory Features

### Memory Consolidation
- **Batch Processing** - Periodically consolidate short-term to long-term memory
- **Conflict Resolution** - Handle contradictory information gracefully
- **Memory Pruning** - Remove outdated or irrelevant memories

### Privacy & Compliance
- **Data Retention Policies** - Automatic cleanup based on regulations
- **User Consent** - Allow users to control memory collection
- **Anonymization** - Remove personally identifiable information

### Performance Optimization
- **Memory Indexing** - Optimize retrieval with proper database indexes
- **Caching Strategy** - Cache frequently accessed memories
- **Batch Operations** - Minimize database round trips

## 🔧 Testing Your Memory System

### Memory Persistence Tests
1. **Session Continuity** - Ask follow-up questions in same session
2. **Cross-Session Recall** - Return later and reference previous conversations  
3. **Learning Verification** - Confirm agent learned new information
4. **Context Assembly** - Check if multiple memory types combine properly

### Example Test Conversation
\`\`\`
User: "Hi, I'm Sarah and I work in finance."
Agent: "Hello Sarah! Nice to meet you. I'll remember that you work in finance."

User: "Can you analyze the Q3 revenue report?"
Agent: "I'll analyze the Q3 revenue report for you, Sarah. Since you work in finance, I'll focus on the key financial metrics that would be most relevant to your role."

[Later session]
User: "Remember me?"
Agent: "Of course! You're Sarah from finance. Last time we discussed the Q3 revenue report. How can I help you today?"
\`\`\`

## 📋 Memory Quality Checklist

- [ ] **Working Memory** - Maintains context during session
- [ ] **Episodic Memory** - Recalls previous conversations  
- [ ] **Semantic Memory** - Learns and applies new facts
- [ ] **Procedural Memory** - Adapts to user patterns
- [ ] **Memory Integration** - Combines different memory types effectively
- [ ] **Privacy Compliance** - Respects data retention policies
- [ ] **Performance** - Memory operations don't slow responses

## 🎯 Key Takeaways

This exercise demonstrates:

1. **Memory Architecture** - Different types serve different purposes
2. **Context Assembly** - Combining memories improves response quality
3. **Learning Systems** - Agents can improve through interaction
4. **Privacy Balance** - Useful memory vs data protection considerations

## 📚 Next Steps

Ready for advanced tool integration?

- [**Exercise: Advanced Tool Calling →**](./exercise-advanced-tools)
- **Production Memory Systems** - Coming soon!
- **Privacy & Compliance** - Coming soon!

You've built an agent that learns and remembers - the foundation of truly intelligent systems! 🧠
```

# docs/exercise-pdf-rag-agent.mdx

```mdx
---
sidebar_position: 30
---

# 🧪 Exercise: Build a PDF RAG Agent

<InstructorNotes 
  timing="PDF RAG Agent Exercise (45-60 minutes)"
  notes={[
    "This is the core hands-on exercise - most time should be spent here",
    "Walk through each step slowly, showing the visual workflow",
    "Have attendees test with their own PDFs if possible",
    "Address common issues: file upload errors, embedding failures",
    "Show debugging techniques in n8n when things go wrong",
    "Emphasize the RAG pattern: Retrieve → Augment → Generate"
  ]}
  tips={[
    "Start with a simple PDF (2-3 pages) for faster testing",
    "Show the MongoDB collection filling up with embeddings",
    "Demonstrate different query types: factual, analytical, summarization",
    "Use the live status badges to verify all services are working",
    "Have backup PDFs ready in case upload issues occur"
  ]}
/>

## 🧪 Objective

Build a multimodal RAG (Retrieval-Augmented Generation) agent that answers questions about uploaded PDF documents using visual and textual understanding.

<LiveStatusBadge />

## 🛠️ Setup

### Step 1: Environment Check
1. **Open your Codespace** - Ensure all services are running
2. **Verify n8n access** - Navigate to your n8n instance (port 5678)
3. **Check MongoDB connection** - Confirm Atlas connection is active
4. **Test API gateway** - Verify the workshop proxy is responding

### Step 2: Import Base Workflow
\`\`\`javascript
// Download the starter workflow
{
  "name": "PDF RAG Agent Starter",
  "nodes": [
    {
      "name": "Webhook",
      "type": "n8n-nodes-base.webhook",
      "parameters": {
        "path": "pdf-rag",
        "httpMethod": "POST"
      }
    },
    // Additional starter nodes...
  ]
}
\`\`\`

## 🧠 Key Concepts

Before building, understand these foundational concepts:

### RAG Architecture Pattern
\`\`\`mermaid
graph LR
    A[User Query] --> B[Retrieve Similar Content]
    B --> C[Augment with Context]
    C --> D[Generate Response]
    D --> E[User Answer]
    
    B --> F[(Vector Database)]
    F --> G[Document Embeddings]
\`\`\`

**You'll implement:**
- **Voyage AI** to create image + text embeddings from PDF pages
- **MongoDB Atlas Vector Search** for intelligent document retrieval  
- **Google Gemini 2.0** with function calling to generate contextual answers
- **n8n workflows** to orchestrate the entire agent pipeline

### Multimodal Understanding
Your agent will process both:
- **Text content** - Extracted paragraphs, headings, captions
- **Visual elements** - Charts, diagrams, images, document layout
- **Unified embeddings** - Single vector space for text + images

## ✅ Success Criteria

Your completed agent should demonstrate:

### Core Functionality
- [ ] **PDF Upload** - Accept PDF files through webhook interface  
- [ ] **Page Processing** - Extract both text and images from each page
- [ ] **Embedding Generation** - Create multimodal embeddings using Voyage AI
- [ ] **Vector Storage** - Store embeddings in MongoDB Atlas with metadata
- [ ] **Question Answering** - Respond to user queries with relevant context
- [ ] **Source Attribution** - Reference specific pages/sections in responses

### Quality Indicators
- [ ] **Accuracy** - Answers reflect actual document content
- [ ] **Relevance** - Responses focus on most relevant document sections
- [ ] **Context** - Includes page numbers and section references
- [ ] **Multimodal** - Incorporates both text and visual information

## 🏗️ Implementation Steps

### Phase 1: PDF Processing Pipeline

<WorkshopExercise 
  title="Build PDF Processing Workflow" 
  difficulty="intermediate"
  timeEstimate="20 minutes"
  objectives={[
    "Extract text and images from PDF pages",
    "Prepare content for embedding generation",
    "Handle various PDF formats and structures"
  ]}
>

**Create the processing chain:**

1. **HTTP Request Receiver**
   \`\`\`javascript
   // Webhook configuration
   {
     "path": "pdf-upload",
     "httpMethod": "POST",
     "responseMode": "responseNode"
   }
   \`\`\`

2. **PDF Text Extraction**
   \`\`\`javascript
   // Function node: Extract text content
   const pdfParse = require('pdf-parse');
   
   const pdfBuffer = Buffer.from($input.first().binary.data, 'base64');
   const pdfData = await pdfParse(pdfBuffer);
   
   return {
     text: pdfData.text,
     numPages: pdfData.numpages,
     info: pdfData.info
   };
   \`\`\`

3. **Image Extraction Node**
   \`\`\`javascript
   // Extract images from PDF pages
   const pdf2pic = require('pdf2pic');
   
   const convert = pdf2pic.fromBuffer(pdfBuffer, {
     density: 150,
     saveFilename: "page",
     savePath: "/tmp/",
     format: "png",
     width: 1024,
     height: 1024
   });
   
   const pages = await convert.bulk(-1);
   return pages.map(page => ({
     pageNumber: page.page,
     imagePath: page.path,
     imageBase64: fs.readFileSync(page.path, 'base64')
   }));
   \`\`\`

</WorkshopExercise>

### Phase 2: Embedding Generation

<WorkshopExercise 
  title="Generate Multimodal Embeddings" 
  difficulty="intermediate"
  timeEstimate="15 minutes"
  objectives={[
    "Use Voyage AI for unified text+image embeddings",
    "Handle batch processing efficiently",
    "Prepare vectors for storage"
  ]}
>

**Configure Voyage AI integration:**

1. **Multimodal Embedding Node**
   \`\`\`javascript
   // HTTP Request to workshop gateway
   {
     "method": "POST",
     "url": "https://workshop-embedding-api.vercel.app/api/embed",
     "body": {
       "input": {
         "text": "{{$json.text}}",
         "image": "{{$json.imageBase64}}"
       },
       "model": "voyage-multimodal-3",
       "input_type": "document"
     }
   }
   \`\`\`

2. **Batch Processing Logic**
   \`\`\`javascript
   // Function node: Prepare batches
   const batchSize = 5; // Process 5 pages at a time
   const pages = $input.all();
   const batches = [];
   
   for (let i = 0; i < pages.length; i += batchSize) {
     batches.push(pages.slice(i, i + batchSize));
   }
   
   return batches.map(batch => ({ batch }));
   \`\`\`

</WorkshopExercise>

### Phase 3: Vector Storage

<WorkshopExercise 
  title="Store in MongoDB Atlas" 
  difficulty="beginner"
  timeEstimate="10 minutes"
  objectives={[
    "Configure MongoDB Atlas connection",
    "Design document schema for retrieval",
    "Create vector search index"
  ]}
>

**Setup vector storage:**

1. **MongoDB Insert Node**
   \`\`\`javascript
   // MongoDB node configuration
   {
     "operation": "insertMany",
     "collection": "pdf_embeddings",
     "documents": [
       {
         "document_id": "{{$json.docId}}",
         "page_number": "{{$json.pageNum}}",
         "text_content": "{{$json.text}}",
         "embedding": "{{$json.embedding}}",
         "metadata": {
           "created_at": "{{$now}}",
           "file_name": "{{$json.fileName}}",
           "page_type": "{{$json.pageType}}"
         }
       }
     ]
   }
   \`\`\`

2. **Vector Search Index** (Atlas UI):
   \`\`\`json
   {
     "type": "vectorSearch",
     "fields": [
       {
         "type": "vector",
         "path": "embedding",
         "numDimensions": 1024,
         "similarity": "cosine"
       },
       {
         "type": "filter",
         "path": "document_id"
       }
     ]
   }
   \`\`\`

</WorkshopExercise>

### Phase 4: Query Processing & Response

<WorkshopExercise 
  title="Implement Question Answering" 
  difficulty="advanced"
  timeEstimate="20 minutes"
  objectives={[
    "Build vector similarity search",
    "Configure Gemini with function calling",
    "Generate contextual responses"
  ]}
>

**Create the QA pipeline:**

1. **Query Vector Search**
   \`\`\`javascript
   // MongoDB Vector Search Aggregation
   [
     {
       "$vectorSearch": {
         "index": "pdf_vector_index",
         "path": "embedding", 
         "queryVector": "{{$json.queryEmbedding}}",
         "numCandidates": 50,
         "limit": 5
       }
     },
     {
       "$project": {
         "text_content": 1,
         "page_number": 1,
         "metadata": 1,
         "score": { "$meta": "vectorSearchScore" }
       }
     }
   ]
   \`\`\`

2. **Gemini Function Calling**
   \`\`\`javascript
   // HTTP Request to Gemini via gateway
   {
     "method": "POST",
     "url": "https://workshop-embedding-api.vercel.app/api/chat",
     "body": {
       "model": "gemini-2.0-flash-exp",
       "messages": [
         {
           "role": "system",
           "content": "You are a helpful AI assistant that answers questions about documents. Use the provided context to give accurate, detailed responses."
         },
         {
           "role": "user", 
           "content": "Context: {{$json.context}}\n\nQuestion: {{$json.question}}"
         }
       ],
       "tools": [
         {
           "function": {
             "name": "search_document",
             "description": "Search for additional information in the document",
             "parameters": {
               "type": "object",
               "properties": {
                 "query": {"type": "string"},
                 "page_filter": {"type": "array"}
               }
             }
           }
         }
       ]
     }
   }
   \`\`\`

</WorkshopExercise>

## 🧩 Extensions & Improvements

Once your basic RAG agent works, try these enhancements:

### Memory & Context
- **Conversation History** - Remember previous questions in the session
- **Document Memory** - Learn from user interactions to improve responses
- **Multi-turn Dialogue** - Handle follow-up questions naturally

### Advanced Features  
- **Source Highlighting** - Show exact text/image sections referenced
- **Confidence Scoring** - Indicate how certain the AI is about answers
- **Multilingual Support** - Process documents in different languages
- **Batch Queries** - Handle multiple questions efficiently

### Production Enhancements
- **Error Recovery** - Graceful handling of processing failures
- **Progress Tracking** - Show upload and processing status
- **Rate Limiting** - Manage concurrent document processing
- **Caching** - Store frequently accessed embeddings

## 🔧 Troubleshooting

### Common Issues & Solutions

| Problem | Symptoms | Solution |
|---------|----------|----------|
| **PDF Upload Fails** | Webhook times out | Check file size limits, try smaller PDF |
| **Embedding Errors** | 429/500 from Voyage API | Verify API gateway status, check rate limits |
| **Vector Search Empty** | No results returned | Confirm index exists, check embedding dimensions |
| **Gemini Timeouts** | Response generation fails | Reduce context length, simplify query |

### Debug Workflow
1. **Check Service Status** - Use the live status badges
2. **Inspect Node Outputs** - Click nodes to see data flow
3. **Test Components** - Isolate each step individually  
4. **Monitor Logs** - Check n8n execution logs for errors

## 📋 Testing Checklist

Before moving to the next exercise, verify:

- [ ] **File Upload** - Can successfully upload various PDF types
- [ ] **Text Extraction** - Extracts readable text from PDF pages
- [ ] **Image Processing** - Converts PDF pages to images properly
- [ ] **Embedding Generation** - Creates 1024-dimensional vectors
- [ ] **Vector Storage** - Documents appear in MongoDB collection
- [ ] **Search Functionality** - Finds relevant content for queries
- [ ] **Answer Quality** - Responses are accurate and well-sourced
- [ ] **Error Handling** - Gracefully handles invalid inputs

## 🎯 Key Takeaways

This exercise demonstrates:

1. **RAG Architecture** - How retrieval enhances generation quality
2. **Multimodal Processing** - Unified handling of text and images  
3. **Vector Databases** - Efficient similarity search at scale
4. **Agent Orchestration** - Complex workflows made visual and manageable

## 📚 Next Steps

Ready for more advanced patterns?

- [**Exercise: Memory & Context Patterns →**](./exercise-memory-context)
- [**Exercise: Advanced Tool Calling →**](./exercise-advanced-tools)
- **Production Deployment** - Coming soon!

You've built a sophisticated AI agent that can understand and answer questions about any PDF document. This foundation scales to handle enterprise document processing, research assistance, and knowledge management systems! 🚀
```

# docs/index.mdx

```mdx
---
sidebar_position: 1
slug: /
title: Workshop Overview
---

# 🎓 Multimodal PDF Agent Workshop

Welcome to the **Build a Multimodal PDF Agent with n8n** workshop! This interactive, hands-on experience will guide you through creating a production-ready AI system that processes PDFs using cutting-edge technologies.

<WorkshopTransition 
  slideTopics={[
    "Workshop overview and learning objectives",
    "Multimodal AI and embedding concepts", 
    "Architecture: n8n, MongoDB Atlas, Voyage AI",
    "What we'll build together today"
  ]}
  instructor="Michael Lynn"
/>

<InstructorNotes 
  timing="Transition from slides to hands-on content (2-3 minutes)"
  notes={[
    "Ensure all attendees can access this documentation URL",
    "Remind them to bookmark this page for future reference",
    "Check that Codespaces users have services running",
    "Ask if anyone needs help with local Docker setup"
  ]}
  tips={[
    "Use screen sharing to show the navigation",
    "Encourage questions before diving into technical content",
    "Mention they can return to this overview page anytime"
  ]}
/>

<ProgressTracker steps={[
  {
    title: "Environment Setup",
    description: "Set up Docker, n8n, and MongoDB Atlas",
    timeEstimate: "15 minutes",
    difficulty: "beginner"
  },
  {
    title: "PDF Processing Workflow", 
    description: "Build workflow to extract and process PDF content",
    timeEstimate: "25 minutes",
    difficulty: "intermediate"
  },
  {
    title: "Vector Search Implementation",
    description: "Configure MongoDB Atlas Vector Search",
    timeEstimate: "20 minutes", 
    difficulty: "intermediate"
  },
  {
    title: "AI Agent Creation",
    description: "Build intelligent agent with tool calling",
    timeEstimate: "30 minutes",
    difficulty: "advanced"
  },
  {
    title: "Memory & Context",
    description: "Add conversation history and context management",
    timeEstimate: "20 minutes",
    difficulty: "advanced"
  },
  {
    title: "Production Deployment",
    description: "Deploy and scale your multimodal agent",
    timeEstimate: "15 minutes",
    difficulty: "intermediate"
  }
]} />

## 🚀 Workshop Sections

### [🚀 Getting Started](/docs/intro)
Begin your journey with environment setup and n8n basics. Choose between GitHub Codespaces for instant setup or local Docker development.

### [⚙️ Setup & Configuration](/docs/mongodb-atlas-setup)
Configure MongoDB Atlas for vector search and set up Voyage AI for multimodal embeddings. These are the foundational services for your agent.

### [🔧 Building Workflows](/docs/pdf-processing-workflow)
Create powerful automation workflows step by step. Start with PDF processing, implement vector search, and build an AI agent with tool calling.

### [🎯 Advanced Topics](/docs/complete-multimodal-agent)
Take your agent to production with advanced features like memory management, web interfaces, and production-grade vector search.

### [📚 Resources & Support](/docs/local-setup-tips)
Find Docker best practices, troubleshooting guides, and community resources to help you succeed.

## 🎯 What You'll Build

By the end of this workshop, you'll have created:

- **PDF Ingestion Pipeline**: Automated processing of documents
- **Multimodal Embeddings**: Text and image understanding with Voyage AI
- **Vector Search API**: Fast similarity search with MongoDB Atlas
- **AI Agent**: Intelligent question answering with Gemini 2.0
- **Production Workflows**: Error handling, monitoring, and scaling

## 🛠️ Technologies Used

<div style={{display: 'flex', gap: '2rem', flexWrap: 'wrap', marginTop: '2rem'}}>
  <div style={{textAlign: 'center'}}>
    <img src="/img/n8n-logo.png" alt="n8n" width="80" />
    <p><strong>n8n</strong><br/>Visual Workflow Automation</p>
  </div>
  <div style={{textAlign: 'center'}}>
    <img src="/img/mongodb-logo.png" alt="MongoDB" width="80" />
    <p><strong>MongoDB Atlas</strong><br/>Vector Database</p>
  </div>
  <div style={{textAlign: 'center'}}>
    <img src="/img/voyage-logo.png" alt="Voyage AI" width="80" />
    <p><strong>Voyage AI</strong><br/>Multimodal Embeddings</p>
  </div>
  <div style={{textAlign: 'center'}}>
    <img src="/img/gemini-logo.png" alt="Gemini" width="80" />
    <p><strong>Gemini 2.0</strong><br/>AI Agent Capabilities</p>
  </div>
</div>

## 🏁 Ready to Start?

<WorkshopExercise 
  title="Pre-Workshop Checklist" 
  difficulty="beginner"
  timeEstimate="5 minutes"
  objectives={[
    "Verify you have all prerequisites",
    "Choose your development environment",
    "Get excited about building!"
  ]}
>

<ExerciseValidation 
  title="Before You Begin"
  checks={[
    {
      id: "github_account",
      description: "I have a GitHub account (for Codespaces) or Docker Desktop installed",
      hint: "GitHub account is free at github.com, Docker Desktop from docker.com"
    },
    {
      id: "mongodb_ready",
      description: "I'm ready to create a MongoDB Atlas account (free tier)",
      hint: "You'll need an email address for signup"
    },
    {
      id: "time_allocated",
      description: "I have ~2 hours for the complete workshop",
      hint: "You can also complete it in sections"
    },
    {
      id: "excitement_level",
      description: "I'm excited to build a multimodal AI agent! 🚀",
      hint: "This is the most important prerequisite!"
    }
  ]}
/>

</WorkshopExercise>

[**Start the Workshop →**](docs/intro)

---

## 📱 Workshop Access & Sharing

<QRCodeAccess 
  url={typeof window !== 'undefined' ? window.location.origin + '/docs/' : 'https://your-workshop-docs.vercel.app/docs/'}
  title="Share Workshop Materials"
/>

<InstructorNotes 
  timing="End of overview (1 minute)"
  notes={[
    "Show attendees how to bookmark this page",
    "Mention they can scan QR code for mobile access",
    "Remind them this documentation stays available after workshop"
  ]}
  tips={[
    "Consider sharing the URL in chat for easy copy/paste",
    "Encourage attendees to take notes directly in their own docs",
    "Mention the progress tracking will persist in their browser"
  ]}
/>
```

# docs/status-badge-usage-guide.mdx

```mdx
---
sidebar_position: 100
---

# 📊 Status Badge Usage Guide

This guide shows instructors and content creators how to use the specialized `LiveStatusBadge` components throughout the workshop to provide progressive validation and real-time feedback.

## 🎯 Overview

The LiveStatusBadge system includes several specialized components for different workshop stages:

| Component | When to Use | Purpose |
|-----------|-------------|---------|
| `CodespaceStatusBadge` | After Codespace launch | Validate development environment |
| `DockerServicesStatusBadge` | After `npm run dev` | Check all Docker services |
| `MongoDBAtlasStatusBadge` | During Atlas setup | Test cloud database connection |
| `VoyageAIStatusBadge` | Before building workflows | Validate AI service integration |
| `WorkflowTestBadge` | After workflow creation | Test complete PDF pipeline |

## 📋 Workshop Flow Integration

### Stage 1: Environment Setup

**In your GitHub Codespaces documentation:**

\`\`\`mdx
# 🚀 Launch Your Codespace

Follow these steps to get your development environment ready:

1. Click the "Open in GitHub Codespaces" button
2. Wait for the environment to initialize
3. Verify your setup with the status check below:

<CodespaceStatusBadge showDetails={true} />

Once all systems show green, you're ready for the next step!
\`\`\`

### Stage 2: Docker Services Startup

**In your service startup documentation:**

\`\`\`mdx
# 🐳 Start Workshop Services

Run the following command to start all required services:

\`\`\`bash
npm run dev
\`\`\`

This starts n8n, MongoDB, and other workshop services. Monitor their status:

<DockerServicesStatusBadge showDetails={true} />

**Troubleshooting:** If any service shows red, check the troubleshooting section below.
\`\`\`

### Stage 3: MongoDB Atlas Configuration

**In your Atlas setup documentation:**

\`\`\`mdx
# ☁️ Configure MongoDB Atlas

Set up your cloud database for production-ready vector search:

<MongoDBAtlasStatusBadge showDetails={true} />

The status badge will guide you through:
1. Connection string configuration
2. Vector search index validation  
3. Database permissions verification
\`\`\`

### Stage 4: AI Service Testing

**In your Voyage AI setup documentation:**

\`\`\`mdx
# 🧠 Test Voyage AI Integration

Before building workflows, verify your embedding capabilities:

<VoyageAIStatusBadge showDetails={true} />

Click "Run Embedding Test" to validate:
- Text embedding generation
- Multimodal (text + image) processing
- Vector dimensions and format
\`\`\`

### Stage 5: End-to-End Workflow Testing

**In your workflow testing documentation:**

\`\`\`mdx
# 🔄 Test Your Complete Workflow

Validate your entire PDF processing pipeline:

<WorkflowTestBadge showDetails={true} />

This tests the complete flow:
1. PDF upload via webhook
2. Text extraction and processing
3. Embedding generation with Voyage AI
4. Storage in MongoDB Atlas
\`\`\`

## 🛠️ Advanced Usage

### Custom Configuration

Each component accepts configuration props:

\`\`\`mdx
<!-- Faster refresh for critical setup steps -->
<DockerServicesStatusBadge 
  showDetails={true} 
  refreshInterval={5000} 
/>

<!-- Custom test document for workflow testing -->
<WorkflowTestBadge 
  testDocument="https://example.com/your-test.pdf"
  workflowEndpoint="https://your-codespace-5678.app.github.dev/webhook/custom"
/>

<!-- Pre-configured Atlas connection -->
<MongoDBAtlasStatusBadge 
  connectionString="mongodb+srv://..." 
/>
\`\`\`

### Conditional Display

Show components based on user progress:

\`\`\`mdx
import { useState } from 'react';

export function ProgressiveSetup() {
  const [step, setStep] = useState(1);
  
  return (
    <div>
      {step === 1 && <CodespaceStatusBadge />}
      {step === 2 && <DockerServicesStatusBadge />}
      {step === 3 && <MongoDBAtlasStatusBadge />}
      
      <button onClick={() => setStep(step + 1)}>
        Next Step
      </button>
    </div>
  );
}
\`\`\`

## 🎨 Styling and UX

### Component Features

All status badge components include:

- ✅ **Real-time monitoring** - Automatic status updates
- 🔧 **Configuration panels** - User-friendly setup forms  
- 📊 **Test execution** - Interactive validation buttons
- 🛠️ **Troubleshooting** - Contextual help and commands
- 📱 **Responsive design** - Works on all screen sizes
- 🌙 **Dark mode support** - Automatic theme adaptation

### Visual Indicators

| Status | Indicator | Meaning |
|--------|-----------|---------|
| 🟢 Online | Green dot | System healthy and responding |
| 🟡 Degraded | Yellow dot | System accessible but slow |
| 🔴 Error | Red dot | System unreachable or failing |
| ⚪ Loading | Gray dot | Checking system status |

## 📚 Best Practices

### 1. Progressive Disclosure
Start with simple checks and gradually introduce complexity:

\`\`\`mdx
<!-- Start simple -->
<CodespaceStatusBadge />

<!-- Add complexity as workshop progresses -->
<VoyageAIStatusBadge />

<!-- End with comprehensive testing -->
<WorkflowTestBadge />
\`\`\`

### 2. Clear Success Criteria
Always explain what success looks like:

\`\`\`mdx
<DockerServicesStatusBadge />

**Success Criteria:** All services showing "Online" means you're ready for the next step!
\`\`\`

### 3. Contextual Help
Provide troubleshooting guidance:

\`\`\`mdx
<MongoDBAtlasStatusBadge />

**Common Issues:**
- Connection string format
- Network access settings
- Database user permissions
\`\`\`

### 4. Instructor Notes
Include guidance for workshop facilitators:

\`\`\`mdx
<InstructorNotes 
  notes={[
    "Have attendees wait for all green indicators before proceeding",
    "Common issue: Codespace port forwarding takes 30-60 seconds",
    "If many attendees show red, check workshop gateway status"
  ]}
/>

<CodespaceStatusBadge />
\`\`\`

## 🚀 Implementation Examples

### Example 1: Setup Checklist Page

\`\`\`mdx
# 📋 Workshop Setup Checklist

Complete each step and verify with the status indicators:

## Step 1: Launch Environment
<CodespaceStatusBadge />

## Step 2: Start Services  
<DockerServicesStatusBadge />

## Step 3: Configure Database
<MongoDBAtlasStatusBadge />

## Step 4: Test AI Services
<VoyageAIStatusBadge />

## Step 5: Validate Complete Workflow
<WorkflowTestBadge />
\`\`\`

### Example 2: Debugging Page

\`\`\`mdx
# 🔧 Troubleshooting Workshop Issues

Use these diagnostic tools to identify and resolve problems:

## Check Your Environment
<CodespaceStatusBadge showDetails={true} />

## Verify Service Health
<DockerServicesStatusBadge showDetails={true} />

## Test External Connections
<MongoDBAtlasStatusBadge showDetails={true} />
<VoyageAIStatusBadge showDetails={true} />
\`\`\`

## 🎯 Key Benefits

Using these specialized status badges throughout your workshop provides:

1. **Immediate Feedback** - Attendees know exactly when each step is working
2. **Reduced Support Load** - Self-service diagnostics reduce instructor interruptions  
3. **Progressive Validation** - Each step builds confidence for the next
4. **Real-world Skills** - Teaches monitoring and troubleshooting practices
5. **Workshop Flow** - Keeps all attendees synchronized and progressing together

The status badge system transforms a potentially frustrating setup process into a guided, validated learning experience! 🎉
```

# docs/summary.mdx

```mdx
---
sidebar_position: 100
---

# 🎯 Workshop Summary

Congratulations! Following this tutorial, you have successfully:

✅ **Built a complete multimodal PDF processing system**  
✅ **Implemented vector search with MongoDB Atlas**  
✅ **Created an AI agent with tool calling**  
✅ **Configured n8n workflows for production**  
✅ **Integrated Voyage AI for multimodal embeddings**  

## 🏆 Key Takeaways

### 1. Visual Workflows Beat Code
n8n's visual interface makes complex AI integrations intuitive and maintainable. You can see data flow in real-time and debug issues easily.

### 2. Multimodal Embeddings Unlock Powerful Search  
Voyage AI's unified vector space allows semantic search across both text and images, opening new possibilities for document understanding.

### 3. Vector Databases Are Essential for AI Applications
MongoDB Atlas Vector Search provides the foundation for RAG applications with enterprise-grade performance and scalability.

### 4. Agent Patterns Create Intelligent Systems
Function calling and tool integration enable AI agents to reason about when and how to retrieve information.

## 🚀 What You've Built

Your complete system includes:

- **PDF Ingestion Pipeline**: Automated processing of documents
- **Multimodal Embeddings**: Text and image understanding
- **Vector Search API**: Fast similarity search
- **AI Agent**: Intelligent question answering
- **Production Workflows**: Error handling and monitoring

## 🔧 Next Steps

### 1. Extend the System

**Add More Document Types**:
- PowerPoint presentations
- Word documents  
- Web pages
- Audio transcripts

**Implement Additional Tools**:
\`\`\`javascript
{
  name: "analyze_sentiment",
  description: "Analyze sentiment of document content"
},
{
  name: "extract_entities", 
  description: "Extract named entities from text"
},
{
  name: "generate_summary",
  description: "Create document summaries"
}
\`\`\`

**Create a Web Interface**:
- React frontend for file uploads
- Real-time chat interface  
- Document preview with highlights
- Search result visualization

### 2. Production Deployment

**Set Up Monitoring**:
- Track processing times
- Monitor API usage
- Alert on failures
- Performance dashboards

**Implement Caching**:
- Redis for query results
- CDN for static assets
- Embedding cache for documents

**Add Authentication**:
- User management
- API key rotation
- Role-based access control

### 3. Advanced Features

**Multi-Language Support**:
\`\`\`javascript
// Detect document language
const language = await detectLanguage(content);

// Route to language-specific processing
if (language === 'es') {
  // Use Spanish embedding model
}
\`\`\`

**Document Clustering**:
\`\`\`javascript
// Group similar documents
const clusters = await clusterDocuments(embeddings);

// Enable browse by topic
\`\`\`

**Automatic Summarization**:
\`\`\`javascript
// Generate document summaries
const summary = await generateSummary(content);

// Store for quick access
\`\`\`

## 📚 Resources for Continued Learning

<WorkshopResources />

## 🌟 Share Your Success

We'd love to see what you've built! Share your projects:

- **GitHub**: Fork and extend the workshop code
- **LinkedIn**: Tag @MongoDB and show your workflows  
- **Twitter**: Use #n8n #MongoDB #VoyageAI
- **Discord**: Join the MongoDB Developer Community

## 💬 Get Help

If you need assistance:

1. **MongoDB Developer Community** - Active forums and Discord
2. **n8n Community** - Workflow help and best practices  
3. **Stack Overflow** - Technical questions with tags
4. **GitHub Issues** - Report bugs or request features

## 🎉 Thank You!

Thank you for participating in this hands-on workshop! You've learned cutting-edge techniques for building multimodal AI systems with visual workflows.

The combination of n8n's visual approach, MongoDB's vector search capabilities, and Voyage AI's multimodal embeddings creates powerful possibilities for document intelligence applications.

Keep building, keep learning, and keep innovating! 🚀

---

**Workshop Repository**: [GitHub - Multimodal PDF Agent with n8n](https://github.com/mongodb-developer/multimodal-pdf-agent-n8n)

**Feedback**: We value your input! Please share your workshop experience and suggestions for improvement.

<WorkshopFeedback 
  workshopTitle="Multimodal PDF Agent with n8n Workshop"
  instructorEmail="michael.lynn@mongodb.com"
  githubRepo="mongodb-developer/multimodal-pdf-agent-n8n"
/>
```

# DOCUMENTATION-UPDATE-PROMPT.md

```md
# Documentation Update Prompt for Claude

## Context
This is a multimodal PDF agent workshop that has been split into two repositories:
1. **Deployment repo** (this one): Contains n8n, MongoDB, and Docker deployment configurations
2. **Documentation repo**: Contains Docusaurus-based workshop materials and guides

## Task
Update the documentation repository to reference the deployment repo correctly and ensure all links, instructions, and references are aligned with the new split architecture.

## Changes Needed

### 1. Update Repository References
- Change all references from single repo to deployment + documentation split
- Update GitHub URLs to point to correct repositories
- Update clone instructions to reference deployment repo for Docker setup

### 2. Fix Setup Instructions
- Update GitHub Codespaces instructions to point to deployment repo
- Modify local setup instructions to reference deployment repo for Docker compose
- Ensure Docker setup steps reference the deployment repo structure

### 3. Update Navigation and Links
- Fix internal links that may have broken due to file structure changes
- Update references to Docker files, compose files, and devcontainer configs
- Ensure workshop flow guides users to correct repo for each step

### 4. Architecture Documentation
- Update architecture diagrams to show the split between deployment and documentation
- Clarify which repository contains which components
- Update file structure references in documentation

### 5. Prerequisites and Setup
- Update the prerequisites section to reference deployment repo for Docker setup
- Ensure MongoDB Atlas setup instructions are complete and accurate
- Update API key configuration instructions

### 6. Workshop Flow Updates
- Ensure workshop steps correctly reference deployment repo for:
  - Docker compose operations
  - n8n access and configuration  
  - MongoDB connection details
  - File uploads and processing directories
- Keep documentation repo references for:
  - Reading workshop content
  - Following tutorial steps
  - Accessing examples and explanations

### 7. Troubleshooting Updates
- Update troubleshooting guides to reference deployment repo structure
- Fix Docker-related troubleshooting to point to correct docker-compose.yml location
- Update service management commands

### 8. GitHub Codespaces Integration
- Ensure Codespaces badge and links point to deployment repo
- Update devcontainer references and explanations
- Verify port forwarding documentation matches deployment repo configuration

## Key URLs to Update
- GitHub repository URLs
- Codespaces launch URLs  
- Docker compose file references
- Environment file references
- Service endpoint documentation

## Deployment Repo Structure Reference
\`\`\`
deployment-repo/
├── .devcontainer/              # Devcontainer configurations
├── docker-compose.yml          # Main service definitions
├── Dockerfile.n8n             # Custom n8n image
├── .env (auto-generated)       # Environment configuration
├── init/
│   ├── workflows/              # Sample n8n workflows
│   ├── sample-data/            # Test data
│   └── mongodb/               # DB initialization
├── files/                     # File processing directory
├── scripts/                   # Testing and management scripts
└── workshop-embedding-api/    # Serverless embedding endpoint
\`\`\`

## Services Configuration
- **n8n**: Port 5678 (primary interface, should auto-open in Codespaces)
- **MongoDB**: Port 27017 (internal database)
- **Mongo Express**: Port 8081 (database admin interface)
- **Documentation**: No longer served from deployment repo

## Environment Variables (from deployment repo)
\`\`\`bash
N8N_ENCRYPTION_KEY=workshop-encryption-key-change-in-production
GENERIC_TIMEZONE=America/New_York
WORKSHOP_EMBEDDING_URL=https://workshop-embedding-api.vercel.app/api/embed
WORKSHOP_MODE=true
\`\`\`

## Instructions for Claude
1. Review all documentation files for references to the old single-repo structure
2. Update setup instructions to use deployment repo for Docker operations
3. Ensure workshop flow correctly separates documentation reading from deployment operations
4. Test that all links and references are valid and point to correct locations
5. Maintain the educational flow while fixing technical references
6. Preserve all workshop content and examples - only update structural references

Focus on accuracy and maintaining the workshop's educational value while ensuring participants can successfully complete the setup using the new repository structure.
```

# docusaurus.config.js

```js
// @ts-check
// Note: type annotations allow type checking and IDEs autocompletion

// Change here to customise config

// Name of the Github Repo, it's also teh baseUrl
const workshopName = 'multimodal-pdf-agent-n8n';
// Change this if hosting outside mongodb-developer
const organizationName = "mongodb-developer";

// Main page config
const title = "Build a Multimodal PDF Agent with n8n";
const tagLine = "Process, encode, and search PDFs using MongoDB Vector Search, Voyage AI, and n8n automation";
const startButtonTitle = "Start Building";
const favicon = "img/favicon.svg"

// Main Page Features
const featureList = [
  {
    title: 'Visual Workflow Building',
    illustration: 'img/n8n-workflow.png',
    description: `
        Build complex AI agents using n8n's visual interface - no coding required!
    `,
  },
  {
    title: 'Multimodal Processing',
    illustration: 'img/multimodal.png',
    description: `
        Process both text and images from PDFs using Voyage AI's multimodal embeddings.
    `,
  },
  {
    title: 'Production-Ready',
    illustration: 'img/mongodb-atlas.png',
    description: `
        Deploy scalable vector search with MongoDB Atlas and n8n's robust automation.
    `,
  },
];

// UTM stuff

const utmAdvocateName = `michael.lynn`;
const utmWorkshopName = 'multimodal_pdf_agent_n8n'

const utmParams = `utm_campaign=devrel&utm_source=workshop&utm_medium=cta&utm_content=${utmWorkshopName}&utm_term=${utmAdvocateName}`;

// Footer links (probably no need to change them)

const footerLinks = [
  {
    label: "Try MongoDB Atlas",
    href: `https://www.mongodb.com/try?${utmParams}`,
  },
  {
    label: "Forums",
    href: `https://www.mongodb.com/community/forums?${utmParams}`,
  },
  {
    label: "Developer Center",
    href: `https://www.mongodb.com/developer?${utmParams}`,
  },
  {
    label: "MongoDB University",
    href: `https://learn.mongodb.com?${utmParams}`,
  },
  {
    href: `https://github.com/${organizationName}/${workshopName}`,
    label: "Workshop GitHub (Deployment)",
  },
];

///////////////////////////////////////////////////////////////////////////////
// DON'T CHANGE ANYTHING BELOW UNLESS YOU KNOW WHAT YOU'RE DOING             //
///////////////////////////////////////////////////////////////////////////////

const { themes } = require("prism-react-renderer");
const lightCodeTheme = themes.github;
const darkCodeTheme = themes.dracula;

/** @type {import('@docusaurus/types').Config} */
const config = {
  title: `${title}`,
  tagline: `${tagLine}`,
  url: process.env.CODESPACES ? `https://${process.env.CODESPACE_NAME}-3000.${process.env.GITHUB_CODESPACES_PORT_FORWARDING_DOMAIN}` : process.env.VERCEL_URL ? `https://${process.env.VERCEL_URL}` : `https://${workshopName}.github.io`,
  baseUrl: process.env.CODESPACES || process.env.VERCEL_URL ? `/` : `/${workshopName}/`,
  projectName: `${organizationName}.github.io`,
  organizationName: `${organizationName}`,
  trailingSlash: false,
  onBrokenLinks: "throw",
  onBrokenMarkdownLinks: "warn",
  favicon: `${favicon}`,
  deploymentBranch: "gh-pages",
  staticDirectories: ["static"],
  i18n: {
    defaultLocale: "en",
    locales: ["en", "es"],
  },
  customFields: {
    startButtonTitle: `${startButtonTitle}`,
    featureList: featureList,
    utmParams,
  },
  presets: [
    [
      "classic",
      /** @type {import('@docusaurus/preset-classic').Options} */
      ({
        docs: {
          sidebarPath: require.resolve("./sidebars.js"),
          editUrl: `https://github.com/${organizationName}/${workshopName}/blob/main`,
        },
        theme: {
          customCss: require.resolve("./src/css/custom.css"),
        },
        gtag: {
          trackingID: "G-ZJ28V71VTQ",
          anonymizeIP: true,
        },
      }),
    ],
  ],
  plugins: [
    [
      require.resolve("docusaurus-lunr-search"),
      {
        languages: ["es", "en"], // language codes
      },
    ],
  ],
  themeConfig:
    /** @type {import('@docusaurus/preset-classic').ThemeConfig} */
    ({
      docs: {
        sidebar: {
          autoCollapseCategories: true,
          hideable: true,
        },
      },
      announcementBar: {
        id: "feedback_form",
        content:
          'This is a demonstration that we can put a pop-up message here! Even <a target="_blank" rel="noopener noreferrer" href="#">links</a>',
        backgroundColor: "#fafbfc",
        textColor: "#091E42",
        isCloseable: true,
      },
      navbar: {
        title: `${title}`,
        logo: {
          alt: "MongoDB Logo",
          src: "img/logo.svg",
          srcDark: "img/logo-dark.svg",
          className: "navbar-logo",
          width: "135px",
          height: "100%",
        },
        items: [
          {
            type: "localeDropdown",
            position: "right",
          },
        ],
      },
      footer: {
        style: "dark",
        links: footerLinks,
        copyright: `© ${new Date().getFullYear()} MongoDB, Inc.`
      },
      prism: {
        theme: lightCodeTheme,
        darkTheme: darkCodeTheme,
        additionalLanguages: ["powershell", "swift", "kotlin"],
      },
      mermaid: {
        theme: { light: "neutral", dark: "forest" },
      },
    }),
  future: {
    v4: {
      removeLegacyPostBuildHeadAttribute: true,
      useCssCascadeLayers: true,
    },
    // Enable faster build options for Vercel deployment
    experimental_faster: {
      swcJsLoader: true,
      swcJsMinimizer: true,
      swcHtmlMinimizer: true,
      lightningCssMinimizer: true,
    },
    experimental_storage: {
      type: "localStorage",
      namespace: true,
    },
  },
  markdown: {
    mermaid: true,
  },
  themes: ["@docusaurus/theme-mermaid"],
};

module.exports = config;

```

# INSTRUCTOR-GUIDE.md

```md
# 🎓 Instructor Guide: Slides + Docusaurus Workshop Delivery

This guide helps you deliver a seamless workshop experience using Google Slides for introduction and Docusaurus for hands-on content.

## 🎯 Workshop Flow Overview

### Phase 1: Introduction (Google Slides) - 15-20 minutes
- Welcome and introductions
- Workshop overview and objectives
- Technology stack introduction (n8n, MongoDB Atlas, Voyage AI)
- Architecture diagrams and concepts
- Logistics (timing, breaks, Q&A)

### Phase 2: Hands-On Learning (Docusaurus) - 90-100 minutes
- Step-by-step technical implementation
- Interactive exercises and validation
- Real-time API testing
- Progress tracking and completion

## 📊 Google Slides Optimization

### Essential Slides to Include

1. **Welcome & Workshop URL Slide**
   \`\`\`
   🎓 Multimodal PDF Agent Workshop
   
   📖 Hands-On Materials:
   [YOUR-DOCUSAURUS-URL]
   
   [QR CODE]
   
   👆 Bookmark this page now!
   \`\`\`

2. **Transition Slide**
   \`\`\`
   🚀 Let's Build Together!
   
   Time to switch from concepts to code
   
   ➡️ Open: [YOUR-DOCUSAURUS-URL]
   ➡️ Navigate to: Getting Started
   
   (Keep this tab open - we'll reference both)
   \`\`\`

3. **Architecture Summary Slide**
   \`\`\`
   🏗️ What You'll Build Today
   
   PDF → n8n Workflow → Voyage AI → MongoDB Atlas → AI Agent
   
   📋 This matches the step-by-step guide in your docs
   \`\`\`

### Best Practices

- **Add QR Codes**: Use [qr-code-generator.com](https://www.qr-code-generator.com/) 
- **Keep URLs Visible**: Add documentation URL to footer of every slide
- **Use Consistent Branding**: Match colors/fonts with Docusaurus theme
- **Include Bookmarking Reminders**: Multiple slides encouraging attendees to bookmark

## 🔄 Smooth Transition Techniques

### 1. The Bridge Statement
*"Great! Now that we understand the concepts, let's build this system together. Please open your bookmarked documentation page..."*

### 2. Screen Sharing Strategy
- **Dual monitors**: Slides on one, Docusaurus on the other
- **Single screen**: Use browser tabs, switch frequently
- **Virtual workshops**: Share documentation screen after slides

### 3. Interactive Check-In
*"Before we dive in, can everyone confirm they can see the workshop documentation? The page should show a progress tracker and welcome message..."*

## 📱 Attendee Access Options

### Option 1: Desktop/Laptop
- Send documentation URL in chat
- Encourage bookmarking
- Show how to navigate sidebar

### Option 2: Mobile + Desktop
- QR code for mobile access to docs
- Desktop for actual development work
- Mobile as reference during coding

### Option 3: Codespaces Users
- Emphasize opening docs in separate tab
- Port forwarding URLs are different
- Documentation stays consistent

## ⏰ Timing Recommendations

### Introduction Phase (Google Slides)
- **Welcome** (3 min): Introductions, logistics
- **Overview** (5 min): Workshop goals, what they'll build
- **Architecture** (5 min): Technical concepts, stack overview
- **Transition** (2 min): Move to hands-on, URL sharing

### Hands-On Phase (Docusaurus)
- **Environment Setup** (15 min): Docker/Codespaces verification
- **MongoDB Atlas** (15 min): Account setup, connection
- **PDF Processing** (25 min): First workflow creation
- **Vector Search** (20 min): Atlas Vector Search setup
- **AI Agent** (30 min): Complete agent with tool calling

## 🛠️ Technical Setup Tips

### Before Workshop
- [ ] Test all documentation links
- [ ] Verify embedding API is responding
- [ ] Have backup n8n instance ready
- [ ] Prepare sample PDFs for testing
- [ ] Check MongoDB Atlas free tier limits

### During Workshop
- [ ] Share documentation URL early and often
- [ ] Monitor chat for setup issues
- [ ] Use instructor notes in Docusaurus (click 👨‍🏫 buttons)
- [ ] Encourage peer-to-peer help
- [ ] Keep backup slides for common troubleshooting

## 🎨 Visual Consistency

### Google Slides Theme
Use colors that complement Docusaurus:
- **Primary**: #667eea (purple-blue gradient)
- **Secondary**: #10b981 (green for success states)
- **Background**: White or light gray
- **Text**: Dark gray (#374151)

### Font Recommendations
- **Headers**: Inter, Segoe UI, or system default
- **Body**: Same as headers for consistency
- **Code**: JetBrains Mono, Fira Code, or monospace

## 📞 Troubleshooting During Workshop

### Common Issues & Quick Fixes

1. **"Can't access documentation"**
   - Share URL in chat again
   - Check for typos in URL
   - Try incognito/private browsing

2. **"n8n not loading"**
   - Check Docker status
   - Verify port 5678 isn't blocked
   - Try different browser

3. **"MongoDB Atlas signup failing"**
   - Use different email address
   - Check spam folder for verification
   - Try incognito mode

4. **"Embedding API not working"**
   - Use built-in tester in docs
   - Check network connectivity
   - Fallback to mock data option

## 🚀 Advanced Tips

### For Virtual Workshops
- Use breakout rooms for troubleshooting
- Screen share documentation frequently
- Record session for later reference
- Use polls to check progress

### For In-Person Workshops
- Print QR codes on handouts
- Use projector for slides + laptop for docs
- Walk around to help with individual issues
- Consider printed backup of key concepts

### For Mixed Audiences
- Acknowledge different skill levels early
- Pair experienced with beginners
- Provide "extra credit" challenges
- Use instructor notes for differentiation

---

## 📋 Pre-Workshop Checklist

**24 Hours Before:**
- [ ] Update documentation with current workshop date/instructor
- [ ] Test all interactive components
- [ ] Verify embedding API availability
- [ ] Prepare Google Slides with correct URLs

**1 Hour Before:**
- [ ] Load both slides and documentation
- [ ] Test screen sharing setup
- [ ] Join workshop platform early
- [ ] Have backup plans ready

**During Workshop:**
- [ ] Share URLs immediately
- [ ] Monitor chat for questions
- [ ] Use timing guides in instructor notes
- [ ] Keep energy high during transitions

This setup gives you the best of both worlds: powerful presentation tools for concepts and interactive documentation for hands-on learning! 🎉
```

# package.json

```json
{
  "name": "docusaurus-template-lab",
  "version": "2.3.0",
  "private": true,
  "scripts": {
    "docusaurus": "docusaurus",
    "start": "docusaurus start --host 0.0.0.0",
    "build": "docusaurus build",
    "swizzle": "docusaurus swizzle",
    "deploy": "docusaurus deploy",
    "clear": "docusaurus clear",
    "serve": "docusaurus serve --host 0.0.0.0",
    "write-translations": "docusaurus write-translations",
    "write-heading-ids": "docusaurus write-heading-ids",
    "workshop:setup": "bash .devcontainer/setup.sh",
    "workshop:start": "docker-compose up -d && npm start",
    "workshop:stop": "docker-compose down",
    "workshop:restart": "docker-compose restart",
    "workshop:logs": "docker-compose logs -f",
    "workshop:reset": "docker-compose down -v",
    "dev": "concurrently \"npm start\" \"docker-compose up -d\"",
    "test:services": "bash scripts/test-services.sh"
  },
  "dependencies": {
    "@docusaurus/core": "3.8.1",
    "@docusaurus/faster": "3.8.1",
    "@docusaurus/module-type-aliases": "3.8.1",
    "@docusaurus/plugin-google-analytics": "3.8.1",
    "@docusaurus/plugin-google-gtag": "3.8.1",
    "@docusaurus/preset-classic": "3.8.1",
    "@docusaurus/theme-mermaid": "3.8.1",
    "@mdx-js/react": "^3.0.1",
    "clsx": "^1.2.1",
    "docusaurus-lunr-search": "3.6.1",
    "prism-react-renderer": "^2.1.0",
    "react": "19.0.0",
    "react-dom": "19.0.0"
  },
  "browserslist": {
    "production": [
      ">0.5%",
      "not dead",
      "not op_mini all"
    ],
    "development": [
      "last 1 chrome version",
      "last 1 firefox version",
      "last 1 safari version"
    ]
  },
  "engines": {
    "node": ">=20.0"
  },
  "devDependencies": {
    "husky": "^9.1.7"
  }
}

```

# README.md

```md
# 📚 Workshop Documentation

This directory contains the Docusaurus documentation site for the Multimodal PDF Agent workshop.

## 🚀 Quick Deploy to Vercel

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2Fmongodb-developer%2Fmultimodal-pdf-agent-n8n-docs)

## 📖 Local Development

\`\`\`bash
npm install
npm start
\`\`\`

## 🏗️ Build & Deploy

\`\`\`bash
npm run build
npm run serve
\`\`\`

## 📝 Content Structure

- `docs/` - Workshop documentation pages
- `static/` - Images, assets, and upload interface
- `src/` - React components and custom pages
- `docusaurus.config.js` - Site configuration

## 🌐 Production URL

Once deployed: https://your-workshop-docs.vercel.app

This documentation is accessed by workshop participants while they work in their Codespaces with the actual n8n workflows from the [deployment repository](https://github.com/mongodb-developer/multimodal-pdf-agent-n8n).
```

# sidebars.js

```js
/**
 * Creating a sidebar enables you to:
 - create an ordered group of docs
 - render a sidebar for each doc of that group
 - provide next/previous navigation

 The sidebars can be generated from the filesystem, or explicitly defined here.

 Create as many sidebars as you want.
 */

// @ts-check

/** @type {import('@docusaurus/plugin-content-docs').SidebarsConfig} */
const sidebars = {
  // Workshop sidebar with organized sections
  tutorialSidebar: [
    {
      type: 'doc',
      id: 'index',
      label: '🎓 Workshop Overview'
    },
    {
      type: 'category',
      label: '🚀 Getting Started',
      collapsible: true,
      collapsed: false,
      className: 'sidebar-getting-started',
      description: 'Begin your journey with environment setup and n8n basics',
      items: [
        {
          type: 'doc',
          id: 'intro',
          label: 'Workshop Introduction'
        },
        {
          type: 'doc',
          id: 'architecture-overview',
          label: '🏗️ Architecture Overview'
        },
        {
          type: 'doc',
          id: 'github-codespaces',
          label: 'GitHub Codespaces Setup'
        },
        {
          type: 'doc',
          id: 'prerequisites',
          label: 'Prerequisites & Local Setup'
        },
        {
          type: 'doc',
          id: 'n8n-first-run',
          label: 'n8n First Run Experience'
        }
      ],
    },
    {
      type: 'category',
      label: '⚙️ Setup & Configuration',
      collapsible: true,
      collapsed: false,
      className: 'sidebar-setup',
      description: 'Configure MongoDB Atlas and Voyage AI for your agent',
      items: [
        {
          type: 'doc',
          id: 'api-architecture',
          label: '🌐 API Gateway Architecture'
        },
        {
          type: 'doc',
          id: 'mongodb-atlas-setup',
          label: 'MongoDB Atlas Setup'
        },
        {
          type: 'doc',
          id: 'voyage-ai-setup',
          label: 'Voyage AI Configuration'
        }
      ],
    },
    {
      type: 'category',
      label: '🔧 Building Workflows',
      collapsible: true,
      collapsed: false,
      className: 'sidebar-workflows',
      description: 'Create powerful automation workflows step by step',
      items: [
        {
          type: 'doc',
          id: 'pdf-processing-workflow',
          label: 'PDF Processing Workflow'
        },
        {
          type: 'doc',
          id: 'vector-search-workflow',
          label: 'Vector Search Implementation'
        },
        {
          type: 'doc',
          id: 'ai-agent-workflow',
          label: 'AI Agent with Tool Calling'
        }
      ],
    },
    {
      type: 'category',
      label: '🧪 Hands-On Exercises',
      collapsible: true,
      collapsed: false,
      className: 'sidebar-exercises',
      description: 'Structured exercises to build complete AI agents',
      items: [
        {
          type: 'doc',
          id: 'exercise-pdf-rag-agent',
          label: '🧪 Exercise: Build a PDF RAG Agent'
        },
        {
          type: 'doc',
          id: 'exercise-memory-context',
          label: '🧪 Exercise: Memory & Context'
        },
        {
          type: 'doc',
          id: 'exercise-advanced-tools',
          label: '🧪 Exercise: Advanced Tool Calling'
        }
      ],
    },
    {
      type: 'category',
      label: '🎯 Advanced Topics',
      collapsible: true,
      collapsed: true,
      className: 'sidebar-advanced',
      description: 'Take your agent to production with advanced features',
      items: [
        {
          type: 'doc',
          id: 'complete-multimodal-agent',
          label: 'Complete Multimodal Agent'
        },
        {
          type: 'doc',
          id: 'mongodb-vector-setup',
          label: 'Production Vector Search'
        },
        {
          type: 'doc',
          id: 'upload-interface',
          label: 'Web Upload Interface'
        },
        {
          type: 'doc',
          id: 'python-mongodb-approaches',
          label: '🐍 Python Integration Options'
        },
        {
          type: 'doc',
          id: 'approach-comparison',
          label: '⚖️ n8n vs Python Comparison'
        },
        {
          type: 'doc',
          id: 'agent-patterns',
          label: '🧠 AI Agent Planning Patterns'
        },
        {
          type: 'doc',
          id: 'memory-context-patterns',
          label: '💾 Memory & Context Patterns'
        },
        {
          type: 'doc',
          id: 'tool-definition-primer',
          label: '🛠️ Tool Definition & Function Calling'
        },
        {
          type: 'doc',
          id: 'multimodal-image-queries',
          label: '🖼️ Multimodal Image Queries'
        }
      ],
    },
    {
      type: 'category',
      label: '📚 Resources & Support',
      collapsible: true,
      collapsed: true,
      className: 'sidebar-resources',
      description: 'Additional resources, troubleshooting, and community',
      items: [
        {
          type: 'doc',
          id: 'local-setup-tips',
          label: 'Docker Best Practices'
        },
        {
          type: 'doc',
          id: 'docker-troubleshooting',
          label: 'Troubleshooting Guide'
        },
        {
          type: 'doc',
          id: 'community-resources',
          label: 'Community Resources'
        },
        {
          type: 'doc',
          id: 'status-badge-usage-guide',
          label: 'Status Badge Usage Guide'
        },
        {
          type: 'doc',
          id: 'summary',
          label: '🎉 Workshop Summary'
        }
      ],
    },
  ],
};

module.exports = sidebars;

```

# src/components/BrowserWindow/index.js

```js
import "./main.css";
import React from "react";

export default function BrowserWindow(props) {
  // Straight out of w3schools: https://www.w3schools.com/howto/howto_css_browser_window.asp

  const url = props.url || "http://localhost:3000";

  return (
    <div className="browser container">
      <div className="row">
        <div className="column left">
        <span className="dot" style={{background: "#ED594A"}}></span>
        <span className="dot" style={{background: "#FDD800"}}></span>
        <span className="dot" style={{background: "#5AC05A"}}></span>
        </div>
        <div className="column middle">
          <input type="text" value={url} />
        </div>
        <div className="column right">
          <div style={{float: "right"}}>
            <span className="bar"></span>
            <span className="bar"></span>
            <span className="bar"></span>
          </div>
        </div>
      </div>

      <div className="content">
        {props.children}
      </div>
    </div>
  )
}
```

# src/components/BrowserWindow/main.css

```css
* {
  box-sizing: border-box;
}

/* The browser window */
.browser.container {
  border: 3px solid #f1f1f1;
  border-top-left-radius: 4px;
  border-top-right-radius: 4px;
  margin-bottom: 10px;
  cursor: not-allowed;
}

/* Container for columns and the top "toolbar" */
.browser .row {
  padding: 10px;
  background: #f1f1f1;
  border-top-left-radius: 4px;
  border-top-right-radius: 4px;
}

/* Create three unequal columns that floats next to each other */
.browser .column {
  float: left;
}

.browser .left {
  width: 15%;
}

.browser .right {
  width: 10%;
}

.browser .middle {
  width: 75%;
}

/* Clear floats after the columns */
.browser .row:after {
  content: "";
  display: table;
  clear: both;
}

/* Three dots */
.browser .dot {
  margin-top: 4px;
  height: 12px;
  width: 12px;
  background-color: #bbb;
  border-radius: 50%;
  display: inline-block;
}

/* Style the input field */
.browser input[type=text] {
  width: 100%;
  border-radius: 3px;
  border: none;
  background-color: white;
  margin-top: -8px;
  height: 25px;
  color: #666;
  padding: 5px;
}

/* Three bars (hamburger menu) */
.browser .bar {
  width: 17px;
  height: 3px;
  background-color: #aaa;
  margin: 3px 0;
  display: block;
}

/* Page content */
.browser .content {
  padding: 10px;
  text-align: center;
}
```

# src/components/CodeBlock/index.js

```js
import React, { useState } from 'react';
import styles from './styles.module.css';

export default function CodeBlock({ 
  language = 'bash',
  children,
  title,
  showCopy = true,
  filename,
  highlight = []
}) {
  const [copied, setCopied] = useState(false);

  const handleCopy = async () => {
    try {
      await navigator.clipboard.writeText(children.trim());
      setCopied(true);
      setTimeout(() => setCopied(false), 2000);
    } catch (err) {
      // Fallback for older browsers
      const textArea = document.createElement('textarea');
      textArea.value = children.trim();
      document.body.appendChild(textArea);
      textArea.select();
      document.execCommand('copy');
      document.body.removeChild(textArea);
      setCopied(true);
      setTimeout(() => setCopied(false), 2000);
    }
  };

  return (
    <div className={styles.codeBlockContainer}>
      {(title || filename) && (
        <div className={styles.header}>
          <span className={styles.title}>
            {filename && <span className={styles.filename}>📄 {filename}</span>}
            {title && <span className={styles.codeTitle}>{title}</span>}
          </span>
          {showCopy && (
            <button 
              className={styles.copyButton}
              onClick={handleCopy}
              disabled={copied}
            >
              {copied ? '✅ Copied!' : '📋 Copy'}
            </button>
          )}
        </div>
      )}
      <div className={styles.codeBlock}>
        <pre className={`${styles.code} language-${language}`}>
          <code>{children.trim()}</code>
        </pre>
        {!title && !filename && showCopy && (
          <button 
            className={styles.floatingCopyButton}
            onClick={handleCopy}
            disabled={copied}
          >
            {copied ? '✅' : '📋'}
          </button>
        )}
      </div>
    </div>
  );
}

export function TerminalCommand({ command, output, prompt = '$' }) {
  const [showOutput, setShowOutput] = useState(false);

  return (
    <div className={styles.terminal}>
      <div className={styles.terminalHeader}>
        <div className={styles.terminalButtons}>
          <div className={styles.terminalButton} style={{backgroundColor: '#ff5f57'}}></div>
          <div className={styles.terminalButton} style={{backgroundColor: '#ffbd2e'}}></div>
          <div className={styles.terminalButton} style={{backgroundColor: '#28ca42'}}></div>
        </div>
        <div className={styles.terminalTitle}>Terminal</div>
      </div>
      <div className={styles.terminalContent}>
        <div className={styles.commandLine}>
          <span className={styles.prompt}>{prompt}</span>
          <span className={styles.command}>{command}</span>
        </div>
        {output && (
          <>
            {!showOutput && (
              <button 
                className={styles.showOutputButton}
                onClick={() => setShowOutput(true)}
              >
                Show expected output ▼
              </button>
            )}
            {showOutput && (
              <div className={styles.output}>
                <pre>{output}</pre>
              </div>
            )}
          </>
        )}
      </div>
    </div>
  );
}
```

# src/components/CodeBlock/styles.module.css

```css
.codeBlockContainer {
  margin: 1.5rem 0;
  border-radius: 8px;
  background: #1e1e1e;
  overflow: hidden;
  box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
}

.header {
  background: #2d2d30;
  padding: 0.75rem 1rem;
  display: flex;
  justify-content: space-between;
  align-items: center;
  border-bottom: 1px solid #404040;
}

.title {
  display: flex;
  align-items: center;
  gap: 0.5rem;
}

.filename {
  color: #ffd700;
  font-weight: 600;
  font-size: 0.9rem;
}

.codeTitle {
  color: #c9d1d9;
  font-weight: 500;
}

.copyButton {
  background: #238636;
  color: white;
  border: none;
  padding: 0.4rem 0.8rem;
  border-radius: 6px;
  cursor: pointer;
  font-size: 0.8rem;
  transition: all 0.2s ease;
}

.copyButton:hover:not(:disabled) {
  background: #2ea043;
  transform: translateY(-1px);
}

.copyButton:disabled {
  background: #28a745;
  cursor: not-allowed;
}

.codeBlock {
  position: relative;
  background: #1e1e1e;
}

.code {
  margin: 0;
  padding: 1.5rem;
  background: transparent;
  color: #c9d1d9;
  font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
  font-size: 0.9rem;
  line-height: 1.6;
  overflow-x: auto;
}

.floatingCopyButton {
  position: absolute;
  top: 1rem;
  right: 1rem;
  background: rgba(45, 45, 48, 0.8);
  color: #c9d1d9;
  border: 1px solid #404040;
  padding: 0.5rem;
  border-radius: 6px;
  cursor: pointer;
  font-size: 0.8rem;
  backdrop-filter: blur(4px);
  transition: all 0.2s ease;
}

.floatingCopyButton:hover:not(:disabled) {
  background: rgba(35, 134, 54, 0.8);
  border-color: #238636;
}

.floatingCopyButton:disabled {
  background: rgba(40, 167, 69, 0.8);
  cursor: not-allowed;
}

/* Terminal Component */
.terminal {
  margin: 1.5rem 0;
  border-radius: 8px;
  background: #000;
  overflow: hidden;
  box-shadow: 0 4px 16px rgba(0, 0, 0, 0.3);
  font-family: 'SFMono-Regular', Consolas, 'Liberation Mono', Menlo, monospace;
}

.terminalHeader {
  background: #2c2c2c;
  padding: 0.75rem;
  display: flex;
  align-items: center;
  justify-content: center;
  position: relative;
}

.terminalButtons {
  position: absolute;
  left: 1rem;
  display: flex;
  gap: 0.5rem;
}

.terminalButton {
  width: 12px;
  height: 12px;
  border-radius: 50%;
}

.terminalTitle {
  color: #c9d1d9;
  font-weight: 500;
  font-size: 0.9rem;
}

.terminalContent {
  padding: 1rem;
  background: #000;
  color: #00ff00;
}

.commandLine {
  display: flex;
  align-items: center;
  margin-bottom: 0.5rem;
}

.prompt {
  color: #00ff00;
  margin-right: 0.5rem;
  font-weight: bold;
}

.command {
  color: #ffffff;
}

.showOutputButton {
  background: transparent;
  color: #6c757d;
  border: 1px solid #404040;
  padding: 0.5rem 1rem;
  border-radius: 4px;
  cursor: pointer;
  font-size: 0.9rem;
  margin-top: 0.5rem;
  transition: all 0.2s ease;
}

.showOutputButton:hover {
  color: #c9d1d9;
  border-color: #6c757d;
}

.output {
  margin-top: 0.5rem;
  color: #c9d1d9;
  font-size: 0.9rem;
}

.output pre {
  margin: 0;
  white-space: pre-wrap;
  word-wrap: break-word;
}
```

# src/components/EmbeddingTester/index.js

```js
import React, { useState } from 'react';
import styles from './styles.module.css';

export default function EmbeddingTester({ 
  apiUrl = "https://workshop-embedding-api.vercel.app/api/embed",
  defaultModel = "voyage-3"
}) {
  const [text, setText] = useState('');
  const [model, setModel] = useState(defaultModel);
  const [loading, setLoading] = useState(false);
  const [result, setResult] = useState(null);
  const [error, setError] = useState(null);
  const [showRawEmbedding, setShowRawEmbedding] = useState(false);
  const [copiedConfig, setCopiedConfig] = useState(false);

  const handleSubmit = async (e) => {
    e.preventDefault();
    
    if (!text.trim()) {
      setError('Please enter some text to embed');
      return;
    }

    setLoading(true);
    setError(null);
    setResult(null);

    try {
      const response = await fetch(apiUrl, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          text: text.trim(),
          model: model
        }),
      });

      const data = await response.json();

      if (!response.ok) {
        throw new Error(data.error || `HTTP ${response.status}: ${response.statusText}`);
      }

      setResult(data);
    } catch (err) {
      setError(err.message || 'Failed to generate embedding');
    } finally {
      setLoading(false);
    }
  };

  const generateN8nConfig = () => {
    return {
      method: 'POST',
      url: apiUrl,
      authentication: 'none',
      sendHeaders: true,
      headerParameters: {
        parameters: [
          {
            name: 'Content-Type',
            value: 'application/json'
          }
        ]
      },
      sendBody: true,
      bodyContentType: 'json',
      specifyBody: 'json',
      jsonBody: JSON.stringify({
        text: "{{ $json.textContent }}",
        model: model
      }, null, 2)
    };
  };

  const copyN8nConfig = async () => {
    const config = generateN8nConfig();
    const configText = `n8n HTTP Request Node Configuration:

Method: ${config.method}
URL: ${config.url}
Authentication: None

Headers:
- Content-Type: application/json

Body (JSON):
${config.jsonBody}`;

    try {
      await navigator.clipboard.writeText(configText);
      setCopiedConfig(true);
      setTimeout(() => setCopiedConfig(false), 2000);
    } catch (err) {
      // Fallback
      const textarea = document.createElement('textarea');
      textarea.value = configText;
      document.body.appendChild(textarea);
      textarea.select();
      document.execCommand('copy');
      document.body.removeChild(textarea);
      setCopiedConfig(true);
      setTimeout(() => setCopiedConfig(false), 2000);
    }
  };

  const exampleTexts = [
    "This document explains how vector embeddings work in machine learning applications.",
    "MongoDB Atlas provides powerful vector search capabilities for AI applications.",
    "n8n is a visual workflow automation tool that makes building AI agents intuitive.",
    "Multimodal embeddings can process both text and images in a unified vector space."
  ];

  const fillExample = (exampleText) => {
    setText(exampleText);
  };

  return (
    <div className={styles.tester}>
      <div className={styles.header}>
        <h3>🧪 Workshop Embedding API Tester</h3>
        <p>Test the embedding API before using it in your n8n workflows</p>
      </div>

      <form onSubmit={handleSubmit} className={styles.form}>
        <div className={styles.formGroup}>
          <label htmlFor="text">Text to Embed:</label>
          <textarea
            id="text"
            value={text}
            onChange={(e) => setText(e.target.value)}
            placeholder="Enter any text you want to convert to embeddings..."
            rows={4}
            className={styles.textarea}
          />
          
          <div className={styles.examples}>
            <span className={styles.exampleLabel}>Try an example:</span>
            {exampleTexts.map((example, index) => (
              <button
                key={index}
                type="button"
                className={styles.exampleButton}
                onClick={() => fillExample(example)}
              >
                Example {index + 1}
              </button>
            ))}
          </div>
        </div>

        <div className={styles.formGroup}>
          <label htmlFor="model">Model:</label>
          <select
            id="model"
            value={model}
            onChange={(e) => setModel(e.target.value)}
            className={styles.select}
          >
            <option value="voyage-3">voyage-3 (Latest)</option>
            <option value="voyage-multimodal-3">voyage-multimodal-3 (Multimodal)</option>
            <option value="voyage-code-3">voyage-code-3 (Code)</option>
          </select>
        </div>

        <div className={styles.actions}>
          <button
            type="submit"
            disabled={loading || !text.trim()}
            className={styles.submitButton}
          >
            {loading ? '⏳ Generating Embedding...' : '🚀 Generate Embedding'}
          </button>

          <button
            type="button"
            onClick={copyN8nConfig}
            className={styles.copyButton}
            disabled={copiedConfig}
          >
            {copiedConfig ? '✅ Copied!' : '📋 Copy n8n Config'}
          </button>
        </div>
      </form>

      {error && (
        <div className={styles.error}>
          <strong>❌ Error:</strong> {error}
        </div>
      )}

      {result && (
        <div className={styles.result}>
          <h4>✅ Success! Embedding Generated</h4>
          
          <div className={styles.resultSection}>
            <h5>Response Details:</h5>
            <div className={styles.details}>
              <div className={styles.detail}>
                <span className={styles.detailLabel}>Model:</span>
                <span className={styles.detailValue}>{result.model}</span>
              </div>
              <div className={styles.detail}>
                <span className={styles.detailLabel}>Dimensions:</span>
                <span className={styles.detailValue}>{result.embeddings[0].length}</span>
              </div>
              <div className={styles.detail}>
                <span className={styles.detailLabel}>Tokens Used:</span>
                <span className={styles.detailValue}>{result.usage?.total_tokens || 'N/A'}</span>
              </div>
            </div>
          </div>

          <div className={styles.resultSection}>
            <h5>Embedding Preview (first 10 values):</h5>
            <code className={styles.embeddingPreview}>
              [{result.embeddings[0].slice(0, 10).map(v => v.toFixed(4)).join(', ')}...]
            </code>
          </div>

          <button
            type="button"
            onClick={() => setShowRawEmbedding(!showRawEmbedding)}
            className={styles.toggleButton}
          >
            {showRawEmbedding ? 'Hide' : 'Show'} Full Embedding ({result.embeddings[0].length} values)
          </button>

          {showRawEmbedding && (
            <div className={styles.rawEmbedding}>
              <pre>{JSON.stringify(result.embeddings[0], null, 2)}</pre>
            </div>
          )}

          <div className={styles.usage}>
            <h5>📝 n8n Usage Example:</h5>
            <p>This response format is exactly what you'll receive in n8n. Access the embedding array with:</p>
            <code className={styles.accessCode}>
              {'{{ $json.embeddings[0] }}'}
            </code>
          </div>
        </div>
      )}

      <div className={styles.info}>
        <h4>ℹ️ About This API</h4>
        <ul>
          <li>No authentication required - designed for workshop use</li>
          <li>Rate limited to prevent abuse</li>
          <li>Supports text embeddings with Voyage AI models</li>
          <li>Returns 1024-dimensional vectors for semantic search</li>
        </ul>
      </div>
    </div>
  );
}

export function EmbeddingVisualizer({ embedding, maxDisplay = 50 }) {
  if (!embedding || !Array.isArray(embedding)) {
    return null;
  }

  const values = embedding.slice(0, maxDisplay);
  const min = Math.min(...values);
  const max = Math.max(...values);
  const range = max - min;

  const normalize = (value) => {
    return ((value - min) / range) * 100;
  };

  return (
    <div className={styles.visualizer}>
      <h4>Embedding Visualization (first {maxDisplay} dimensions)</h4>
      <div className={styles.chart}>
        {values.map((value, index) => (
          <div
            key={index}
            className={styles.bar}
            style={{
              height: `${normalize(value)}%`,
              backgroundColor: value >= 0 ? '#10b981' : '#ef4444'
            }}
            title={`Dimension ${index}: ${value.toFixed(4)}`}
          />
        ))}
      </div>
      <div className={styles.chartLabels}>
        <span>Negative ←</span>
        <span>→ Positive</span>
      </div>
    </div>
  );
}
```

# src/components/EmbeddingTester/styles.module.css

```css
.tester {
  background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
  border-radius: 12px;
  padding: 2rem;
  margin: 2rem 0;
  color: white;
  box-shadow: 0 8px 24px rgba(102, 126, 234, 0.3);
}

.header {
  text-align: center;
  margin-bottom: 2rem;
}

.header h3 {
  margin: 0 0 0.5rem 0;
  font-size: 1.6rem;
}

.header p {
  margin: 0;
  opacity: 0.9;
}

.form {
  background: rgba(255, 255, 255, 0.1);
  border-radius: 8px;
  padding: 1.5rem;
  backdrop-filter: blur(10px);
}

.formGroup {
  margin-bottom: 1.5rem;
}

.formGroup label {
  display: block;
  margin-bottom: 0.5rem;
  font-weight: 600;
  font-size: 1rem;
}

.textarea {
  width: 100%;
  padding: 0.75rem;
  border: 2px solid rgba(255, 255, 255, 0.3);
  border-radius: 6px;
  background: rgba(255, 255, 255, 0.9);
  color: #374151;
  font-size: 1rem;
  resize: vertical;
  transition: border-color 0.2s ease;
}

.textarea:focus {
  outline: none;
  border-color: #fff;
  box-shadow: 0 0 0 3px rgba(255, 255, 255, 0.3);
}

.examples {
  display: flex;
  gap: 0.5rem;
  align-items: center;
  margin-top: 0.5rem;
  flex-wrap: wrap;
}

.exampleLabel {
  font-size: 0.9rem;
  opacity: 0.9;
}

.exampleButton {
  background: rgba(255, 255, 255, 0.2);
  border: 1px solid rgba(255, 255, 255, 0.3);
  color: white;
  padding: 0.4rem 0.8rem;
  border-radius: 4px;
  cursor: pointer;
  font-size: 0.85rem;
  transition: all 0.2s ease;
}

.exampleButton:hover {
  background: rgba(255, 255, 255, 0.3);
  transform: translateY(-1px);
}

.select {
  width: 100%;
  padding: 0.75rem;
  border: 2px solid rgba(255, 255, 255, 0.3);
  border-radius: 6px;
  background: rgba(255, 255, 255, 0.9);
  color: #374151;
  font-size: 1rem;
  cursor: pointer;
}

.select:focus {
  outline: none;
  border-color: #fff;
  box-shadow: 0 0 0 3px rgba(255, 255, 255, 0.3);
}

.actions {
  display: flex;
  gap: 1rem;
  justify-content: center;
}

.submitButton {
  background: linear-gradient(135deg, #10b981, #34d399);
  color: white;
  border: none;
  padding: 0.75rem 1.5rem;
  border-radius: 6px;
  font-weight: 600;
  cursor: pointer;
  font-size: 1rem;
  transition: all 0.2s ease;
}

.submitButton:hover:not(:disabled) {
  transform: translateY(-2px);
  box-shadow: 0 4px 12px rgba(16, 185, 129, 0.4);
}

.submitButton:disabled {
  opacity: 0.6;
  cursor: not-allowed;
  transform: none;
}

.copyButton {
  background: rgba(255, 255, 255, 0.2);
  color: white;
  border: 2px solid rgba(255, 255, 255, 0.3);
  padding: 0.75rem 1.5rem;
  border-radius: 6px;
  font-weight: 600;
  cursor: pointer;
  font-size: 1rem;
  transition: all 0.2s ease;
}

.copyButton:hover:not(:disabled) {
  background: rgba(255, 255, 255, 0.3);
  transform: translateY(-1px);
}

.copyButton:disabled {
  background: rgba(40, 167, 69, 0.8);
  border-color: #28a745;
}

.error {
  background: rgba(239, 68, 68, 0.2);
  border: 2px solid #ef4444;
  border-radius: 8px;
  padding: 1rem;
  margin-top: 1rem;
  color: #fee2e2;
}

.result {
  background: rgba(255, 255, 255, 0.1);
  border-radius: 8px;
  padding: 1.5rem;
  margin-top: 1.5rem;
  backdrop-filter: blur(10px);
}

.result h4 {
  margin: 0 0 1rem 0;
  color: #10b981;
  font-size: 1.2rem;
}

.resultSection {
  margin-bottom: 1.5rem;
}

.resultSection h5 {
  margin: 0 0 0.5rem 0;
  opacity: 0.9;
}

.details {
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
  gap: 1rem;
}

.detail {
  background: rgba(255, 255, 255, 0.1);
  padding: 0.75rem;
  border-radius: 6px;
  display: flex;
  justify-content: space-between;
  align-items: center;
}

.detailLabel {
  font-weight: 600;
  opacity: 0.9;
}

.detailValue {
  font-family: monospace;
  background: rgba(255, 255, 255, 0.2);
  padding: 0.25rem 0.5rem;
  border-radius: 4px;
}

.embeddingPreview {
  display: block;
  background: rgba(0, 0, 0, 0.3);
  color: #10b981;
  padding: 1rem;
  border-radius: 6px;
  font-family: monospace;
  font-size: 0.9rem;
  overflow-x: auto;
}

.toggleButton {
  background: rgba(255, 255, 255, 0.2);
  color: white;
  border: 1px solid rgba(255, 255, 255, 0.3);
  padding: 0.5rem 1rem;
  border-radius: 6px;
  cursor: pointer;
  font-size: 0.9rem;
  transition: all 0.2s ease;
}

.toggleButton:hover {
  background: rgba(255, 255, 255, 0.3);
}

.rawEmbedding {
  margin-top: 1rem;
  max-height: 300px;
  overflow-y: auto;
}

.rawEmbedding pre {
  background: rgba(0, 0, 0, 0.3);
  color: #e5e7eb;
  padding: 1rem;
  border-radius: 6px;
  font-size: 0.8rem;
  margin: 0;
}

.usage {
  background: rgba(59, 130, 246, 0.2);
  border: 2px solid #3b82f6;
  border-radius: 8px;
  padding: 1rem;
  margin-top: 1.5rem;
}

.usage h5 {
  margin: 0 0 0.5rem 0;
  color: #93c5fd;
}

.usage p {
  margin: 0 0 0.5rem 0;
  opacity: 0.9;
}

.accessCode {
  display: inline-block;
  background: rgba(0, 0, 0, 0.3);
  color: #fbbf24;
  padding: 0.5rem 1rem;
  border-radius: 4px;
  font-family: monospace;
}

.info {
  background: rgba(255, 255, 255, 0.1);
  border-radius: 8px;
  padding: 1.5rem;
  margin-top: 1.5rem;
}

.info h4 {
  margin: 0 0 1rem 0;
  opacity: 0.9;
}

.info ul {
  margin: 0;
  padding-left: 1.5rem;
}

.info li {
  margin-bottom: 0.5rem;
  opacity: 0.9;
}

/* Visualizer Styles */
.visualizer {
  background: rgba(255, 255, 255, 0.1);
  border-radius: 8px;
  padding: 1rem;
  margin-top: 1rem;
}

.visualizer h4 {
  margin: 0 0 1rem 0;
  font-size: 1rem;
  opacity: 0.9;
}

.chart {
  display: flex;
  align-items: flex-end;
  height: 100px;
  gap: 2px;
  padding: 0.5rem;
  background: rgba(0, 0, 0, 0.2);
  border-radius: 4px;
}

.bar {
  flex: 1;
  min-height: 2px;
  transition: height 0.3s ease;
  border-radius: 2px 2px 0 0;
  cursor: pointer;
}

.bar:hover {
  opacity: 0.8;
}

.chartLabels {
  display: flex;
  justify-content: space-between;
  margin-top: 0.5rem;
  font-size: 0.8rem;
  opacity: 0.7;
}

/* Dark mode adjustments */
[data-theme='dark'] .textarea,
[data-theme='dark'] .select {
  background: rgba(31, 41, 55, 0.9);
  color: #e5e7eb;
}

[data-theme='dark'] .error {
  color: #fecaca;
}

/* Responsive design */
@media (max-width: 768px) {
  .tester {
    padding: 1.5rem;
  }

  .actions {
    flex-direction: column;
  }

  .submitButton,
  .copyButton {
    width: 100%;
  }

  .examples {
    justify-content: center;
  }
}
```

# src/components/HomepageFeatures/index.js

```js
import React from 'react';
import clsx from 'clsx';
import styles from './styles.module.css';
import useDocusaurusContext from '@docusaurus/useDocusaurusContext';

function Feature({ illustration, title, description, fetchPriority }) {
  return (
    <div className={clsx('col col--4')}>
      <div className="text--center">
        <img
          src={illustration}
          className={styles.featureImg}
          width="450px"
          height="100%"
          role="img"
          alt=""
          fetchpriority={fetchPriority}
        />
      </div>
      <div className="text--center padding-horiz--md">
        <h2>{title}</h2>
        <p>{description}</p>
      </div>
    </div>
  );
}

export default function HomepageFeatures() {
  const { siteConfig } = useDocusaurusContext();

  return (
    <section className={styles.features}>
      <div className={`container ${styles.featuresContainer}`}>
        <div className="row">
          {siteConfig.customFields.featureList.map((props, idx) => (
            <Feature key={idx} fetchPriority={idx ? 'low' : 'high'} {...props} />
          ))}
        </div>
      </div>
    </section>
  );
}

```

# src/components/HomepageFeatures/styles.module.css

```css
.features {
  display: flex;
  align-items: center;
  padding: 5rem 0;
  width: 100%;
}

.featureImg {
  margin-bottom: 2.5rem;
  height: 100%;
}

@media screen and (max-width: 480px) {
  .featureImg {
    width: 350px;
  }
}


@media screen and (max-width: 997px) {
  .featureImg {
    width: 500px;
  }
}

@media screen and (min-width: 1280px) {
  .features {
    padding: 1rem 0;

  }

  .featuresContainer {
    max-width: 100%;
  }

  .featureImg {
    width: 450px;
  }
}

@media screen and (min-width: 1550px) {
  .featuresContainer {
    max-width: 90%;
  }

  .featureImg {
    width: 600px;
  }
}


@media screen and (min-width: 1980px) {
  .featuresContainer {
    max-width: 85%;
  }
}


```

# src/components/InteractiveDemo/index.js

```js
import React, { useState } from 'react';
import styles from './styles.module.css';

export default function InteractiveDemo({ 
  title, 
  description, 
  steps = [], 
  initialData = {},
  onComplete 
}) {
  const [currentStep, setCurrentStep] = useState(0);
  const [data, setData] = useState(initialData);
  const [isCompleted, setIsCompleted] = useState(false);

  const handleNext = () => {
    if (currentStep < steps.length - 1) {
      setCurrentStep(currentStep + 1);
    } else {
      setIsCompleted(true);
      if (onComplete) onComplete(data);
    }
  };

  const handlePrevious = () => {
    if (currentStep > 0) {
      setCurrentStep(currentStep - 1);
    }
  };

  const updateData = (key, value) => {
    setData(prev => ({ ...prev, [key]: value }));
  };

  const currentStepData = steps[currentStep] || {};

  return (
    <div className={styles.demoContainer}>
      <div className={styles.header}>
        <h3>{title}</h3>
        <p>{description}</p>
      </div>

      <div className={styles.progressIndicator}>
        {steps.map((_, index) => (
          <div 
            key={index}
            className={`${styles.progressDot} ${
              index <= currentStep ? styles.active : ''
            } ${
              index < currentStep ? styles.completed : ''
            }`}
            onClick={() => setCurrentStep(index)}
          />
        ))}
      </div>

      {!isCompleted ? (
        <div className={styles.stepContent}>
          <div className={styles.stepHeader}>
            <h4>Step {currentStep + 1}: {currentStepData.title}</h4>
            {currentStepData.timeEstimate && (
              <span className={styles.timeEstimate}>⏱️ {currentStepData.timeEstimate}</span>
            )}
          </div>

          <div className={styles.stepBody}>
            {currentStepData.content}
            
            {currentStepData.interactive && (
              <div className={styles.interactive}>
                {currentStepData.interactive({ data, updateData })}
              </div>
            )}
          </div>

          <div className={styles.navigation}>
            <button 
              className={styles.navButton}
              onClick={handlePrevious}
              disabled={currentStep === 0}
            >
              ← Previous
            </button>
            
            <span className={styles.stepCounter}>
              {currentStep + 1} of {steps.length}
            </span>
            
            <button 
              className={styles.navButton}
              onClick={handleNext}
            >
              {currentStep === steps.length - 1 ? 'Complete' : 'Next →'}
            </button>
          </div>
        </div>
      ) : (
        <div className={styles.completion}>
          <div className={styles.completionIcon}>🎉</div>
          <h4>Demo Completed!</h4>
          <p>Great job! You've successfully completed the interactive demo.</p>
          <div className={styles.completionData}>
            <h5>Your Configuration:</h5>
            <pre>{JSON.stringify(data, null, 2)}</pre>
          </div>
          <button 
            className={styles.resetButton}
            onClick={() => {
              setCurrentStep(0);
              setData(initialData);
              setIsCompleted(false);
            }}
          >
            Try Again
          </button>
        </div>
      )}
    </div>
  );
}

export function ConfigBuilder({ title, config = {}, onChange }) {
  const [values, setValues] = useState(config);

  const handleChange = (key, value) => {
    const newValues = { ...values, [key]: value };
    setValues(newValues);
    if (onChange) onChange(newValues);
  };

  return (
    <div className={styles.configBuilder}>
      <h4>{title}</h4>
      <div className={styles.configForm}>
        {Object.entries(config).map(([key, defaultValue]) => (
          <div key={key} className={styles.configField}>
            <label className={styles.configLabel}>
              {key.replace(/([A-Z])/g, ' $1').replace(/^./, str => str.toUpperCase())}:
            </label>
            <input
              type="text"
              value={values[key] || defaultValue}
              onChange={(e) => handleChange(key, e.target.value)}
              className={styles.configInput}
              placeholder={String(defaultValue)}
            />
          </div>
        ))}
      </div>
    </div>
  );
}

export function ServiceTester({ serviceName, testUrl, testData }) {
  const [isLoading, setIsLoading] = useState(false);
  const [result, setResult] = useState(null);
  const [error, setError] = useState(null);

  const runTest = async () => {
    setIsLoading(true);
    setError(null);
    setResult(null);

    try {
      const response = await fetch(testUrl, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(testData),
      });

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}: ${response.statusText}`);
      }

      const data = await response.json();
      setResult(data);
    } catch (err) {
      setError(err.message);
    } finally {
      setIsLoading(false);
    }
  };

  return (
    <div className={styles.serviceTester}>
      <div className={styles.testerHeader}>
        <h4>🔧 Test {serviceName}</h4>
        <button 
          className={styles.testButton}
          onClick={runTest}
          disabled={isLoading}
        >
          {isLoading ? '⏳ Testing...' : '🚀 Run Test'}
        </button>
      </div>

      {error && (
        <div className={styles.error}>
          <strong>❌ Error:</strong> {error}
        </div>
      )}

      {result && (
        <div className={styles.success}>
          <strong>✅ Success!</strong>
          <pre className={styles.resultData}>{JSON.stringify(result, null, 2)}</pre>
        </div>
      )}

      <details className={styles.testDetails}>
        <summary>Test Configuration</summary>
        <div className={styles.testConfig}>
          <p><strong>URL:</strong> {testUrl}</p>
          <p><strong>Method:</strong> POST</p>
          <p><strong>Data:</strong></p>
          <pre>{JSON.stringify(testData, null, 2)}</pre>
        </div>
      </details>
    </div>
  );
}
```

# src/components/InteractiveDemo/styles.module.css

```css
.demoContainer {
  border: 2px solid #e1e8ed;
  border-radius: 12px;
  background: #ffffff;
  margin: 2rem 0;
  overflow: hidden;
  box-shadow: 0 4px 16px rgba(0, 0, 0, 0.1);
}

.header {
  background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
  color: white;
  padding: 1.5rem;
  text-align: center;
}

.header h3 {
  margin: 0 0 0.5rem 0;
  font-size: 1.4rem;
}

.header p {
  margin: 0;
  opacity: 0.9;
}

.progressIndicator {
  display: flex;
  justify-content: center;
  gap: 0.5rem;
  padding: 1rem;
  background: #f8f9fa;
  border-bottom: 1px solid #e1e8ed;
}

.progressDot {
  width: 1rem;
  height: 1rem;
  border-radius: 50%;
  background: #dee2e6;
  cursor: pointer;
  transition: all 0.3s ease;
}

.progressDot.active {
  background: #007bff;
  transform: scale(1.2);
}

.progressDot.completed {
  background: #28a745;
}

.stepContent {
  padding: 2rem;
}

.stepHeader {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 1.5rem;
  padding-bottom: 1rem;
  border-bottom: 1px solid #e1e8ed;
}

.stepHeader h4 {
  margin: 0;
  color: #495057;
}

.timeEstimate {
  color: #6c757d;
  font-size: 0.9rem;
}

.stepBody {
  margin-bottom: 2rem;
  line-height: 1.6;
}

.interactive {
  background: #f8f9fa;
  border: 1px solid #e1e8ed;
  border-radius: 8px;
  padding: 1.5rem;
  margin: 1rem 0;
}

.navigation {
  display: flex;
  justify-content: space-between;
  align-items: center;
  padding-top: 1rem;
  border-top: 1px solid #e1e8ed;
}

.navButton {
  background: #007bff;
  color: white;
  border: none;
  padding: 0.75rem 1.5rem;
  border-radius: 6px;
  cursor: pointer;
  font-weight: 500;
  transition: all 0.2s ease;
}

.navButton:hover:not(:disabled) {
  background: #0056b3;
  transform: translateY(-2px);
}

.navButton:disabled {
  background: #6c757d;
  cursor: not-allowed;
  transform: none;
}

.stepCounter {
  color: #6c757d;
  font-weight: 500;
}

.completion {
  padding: 3rem 2rem;
  text-align: center;
}

.completionIcon {
  font-size: 4rem;
  margin-bottom: 1rem;
}

.completion h4 {
  color: #28a745;
  margin-bottom: 1rem;
}

.completionData {
  background: #f8f9fa;
  border: 1px solid #e1e8ed;
  border-radius: 8px;
  padding: 1rem;
  margin: 1.5rem 0;
  text-align: left;
}

.completionData h5 {
  margin: 0 0 0.5rem 0;
  color: #495057;
}

.completionData pre {
  background: #343a40;
  color: #ffffff;
  padding: 1rem;
  border-radius: 4px;
  overflow-x: auto;
  font-size: 0.9rem;
}

.resetButton {
  background: #6c757d;
  color: white;
  border: none;
  padding: 0.75rem 1.5rem;
  border-radius: 6px;
  cursor: pointer;
  transition: background-color 0.2s ease;
}

.resetButton:hover {
  background: #5a6268;
}

/* Config Builder */
.configBuilder {
  background: #ffffff;
  border: 1px solid #e1e8ed;
  border-radius: 8px;
  padding: 1.5rem;
  margin: 1rem 0;
}

.configBuilder h4 {
  margin: 0 0 1rem 0;
  color: #495057;
}

.configForm {
  display: flex;
  flex-direction: column;
  gap: 1rem;
}

.configField {
  display: flex;
  flex-direction: column;
  gap: 0.5rem;
}

.configLabel {
  font-weight: 500;
  color: #495057;
}

.configInput {
  padding: 0.75rem;
  border: 1px solid #ced4da;
  border-radius: 4px;
  font-size: 1rem;
  transition: border-color 0.2s ease;
}

.configInput:focus {
  outline: none;
  border-color: #007bff;
  box-shadow: 0 0 0 2px rgba(0, 123, 255, 0.25);
}

/* Service Tester */
.serviceTester {
  background: #ffffff;
  border: 1px solid #e1e8ed;
  border-radius: 8px;
  margin: 1rem 0;
  overflow: hidden;
}

.testerHeader {
  background: #f8f9fa;
  padding: 1rem 1.5rem;
  display: flex;
  justify-content: space-between;
  align-items: center;
  border-bottom: 1px solid #e1e8ed;
}

.testerHeader h4 {
  margin: 0;
  color: #495057;
}

.testButton {
  background: #28a745;
  color: white;
  border: none;
  padding: 0.5rem 1rem;
  border-radius: 6px;
  cursor: pointer;
  font-weight: 500;
  transition: all 0.2s ease;
}

.testButton:hover:not(:disabled) {
  background: #218838;
  transform: translateY(-1px);
}

.testButton:disabled {
  background: #6c757d;
  cursor: not-allowed;
  transform: none;
}

.error {
  background: #f8d7da;
  color: #721c24;
  padding: 1rem 1.5rem;
  border-bottom: 1px solid #f5c6cb;
}

.success {
  background: #d4edda;
  color: #155724;
  padding: 1rem 1.5rem;
  border-bottom: 1px solid #c3e6cb;
}

.resultData {
  background: #343a40;
  color: #ffffff;
  padding: 1rem;
  border-radius: 4px;
  margin-top: 0.5rem;
  overflow-x: auto;
  font-size: 0.9rem;
}

.testDetails {
  padding: 1rem 1.5rem;
}

.testDetails summary {
  cursor: pointer;
  font-weight: 500;
  color: #495057;
  margin-bottom: 0.5rem;
}

.testConfig {
  background: #f8f9fa;
  padding: 1rem;
  border-radius: 4px;
  margin-top: 0.5rem;
}

.testConfig p {
  margin: 0.5rem 0;
}

.testConfig pre {
  background: #343a40;
  color: #ffffff;
  padding: 1rem;
  border-radius: 4px;
  overflow-x: auto;
  font-size: 0.9rem;
}
```

# src/components/Link.js

```js
import React from "react";
import Link from '@docusaurus/Link';
import useDocusaurusContext from '@docusaurus/useDocusaurusContext';

export default function UTMLink(props) {
  const context = useDocusaurusContext();
  const utmParams = context?.siteConfig?.customFields?.utmParams || '';
  const to = `${props.to}?${utmParams}`;
  return <Link {...props} to={to} />;
}

```

# src/components/LiveStatusBadge/CodespaceStatusBadge.js

```js
import React from 'react';
import LiveStatusBadge from './index.js';

/**
 * Specialized status badge for initial Codespace setup validation
 * Used right after attendees launch their Codespace environment
 */
export default function CodespaceStatusBadge({ 
  showDetails = true,
  refreshInterval = 15000 // More frequent checks during setup
}) {
  const codespaceSpecificSystems = [
    {
      name: "GitHub Codespace Environment",
      endpoint: null, // Will be detected automatically
      description: "Development container and VS Code",
      test: () => {
        // Check if we're running in a Codespace
        if (typeof window !== 'undefined') {
          const hostname = window.location.hostname;
          return hostname.includes('app.github.dev') || hostname.includes('preview.app.github.dev');
        }
        return false;
      },
      localTest: true
    },
    {
      name: "Docker Environment",
      endpoint: "http://localhost:2375/version", // Docker daemon endpoint
      description: "Container runtime for workshop services",
      local: true,
      fallbackTest: async () => {
        // Fallback: Check if we can reach typical Docker services
        try {
          const response = await fetch('http://localhost:5678', { method: 'HEAD', mode: 'no-cors' });
          return true; // If n8n is accessible, Docker is likely running
        } catch {
          return false;
        }
      }
    },
    {
      name: "Port Forwarding",
      endpoint: null,
      description: "Codespace port accessibility",
      test: async () => {
        // Test if we can access forwarded ports
        if (typeof window === 'undefined') return false;
        
        const hostname = window.location.hostname;
        if (!hostname.includes('app.github.dev')) return false;
        
        // Extract codespace ID and test a known port
        const parts = hostname.split('-');
        if (parts.length >= 2) {
          const codespaceId = parts[0];
          try {
            // Test if port 3000 (docs) is accessible - it should be since we're viewing it
            const testUrl = `https://${codespaceId}-3000.app.github.dev`;
            const response = await fetch(testUrl, { method: 'HEAD', mode: 'no-cors' });
            return true;
          } catch {
            return false;
          }
        }
        return false;
      },
      localTest: true
    }
  ];

  return (
    <div>
      <LiveStatusBadge 
        systems={codespaceSpecificSystems}
        showDetails={showDetails}
        refreshInterval={refreshInterval}
      />
      
      <div style={{ 
        marginTop: '1rem', 
        padding: '1rem', 
        background: 'var(--ifm-color-info-contrast-background)',
        borderRadius: '4px',
        border: '1px solid var(--ifm-color-info-contrast-border)'
      }}>
        <h4 style={{ margin: '0 0 0.5rem 0', color: 'var(--ifm-color-info)' }}>
          🚀 Codespace Setup Checklist
        </h4>
        <ul style={{ margin: '0', paddingLeft: '1.5rem' }}>
          <li><strong>Environment Active</strong> - Your Codespace container is running</li>
          <li><strong>Docker Available</strong> - Container runtime ready for workshop services</li>
          <li><strong>Port Forwarding</strong> - Services will be accessible through secure URLs</li>
        </ul>
        <p style={{ margin: '0.5rem 0 0 0', fontSize: '0.9rem', color: 'var(--ifm-color-content-secondary)' }}>
          💡 <strong>Next Step:</strong> Once all systems show green, you're ready to start the Docker services!
        </p>
      </div>
    </div>
  );
}
```

# src/components/LiveStatusBadge/DockerServicesStatusBadge.js

```js
import React from 'react';
import LiveStatusBadge from './index.js';

/**
 * Specialized status badge for Docker services validation
 * Used after attendees run `npm run dev` or `docker-compose up`
 */
export default function DockerServicesStatusBadge({ 
  showDetails = true,
  refreshInterval = 10000 // Frequent checks during service startup
}) {
  // Auto-detect Codespace environment for service URLs
  const getCodespaceUrl = (port) => {
    if (typeof window !== 'undefined') {
      const hostname = window.location.hostname;
      if (hostname.includes('app.github.dev') || hostname.includes('preview.app.github.dev')) {
        const parts = hostname.split('-');
        if (parts.length >= 2) {
          const codespaceId = parts[0];
          return `https://${codespaceId}-${port}.app.github.dev`;
        }
      }
    }
    return `http://localhost:${port}`;
  };

  const dockerServiceSystems = [
    {
      name: "n8n Workflow Engine",
      endpoint: `${getCodespaceUrl(5678)}/healthz`,
      description: "Visual workflow automation platform",
      local: true,
      expectedResponse: { status: 'ok' },
      troubleshooting: [
        "Check if Docker containers are running: `docker ps`",
        "Restart n8n service: `docker-compose restart n8n`",
        "Check n8n logs: `docker-compose logs n8n`"
      ]
    },
    {
      name: "Documentation Site",
      endpoint: `${getCodespaceUrl(3000)}`,
      description: "This workshop documentation (should be running)",
      local: true,
      expectedResponse: null, // HTML response
      isCurrentSite: true
    }
  ];

  return (
    <div>
      <LiveStatusBadge 
        systems={dockerServiceSystems}
        showDetails={showDetails}
        refreshInterval={refreshInterval}
      />
      
      <div style={{ 
        marginTop: '1rem', 
        padding: '1rem', 
        background: 'var(--ifm-color-success-contrast-background)',
        borderRadius: '4px',
        border: '1px solid var(--ifm-color-success-contrast-border)'
      }}>
        <h4 style={{ margin: '0 0 0.5rem 0', color: 'var(--ifm-color-success)' }}>
          🐳 Docker Services Status
        </h4>
        <div style={{ display: 'grid', gridTemplateColumns: 'repeat(auto-fit, minmax(250px, 1fr))', gap: '1rem', margin: '1rem 0' }}>
          <div>
            <strong>n8n Workflow Engine</strong>
            <br />
            <small>Visual workflow builder - your main tool</small>
          </div>
          <div>
            <strong>Documentation Site</strong>
            <br />
            <small>Workshop guidance (this site)</small>
          </div>
        </div>
        
        <details style={{ marginTop: '1rem' }}>
          <summary style={{ cursor: 'pointer', fontWeight: '600' }}>
            🔧 Troubleshooting Commands
          </summary>
          <div style={{ marginTop: '0.5rem', fontFamily: 'var(--ifm-font-family-monospace)', fontSize: '0.85rem' }}>
            <div><strong>Check all services:</strong> <code>docker ps</code></div>
            <div><strong>View service logs:</strong> <code>docker-compose logs [service-name]</code></div>
            <div><strong>Restart services:</strong> <code>docker-compose restart</code></div>
            <div><strong>Stop and restart all:</strong> <code>docker-compose down && docker-compose up -d</code></div>
          </div>
        </details>
        
        <p style={{ margin: '1rem 0 0 0', fontSize: '0.9rem', color: 'var(--ifm-color-content-secondary)' }}>
          💡 <strong>Success Criteria:</strong> All services showing "Online" means you're ready to build workflows!
        </p>
      </div>
    </div>
  );
}
```

# src/components/LiveStatusBadge/index.js

```js
import React, { useState, useEffect } from 'react';
import styles from './styles.module.css';

// Auto-detect Codespace environment and build n8n URL
const detectCodespaceN8nUrl = () => {
  if (typeof window !== 'undefined') {
    const hostname = window.location.hostname;
    // Check if we're in a Codespace environment
    if (hostname.includes('app.github.dev') || hostname.includes('preview.app.github.dev')) {
      // Extract the Codespace identifier and build n8n URL
      const parts = hostname.split('-');
      if (parts.length >= 2) {
        const codespaceId = parts[0];
        return `https://${codespaceId}-5678.app.github.dev/healthz`;
      }
    }
  }
  return null;
};

// Get saved configuration from localStorage
const getSavedConfig = () => {
  if (typeof window !== 'undefined') {
    try {
      const saved = localStorage.getItem('workshop-status-config');
      return saved ? JSON.parse(saved) : {};
    } catch (error) {
      console.warn('Could not load saved configuration:', error);
      return {};
    }
  }
  return {};
};

// Save configuration to localStorage
const saveConfig = (config) => {
  if (typeof window !== 'undefined') {
    try {
      localStorage.setItem('workshop-status-config', JSON.stringify(config));
    } catch (error) {
      console.warn('Could not save configuration:', error);
    }
  }
};

export default function LiveStatusBadge({ 
  systems = null, // Will be built dynamically based on config
  refreshInterval = 30000, // 30 seconds
  showDetails = false
}) {
  const [systemStatus, setSystemStatus] = useState({});
  const [lastUpdate, setLastUpdate] = useState(null);
  const [isExpanded, setIsExpanded] = useState(showDetails);
  const [showConfig, setShowConfig] = useState(false);
  const [config, setConfig] = useState({});
  const [configForm, setConfigForm] = useState({
    n8nUrl: '',
    mongoDbTestUrl: '',
    codespaceId: ''
  });

  // Initialize configuration on mount
  useEffect(() => {
    const savedConfig = getSavedConfig();
    const detectedN8nUrl = detectCodespaceN8nUrl();
    
    const initialConfig = {
      n8nUrl: savedConfig.n8nUrl || detectedN8nUrl || '',
      mongoDbTestUrl: savedConfig.mongoDbTestUrl || '',
      codespaceId: savedConfig.codespaceId || ''
    };
    
    setConfig(initialConfig);
    setConfigForm(initialConfig);
    
    // If no configuration exists, show config panel
    if (!savedConfig.n8nUrl && !detectedN8nUrl) {
      setShowConfig(true);
    }
  }, []);

  // Build systems array dynamically based on configuration
  const buildSystems = () => {
    const systemsArray = [
      {
        name: "Workshop API Gateway",
        endpoint: "https://workshop-embedding-api.vercel.app/api/health",
        description: "Embedding and proxy services",
        configurable: false
      }
    ];

    // Add n8n system if configured
    if (config.n8nUrl) {
      systemsArray.push({
        name: "n8n Workflow Engine",
        endpoint: config.n8nUrl,
        description: "Visual workflow automation",
        local: true,
        configurable: true
      });
    }

    // Add MongoDB system - either test endpoint or Atlas check
    if (config.mongoDbTestUrl) {
      systemsArray.push({
        name: "MongoDB Atlas",
        endpoint: config.mongoDbTestUrl,
        description: "Vector database and storage",
        configurable: true
      });
    } else {
      systemsArray.push({
        name: "MongoDB Atlas",
        endpoint: "https://workshop-embedding-api.vercel.app/api/check-db",
        description: "Vector database and storage (generic check)",
        configurable: false
      });
    }

    return systemsArray;
  };

  const currentSystems = systems || buildSystems();

  // Check system health
  const checkSystemHealth = async (system) => {
    try {
      const controller = new AbortController();
      const timeoutId = setTimeout(() => controller.abort(), 5000); // 5 second timeout
      
      const response = await fetch(system.endpoint, {
        method: 'GET',
        signal: controller.signal,
        mode: system.local ? 'no-cors' : 'cors'
      });
      
      clearTimeout(timeoutId);
      
      if (system.local && response.type === 'opaque') {
        // For local services, opaque response means it's reachable
        return { status: 'ok', responseTime: Date.now() };
      }
      
      if (response.ok) {
        const data = await response.json().catch(() => ({}));
        return { 
          status: 'ok', 
          responseTime: Date.now(),
          data: data
        };
      } else {
        return { 
          status: 'error', 
          responseTime: Date.now(),
          error: `HTTP ${response.status}`
        };
      }
    } catch (error) {
      if (error.name === 'AbortError') {
        return { status: 'timeout', error: 'Request timeout' };
      }
      return { 
        status: 'error', 
        error: system.local ? 'Service not running locally' : error.message 
      };
    }
  };

  // Check all systems
  const checkAllSystems = async () => {
    const results = {};
    
    for (const system of currentSystems) {
      results[system.name] = await checkSystemHealth(system);
    }
    
    setSystemStatus(results);
    setLastUpdate(new Date());
  };

  // Configuration form handlers
  const handleConfigSubmit = (e) => {
    e.preventDefault();
    const newConfig = { ...configForm };
    setConfig(newConfig);
    saveConfig(newConfig);
    setShowConfig(false);
    // Re-check systems with new config
    setTimeout(checkAllSystems, 100);
  };

  const handleConfigReset = () => {
    const detectedN8nUrl = detectCodespaceN8nUrl();
    const resetConfig = {
      n8nUrl: detectedN8nUrl || '',
      mongoDbTestUrl: '',
      codespaceId: ''
    };
    setConfigForm(resetConfig);
  };

  // Initial check and setup interval
  useEffect(() => {
    if (currentSystems.length > 0) {
      checkAllSystems();
    }
    
    const interval = setInterval(() => {
      if (currentSystems.length > 0) {
        checkAllSystems();
      }
    }, refreshInterval);
    return () => clearInterval(interval);
  }, [refreshInterval, config]); // Re-run when config changes

  // Get overall system status
  const getOverallStatus = () => {
    const statuses = Object.values(systemStatus);
    if (statuses.length === 0) return 'loading';
    if (statuses.every(s => s.status === 'ok')) return 'healthy';
    if (statuses.some(s => s.status === 'error' || s.status === 'timeout')) return 'degraded';
    return 'checking';
  };

  const overallStatus = getOverallStatus();

  return (
    <div className={styles.statusContainer}>
      <div 
        className={styles.statusHeader}
        onClick={() => setIsExpanded(!isExpanded)}
      >
        <div className={styles.statusIndicator}>
          <div className={`${styles.statusDot} ${styles[overallStatus]}`}></div>
          <span className={styles.statusText}>
            Workshop Systems: {overallStatus === 'healthy' ? 'All Online' : 
                              overallStatus === 'degraded' ? 'Issues Detected' : 
                              overallStatus === 'loading' ? 'Checking...' : 'Unknown'}
          </span>
        </div>
        
        <div className={styles.controls}>
          {lastUpdate && (
            <span className={styles.lastUpdate}>
              Last check: {lastUpdate.toLocaleTimeString()}
            </span>
          )}
          <button 
            onClick={(e) => {
              e.stopPropagation();
              setShowConfig(!showConfig);
            }}
            className={styles.refreshButton}
            title="Configure endpoints"
          >
            ⚙️
          </button>
          <button 
            onClick={(e) => {
              e.stopPropagation();
              checkAllSystems();
            }}
            className={styles.refreshButton}
            title="Refresh status"
          >
            🔄
          </button>
          <span className={styles.expandIcon}>
            {isExpanded ? '▼' : '▶'}
          </span>
        </div>
      </div>

      {showConfig && (
        <div className={styles.configPanel}>
          <form onSubmit={handleConfigSubmit} className={styles.configForm}>
            <h4>🔧 Configure Your Workshop Environment</h4>
            <p className={styles.configHelp}>
              Personalize the status checks for your specific Codespace and MongoDB Atlas instance.
            </p>
            
            <div className={styles.configField}>
              <label htmlFor="n8nUrl">n8n Workflow Engine URL:</label>
              <input
                type="text"
                id="n8nUrl"
                value={configForm.n8nUrl}
                onChange={(e) => setConfigForm({...configForm, n8nUrl: e.target.value})}
                placeholder="https://your-codespace-5678.app.github.dev/healthz"
                className={styles.configInput}
              />
              <small className={styles.configHint}>
                💡 Find this in your Codespace: Go to the PORTS tab and look for port 5678, then add '/healthz' to the URL
              </small>
            </div>

            <div className={styles.configField}>
              <label htmlFor="mongoDbTestUrl">MongoDB Atlas Test URL (optional):</label>
              <input
                type="text"
                id="mongoDbTestUrl"
                value={configForm.mongoDbTestUrl}
                onChange={(e) => setConfigForm({...configForm, mongoDbTestUrl: e.target.value})}
                placeholder="Custom MongoDB health check endpoint"
                className={styles.configInput}
              />
              <small className={styles.configHint}>
                💡 Leave empty to use the generic MongoDB check via workshop gateway
              </small>
            </div>

            <div className={styles.configActions}>
              <button type="submit" className={styles.configSave}>
                Save Configuration
              </button>
              <button type="button" onClick={handleConfigReset} className={styles.configReset}>
                Auto-Detect
              </button>
              <button type="button" onClick={() => setShowConfig(false)} className={styles.configCancel}>
                Cancel
              </button>
            </div>
          </form>
        </div>
      )}

      {isExpanded && (
        <div className={styles.systemDetails}>
          {currentSystems.map((system) => {
            const status = systemStatus[system.name] || { status: 'loading' };
            
            return (
              <div key={system.name} className={styles.systemRow}>
                <div className={styles.systemInfo}>
                  <div className={`${styles.systemDot} ${styles[status.status]}`}></div>
                  <div>
                    <div className={styles.systemName}>{system.name}</div>
                    <div className={styles.systemDescription}>{system.description}</div>
                  </div>
                </div>
                
                <div className={styles.systemStatus}>
                  <span className={`${styles.statusLabel} ${styles[status.status]}`}>
                    {status.status === 'ok' ? 'Online' :
                     status.status === 'error' ? 'Error' :
                     status.status === 'timeout' ? 'Timeout' : 'Checking...'}
                  </span>
                  
                  {status.error && (
                    <div className={styles.errorMessage}>{status.error}</div>
                  )}
                  
                  {system.local && status.status !== 'ok' && (
                    <div className={styles.localHelp}>
                      💡 Make sure your Codespace is running and n8n is started
                    </div>
                  )}
                </div>
              </div>
            );
          })}
          
          <div className={styles.statusFooter}>
            <div className={styles.helpText}>
              {overallStatus === 'healthy' ? 
                '✅ All systems operational - ready for workshop exercises!' :
                '⚠️ Some systems need attention - check the details above'}
            </div>
            
            <div className={styles.troubleshootLinks}>
              <a href="/docs/docker-troubleshooting" className={styles.helpLink}>
                🔧 Troubleshooting Guide
              </a>
              <a href="/docs/github-codespaces" className={styles.helpLink}>
                ☁️ Codespace Setup
              </a>
            </div>
          </div>
        </div>
      )}
    </div>
  );
}

// Compact version for inline use
export function StatusDot({ 
  system, 
  endpoint, 
  size = 'small',
  showLabel = true 
}) {
  const [status, setStatus] = useState('loading');
  
  useEffect(() => {
    const checkStatus = async () => {
      try {
        const response = await fetch(endpoint, { 
          method: 'GET',
          signal: AbortSignal.timeout(3000)
        });
        setStatus(response.ok ? 'ok' : 'error');
      } catch (error) {
        setStatus('error');
      }
    };
    
    checkStatus();
    const interval = setInterval(checkStatus, 60000); // Check every minute
    return () => clearInterval(interval);
  }, [endpoint]);

  return (
    <span className={`${styles.inlineStatus} ${styles[size]}`}>
      <div className={`${styles.statusDot} ${styles[status]}`}></div>
      {showLabel && <span>{system}: {status === 'ok' ? 'Online' : 'Offline'}</span>}
    </span>
  );
}

// System health dashboard for instructor view
export function SystemHealthDashboard() {
  return (
    <div className={styles.dashboard}>
      <h3>🖥️ Workshop System Health</h3>
      <LiveStatusBadge showDetails={true} refreshInterval={15000} />
      
      <div className={styles.dashboardHelp}>
        <h4>For Instructors:</h4>
        <ul>
          <li>Green: System is responsive and healthy</li>
          <li>Yellow: System responding but may be slow</li>
          <li>Red: System unreachable or error detected</li>
        </ul>
        
        <p>
          <strong>Before starting exercises:</strong> Verify all systems show green.
          If any are red, use the troubleshooting links or have attendees switch to working systems.
        </p>
      </div>
    </div>
  );
}

// Import and re-export specialized status badge components
export { default as CodespaceStatusBadge } from './CodespaceStatusBadge.js';
export { default as DockerServicesStatusBadge } from './DockerServicesStatusBadge.js';
export { default as MongoDBAtlasStatusBadge } from './MongoDBAtlasStatusBadge.js';
export { default as VoyageAIStatusBadge } from './VoyageAIStatusBadge.js';
export { default as WorkflowTestBadge } from './WorkflowTestBadge.js';
```

# src/components/LiveStatusBadge/MongoDBAtlasStatusBadge.js

```js
import React, { useState, useEffect } from 'react';
import LiveStatusBadge from './index.js';

/**
 * Specialized status badge for MongoDB Atlas setup validation
 * Used when attendees configure their MongoDB Atlas connection
 */
export default function MongoDBAtlasStatusBadge({ 
  showDetails = true,
  refreshInterval = 20000, // Less frequent for external service
  connectionString = null // Allow passing connection string for testing
}) {
  const [atlasConfig, setAtlasConfig] = useState({
    connectionString: connectionString || '',
    clusterName: '',
    database: 'workshop'
  });
  const [showConnectionForm, setShowConnectionForm] = useState(false);

  // Load saved Atlas configuration
  useEffect(() => {
    const savedConfig = localStorage.getItem('workshop-atlas-config');
    if (savedConfig) {
      try {
        const config = JSON.parse(savedConfig);
        setAtlasConfig(config);
      } catch (error) {
        console.warn('Could not load Atlas configuration:', error);
      }
    } else if (!connectionString) {
      setShowConnectionForm(true); // Show config form if no saved config
    }
  }, [connectionString]);

  const saveAtlasConfig = (config) => {
    try {
      localStorage.setItem('workshop-atlas-config', JSON.stringify(config));
    } catch (error) {
      console.warn('Could not save Atlas configuration:', error);
    }
  };

  const atlasSpecificSystems = [
    {
      name: "MongoDB Atlas Cluster",
      endpoint: "https://workshop-embedding-api.vercel.app/api/atlas-test",
      description: "Cloud MongoDB cluster connectivity",
      method: "POST",
      body: {
        connectionString: atlasConfig.connectionString,
        database: atlasConfig.database
      },
      expectedResponse: { status: 'connected' },
      configurable: true
    },
    {
      name: "Vector Search Index",
      endpoint: "https://workshop-embedding-api.vercel.app/api/vector-index-test", 
      description: "AI-powered search capabilities",
      method: "POST",
      body: {
        connectionString: atlasConfig.connectionString,
        database: atlasConfig.database,
        collection: 'embeddings'
      },
      dependsOn: "MongoDB Atlas Cluster",
      configurable: true
    },
    {
      name: "Database Permissions",
      endpoint: "https://workshop-embedding-api.vercel.app/api/permissions-test",
      description: "Read/write access verification", 
      method: "POST",
      body: {
        connectionString: atlasConfig.connectionString,
        database: atlasConfig.database
      },
      dependsOn: "MongoDB Atlas Cluster",
      configurable: true
    }
  ];

  const handleConfigSubmit = (e) => {
    e.preventDefault();
    const formData = new FormData(e.target);
    const newConfig = {
      connectionString: formData.get('connectionString'),
      clusterName: formData.get('clusterName') || 'workshop-cluster',
      database: formData.get('database') || 'workshop'
    };
    
    setAtlasConfig(newConfig);
    saveAtlasConfig(newConfig);
    setShowConnectionForm(false);
  };

  return (
    <div>
      <LiveStatusBadge 
        systems={atlasSpecificSystems}
        showDetails={showDetails}
        refreshInterval={refreshInterval}
      />
      
      {showConnectionForm && (
        <div style={{ 
          marginTop: '1rem', 
          padding: '1.5rem', 
          background: 'var(--ifm-color-warning-contrast-background)',
          borderRadius: '4px',
          border: '1px solid var(--ifm-color-warning-contrast-border)'
        }}>
          <h4 style={{ margin: '0 0 1rem 0', color: 'var(--ifm-color-warning)' }}>
            🔧 Configure MongoDB Atlas Connection
          </h4>
          
          <form onSubmit={handleConfigSubmit}>
            <div style={{ marginBottom: '1rem' }}>
              <label htmlFor="connectionString" style={{ display: 'block', marginBottom: '0.5rem', fontWeight: '600' }}>
                MongoDB Atlas Connection String:
              </label>
              <input
                type="text"
                id="connectionString"
                name="connectionString"
                placeholder="mongodb+srv://username:password@cluster.mongodb.net/"
                style={{
                  width: '100%',
                  padding: '0.75rem',
                  border: '1px solid var(--ifm-color-emphasis-300)',
                  borderRadius: '4px',
                  fontFamily: 'var(--ifm-font-family-monospace)',
                  fontSize: '0.85rem'
                }}
                required
                defaultValue={atlasConfig.connectionString}
              />
              <small style={{ color: 'var(--ifm-color-content-secondary)', fontSize: '0.8rem' }}>
                💡 Find this in your MongoDB Atlas dashboard under "Connect" → "Connect your application"
              </small>
            </div>

            <div style={{ display: 'grid', gridTemplateColumns: '1fr 1fr', gap: '1rem', marginBottom: '1rem' }}>
              <div>
                <label htmlFor="clusterName" style={{ display: 'block', marginBottom: '0.5rem', fontWeight: '600' }}>
                  Cluster Name (optional):
                </label>
                <input
                  type="text"
                  id="clusterName"
                  name="clusterName"
                  placeholder="workshop-cluster"
                  style={{
                    width: '100%',
                    padding: '0.75rem',
                    border: '1px solid var(--ifm-color-emphasis-300)',
                    borderRadius: '4px'
                  }}
                  defaultValue={atlasConfig.clusterName}
                />
              </div>
              
              <div>
                <label htmlFor="database" style={{ display: 'block', marginBottom: '0.5rem', fontWeight: '600' }}>
                  Database Name:
                </label>
                <input
                  type="text"
                  id="database"
                  name="database"
                  placeholder="workshop"
                  style={{
                    width: '100%',
                    padding: '0.75rem',
                    border: '1px solid var(--ifm-color-emphasis-300)',
                    borderRadius: '4px'
                  }}
                  defaultValue={atlasConfig.database}
                />
              </div>
            </div>

            <div style={{ display: 'flex', gap: '0.75rem', justifyContent: 'flex-end' }}>
              <button
                type="button"
                onClick={() => setShowConnectionForm(false)}
                style={{
                  padding: '0.5rem 1rem',
                  border: '1px solid var(--ifm-color-emphasis-300)',
                  borderRadius: '4px',
                  background: 'var(--ifm-background-color)',
                  cursor: 'pointer'
                }}
              >
                Cancel
              </button>
              <button
                type="submit"
                style={{
                  padding: '0.5rem 1rem',
                  border: 'none',
                  borderRadius: '4px',
                  background: 'var(--ifm-color-primary)',
                  color: 'white',
                  cursor: 'pointer'
                }}
              >
                Test Connection
              </button>
            </div>
          </form>
        </div>
      )}
      
      <div style={{ 
        marginTop: '1rem', 
        padding: '1rem', 
        background: 'var(--ifm-color-info-contrast-background)',
        borderRadius: '4px',
        border: '1px solid var(--ifm-color-info-contrast-border)'
      }}>
        <h4 style={{ margin: '0 0 0.5rem 0', color: 'var(--ifm-color-info)' }}>
          ☁️ MongoDB Atlas Setup Validation
        </h4>
        <div style={{ display: 'grid', gridTemplateColumns: 'repeat(auto-fit, minmax(200px, 1fr))', gap: '1rem', margin: '1rem 0' }}>
          <div>
            <strong>✅ Cluster Connectivity</strong>
            <br />
            <small>Basic connection to your Atlas cluster</small>
          </div>
          <div>
            <strong>🔍 Vector Search Ready</strong>
            <br />
            <small>AI-powered search index available</small>
          </div>
          <div>
            <strong>🔐 Permissions Verified</strong>
            <br />
            <small>Read/write access confirmed</small>
          </div>
        </div>
        
        <details style={{ marginTop: '1rem' }}>
          <summary style={{ cursor: 'pointer', fontWeight: '600' }}>
            🛠️ Atlas Setup Checklist
          </summary>
          <ul style={{ marginTop: '0.5rem', paddingLeft: '1.5rem' }}>
            <li>Create MongoDB Atlas account (free tier)</li>
            <li>Create a new cluster (M0 Sandbox is sufficient)</li>
            <li>Add your IP address to Network Access</li>
            <li>Create database user with read/write permissions</li>
            <li>Get connection string from "Connect" button</li>
            <li>Replace &lt;password&gt; with your actual password</li>
          </ul>
        </details>

        <div style={{ display: 'flex', alignItems: 'center', gap: '0.5rem', marginTop: '1rem' }}>
          <button
            onClick={() => setShowConnectionForm(true)}
            style={{
              padding: '0.5rem 1rem',
              border: '1px solid var(--ifm-color-primary)',
              borderRadius: '4px',
              background: 'var(--ifm-background-color)',
              color: 'var(--ifm-color-primary)',
              cursor: 'pointer',
              fontSize: '0.9rem'
            }}
          >
            ⚙️ Configure Connection
          </button>
          <span style={{ fontSize: '0.9rem', color: 'var(--ifm-color-content-secondary)' }}>
            Update your MongoDB Atlas connection details
          </span>
        </div>
      </div>
    </div>
  );
}
```

# src/components/LiveStatusBadge/styles.module.css

```css
.statusContainer {
  margin: 1rem 0;
  background: var(--ifm-background-surface-color);
  border: 2px solid var(--ifm-color-emphasis-200);
  border-radius: 8px;
  overflow: hidden;
  font-family: var(--ifm-font-family-base);
}

.statusHeader {
  display: flex;
  justify-content: space-between;
  align-items: center;
  padding: 0.75rem 1rem;
  background: var(--ifm-color-emphasis-100);
  cursor: pointer;
  transition: background-color 0.2s ease;
}

.statusHeader:hover {
  background: var(--ifm-color-emphasis-200);
}

.statusIndicator {
  display: flex;
  align-items: center;
  gap: 0.5rem;
}

.statusDot {
  width: 12px;
  height: 12px;
  border-radius: 50%;
  flex-shrink: 0;
  position: relative;
}

.statusDot.loading {
  background: #9ca3af;
  animation: pulse 2s infinite;
}

.statusDot.healthy {
  background: #10b981;
  box-shadow: 0 0 0 0 rgba(16, 185, 129, 0.7);
  animation: pulse-green 2s infinite;
}

.statusDot.ok {
  background: #10b981;
}

.statusDot.degraded {
  background: #f59e0b;
  animation: pulse-yellow 2s infinite;
}

.statusDot.error {
  background: #ef4444;
}

.statusDot.timeout {
  background: #f59e0b;
}

@keyframes pulse {
  0% {
    transform: scale(0.95);
    opacity: 1;
  }
  70% {
    transform: scale(1);
    opacity: 0.7;
  }
  100% {
    transform: scale(0.95);
    opacity: 1;
  }
}

@keyframes pulse-green {
  0% {
    box-shadow: 0 0 0 0 rgba(16, 185, 129, 0.7);
  }
  70% {
    box-shadow: 0 0 0 4px rgba(16, 185, 129, 0);
  }
  100% {
    box-shadow: 0 0 0 0 rgba(16, 185, 129, 0);
  }
}

@keyframes pulse-yellow {
  0% {
    box-shadow: 0 0 0 0 rgba(245, 158, 11, 0.7);
  }
  70% {
    box-shadow: 0 0 0 4px rgba(245, 158, 11, 0);
  }
  100% {
    box-shadow: 0 0 0 0 rgba(245, 158, 11, 0);
  }
}

.statusText {
  font-weight: 600;
  color: var(--ifm-color-content);
  font-size: 0.9rem;
}

.controls {
  display: flex;
  align-items: center;
  gap: 0.75rem;
  font-size: 0.8rem;
}

.lastUpdate {
  color: var(--ifm-color-content-secondary);
  font-family: var(--ifm-font-family-monospace);
}

.refreshButton {
  background: none;
  border: none;
  cursor: pointer;
  font-size: 1rem;
  padding: 0.25rem;
  border-radius: 4px;
  transition: background-color 0.2s ease;
}

.refreshButton:hover {
  background: var(--ifm-color-emphasis-200);
}

.expandIcon {
  color: var(--ifm-color-content-secondary);
  font-size: 0.8rem;
  transition: transform 0.2s ease;
}

.systemDetails {
  border-top: 1px solid var(--ifm-color-emphasis-200);
  background: var(--ifm-background-color);
}

.systemRow {
  display: flex;
  justify-content: space-between;
  align-items: center;
  padding: 1rem;
  border-bottom: 1px solid var(--ifm-color-emphasis-100);
}

.systemRow:last-child {
  border-bottom: none;
}

.systemInfo {
  display: flex;
  align-items: center;
  gap: 0.75rem;
  flex: 1;
}

.systemDot {
  width: 10px;
  height: 10px;
  border-radius: 50%;
  flex-shrink: 0;
}

.systemName {
  font-weight: 600;
  color: var(--ifm-color-content);
  font-size: 0.9rem;
}

.systemDescription {
  color: var(--ifm-color-content-secondary);
  font-size: 0.8rem;
  margin-top: 0.25rem;
}

.systemStatus {
  text-align: right;
}

.statusLabel {
  font-weight: 600;
  font-size: 0.8rem;
  padding: 0.25rem 0.5rem;
  border-radius: 4px;
  text-transform: uppercase;
  letter-spacing: 0.5px;
}

.statusLabel.ok {
  background: rgba(16, 185, 129, 0.1);
  color: #059669;
}

.statusLabel.error {
  background: rgba(239, 68, 68, 0.1);
  color: #dc2626;
}

.statusLabel.timeout {
  background: rgba(245, 158, 11, 0.1);
  color: #d97706;
}

.statusLabel.loading {
  background: rgba(156, 163, 175, 0.1);
  color: #6b7280;
}

.errorMessage {
  color: var(--ifm-color-danger);
  font-size: 0.75rem;
  margin-top: 0.25rem;
  font-family: var(--ifm-font-family-monospace);
}

.localHelp {
  color: var(--ifm-color-info);
  font-size: 0.75rem;
  margin-top: 0.25rem;
  font-style: italic;
}

.statusFooter {
  padding: 1rem;
  background: var(--ifm-color-emphasis-50);
  border-top: 1px solid var(--ifm-color-emphasis-200);
}

.helpText {
  margin-bottom: 0.75rem;
  font-size: 0.9rem;
  color: var(--ifm-color-content);
}

.troubleshootLinks {
  display: flex;
  gap: 1rem;
  flex-wrap: wrap;
}

.helpLink {
  color: var(--ifm-color-primary);
  text-decoration: none;
  font-size: 0.8rem;
  font-weight: 500;
}

.helpLink:hover {
  text-decoration: underline;
}

/* Inline status dot */
.inlineStatus {
  display: inline-flex;
  align-items: center;
  gap: 0.25rem;
  margin: 0 0.25rem;
}

.inlineStatus.small .statusDot {
  width: 8px;
  height: 8px;
}

.inlineStatus span {
  font-size: 0.8rem;
  color: var(--ifm-color-content-secondary);
}

/* Dashboard styles */
.dashboard {
  margin: 2rem 0;
  padding: 1.5rem;
  background: var(--ifm-color-emphasis-50);
  border-radius: 8px;
  border: 1px solid var(--ifm-color-emphasis-200);
}

.dashboard h3 {
  margin: 0 0 1rem 0;
  color: var(--ifm-color-content);
}

.dashboardHelp {
  margin-top: 1.5rem;
  padding-top: 1rem;
  border-top: 1px solid var(--ifm-color-emphasis-200);
}

.dashboardHelp h4 {
  margin: 0 0 0.5rem 0;
  color: var(--ifm-color-content);
  font-size: 1rem;
}

.dashboardHelp ul {
  margin: 0.5rem 0;
  padding-left: 1.5rem;
}

.dashboardHelp li {
  margin-bottom: 0.25rem;
  font-size: 0.9rem;
  color: var(--ifm-color-content-secondary);
}

.dashboardHelp p {
  margin: 1rem 0 0 0;
  font-size: 0.9rem;
  color: var(--ifm-color-content);
}

/* Dark theme adjustments */
[data-theme='dark'] .statusContainer {
  border-color: var(--ifm-color-emphasis-300);
}

[data-theme='dark'] .statusHeader {
  background: var(--ifm-color-emphasis-200);
}

[data-theme='dark'] .statusHeader:hover {
  background: var(--ifm-color-emphasis-300);
}

[data-theme='dark'] .systemDetails {
  background: var(--ifm-color-emphasis-100);
}

[data-theme='dark'] .statusFooter {
  background: var(--ifm-color-emphasis-200);
}

/* Mobile responsiveness */
@media (max-width: 768px) {
  .statusHeader {
    padding: 0.5rem;
  }
  
  .controls {
    gap: 0.5rem;
  }
  
  .lastUpdate {
    display: none;
  }
  
  .systemRow {
    padding: 0.75rem 0.5rem;
    flex-direction: column;
    align-items: flex-start;
    gap: 0.5rem;
  }
  
  .systemStatus {
    text-align: left;
    width: 100%;
  }
  
  .troubleshootLinks {
    flex-direction: column;
    gap: 0.5rem;
  }
}

/* Configuration panel styles */
.configPanel {
  border-top: 1px solid var(--ifm-color-emphasis-200);
  background: var(--ifm-color-emphasis-50);
  padding: 1.5rem;
}

.configForm h4 {
  margin: 0 0 0.5rem 0;
  color: var(--ifm-color-content);
  font-size: 1rem;
}

.configHelp {
  margin: 0 0 1.5rem 0;
  color: var(--ifm-color-content-secondary);
  font-size: 0.9rem;
  line-height: 1.4;
}

.configField {
  margin-bottom: 1.5rem;
}

.configField label {
  display: block;
  margin-bottom: 0.5rem;
  font-weight: 600;
  color: var(--ifm-color-content);
  font-size: 0.9rem;
}

.configInput {
  width: 100%;
  padding: 0.75rem;
  border: 1px solid var(--ifm-color-emphasis-300);
  border-radius: 4px;
  font-size: 0.9rem;
  font-family: var(--ifm-font-family-monospace);
  background: var(--ifm-background-color);
  color: var(--ifm-color-content);
  transition: border-color 0.2s ease;
}

.configInput:focus {
  outline: none;
  border-color: var(--ifm-color-primary);
  box-shadow: 0 0 0 2px rgba(var(--ifm-color-primary-rgb), 0.1);
}

.configHint {
  display: block;
  margin-top: 0.5rem;
  color: var(--ifm-color-content-secondary);
  font-size: 0.8rem;
  line-height: 1.3;
}

.configActions {
  display: flex;
  gap: 0.75rem;
  justify-content: flex-end;
  margin-top: 1.5rem;
}

.configSave,
.configReset,
.configCancel {
  padding: 0.5rem 1rem;
  border: none;
  border-radius: 4px;
  font-size: 0.9rem;
  font-weight: 500;
  cursor: pointer;
  transition: all 0.2s ease;
}

.configSave {
  background: var(--ifm-color-primary);
  color: white;
}

.configSave:hover {
  background: var(--ifm-color-primary-dark);
}

.configReset {
  background: var(--ifm-color-info);
  color: white;
}

.configReset:hover {
  background: var(--ifm-color-info-dark);
}

.configCancel {
  background: var(--ifm-color-emphasis-200);
  color: var(--ifm-color-content);
}

.configCancel:hover {
  background: var(--ifm-color-emphasis-300);
}

/* Dark theme adjustments for config panel */
[data-theme='dark'] .configPanel {
  background: var(--ifm-color-emphasis-200);
}

[data-theme='dark'] .configInput {
  background: var(--ifm-color-emphasis-100);
  border-color: var(--ifm-color-emphasis-400);
}

/* Mobile responsiveness for config panel */
@media (max-width: 768px) {
  .configPanel {
    padding: 1rem;
  }
  
  .configActions {
    flex-direction: column;
    gap: 0.5rem;
  }
  
  .configSave,
  .configReset,
  .configCancel {
    width: 100%;
  }
}
```

# src/components/LiveStatusBadge/VoyageAIStatusBadge.js

```js
import React, { useState, useEffect } from 'react';
import LiveStatusBadge from './index.js';

/**
 * Specialized status badge for Voyage AI integration testing
 * Used when attendees test their embedding generation capabilities
 */
export default function VoyageAIStatusBadge({ 
  showDetails = true,
  refreshInterval = 30000, // Less frequent for external API
  testMode = 'workshop' // 'workshop' uses proxy, 'direct' uses user's API key
}) {
  const [testResults, setTestResults] = useState({});
  const [isRunningTest, setIsRunningTest] = useState(false);

  const voyageAITestSystems = [
    {
      name: "Workshop API Gateway",
      endpoint: "https://workshop-embedding-api.vercel.app/api/health",
      description: "Proxy service for Voyage AI access",
      expectedResponse: { status: 'ok' }
    },
    {
      name: "Voyage AI Text Embeddings",
      endpoint: "https://workshop-embedding-api.vercel.app/api/embed",
      description: "Text-to-vector conversion",
      method: "POST",
      body: {
        input: { text: "This is a test embedding for the workshop" },
        model: "voyage-3",
        input_type: "document"
      },
      expectedResponse: { embeddings: [] },
      testResultKey: 'textEmbed'
    },
    {
      name: "Voyage AI Multimodal Embeddings", 
      endpoint: "https://workshop-embedding-api.vercel.app/api/embed",
      description: "Combined text + image embeddings",
      method: "POST",
      body: {
        input: { 
          text: "Sample document text",
          image: "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mP8/5+hHgAHggJ/PchI7wAAAABJRU5ErkJggg==" // 1x1 pixel PNG
        },
        model: "voyage-multimodal-3"
      },
      expectedResponse: { embeddings: [] },
      testResultKey: 'multimodalEmbed'
    },
    {
      name: "Embedding Dimensions",
      endpoint: null, // Custom test based on previous results
      description: "Verify 1024-dimensional vectors",
      customTest: async () => {
        const textResult = testResults.textEmbed;
        if (textResult && textResult.embeddings && textResult.embeddings.length > 0) {
          const dimensions = textResult.embeddings[0].length;
          return {
            status: dimensions === 1024 ? 'ok' : 'error',
            message: `Vector dimensions: ${dimensions} (expected: 1024)`,
            dimensions
          };
        }
        return { status: 'pending', message: 'Waiting for embedding test results' };
      },
      dependsOn: ["Voyage AI Text Embeddings"]
    }
  ];

  // Run comprehensive embedding test
  const runEmbeddingTest = async () => {
    setIsRunningTest(true);
    const results = {};
    
    try {
      // Test text embeddings
      const textResponse = await fetch('https://workshop-embedding-api.vercel.app/api/embed', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          input: { text: "Workshop embedding test - text only" },
          model: "voyage-3",
          input_type: "document"
        })
      });
      
      if (textResponse.ok) {
        results.textEmbed = await textResponse.json();
      }

      // Test multimodal embeddings
      const multimodalResponse = await fetch('https://workshop-embedding-api.vercel.app/api/embed', {
        method: 'POST', 
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          input: { 
            text: "Workshop test - multimodal",
            image: "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mP8/5+hHgAHggJ/PchI7wAAAABJRU5ErkJggg=="
          },
          model: "voyage-multimodal-3"
        })
      });
      
      if (multimodalResponse.ok) {
        results.multimodalEmbed = await multimodalResponse.json();
      }

      setTestResults(results);
    } catch (error) {
      console.error('Embedding test failed:', error);
    } finally {
      setIsRunningTest(false);
    }
  };

  return (
    <div>
      <LiveStatusBadge 
        systems={voyageAITestSystems}
        showDetails={showDetails}
        refreshInterval={refreshInterval}
      />
      
      <div style={{ 
        marginTop: '1rem', 
        padding: '1rem', 
        background: 'var(--ifm-color-secondary-contrast-background)',
        borderRadius: '4px',
        border: '1px solid var(--ifm-color-secondary-contrast-border)'
      }}>
        <h4 style={{ margin: '0 0 0.5rem 0', color: 'var(--ifm-color-secondary)' }}>
          🚀 Voyage AI Integration Testing
        </h4>
        
        <div style={{ display: 'grid', gridTemplateColumns: 'repeat(auto-fit, minmax(250px, 1fr))', gap: '1rem', margin: '1rem 0' }}>
          <div>
            <strong>📝 Text Embeddings</strong>
            <br />
            <small>Convert text to 1024-dimensional vectors</small>
            {testResults.textEmbed && (
              <div style={{ marginTop: '0.5rem', fontSize: '0.8rem', color: 'var(--ifm-color-success)' }}>
                ✅ {testResults.textEmbed.embeddings?.[0]?.length || 0} dimensions
              </div>
            )}
          </div>
          
          <div>
            <strong>🖼️ Multimodal Embeddings</strong>
            <br />
            <small>Unified text + image vector space</small>
            {testResults.multimodalEmbed && (
              <div style={{ marginTop: '0.5rem', fontSize: '0.8rem', color: 'var(--ifm-color-success)' }}>
                ✅ {testResults.multimodalEmbed.embeddings?.[0]?.length || 0} dimensions
              </div>
            )}
          </div>
          
          <div>
            <strong>⚡ API Performance</strong>
            <br />
            <small>Response time and throughput</small>
            {testResults.textEmbed && (
              <div style={{ marginTop: '0.5rem', fontSize: '0.8rem', color: 'var(--ifm-color-info)' }}>
                📊 Usage: {testResults.textEmbed.usage?.total_tokens || 0} tokens
              </div>
            )}
          </div>
        </div>

        <div style={{ 
          display: 'flex', 
          alignItems: 'center', 
          gap: '1rem', 
          marginTop: '1rem',
          padding: '1rem',
          background: 'var(--ifm-color-emphasis-100)',
          borderRadius: '4px'
        }}>
          <button
            onClick={runEmbeddingTest}
            disabled={isRunningTest}
            style={{
              padding: '0.75rem 1.5rem',
              border: 'none',
              borderRadius: '4px',
              background: isRunningTest ? 'var(--ifm-color-emphasis-300)' : 'var(--ifm-color-primary)',
              color: 'white',
              cursor: isRunningTest ? 'not-allowed' : 'pointer',
              fontSize: '0.9rem',
              fontWeight: '600'
            }}
          >
            {isRunningTest ? '🔄 Testing...' : '🧪 Run Embedding Test'}
          </button>
          
          <div style={{ flex: 1 }}>
            <strong>Comprehensive Test</strong>
            <br />
            <small style={{ color: 'var(--ifm-color-content-secondary)' }}>
              Tests both text and multimodal embedding generation with real API calls
            </small>
          </div>
        </div>

        <details style={{ marginTop: '1rem' }}>
          <summary style={{ cursor: 'pointer', fontWeight: '600' }}>
            📋 What This Test Validates
          </summary>
          <ul style={{ marginTop: '0.5rem', paddingLeft: '1.5rem', fontSize: '0.9rem' }}>
            <li><strong>API Connectivity:</strong> Workshop gateway can reach Voyage AI services</li>
            <li><strong>Text Processing:</strong> Plain text converts to 1024-dimensional vectors</li>
            <li><strong>Multimodal Processing:</strong> Combined text+image creates unified embeddings</li>
            <li><strong>Vector Dimensions:</strong> Confirms standard 1024-dimensional output</li>
            <li><strong>Response Format:</strong> Validates expected JSON structure and fields</li>
          </ul>
        </details>

        {testResults.textEmbed && (
          <details style={{ marginTop: '1rem' }}>
            <summary style={{ cursor: 'pointer', fontWeight: '600' }}>
              📊 Latest Test Results
            </summary>
            <div style={{ 
              marginTop: '0.5rem', 
              padding: '0.75rem',
              background: 'var(--ifm-background-color)',
              borderRadius: '4px',
              fontFamily: 'var(--ifm-font-family-monospace)',
              fontSize: '0.8rem',
              maxHeight: '200px',
              overflow: 'auto'
            }}>
              <div><strong>Text Embedding Sample:</strong></div>
              <div>Dimensions: {testResults.textEmbed.embeddings?.[0]?.length}</div>
              <div>First 5 values: [{testResults.textEmbed.embeddings?.[0]?.slice(0, 5).map(v => v.toFixed(4)).join(', ')}...]</div>
              <div>Usage: {JSON.stringify(testResults.textEmbed.usage)}</div>
              
              {testResults.multimodalEmbed && (
                <>
                  <div style={{ marginTop: '0.5rem' }}><strong>Multimodal Embedding Sample:</strong></div>
                  <div>Dimensions: {testResults.multimodalEmbed.embeddings?.[0]?.length}</div>
                  <div>First 5 values: [{testResults.multimodalEmbed.embeddings?.[0]?.slice(0, 5).map(v => v.toFixed(4)).join(', ')}...]</div>
                </>
              )}
            </div>
          </details>
        )}

        <p style={{ margin: '1rem 0 0 0', fontSize: '0.9rem', color: 'var(--ifm-color-content-secondary)' }}>
          💡 <strong>Next Step:</strong> Once embeddings work, you're ready to store them in MongoDB Atlas!
        </p>
      </div>
    </div>
  );
}
```

# src/components/LiveStatusBadge/WorkflowTestBadge.js

```js
import React, { useState, useEffect } from 'react';
import LiveStatusBadge from './index.js';

/**
 * Specialized status badge for testing complete n8n workflows
 * Used when attendees build and test their PDF processing workflows
 */
export default function WorkflowTestBadge({ 
  showDetails = true,
  refreshInterval = 45000, // Less frequent for complex workflow tests
  workflowEndpoint = null, // Allow custom workflow webhook URL
  testDocument = null // Allow custom test document
}) {
  const [workflowConfig, setWorkflowConfig] = useState({
    webhookUrl: workflowEndpoint || '',
    testDocumentUrl: testDocument || 'https://workshop-files.s3.amazonaws.com/sample-report.pdf'
  });
  const [testResults, setTestResults] = useState({});
  const [isRunningWorkflowTest, setIsRunningWorkflowTest] = useState(false);
  const [showWorkflowConfig, setShowWorkflowConfig] = useState(false);

  // Auto-detect n8n webhook URL if possible
  useEffect(() => {
    if (!workflowEndpoint && typeof window !== 'undefined') {
      const hostname = window.location.hostname;
      if (hostname.includes('app.github.dev')) {
        const parts = hostname.split('-');
        if (parts.length >= 2) {
          const codespaceId = parts[0];
          const detectedUrl = `https://${codespaceId}-5678.app.github.dev/webhook/pdf-upload`;
          setWorkflowConfig(prev => ({
            ...prev,
            webhookUrl: prev.webhookUrl || detectedUrl
          }));
        }
      }
    }
  }, [workflowEndpoint]);

  const workflowTestSystems = [
    {
      name: "n8n Webhook Endpoint",
      endpoint: workflowConfig.webhookUrl || null,
      description: "PDF upload webhook receiver",
      method: "POST",
      body: { test: true },
      local: true,
      configurable: true
    },
    {
      name: "PDF Processing Pipeline",
      endpoint: null, // Custom test
      description: "Complete PDF-to-embeddings workflow",
      customTest: async () => {
        if (!workflowConfig.webhookUrl) {
          return { status: 'error', message: 'Webhook URL not configured' };
        }
        
        try {
          const response = await fetch(workflowConfig.webhookUrl, {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({
              documentUrl: workflowConfig.testDocumentUrl,
              test: true
            })
          });
          
          if (response.ok) {
            const result = await response.json();
            return {
              status: 'ok',
              message: `Processed successfully: ${result.pages || 0} pages`,
              result
            };
          } else {
            return {
              status: 'error', 
              message: `HTTP ${response.status}: ${response.statusText}`
            };
          }
        } catch (error) {
          return {
            status: 'error',
            message: error.message
          };
        }
      },
      dependsOn: ["n8n Webhook Endpoint"]
    },
    {
      name: "MongoDB Storage",
      endpoint: null,
      description: "Embeddings stored in database",
      customTest: async () => {
        // This would check if the workflow actually stored data in MongoDB
        // For now, we'll simulate based on the PDF processing result
        const pdfResult = testResults.pdfProcessing;
        if (pdfResult && pdfResult.result && pdfResult.result.embeddings) {
          return {
            status: 'ok',
            message: `${pdfResult.result.embeddings.length} embeddings stored`
          };
        }
        return { status: 'pending', message: 'Waiting for PDF processing results' };
      },
      dependsOn: ["PDF Processing Pipeline"]
    }
  ];

  // Run comprehensive workflow test
  const runWorkflowTest = async () => {
    setIsRunningWorkflowTest(true);
    const results = {};
    
    try {
      // Test the complete workflow with a real document
      const response = await fetch(workflowConfig.webhookUrl, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          documentUrl: workflowConfig.testDocumentUrl,
          options: {
            maxPages: 3, // Limit for testing
            generateEmbeddings: true,
            storeInMongoDB: true
          }
        })
      });
      
      if (response.ok) {
        results.workflowTest = await response.json();
        results.success = true;
      } else {
        results.error = `HTTP ${response.status}: ${response.statusText}`;
        results.success = false;
      }
      
      setTestResults(results);
    } catch (error) {
      console.error('Workflow test failed:', error);
      setTestResults({ error: error.message, success: false });
    } finally {
      setIsRunningWorkflowTest(false);
    }
  };

  const handleConfigSubmit = (e) => {
    e.preventDefault();
    const formData = new FormData(e.target);
    setWorkflowConfig({
      webhookUrl: formData.get('webhookUrl'),
      testDocumentUrl: formData.get('testDocumentUrl')
    });
    setShowWorkflowConfig(false);
  };

  return (
    <div>
      <LiveStatusBadge 
        systems={workflowTestSystems}
        showDetails={showDetails}
        refreshInterval={refreshInterval}
      />
      
      {showWorkflowConfig && (
        <div style={{ 
          marginTop: '1rem', 
          padding: '1.5rem', 
          background: 'var(--ifm-color-warning-contrast-background)',
          borderRadius: '4px',
          border: '1px solid var(--ifm-color-warning-contrast-border)'
        }}>
          <h4 style={{ margin: '0 0 1rem 0', color: 'var(--ifm-color-warning)' }}>
            🔧 Configure Workflow Testing
          </h4>
          
          <form onSubmit={handleConfigSubmit}>
            <div style={{ marginBottom: '1rem' }}>
              <label htmlFor="webhookUrl" style={{ display: 'block', marginBottom: '0.5rem', fontWeight: '600' }}>
                n8n Webhook URL:
              </label>
              <input
                type="text"
                id="webhookUrl"
                name="webhookUrl"
                placeholder="https://your-codespace-5678.app.github.dev/webhook/pdf-upload"
                style={{
                  width: '100%',
                  padding: '0.75rem',
                  border: '1px solid var(--ifm-color-emphasis-300)',
                  borderRadius: '4px',
                  fontFamily: 'var(--ifm-font-family-monospace)',
                  fontSize: '0.85rem'
                }}
                required
                defaultValue={workflowConfig.webhookUrl}
              />
              <small style={{ color: 'var(--ifm-color-content-secondary)', fontSize: '0.8rem' }}>
                💡 This should be your n8n webhook trigger URL for the PDF processing workflow
              </small>
            </div>

            <div style={{ marginBottom: '1rem' }}>
              <label htmlFor="testDocumentUrl" style={{ display: 'block', marginBottom: '0.5rem', fontWeight: '600' }}>
                Test Document URL:
              </label>
              <input
                type="url"
                id="testDocumentUrl"
                name="testDocumentUrl"
                placeholder="https://example.com/sample-document.pdf"
                style={{
                  width: '100%',
                  padding: '0.75rem',
                  border: '1px solid var(--ifm-color-emphasis-300)',
                  borderRadius: '4px'
                }}
                defaultValue={workflowConfig.testDocumentUrl}
              />
              <small style={{ color: 'var(--ifm-color-content-secondary)', fontSize: '0.8rem' }}>
                💡 A publicly accessible PDF URL for testing your workflow
              </small>
            </div>

            <div style={{ display: 'flex', gap: '0.75rem', justifyContent: 'flex-end' }}>
              <button
                type="button"
                onClick={() => setShowWorkflowConfig(false)}
                style={{
                  padding: '0.5rem 1rem',
                  border: '1px solid var(--ifm-color-emphasis-300)',
                  borderRadius: '4px',
                  background: 'var(--ifm-background-color)',
                  cursor: 'pointer'
                }}
              >
                Cancel
              </button>
              <button
                type="submit"
                style={{
                  padding: '0.5rem 1rem',
                  border: 'none',
                  borderRadius: '4px',
                  background: 'var(--ifm-color-primary)',
                  color: 'white',
                  cursor: 'pointer'
                }}
              >
                Save Configuration
              </button>
            </div>
          </form>
        </div>
      )}
      
      <div style={{ 
        marginTop: '1rem', 
        padding: '1rem', 
        background: 'var(--ifm-color-success-contrast-background)',
        borderRadius: '4px',
        border: '1px solid var(--ifm-color-success-contrast-border)'
      }}>
        <h4 style={{ margin: '0 0 0.5rem 0', color: 'var(--ifm-color-success)' }}>
          🔄 End-to-End Workflow Testing
        </h4>
        
        <div style={{ display: 'grid', gridTemplateColumns: 'repeat(auto-fit, minmax(200px, 1fr))', gap: '1rem', margin: '1rem 0' }}>
          <div>
            <strong>📋 PDF Processing</strong>
            <br />
            <small>Text extraction and page analysis</small>
            {testResults.workflowTest?.pages && (
              <div style={{ marginTop: '0.5rem', fontSize: '0.8rem', color: 'var(--ifm-color-success)' }}>
                ✅ {testResults.workflowTest.pages} pages processed
              </div>
            )}
          </div>
          
          <div>
            <strong>🧠 Embedding Generation</strong>
            <br />
            <small>Text-to-vector conversion</small>
            {testResults.workflowTest?.embeddings && (
              <div style={{ marginTop: '0.5rem', fontSize: '0.8rem', color: 'var(--ifm-color-success)' }}>
                ✅ {testResults.workflowTest.embeddings.length} embeddings
              </div>
            )}
          </div>
          
          <div>
            <strong>💾 Database Storage</strong>
            <br />
            <small>MongoDB Atlas persistence</small>
            {testResults.workflowTest?.stored && (
              <div style={{ marginTop: '0.5rem', fontSize: '0.8rem', color: 'var(--ifm-color-success)' }}>
                ✅ Data stored successfully
              </div>
            )}
          </div>
        </div>

        <div style={{ 
          display: 'flex', 
          alignItems: 'center', 
          gap: '1rem', 
          marginTop: '1rem',
          padding: '1rem',
          background: 'var(--ifm-color-emphasis-100)',
          borderRadius: '4px'
        }}>
          <button
            onClick={runWorkflowTest}
            disabled={isRunningWorkflowTest || !workflowConfig.webhookUrl}
            style={{
              padding: '0.75rem 1.5rem',
              border: 'none',
              borderRadius: '4px',
              background: isRunningWorkflowTest || !workflowConfig.webhookUrl ? 
                'var(--ifm-color-emphasis-300)' : 'var(--ifm-color-success)',
              color: 'white',
              cursor: isRunningWorkflowTest || !workflowConfig.webhookUrl ? 'not-allowed' : 'pointer',
              fontSize: '0.9rem',
              fontWeight: '600'
            }}
          >
            {isRunningWorkflowTest ? '🔄 Testing Workflow...' : '🚀 Test Complete Workflow'}
          </button>
          
          <div style={{ flex: 1 }}>
            <strong>Full Pipeline Test</strong>
            <br />
            <small style={{ color: 'var(--ifm-color-content-secondary)' }}>
              Tests PDF upload → processing → embedding → storage pipeline
            </small>
          </div>
        </div>

        <div style={{ display: 'flex', alignItems: 'center', gap: '0.5rem', marginTop: '1rem' }}>
          <button
            onClick={() => setShowWorkflowConfig(true)}
            style={{
              padding: '0.5rem 1rem',
              border: '1px solid var(--ifm-color-primary)',
              borderRadius: '4px',
              background: 'var(--ifm-background-color)',
              color: 'var(--ifm-color-primary)',
              cursor: 'pointer',
              fontSize: '0.9rem'
            }}
          >
            ⚙️ Configure Endpoints
          </button>
          <span style={{ fontSize: '0.9rem', color: 'var(--ifm-color-content-secondary)' }}>
            Set your n8n webhook URL and test document
          </span>
        </div>

        {testResults.success === false && (
          <div style={{
            marginTop: '1rem',
            padding: '0.75rem',
            background: 'var(--ifm-color-danger-contrast-background)',
            border: '1px solid var(--ifm-color-danger-contrast-border)',
            borderRadius: '4px',
            color: 'var(--ifm-color-danger)'
          }}>
            <strong>❌ Test Failed:</strong> {testResults.error}
          </div>
        )}

        {testResults.workflowTest && (
          <details style={{ marginTop: '1rem' }}>
            <summary style={{ cursor: 'pointer', fontWeight: '600' }}>
              📊 Latest Workflow Results
            </summary>
            <div style={{ 
              marginTop: '0.5rem', 
              padding: '0.75rem',
              background: 'var(--ifm-background-color)',
              borderRadius: '4px',
              fontFamily: 'var(--ifm-font-family-monospace)',
              fontSize: '0.8rem',
              maxHeight: '300px',
              overflow: 'auto'
            }}>
              <pre>{JSON.stringify(testResults.workflowTest, null, 2)}</pre>
            </div>
          </details>
        )}

        <p style={{ margin: '1rem 0 0 0', fontSize: '0.9rem', color: 'var(--ifm-color-content-secondary)' }}>
          💡 <strong>Success means:</strong> Your complete PDF agent pipeline is working end-to-end!
        </p>
      </div>
    </div>
  );
}
```

# src/components/ProgressTracker/index.js

```js
import React, { useState, useEffect } from 'react';
import styles from './styles.module.css';

export default function ProgressTracker({ steps = [], currentStep = 0 }) {
  const [completedSteps, setCompletedSteps] = useState(new Set());

  useEffect(() => {
    // Load completed steps from localStorage
    const saved = localStorage.getItem('workshop-progress');
    if (saved) {
      try {
        const parsed = JSON.parse(saved);
        setCompletedSteps(new Set(parsed));
      } catch (e) {
        console.warn('Could not parse saved progress');
      }
    }
  }, []);

  useEffect(() => {
    // Save progress to localStorage
    localStorage.setItem('workshop-progress', JSON.stringify([...completedSteps]));
  }, [completedSteps]);

  const toggleStep = (stepIndex) => {
    const newCompleted = new Set(completedSteps);
    if (newCompleted.has(stepIndex)) {
      newCompleted.delete(stepIndex);
    } else {
      newCompleted.add(stepIndex);
    }
    setCompletedSteps(newCompleted);
  };

  const completionPercentage = (completedSteps.size / steps.length) * 100;

  return (
    <div className={styles.progressContainer}>
      <div className={styles.header}>
        <h3>🎓 Workshop Progress</h3>
        <div className={styles.stats}>
          <span className={styles.percentage}>{Math.round(completionPercentage)}% Complete</span>
          <span className={styles.count}>{completedSteps.size} / {steps.length}</span>
        </div>
      </div>
      
      <div className={styles.progressBar}>
        <div 
          className={styles.progressFill}
          style={{ width: `${completionPercentage}%` }}
        />
      </div>

      <div className={styles.stepsList}>
        {steps.map((step, index) => (
          <div 
            key={index}
            className={`${styles.step} ${
              completedSteps.has(index) ? styles.completed : ''
            } ${
              index === currentStep ? styles.current : ''
            }`}
          >
            <div className={styles.stepIndicator}>
              <div className={styles.stepNumber}>
                {completedSteps.has(index) ? '✅' : index + 1}
              </div>
              {index < steps.length - 1 && (
                <div className={`${styles.connector} ${
                  completedSteps.has(index) ? styles.connectorCompleted : ''
                }`} />
              )}
            </div>
            
            <div className={styles.stepContent}>
              <h4 className={styles.stepTitle}>{step.title}</h4>
              <p className={styles.stepDescription}>{step.description}</p>
              <div className={styles.stepMeta}>
                {step.timeEstimate && (
                  <span className={styles.timeEstimate}>⏱️ {step.timeEstimate}</span>
                )}
                {step.difficulty && (
                  <span className={`${styles.difficulty} ${styles[step.difficulty]}`}>
                    {step.difficulty}
                  </span>
                )}
              </div>
              
              <button
                className={styles.toggleButton}
                onClick={() => toggleStep(index)}
              >
                {completedSteps.has(index) ? 'Mark Incomplete' : 'Mark Complete'}
              </button>
            </div>
          </div>
        ))}
      </div>

      {completionPercentage === 100 && (
        <div className={styles.celebration}>
          🎉 Congratulations! You've completed the entire workshop! 🎉
        </div>
      )}
    </div>
  );
}

export function StepIndicator({ current, total, titles = [] }) {
  return (
    <div className={styles.stepIndicator}>
      <div className={styles.breadcrumb}>
        {Array.from({ length: total }, (_, i) => (
          <React.Fragment key={i}>
            <div className={`${styles.breadcrumbStep} ${
              i < current ? styles.completed : ''
            } ${
              i === current ? styles.active : ''
            }`}>
              <span className={styles.breadcrumbNumber}>
                {i < current ? '✓' : i + 1}
              </span>
              {titles[i] && (
                <span className={styles.breadcrumbTitle}>{titles[i]}</span>
              )}
            </div>
            {i < total - 1 && (
              <div className={`${styles.breadcrumbConnector} ${
                i < current ? styles.connectorCompleted : ''
              }`} />
            )}
          </React.Fragment>
        ))}
      </div>
    </div>
  );
}
```

# src/components/ProgressTracker/styles.module.css

```css
.progressContainer {
  background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
  color: white;
  border-radius: 12px;
  padding: 1.5rem;
  margin: 2rem 0;
  box-shadow: 0 8px 24px rgba(102, 126, 234, 0.3);
}

.header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 1rem;
}

.header h3 {
  margin: 0;
  font-size: 1.4rem;
}

.stats {
  display: flex;
  gap: 1rem;
  align-items: center;
}

.percentage {
  font-size: 1.2rem;
  font-weight: bold;
}

.count {
  background: rgba(255, 255, 255, 0.2);
  padding: 0.25rem 0.75rem;
  border-radius: 20px;
  font-size: 0.9rem;
}

.progressBar {
  background: rgba(255, 255, 255, 0.2);
  height: 8px;
  border-radius: 4px;
  overflow: hidden;
  margin-bottom: 1.5rem;
}

.progressFill {
  background: linear-gradient(90deg, #28a745, #20c997);
  height: 100%;
  border-radius: 4px;
  transition: width 0.5s ease;
}

.stepsList {
  display: flex;
  flex-direction: column;
  gap: 1rem;
}

.step {
  display: flex;
  background: rgba(255, 255, 255, 0.1);
  border-radius: 8px;
  padding: 1rem;
  transition: all 0.3s ease;
}

.step:hover {
  background: rgba(255, 255, 255, 0.15);
  transform: translateX(4px);
}

.step.completed {
  background: rgba(40, 167, 69, 0.2);
  border: 1px solid rgba(40, 167, 69, 0.4);
}

.step.current {
  background: rgba(255, 193, 7, 0.2);
  border: 2px solid #ffc107;
}

.stepIndicator {
  display: flex;
  flex-direction: column;
  align-items: center;
  margin-right: 1rem;
  position: relative;
}

.stepNumber {
  width: 2.5rem;
  height: 2.5rem;
  border-radius: 50%;
  background: rgba(255, 255, 255, 0.2);
  display: flex;
  align-items: center;
  justify-content: center;
  font-weight: bold;
  font-size: 1rem;
  position: relative;
  z-index: 1;
}

.step.completed .stepNumber {
  background: #28a745;
}

.step.current .stepNumber {
  background: #ffc107;
  color: #000;
}

.connector {
  width: 2px;
  height: 2rem;
  background: rgba(255, 255, 255, 0.3);
  margin-top: 0.5rem;
}

.connectorCompleted {
  background: #28a745;
}

.stepContent {
  flex: 1;
}

.stepTitle {
  margin: 0 0 0.5rem 0;
  font-size: 1.1rem;
}

.stepDescription {
  margin: 0 0 0.75rem 0;
  opacity: 0.9;
  line-height: 1.5;
}

.stepMeta {
  display: flex;
  gap: 1rem;
  margin-bottom: 0.75rem;
}

.timeEstimate {
  font-size: 0.9rem;
  opacity: 0.8;
}

.difficulty {
  padding: 0.2rem 0.6rem;
  border-radius: 12px;
  font-size: 0.8rem;
  font-weight: 600;
  text-transform: uppercase;
}

.difficulty.beginner {
  background: #28a745;
}

.difficulty.intermediate {
  background: #ffc107;
  color: #000;
}

.difficulty.advanced {
  background: #dc3545;
}

.toggleButton {
  background: rgba(255, 255, 255, 0.2);
  color: white;
  border: 1px solid rgba(255, 255, 255, 0.3);
  padding: 0.5rem 1rem;
  border-radius: 6px;
  cursor: pointer;
  font-size: 0.9rem;
  transition: all 0.2s ease;
}

.toggleButton:hover {
  background: rgba(255, 255, 255, 0.3);
  border-color: rgba(255, 255, 255, 0.5);
}

.celebration {
  text-align: center;
  background: linear-gradient(135deg, #28a745, #20c997);
  padding: 1.5rem;
  border-radius: 8px;
  margin-top: 1.5rem;
  font-size: 1.2rem;
  font-weight: bold;
  animation: bounce 2s infinite;
}

@keyframes bounce {
  0%, 20%, 50%, 80%, 100% {
    transform: translateY(0);
  }
  40% {
    transform: translateY(-10px);
  }
  60% {
    transform: translateY(-5px);
  }
}

/* Step Indicator Component */
.breadcrumb {
  display: flex;
  align-items: center;
  gap: 0.5rem;
  padding: 1rem;
  background: #f8f9fa;
  border-radius: 8px;
  margin: 1rem 0;
  overflow-x: auto;
}

.breadcrumbStep {
  display: flex;
  align-items: center;
  gap: 0.5rem;
  padding: 0.5rem 1rem;
  border-radius: 20px;
  background: #e9ecef;
  color: #6c757d;
  transition: all 0.3s ease;
  white-space: nowrap;
}

.breadcrumbStep.completed {
  background: #28a745;
  color: white;
}

.breadcrumbStep.active {
  background: #007bff;
  color: white;
  transform: scale(1.05);
}

.breadcrumbNumber {
  width: 1.5rem;
  height: 1.5rem;
  border-radius: 50%;
  background: rgba(255, 255, 255, 0.2);
  display: flex;
  align-items: center;
  justify-content: center;
  font-size: 0.8rem;
  font-weight: bold;
}

.breadcrumbTitle {
  font-size: 0.9rem;
  font-weight: 500;
}

.breadcrumbConnector {
  width: 2rem;
  height: 2px;
  background: #dee2e6;
  transition: background-color 0.3s ease;
}

.breadcrumbConnector.connectorCompleted {
  background: #28a745;
}
```

# src/components/QuickEmbeddingTest/index.js

```js
import React, { useState } from 'react';
import styles from './styles.module.css';

export default function QuickEmbeddingTest({ 
  text = "Test the workshop embedding API with this sample text",
  label = "Quick API Test"
}) {
  const [loading, setLoading] = useState(false);
  const [result, setResult] = useState(null);
  const [error, setError] = useState(null);

  const testAPI = async () => {
    setLoading(true);
    setError(null);
    setResult(null);

    try {
      const response = await fetch('https://workshop-embedding-api.vercel.app/api/embed', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          text: text,
          model: 'voyage-3'
        }),
      });

      const data = await response.json();

      if (!response.ok) {
        throw new Error(data.error || `HTTP ${response.status}`);
      }

      setResult(data);
    } catch (err) {
      setError(err.message);
    } finally {
      setLoading(false);
    }
  };

  return (
    <div className={styles.quickTest}>
      <div className={styles.header}>
        <span className={styles.label}>{label}</span>
        <button 
          onClick={testAPI}
          disabled={loading}
          className={styles.testButton}
        >
          {loading ? '⏳ Testing...' : '🚀 Test API'}
        </button>
      </div>

      {error && (
        <div className={styles.error}>
          ❌ {error}
        </div>
      )}

      {result && (
        <div className={styles.success}>
          ✅ API Working! Generated {result.embeddings[0].length}D embedding
          <div className={styles.details}>
            Model: {result.model} | Tokens: {result.usage?.total_tokens || 'N/A'}
          </div>
        </div>
      )}

      <div className={styles.testText}>
        <strong>Test text:</strong> "{text.substring(0, 100)}{text.length > 100 ? '...' : ''}"
      </div>
    </div>
  );
}
```

# src/components/QuickEmbeddingTest/styles.module.css

```css
.quickTest {
  background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
  border-radius: 8px;
  padding: 1rem;
  margin: 1rem 0;
  color: white;
  font-size: 0.9rem;
}

.header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 0.75rem;
}

.label {
  font-weight: 600;
  font-size: 1rem;
}

.testButton {
  background: rgba(255, 255, 255, 0.2);
  color: white;
  border: 2px solid rgba(255, 255, 255, 0.3);
  padding: 0.5rem 1rem;
  border-radius: 6px;
  cursor: pointer;
  font-weight: 600;
  font-size: 0.9rem;
  transition: all 0.2s ease;
}

.testButton:hover:not(:disabled) {
  background: rgba(255, 255, 255, 0.3);
  transform: translateY(-1px);
}

.testButton:disabled {
  opacity: 0.7;
  cursor: not-allowed;
  transform: none;
}

.error {
  background: rgba(239, 68, 68, 0.3);
  border: 1px solid #ef4444;
  border-radius: 4px;
  padding: 0.75rem;
  margin: 0.5rem 0;
  font-weight: 500;
}

.success {
  background: rgba(16, 185, 129, 0.3);
  border: 1px solid #10b981;
  border-radius: 4px;
  padding: 0.75rem;
  margin: 0.5rem 0;
  font-weight: 500;
}

.details {
  font-size: 0.8rem;
  opacity: 0.9;
  margin-top: 0.25rem;
  font-family: monospace;
}

.testText {
  background: rgba(0, 0, 0, 0.2);
  border-radius: 4px;
  padding: 0.5rem;
  font-size: 0.85rem;
  margin-top: 0.5rem;
  font-style: italic;
}

/* Dark mode adjustments */
[data-theme='dark'] .error {
  background: rgba(239, 68, 68, 0.2);
  border-color: #dc2626;
}

[data-theme='dark'] .success {
  background: rgba(16, 185, 129, 0.2);
  border-color: #059669;
}

/* Mobile responsive */
@media (max-width: 480px) {
  .header {
    flex-direction: column;
    gap: 0.5rem;
    text-align: center;
  }
  
  .testButton {
    width: 100%;
  }
}
```

# src/components/Quiz/index.js

```js
import React, { useState } from 'react';
import styles from './styles.module.css';

export default function Quiz({ 
  title, 
  questions = [], 
  onComplete,
  passingScore = 70 
}) {
  const [currentQuestion, setCurrentQuestion] = useState(0);
  const [answers, setAnswers] = useState({});
  const [showResults, setShowResults] = useState(false);
  const [score, setScore] = useState(0);

  const handleAnswer = (questionIndex, answerIndex) => {
    setAnswers(prev => ({
      ...prev,
      [questionIndex]: answerIndex
    }));
  };

  const calculateScore = () => {
    let correct = 0;
    questions.forEach((question, index) => {
      if (answers[index] === question.correctAnswer) {
        correct++;
      }
    });
    return Math.round((correct / questions.length) * 100);
  };

  const handleSubmit = () => {
    const finalScore = calculateScore();
    setScore(finalScore);
    setShowResults(true);
    
    // Save to localStorage
    localStorage.setItem(`quiz-${title}`, JSON.stringify({
      score: finalScore,
      passed: finalScore >= passingScore,
      answers,
      completedAt: new Date().toISOString()
    }));

    if (onComplete) {
      onComplete({ score: finalScore, passed: finalScore >= passingScore });
    }
  };

  const resetQuiz = () => {
    setCurrentQuestion(0);
    setAnswers({});
    setShowResults(false);
    setScore(0);
  };

  if (showResults) {
    const passed = score >= passingScore;
    return (
      <div className={styles.quiz}>
        <div className={styles.results}>
          <div className={`${styles.scoreCard} ${passed ? styles.passed : styles.failed}`}>
            <div className={styles.scoreIcon}>
              {passed ? '🎉' : '📚'}
            </div>
            <h3>Quiz Results</h3>
            <div className={styles.scoreDisplay}>
              <span className={styles.scoreNumber}>{score}%</span>
              <span className={styles.scoreLabel}>
                {passed ? 'Passed!' : 'Needs Review'}
              </span>
            </div>
            
            {passed ? (
              <p>Excellent work! You've mastered this topic.</p>
            ) : (
              <p>Review the material and try again. You need {passingScore}% to pass.</p>
            )}
          </div>

          <div className={styles.answerReview}>
            <h4>Review Your Answers:</h4>
            {questions.map((question, qIndex) => (
              <div key={qIndex} className={styles.reviewQuestion}>
                <h5>Q{qIndex + 1}: {question.question}</h5>
                <div className={styles.reviewAnswers}>
                  {question.options.map((option, aIndex) => {
                    const isSelected = answers[qIndex] === aIndex;
                    const isCorrect = aIndex === question.correctAnswer;
                    
                    return (
                      <div 
                        key={aIndex}
                        className={`${styles.reviewAnswer} ${
                          isSelected ? styles.selected : ''
                        } ${
                          isCorrect ? styles.correct : ''
                        } ${
                          isSelected && !isCorrect ? styles.incorrect : ''
                        }`}
                      >
                        {option}
                        {isCorrect && <span className={styles.correctIcon}>✓</span>}
                        {isSelected && !isCorrect && <span className={styles.incorrectIcon}>✗</span>}
                      </div>
                    );
                  })}
                </div>
                {question.explanation && (
                  <div className={styles.explanation}>
                    <strong>Explanation:</strong> {question.explanation}
                  </div>
                )}
              </div>
            ))}
          </div>

          <div className={styles.resultActions}>
            <button className={styles.retryButton} onClick={resetQuiz}>
              Try Again
            </button>
            {passed && (
              <button className={styles.continueButton}>
                Continue to Next Section →
              </button>
            )}
          </div>
        </div>
      </div>
    );
  }

  const currentQ = questions[currentQuestion];
  const progress = ((currentQuestion + 1) / questions.length) * 100;

  return (
    <div className={styles.quiz}>
      <div className={styles.header}>
        <h3>{title}</h3>
        <div className={styles.progress}>
          <div className={styles.progressBar}>
            <div 
              className={styles.progressFill}
              style={{ width: `${progress}%` }}
            />
          </div>
          <span className={styles.progressText}>
            {currentQuestion + 1} of {questions.length}
          </span>
        </div>
      </div>

      <div className={styles.questionCard}>
        <h4 className={styles.questionText}>
          {currentQ?.question}
        </h4>

        <div className={styles.options}>
          {currentQ?.options.map((option, index) => (
            <button
              key={index}
              className={`${styles.option} ${
                answers[currentQuestion] === index ? styles.selected : ''
              }`}
              onClick={() => handleAnswer(currentQuestion, index)}
            >
              <span className={styles.optionLetter}>
                {String.fromCharCode(65 + index)}
              </span>
              {option}
            </button>
          ))}
        </div>
      </div>

      <div className={styles.navigation}>
        <button
          className={styles.navButton}
          onClick={() => setCurrentQuestion(Math.max(0, currentQuestion - 1))}
          disabled={currentQuestion === 0}
        >
          ← Previous
        </button>

        <div className={styles.questionDots}>
          {questions.map((_, index) => (
            <button
              key={index}
              className={`${styles.dot} ${
                index === currentQuestion ? styles.active : ''
              } ${
                answers[index] !== undefined ? styles.answered : ''
              }`}
              onClick={() => setCurrentQuestion(index)}
            >
              {index + 1}
            </button>
          ))}
        </div>

        {currentQuestion < questions.length - 1 ? (
          <button
            className={styles.navButton}
            onClick={() => setCurrentQuestion(currentQuestion + 1)}
          >
            Next →
          </button>
        ) : (
          <button
            className={styles.submitButton}
            onClick={handleSubmit}
            disabled={Object.keys(answers).length < questions.length}
          >
            Submit Quiz
          </button>
        )}
      </div>
    </div>
  );
}

export function QuickCheck({ question, options, correctAnswer, explanation }) {
  const [selected, setSelected] = useState(null);
  const [showResult, setShowResult] = useState(false);

  const handleAnswer = (index) => {
    setSelected(index);
    setShowResult(true);
  };

  const isCorrect = selected === correctAnswer;

  return (
    <div className={styles.quickCheck}>
      <h4>🤔 Quick Check</h4>
      <p className={styles.quickQuestion}>{question}</p>
      
      <div className={styles.quickOptions}>
        {options.map((option, index) => (
          <button
            key={index}
            className={`${styles.quickOption} ${
              selected === index ? styles.selected : ''
            } ${
              showResult && index === correctAnswer ? styles.correct : ''
            } ${
              showResult && selected === index && index !== correctAnswer ? styles.incorrect : ''
            }`}
            onClick={() => handleAnswer(index)}
            disabled={showResult}
          >
            {option}
          </button>
        ))}
      </div>

      {showResult && (
        <div className={`${styles.quickResult} ${isCorrect ? styles.correct : styles.incorrect}`}>
          <div className={styles.resultIcon}>
            {isCorrect ? '✅' : '❌'}
          </div>
          <div className={styles.resultText}>
            {isCorrect ? 'Correct!' : 'Not quite right.'}
            {explanation && (
              <p className={styles.quickExplanation}>{explanation}</p>
            )}
          </div>
        </div>
      )}
    </div>
  );
}
```

# src/components/Quiz/styles.module.css

```css
.quiz {
  background: #ffffff;
  border: 2px solid #e1e8ed;
  border-radius: 12px;
  margin: 2rem 0;
  overflow: hidden;
  box-shadow: 0 4px 16px rgba(0, 0, 0, 0.1);
}

.header {
  background: linear-gradient(135deg, #6366f1 0%, #8b5cf6 100%);
  color: white;
  padding: 1.5rem;
}

.header h3 {
  margin: 0 0 1rem 0;
  font-size: 1.4rem;
}

.progress {
  display: flex;
  align-items: center;
  gap: 1rem;
}

.progressBar {
  flex: 1;
  height: 8px;
  background: rgba(255, 255, 255, 0.3);
  border-radius: 4px;
  overflow: hidden;
}

.progressFill {
  height: 100%;
  background: linear-gradient(90deg, #10b981, #34d399);
  border-radius: 4px;
  transition: width 0.3s ease;
}

.progressText {
  font-size: 0.9rem;
  opacity: 0.9;
}

.questionCard {
  padding: 2rem;
}

.questionText {
  margin: 0 0 1.5rem 0;
  font-size: 1.2rem;
  color: #374151;
  line-height: 1.6;
}

.options {
  display: flex;
  flex-direction: column;
  gap: 1rem;
}

.option {
  display: flex;
  align-items: center;
  gap: 1rem;
  padding: 1rem 1.5rem;
  background: #f9fafb;
  border: 2px solid #e5e7eb;
  border-radius: 8px;
  cursor: pointer;
  transition: all 0.2s ease;
  text-align: left;
  font-size: 1rem;
}

.option:hover {
  background: #f3f4f6;
  border-color: #d1d5db;
}

.option.selected {
  background: #dbeafe;
  border-color: #3b82f6;
}

.optionLetter {
  width: 2rem;
  height: 2rem;
  background: #6b7280;
  color: white;
  border-radius: 50%;
  display: flex;
  align-items: center;
  justify-content: center;
  font-weight: bold;
  font-size: 0.9rem;
  flex-shrink: 0;
}

.option.selected .optionLetter {
  background: #3b82f6;
}

.navigation {
  padding: 1.5rem;
  border-top: 1px solid #e5e7eb;
  display: flex;
  justify-content: space-between;
  align-items: center;
}

.navButton {
  background: #6b7280;
  color: white;
  border: none;
  padding: 0.75rem 1.5rem;
  border-radius: 6px;
  cursor: pointer;
  font-weight: 500;
  transition: background-color 0.2s ease;
}

.navButton:hover:not(:disabled) {
  background: #4b5563;
}

.navButton:disabled {
  background: #d1d5db;
  cursor: not-allowed;
}

.submitButton {
  background: linear-gradient(135deg, #10b981, #34d399);
  color: white;
  border: none;
  padding: 0.75rem 1.5rem;
  border-radius: 6px;
  cursor: pointer;
  font-weight: 600;
  transition: all 0.2s ease;
}

.submitButton:hover:not(:disabled) {
  transform: translateY(-2px);
  box-shadow: 0 4px 12px rgba(16, 185, 129, 0.3);
}

.submitButton:disabled {
  background: #d1d5db;
  cursor: not-allowed;
  transform: none;
}

.questionDots {
  display: flex;
  gap: 0.5rem;
}

.dot {
  width: 2rem;
  height: 2rem;
  border-radius: 50%;
  background: #e5e7eb;
  color: #6b7280;
  border: none;
  cursor: pointer;
  font-size: 0.8rem;
  font-weight: bold;
  transition: all 0.2s ease;
}

.dot.active {
  background: #3b82f6;
  color: white;
}

.dot.answered {
  background: #10b981;
  color: white;
}

/* Results Styles */
.results {
  padding: 2rem;
}

.scoreCard {
  text-align: center;
  padding: 2rem;
  border-radius: 12px;
  margin-bottom: 2rem;
}

.scoreCard.passed {
  background: linear-gradient(135deg, #d1fae5, #a7f3d0);
  border: 2px solid #10b981;
}

.scoreCard.failed {
  background: linear-gradient(135deg, #fee2e2, #fecaca);
  border: 2px solid #ef4444;
}

.scoreIcon {
  font-size: 4rem;
  margin-bottom: 1rem;
}

.scoreCard h3 {
  margin: 0 0 1rem 0;
  color: #374151;
}

.scoreDisplay {
  display: flex;
  flex-direction: column;
  align-items: center;
  gap: 0.5rem;
  margin-bottom: 1rem;
}

.scoreNumber {
  font-size: 3rem;
  font-weight: bold;
  color: #059669;
}

.scoreCard.failed .scoreNumber {
  color: #dc2626;
}

.scoreLabel {
  font-size: 1.2rem;
  font-weight: 600;
  color: #374151;
}

.answerReview {
  margin-bottom: 2rem;
}

.answerReview h4 {
  margin: 0 0 1.5rem 0;
  color: #374151;
}

.reviewQuestion {
  margin-bottom: 2rem;
  padding: 1.5rem;
  background: #f9fafb;
  border-radius: 8px;
}

.reviewQuestion h5 {
  margin: 0 0 1rem 0;
  color: #374151;
}

.reviewAnswers {
  display: flex;
  flex-direction: column;
  gap: 0.5rem;
  margin-bottom: 1rem;
}

.reviewAnswer {
  padding: 0.75rem 1rem;
  border-radius: 6px;
  display: flex;
  align-items: center;
  justify-content: space-between;
  background: white;
  border: 1px solid #e5e7eb;
}

.reviewAnswer.correct {
  background: #dcfce7;
  border-color: #16a34a;
  color: #15803d;
}

.reviewAnswer.incorrect {
  background: #fee2e2;
  border-color: #dc2626;
  color: #dc2626;
}

.reviewAnswer.selected.correct {
  background: #bbf7d0;
}

.correctIcon, .incorrectIcon {
  font-weight: bold;
  font-size: 1.2rem;
}

.explanation {
  background: #eff6ff;
  padding: 1rem;
  border-radius: 6px;
  border-left: 4px solid #3b82f6;
  color: #1e40af;
}

.resultActions {
  display: flex;
  gap: 1rem;
  justify-content: center;
}

.retryButton {
  background: #6b7280;
  color: white;
  border: none;
  padding: 0.75rem 1.5rem;
  border-radius: 6px;
  cursor: pointer;
  font-weight: 500;
  transition: background-color 0.2s ease;
}

.retryButton:hover {
  background: #4b5563;
}

.continueButton {
  background: linear-gradient(135deg, #3b82f6, #1d4ed8);
  color: white;
  border: none;
  padding: 0.75rem 1.5rem;
  border-radius: 6px;
  cursor: pointer;
  font-weight: 600;
  transition: all 0.2s ease;
}

.continueButton:hover {
  transform: translateY(-2px);
  box-shadow: 0 4px 12px rgba(59, 130, 246, 0.3);
}

/* Quick Check Styles */
.quickCheck {
  background: #fef3c7;
  border: 2px solid #f59e0b;
  border-radius: 8px;
  padding: 1.5rem;
  margin: 1.5rem 0;
}

.quickCheck h4 {
  margin: 0 0 1rem 0;
  color: #92400e;
}

.quickQuestion {
  margin: 0 0 1rem 0;
  font-weight: 500;
  color: #78350f;
}

.quickOptions {
  display: flex;
  flex-direction: column;
  gap: 0.5rem;
  margin-bottom: 1rem;
}

.quickOption {
  padding: 0.75rem 1rem;
  background: white;
  border: 2px solid #fbbf24;
  border-radius: 6px;
  cursor: pointer;
  transition: all 0.2s ease;
  text-align: left;
}

.quickOption:hover:not(:disabled) {
  background: #fef3c7;
}

.quickOption.selected {
  background: #fed7aa;
  border-color: #f97316;
}

.quickOption.correct {
  background: #dcfce7;
  border-color: #16a34a;
  color: #15803d;
}

.quickOption.incorrect {
  background: #fee2e2;
  border-color: #dc2626;
  color: #dc2626;
}

.quickResult {
  display: flex;
  align-items: flex-start;
  gap: 1rem;
  padding: 1rem;
  border-radius: 6px;
}

.quickResult.correct {
  background: #dcfce7;
  border: 1px solid #16a34a;
}

.quickResult.incorrect {
  background: #fee2e2;
  border: 1px solid #dc2626;
}

.resultIcon {
  font-size: 1.5rem;
  flex-shrink: 0;
}

.resultText {
  flex: 1;
}

.quickExplanation {
  margin: 0.5rem 0 0 0;
  font-size: 0.9rem;
  opacity: 0.9;
}
```

# src/components/Screenshot.js

```js
import React from "react";
import BrowserWindow from "@site/src/components/BrowserWindow";
import useBaseUrl from '@docusaurus/useBaseUrl';

export default function Screenshot(props) {
  return (
    <BrowserWindow {...props}>
      <img src={useBaseUrl(props.src)} alt={props.alt} />
    </BrowserWindow>
  )
};
```

# src/components/WorkshopExercise/index.js

```js
import React, { useState } from 'react';
import styles from './styles.module.css';

export default function WorkshopExercise({ 
  title, 
  difficulty = "beginner", 
  timeEstimate, 
  children, 
  objectives = [],
  onComplete 
}) {
  const [isCompleted, setIsCompleted] = useState(false);
  const [isExpanded, setIsExpanded] = useState(true);

  const handleComplete = () => {
    setIsCompleted(true);
    if (onComplete) {
      onComplete();
    }
    // Store completion in localStorage
    localStorage.setItem(`workshop-exercise-${title}`, 'completed');
  };

  // Check if previously completed
  React.useEffect(() => {
    const wasCompleted = localStorage.getItem(`workshop-exercise-${title}`);
    if (wasCompleted === 'completed') {
      setIsCompleted(true);
    }
  }, [title]);

  const difficultyColors = {
    beginner: '#28a745',
    intermediate: '#ffc107', 
    advanced: '#dc3545'
  };

  return (
    <div className={`${styles.exercise} ${isCompleted ? styles.completed : ''}`}>
      <div className={styles.header} onClick={() => setIsExpanded(!isExpanded)}>
        <div className={styles.titleSection}>
          <h3 className={styles.title}>
            {isCompleted && <span className={styles.checkmark}>✅</span>}
            {title}
          </h3>
          <div className={styles.metadata}>
            <span 
              className={styles.difficulty}
              style={{ backgroundColor: difficultyColors[difficulty] }}
            >
              {difficulty}
            </span>
            {timeEstimate && (
              <span className={styles.time}>⏱️ {timeEstimate}</span>
            )}
          </div>
        </div>
        <button className={styles.expandButton}>
          {isExpanded ? '▼' : '▶'}
        </button>
      </div>
      
      {isExpanded && (
        <div className={styles.content}>
          {objectives.length > 0 && (
            <div className={styles.objectives}>
              <h4>📋 Learning Objectives:</h4>
              <ul>
                {objectives.map((objective, index) => (
                  <li key={index}>{objective}</li>
                ))}
              </ul>
            </div>
          )}
          
          <div className={styles.instructions}>
            {children}
          </div>
          
          {!isCompleted && (
            <button 
              className={styles.completeButton}
              onClick={handleComplete}
            >
              Mark as Complete ✅
            </button>
          )}
          
          {isCompleted && (
            <div className={styles.completedMessage}>
              🎉 Exercise completed! Great work!
            </div>
          )}
        </div>
      )}
    </div>
  );
}

// Sub-components for structured exercises
export function ExerciseStep({ stepNumber, title, children }) {
  const [isCompleted, setIsCompleted] = useState(false);

  return (
    <div className={styles.step}>
      <div className={styles.stepHeader}>
        <span className={`${styles.stepNumber} ${isCompleted ? styles.stepCompleted : ''}`}>
          {isCompleted ? '✅' : stepNumber}
        </span>
        <h4 className={styles.stepTitle}>{title}</h4>
      </div>
      <div className={styles.stepContent}>
        {children}
      </div>
      <button 
        className={styles.stepCompleteButton}
        onClick={() => setIsCompleted(!isCompleted)}
      >
        {isCompleted ? 'Unmark' : 'Complete Step'}
      </button>
    </div>
  );
}

export function ExerciseValidation({ title, checks = [], onValidate }) {
  const [validationResults, setValidationResults] = useState({});
  
  const handleCheck = (checkId, passed) => {
    setValidationResults(prev => ({
      ...prev,
      [checkId]: passed
    }));
  };

  const allPassed = checks.every(check => validationResults[check.id] === true);

  return (
    <div className={styles.validation}>
      <h4>🔍 {title}</h4>
      <div className={styles.checks}>
        {checks.map((check) => (
          <div key={check.id} className={styles.check}>
            <label className={styles.checkLabel}>
              <input
                type="checkbox"
                checked={validationResults[check.id] || false}
                onChange={(e) => handleCheck(check.id, e.target.checked)}
              />
              {check.description}
            </label>
            {check.hint && !validationResults[check.id] && (
              <div className={styles.hint}>💡 {check.hint}</div>
            )}
          </div>
        ))}
      </div>
      
      {allPassed && (
        <div className={styles.validationSuccess}>
          ✅ All validations passed! You're ready to continue.
        </div>
      )}
    </div>
  );
}
```

# src/components/WorkshopExercise/styles.module.css

```css
.exercise {
  border: 2px solid #e1e8ed;
  border-radius: 12px;
  margin: 1.5rem 0;
  background: linear-gradient(145deg, #ffffff, #f8f9fa);
  box-shadow: 0 4px 12px rgba(0, 0, 0, 0.05);
  transition: all 0.3s ease;
}

.exercise:hover {
  box-shadow: 0 6px 20px rgba(0, 0, 0, 0.1);
  transform: translateY(-2px);
}

.exercise.completed {
  border-color: #28a745;
  background: linear-gradient(145deg, #f8fff9, #e8f5e8);
}

.header {
  padding: 1.5rem;
  cursor: pointer;
  display: flex;
  justify-content: space-between;
  align-items: center;
  border-bottom: 1px solid #e1e8ed;
}

.titleSection {
  flex: 1;
}

.title {
  margin: 0 0 0.5rem 0;
  font-size: 1.3rem;
  color: #1c1e21;
  display: flex;
  align-items: center;
  gap: 0.5rem;
}

.checkmark {
  font-size: 1rem;
}

.metadata {
  display: flex;
  gap: 1rem;
  align-items: center;
}

.difficulty {
  padding: 0.25rem 0.75rem;
  border-radius: 20px;
  color: white;
  font-size: 0.8rem;
  font-weight: 600;
  text-transform: uppercase;
}

.time {
  color: #6c757d;
  font-size: 0.9rem;
}

.expandButton {
  background: none;
  border: none;
  font-size: 1.2rem;
  cursor: pointer;
  padding: 0.5rem;
  border-radius: 4px;
  transition: background-color 0.2s;
}

.expandButton:hover {
  background-color: #f1f3f4;
}

.content {
  padding: 1.5rem;
}

.objectives {
  background-color: #e3f2fd;
  padding: 1rem;
  border-radius: 8px;
  margin-bottom: 1.5rem;
  border-left: 4px solid #2196f3;
}

.objectives h4 {
  margin: 0 0 0.5rem 0;
  color: #1565c0;
}

.objectives ul {
  margin: 0;
  padding-left: 1.2rem;
}

.objectives li {
  margin-bottom: 0.25rem;
  color: #1976d2;
}

.instructions {
  margin-bottom: 1.5rem;
}

.completeButton {
  background: linear-gradient(135deg, #28a745, #20c997);
  color: white;
  border: none;
  padding: 0.75rem 1.5rem;
  border-radius: 8px;
  font-weight: 600;
  cursor: pointer;
  transition: all 0.3s ease;
  font-size: 1rem;
}

.completeButton:hover {
  transform: translateY(-2px);
  box-shadow: 0 4px 12px rgba(40, 167, 69, 0.3);
}

.completedMessage {
  background: linear-gradient(135deg, #d4edda, #c3e6cb);
  color: #155724;
  padding: 1rem;
  border-radius: 8px;
  text-align: center;
  font-weight: 600;
  border: 2px solid #28a745;
}

/* Step Components */
.step {
  border: 1px solid #dee2e6;
  border-radius: 8px;
  margin: 1rem 0;
  background: white;
}

.stepHeader {
  display: flex;
  align-items: center;
  padding: 1rem;
  background: #f8f9fa;
  border-bottom: 1px solid #dee2e6;
}

.stepNumber {
  width: 2rem;
  height: 2rem;
  border-radius: 50%;
  background: #6c757d;
  color: white;
  display: flex;
  align-items: center;
  justify-content: center;
  font-weight: bold;
  margin-right: 1rem;
  font-size: 0.9rem;
}

.stepNumber.stepCompleted {
  background: #28a745;
}

.stepTitle {
  margin: 0;
  color: #495057;
}

.stepContent {
  padding: 1rem;
}

.stepCompleteButton {
  margin: 0 1rem 1rem 1rem;
  background: #007bff;
  color: white;
  border: none;
  padding: 0.5rem 1rem;
  border-radius: 6px;
  cursor: pointer;
  font-size: 0.9rem;
  transition: background-color 0.2s;
}

.stepCompleteButton:hover {
  background: #0056b3;
}

/* Validation Components */
.validation {
  background: #fff3cd;
  border: 1px solid #ffeaa7;
  border-radius: 8px;
  padding: 1rem;
  margin: 1rem 0;
}

.validation h4 {
  margin: 0 0 1rem 0;
  color: #856404;
}

.checks {
  margin-bottom: 1rem;
}

.check {
  margin-bottom: 0.75rem;
}

.checkLabel {
  display: flex;
  align-items: flex-start;
  gap: 0.5rem;
  cursor: pointer;
  font-weight: 500;
}

.checkLabel input[type="checkbox"] {
  margin: 0;
  transform: scale(1.2);
}

.hint {
  margin-top: 0.5rem;
  padding: 0.5rem;
  background: #e3f2fd;
  border-radius: 4px;
  font-size: 0.9rem;
  color: #1565c0;
  margin-left: 1.7rem;
}

.validationSuccess {
  background: #d4edda;
  color: #155724;
  padding: 0.75rem;
  border-radius: 6px;
  text-align: center;
  font-weight: 600;
  border: 1px solid #c3e6cb;
}
```

# src/components/WorkshopFeedback/index.js

```js
import React, { useState } from 'react';
import styles from './styles.module.css';

export default function WorkshopFeedback({ 
  workshopTitle = "Multimodal PDF Agent Workshop",
  instructorEmail = "instructor@example.com",
  githubRepo = "mongodb-developer/multimodal-pdf-agent-n8n"
}) {
  const [isExpanded, setIsExpanded] = useState(false);
  const [feedback, setFeedback] = useState({
    rating: 0,
    difficulty: '',
    mostValuable: '',
    improvements: '',
    recommend: '',
    additionalComments: ''
  });

  const handleSubmit = (e) => {
    e.preventDefault();
    
    // Create email subject and body
    const subject = encodeURIComponent(`Workshop Feedback: ${workshopTitle}`);
    const body = encodeURIComponent(`
Workshop Feedback

Overall Rating: ${feedback.rating}/5 stars
Difficulty Level: ${feedback.difficulty}

Most Valuable Part:
${feedback.mostValuable}

Suggested Improvements:
${feedback.improvements}

Would Recommend: ${feedback.recommend}

Additional Comments:
${feedback.additionalComments}

---
Submitted: ${new Date().toISOString()}
    `.trim());

    // Open email client
    window.open(`mailto:${instructorEmail}?subject=${subject}&body=${body}`);
  };

  const handleGitHubIssue = () => {
    const title = encodeURIComponent(`Workshop Feedback: ${new Date().toLocaleDateString()}`);
    const body = encodeURIComponent(`
## Workshop Feedback

**Overall Rating:** ${feedback.rating}/5 ⭐

**Difficulty Level:** ${feedback.difficulty}

**Most Valuable Part:**
${feedback.mostValuable}

**Suggested Improvements:**
${feedback.improvements}

**Would Recommend:** ${feedback.recommend}

**Additional Comments:**
${feedback.additionalComments}

---
*Submitted via workshop documentation feedback form*
    `.trim());

    window.open(`https://github.com/${githubRepo}/issues/new?title=${title}&body=${body}&labels=feedback`);
  };

  return (
    <div className={styles.feedbackContainer}>
      <div className={styles.feedbackHeader} onClick={() => setIsExpanded(!isExpanded)}>
        <h3>📝 Workshop Feedback</h3>
        <span className={styles.expandIcon}>{isExpanded ? '−' : '+'}</span>
      </div>
      
      {isExpanded && (
        <div className={styles.feedbackForm}>
          <p>Help us improve this workshop! Your feedback is valuable for future attendees.</p>
          
          <form onSubmit={handleSubmit}>
            <div className={styles.formGroup}>
              <label>Overall Rating</label>
              <div className={styles.starRating}>
                {[1, 2, 3, 4, 5].map(star => (
                  <button
                    key={star} 
                    type="button"
                    className={`${styles.star} ${feedback.rating >= star ? styles.starFilled : ''}`}
                    onClick={() => setFeedback({...feedback, rating: star})}
                  >
                    ⭐
                  </button>
                ))}
              </div>
            </div>

            <div className={styles.formGroup}>
              <label>Difficulty Level</label>
              <select 
                value={feedback.difficulty} 
                onChange={(e) => setFeedback({...feedback, difficulty: e.target.value})}
              >
                <option value="">Select difficulty</option>
                <option value="Too Easy">Too Easy</option>
                <option value="Just Right">Just Right</option>
                <option value="Too Hard">Too Hard</option>
                <option value="Mixed Levels">Mixed Levels</option>
              </select>
            </div>

            <div className={styles.formGroup}>
              <label>Most Valuable Part</label>
              <textarea
                value={feedback.mostValuable}
                onChange={(e) => setFeedback({...feedback, mostValuable: e.target.value})}
                placeholder="What did you find most useful or interesting?"
                rows={3}
              />
            </div>

            <div className={styles.formGroup}>
              <label>Suggested Improvements</label>
              <textarea
                value={feedback.improvements}
                onChange={(e) => setFeedback({...feedback, improvements: e.target.value})}
                placeholder="What could we improve or add?"
                rows={3}
              />
            </div>

            <div className={styles.formGroup}>
              <label>Would you recommend this workshop?</label>
              <div className={styles.radioGroup}>
                {['Definitely', 'Probably', 'Not Sure', 'Probably Not', 'Definitely Not'].map(option => (
                  <label key={option} className={styles.radioLabel}>
                    <input
                      type="radio"
                      name="recommend"
                      value={option}
                      checked={feedback.recommend === option}
                      onChange={(e) => setFeedback({...feedback, recommend: e.target.value})}
                    />
                    {option}
                  </label>
                ))}
              </div>
            </div>

            <div className={styles.formGroup}>
              <label>Additional Comments</label>
              <textarea
                value={feedback.additionalComments}
                onChange={(e) => setFeedback({...feedback, additionalComments: e.target.value})}
                placeholder="Anything else you'd like to share?"
                rows={4}
              />
            </div>

            <div className={styles.submitButtons}>
              <button type="submit" className={styles.emailButton}>
                📧 Send via Email
              </button>
              <button type="button" onClick={handleGitHubIssue} className={styles.githubButton}>
                🐙 Submit as GitHub Issue
              </button>
            </div>
          </form>

          <div className={styles.feedbackNote}>
            <p><strong>Privacy Note:</strong> This form doesn't store data. It opens your email client or GitHub to submit feedback.</p>
          </div>
        </div>
      )}
    </div>
  );
}
```

# src/components/WorkshopFeedback/styles.module.css

```css
.feedbackContainer {
  margin: 2rem 0;
  border: 2px solid var(--ifm-color-primary-light);
  border-radius: 12px;
  overflow: hidden;
  background: var(--ifm-color-emphasis-100);
}

.feedbackHeader {
  padding: 1rem 1.5rem;
  background: var(--ifm-color-primary-lightest);
  border-bottom: 1px solid var(--ifm-color-primary-light);
  cursor: pointer;
  display: flex;
  justify-content: space-between;
  align-items: center;
  user-select: none;
  transition: background-color 0.2s;
}

.feedbackHeader:hover {
  background: var(--ifm-color-primary-lighter);
}

.feedbackHeader h3 {
  margin: 0;
  color: var(--ifm-color-primary-darkest);
  font-size: 1.1rem;
}

.expandIcon {
  font-size: 1.5rem;
  font-weight: bold;
  color: var(--ifm-color-primary);
  transition: transform 0.2s;
}

.feedbackForm {
  padding: 1.5rem;
}

.formGroup {
  margin-bottom: 1.5rem;
}

.formGroup label {
  display: block;
  font-weight: 600;
  margin-bottom: 0.5rem;
  color: var(--ifm-color-content);
}

.starRating {
  display: flex;
  gap: 0.25rem;
}

.star {
  background: none;
  border: none;
  font-size: 1.5rem;
  cursor: pointer;
  padding: 0.25rem;
  border-radius: 4px;
  transition: transform 0.1s;
  filter: grayscale(100%);
}

.star:hover {
  transform: scale(1.1);
}

.starFilled {
  filter: none;
}

.formGroup select {
  width: 100%;
  padding: 0.75rem;
  border: 1px solid var(--ifm-color-emphasis-300);
  border-radius: 6px;
  font-size: 1rem;
  background: var(--ifm-background-color);
  color: var(--ifm-color-content);
}

.formGroup textarea {
  width: 100%;
  padding: 0.75rem;
  border: 1px solid var(--ifm-color-emphasis-300);
  border-radius: 6px;
  font-size: 1rem;
  font-family: inherit;
  resize: vertical;
  background: var(--ifm-background-color);
  color: var(--ifm-color-content);
}

.radioGroup {
  display: flex;
  flex-direction: column;
  gap: 0.5rem;
}

.radioLabel {
  display: flex;
  align-items: center;
  gap: 0.5rem;
  font-weight: normal;
  margin-bottom: 0 !important;
  cursor: pointer;
  padding: 0.5rem;
  border-radius: 4px;
  transition: background-color 0.2s;
}

.radioLabel:hover {
  background: var(--ifm-color-emphasis-100);
}

.radioLabel input[type="radio"] {
  margin: 0;
}

.submitButtons {
  display: flex;
  gap: 1rem;
  flex-wrap: wrap;
  margin-top: 2rem;
}

.emailButton,
.githubButton {
  padding: 0.75rem 1.5rem;
  border: none;
  border-radius: 6px;
  font-size: 1rem;
  font-weight: 600;
  cursor: pointer;
  transition: all 0.2s;
  display: flex;
  align-items: center;
  gap: 0.5rem;
}

.emailButton {
  background: var(--ifm-color-primary);
  color: white;
}

.emailButton:hover {
  background: var(--ifm-color-primary-dark);
  transform: translateY(-1px);
}

.githubButton {
  background: #24292e;
  color: white;
}

.githubButton:hover {
  background: #1b1f23;
  transform: translateY(-1px);
}

.feedbackNote {
  margin-top: 1.5rem;
  padding: 1rem;
  background: var(--ifm-color-warning-lightest);
  border-left: 4px solid var(--ifm-color-warning);
  border-radius: 4px;
}

.feedbackNote p {
  margin: 0;
  font-size: 0.9rem;
  color: var(--ifm-color-warning-darkest);
}

/* Dark theme adjustments */
[data-theme='dark'] .feedbackContainer {
  border-color: var(--ifm-color-primary-darker);
}

[data-theme='dark'] .feedbackHeader {
  background: var(--ifm-color-primary-darker);
}

[data-theme='dark'] .feedbackHeader:hover {
  background: var(--ifm-color-primary-dark);
}

[data-theme='dark'] .feedbackNote {
  background: rgba(255, 165, 0, 0.1);
}

/* Mobile responsiveness */
@media (max-width: 768px) {
  .submitButtons {
    flex-direction: column;
  }
  
  .emailButton,
  .githubButton {
    width: 100%;
    justify-content: center;
  }
  
  .radioGroup {
    gap: 0.75rem;
  }
  
  .feedbackForm {
    padding: 1rem;
  }
}
```

# src/components/WorkshopResources/index.js

```js
import React, { useState } from 'react';
import styles from './styles.module.css';

export default function WorkshopResources({ 
  title = "Additional Resources",
  categories = {
    "Documentation": [
      {
        title: "n8n Documentation",
        url: "https://docs.n8n.io/",
        description: "Complete n8n reference and tutorials",
        icon: "📚"
      },
      {
        title: "MongoDB Atlas Vector Search",
        url: "https://www.mongodb.com/docs/atlas/atlas-vector-search/",
        description: "Official vector search documentation",
        icon: "🔍"
      },
      {
        title: "Voyage AI API Reference",
        url: "https://docs.voyageai.com/",
        description: "Multimodal embedding API documentation",
        icon: "🚢"
      }
    ],
    "Community & Support": [
      {
        title: "n8n Community Forum",
        url: "https://community.n8n.io/",
        description: "Get help and share workflows",
        icon: "💬"
      },
      {
        title: "MongoDB Developer Community",
        url: "https://www.mongodb.com/community/forums/",
        description: "Connect with MongoDB developers",
        icon: "🌐"
      },
      {
        title: "Workshop GitHub Issues",
        url: "https://github.com/mongodb-developer/multimodal-pdf-agent-n8n/issues",
        description: "Report issues or ask questions",
        icon: "🐛"
      }
    ],
    "Sample Data & Templates": [
      {
        title: "Sample PDF Collection",
        url: "/static/sample-pdfs/",
        description: "Test PDFs for workshop exercises",
        icon: "📄"
      },
      {
        title: "n8n Workflow Templates",
        url: "https://n8n.io/workflows/",
        description: "Ready-made workflow templates",
        icon: "⚡"
      },
      {
        title: "Vector Search Examples",
        url: "https://github.com/mongodb-developer/vector-search-examples",
        description: "Example implementations and patterns",
        icon: "💡"
      }
    ],
    "Tools & Extensions": [
      {
        title: "MongoDB Compass",
        url: "https://www.mongodb.com/products/compass",
        description: "Visual MongoDB database browser",
        icon: "🧭"
      },
      {
        title: "n8n Desktop App",
        url: "https://n8n.io/download/",
        description: "Desktop version of n8n",
        icon: "💻"
      },
      {
        title: "Vector Database Benchmarks",
        url: "https://github.com/erikbern/ann-benchmarks",
        description: "Performance comparisons and metrics",
        icon: "📊"
      }
    ]
  }
}) {
  const [activeCategory, setActiveCategory] = useState(Object.keys(categories)[0]);

  const openLink = (url) => {
    window.open(url, '_blank', 'noopener,noreferrer');
  };

  return (
    <div className={styles.resourcesContainer}>
      <h3 className={styles.resourcesTitle}>{title}</h3>
      
      <div className={styles.resourcesContent}>
        <div className={styles.categoryTabs}>
          {Object.keys(categories).map(category => (
            <button
              key={category}
              className={`${styles.categoryTab} ${activeCategory === category ? styles.activeTab : ''}`}
              onClick={() => setActiveCategory(category)}
            >
              {category}
            </button>
          ))}
        </div>

        <div className={styles.resourcesList}>
          {categories[activeCategory]?.map((resource, index) => (
            <div key={index} className={styles.resourceCard} onClick={() => openLink(resource.url)}>
              <div className={styles.resourceHeader}>
                <span className={styles.resourceIcon}>{resource.icon}</span>
                <h4 className={styles.resourceTitle}>{resource.title}</h4>
                <span className={styles.externalIcon}>↗</span>
              </div>
              <p className={styles.resourceDescription}>{resource.description}</p>
            </div>
          ))}
        </div>
      </div>

      <div className={styles.resourcesFooter}>
        <div className={styles.quickAccess}>
          <h4>🔗 Quick Access</h4>
          <div className={styles.quickLinks}>
            <button onClick={() => openLink('https://github.com/mongodb-developer/multimodal-pdf-agent-n8n')} className={styles.quickLink}>
              📁 Workshop Repo
            </button>
            <button onClick={() => openLink('https://www.mongodb.com/try')} className={styles.quickLink}>
              ☁️ MongoDB Atlas
            </button>
            <button onClick={() => openLink('https://docs.n8n.io/')} className={styles.quickLink}>
              📖 n8n Docs
            </button>
          </div>
        </div>

        <div className={styles.downloadSection}>
          <h4>📥 Workshop Materials</h4>
          <p>Access additional workshop resources:</p>
          <div className={styles.downloadLinks}>
            <a href="/static/workshop-slides.pdf" download className={styles.downloadLink}>
              🖼️ Workshop Slides (PDF)
            </a>
            <a href="/static/sample-workflows.json" download className={styles.downloadLink}>
              ⚡ Sample n8n Workflows
            </a>
            <a href="/static/cheat-sheet.pdf" download className={styles.downloadLink}>
              📋 Quick Reference Guide
            </a>
          </div>
        </div>
      </div>
    </div>
  );
}
```

# src/components/WorkshopResources/styles.module.css

```css
.resourcesContainer {
  margin: 2rem 0;
  padding: 0;
  border: 2px solid var(--ifm-color-primary-light);
  border-radius: 12px;
  background: var(--ifm-background-surface-color);
  overflow: hidden;
}

.resourcesTitle {
  margin: 0;
  padding: 1.5rem;
  background: linear-gradient(135deg, var(--ifm-color-primary-lightest), var(--ifm-color-primary-lighter));
  color: var(--ifm-color-primary-darkest);
  font-size: 1.3rem;
  font-weight: 700;
  text-align: center;
  border-bottom: 1px solid var(--ifm-color-primary-light);
}

.resourcesContent {
  padding: 0;
}

.categoryTabs {
  display: flex;
  background: var(--ifm-color-emphasis-100);
  border-bottom: 1px solid var(--ifm-color-emphasis-200);
  overflow-x: auto;
}

.categoryTab {
  padding: 1rem 1.5rem;
  border: none;
  background: transparent;
  color: var(--ifm-color-content-secondary);
  font-weight: 500;
  cursor: pointer;
  transition: all 0.2s;
  white-space: nowrap;
  border-bottom: 3px solid transparent;
}

.categoryTab:hover {
  background: var(--ifm-color-emphasis-200);
  color: var(--ifm-color-content);
}

.activeTab {
  background: var(--ifm-background-surface-color) !important;
  color: var(--ifm-color-primary) !important;
  border-bottom-color: var(--ifm-color-primary) !important;
  font-weight: 600;
}

.resourcesList {
  padding: 1.5rem;
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
  gap: 1rem;
}

.resourceCard {
  padding: 1.25rem;
  border: 1px solid var(--ifm-color-emphasis-200);
  border-radius: 8px;
  background: var(--ifm-background-color);
  cursor: pointer;
  transition: all 0.2s;
  position: relative;
}

.resourceCard:hover {
  border-color: var(--ifm-color-primary);
  transform: translateY(-2px);
  box-shadow: 0 4px 12px rgba(var(--ifm-color-primary-rgb), 0.15);
}

.resourceHeader {
  display: flex;
  align-items: center;
  gap: 0.75rem;
  margin-bottom: 0.75rem;
}

.resourceIcon {
  font-size: 1.5rem;
  flex-shrink: 0;
}

.resourceTitle {
  margin: 0;
  font-size: 1.1rem;
  font-weight: 600;
  color: var(--ifm-color-content);
  flex-grow: 1;
}

.externalIcon {
  color: var(--ifm-color-content-secondary);
  font-size: 1rem;
  opacity: 0.6;
  transition: opacity 0.2s;
}

.resourceCard:hover .externalIcon {
  opacity: 1;
  color: var(--ifm-color-primary);
}

.resourceDescription {
  margin: 0;
  color: var(--ifm-color-content-secondary);
  font-size: 0.95rem;
  line-height: 1.4;
}

.resourcesFooter {
  border-top: 1px solid var(--ifm-color-emphasis-200);
  padding: 1.5rem;
  background: var(--ifm-color-emphasis-50);
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
  gap: 2rem;
}

.quickAccess h4,
.downloadSection h4 {
  margin: 0 0 1rem 0;
  color: var(--ifm-color-content);
  font-size: 1rem;
  font-weight: 600;
}

.quickLinks {
  display: flex;
  gap: 0.5rem;
  flex-wrap: wrap;
}

.quickLink {
  padding: 0.5rem 1rem;
  border: 1px solid var(--ifm-color-primary);
  background: transparent;
  color: var(--ifm-color-primary);
  border-radius: 20px;
  font-size: 0.9rem;
  cursor: pointer;
  transition: all 0.2s;
  white-space: nowrap;
}

.quickLink:hover {
  background: var(--ifm-color-primary);
  color: white;
  transform: translateY(-1px);
}

.downloadSection p {
  margin: 0 0 1rem 0;
  color: var(--ifm-color-content-secondary);
  font-size: 0.9rem;
}

.downloadLinks {
  display: flex;
  flex-direction: column;
  gap: 0.5rem;
}

.downloadLink {
  display: inline-flex;
  align-items: center;
  gap: 0.5rem;
  padding: 0.75rem 1rem;
  background: var(--ifm-color-success-lightest);
  color: var(--ifm-color-success-darkest);
  text-decoration: none;
  border-radius: 6px;
  font-size: 0.9rem;
  font-weight: 500;
  transition: all 0.2s;
  border: 1px solid var(--ifm-color-success-light);
}

.downloadLink:hover {
  background: var(--ifm-color-success-lighter);
  transform: translateY(-1px);
  text-decoration: none;
  color: var(--ifm-color-success-darkest);
}

/* Dark theme adjustments */
[data-theme='dark'] .resourcesContainer {
  border-color: var(--ifm-color-primary-darker);
}

[data-theme='dark'] .resourcesTitle {
  background: linear-gradient(135deg, var(--ifm-color-primary-darker), var(--ifm-color-primary-dark));
  color: var(--ifm-color-primary-lightest);
}

[data-theme='dark'] .resourceCard:hover {
  box-shadow: 0 4px 12px rgba(var(--ifm-color-primary-rgb), 0.25);
}

[data-theme='dark'] .downloadLink {
  background: rgba(var(--ifm-color-success-rgb), 0.1);
  color: var(--ifm-color-success-light);
  border-color: rgba(var(--ifm-color-success-rgb), 0.3);
}

[data-theme='dark'] .downloadLink:hover {
  background: rgba(var(--ifm-color-success-rgb), 0.2);
  color: var(--ifm-color-success-light);
}

/* Mobile responsiveness */
@media (max-width: 768px) {
  .resourcesList {
    grid-template-columns: 1fr;
    padding: 1rem;
  }
  
  .resourcesFooter {
    grid-template-columns: 1fr;
    gap: 1.5rem;
    padding: 1rem;
  }
  
  .categoryTabs {
    flex-wrap: nowrap;
    overflow-x: auto;
    -webkit-overflow-scrolling: touch;
  }
  
  .categoryTab {
    padding: 0.75rem 1rem;
    font-size: 0.9rem;
  }
  
  .quickLinks {
    justify-content: flex-start;
  }
  
  .quickLink {
    font-size: 0.8rem;
    padding: 0.4rem 0.8rem;
  }
}
```

# src/components/WorkshopTransition/index.js

```js
import React, { useState, useEffect } from 'react';
import styles from './styles.module.css';

export default function WorkshopTransition({ 
  slideTopics = [],
  handsOnUrl,
  welcomeMessage = "Welcome to the Hands-On Workshop!",
  instructor = "Instructor"
}) {
  const [currentTime, setCurrentTime] = useState(new Date());

  useEffect(() => {
    const timer = setInterval(() => {
      setCurrentTime(new Date());
    }, 1000);

    return () => clearInterval(timer);
  }, []);

  return (
    <div className={styles.transition}>
      <div className={styles.header}>
        <div className={styles.welcome}>
          <h2>{welcomeMessage}</h2>
          <div className={styles.instructor}>with {instructor}</div>
          <div className={styles.time}>
            {currentTime.toLocaleTimeString()} | Let's Build Together! 🚀
          </div>
        </div>
      </div>

      <div className={styles.content}>
        <div className={styles.section}>
          <h3>📋 What We Covered in Slides</h3>
          <div className={styles.slideRecap}>
            {slideTopics.map((topic, index) => (
              <div key={index} className={styles.recapItem}>
                <span className={styles.checkmark}>✅</span>
                <span>{topic}</span>
              </div>
            ))}
          </div>
        </div>

        <div className={styles.section}>
          <h3>🎯 Now: Hands-On Building</h3>
          <div className={styles.handsOnInfo}>
            <div className={styles.infoCard}>
              <div className={styles.cardIcon}>💻</div>
              <div className={styles.cardContent}>
                <h4>Interactive Learning</h4>
                <p>Follow along with step-by-step exercises, interactive components, and real-time testing.</p>
              </div>
            </div>
            
            <div className={styles.infoCard}>
              <div className={styles.cardIcon}>🔧</div>
              <div className={styles.cardContent}>
                <h4>Build As You Learn</h4>
                <p>Create your multimodal PDF agent with guided validation at each step.</p>
              </div>
            </div>
            
            <div className={styles.infoCard}>
              <div className={styles.cardIcon}>📱</div>
              <div className={styles.cardContent}>
                <h4>Always Available</h4>
                <p>Bookmark this page - return anytime for reference and continued learning.</p>
              </div>
            </div>
          </div>
        </div>

        <div className={styles.actionSection}>
          <div className={styles.actionCard}>
            <div className={styles.actionHeader}>
              <h3>🚀 Ready to Start Building?</h3>
              <p>Let's transform those concepts into working code!</p>
            </div>
            
            <div className={styles.actionButtons}>
              <button 
                className={styles.primaryButton}
                onClick={() => window.location.href = '/multimodal-pdf-agent-n8n/docs/intro'}
              >
                Start Workshop →
              </button>
              
              <button 
                className={styles.secondaryButton}
                onClick={() => window.open('/multimodal-pdf-agent-n8n/docs/', '_blank')}
              >
                Open in New Tab
              </button>
            </div>
          </div>
        </div>
      </div>
    </div>
  );
}

export function SlideRecap({ title, items = [], nextSection }) {
  return (
    <div className={styles.slideRecap}>
      <div className={styles.recapHeader}>
        <h4>📖 {title}</h4>
        <div className={styles.recapSubtitle}>Key points from our presentation</div>
      </div>
      
      <div className={styles.recapItems}>
        {items.map((item, index) => (
          <div key={index} className={styles.recapItem}>
            <div className={styles.recapIcon}>
              {item.icon || '•'}
            </div>
            <div className={styles.recapContent}>
              <strong>{item.title}</strong>
              {item.description && <p>{item.description}</p>}
            </div>
          </div>
        ))}
      </div>

      {nextSection && (
        <div className={styles.recapNext}>
          <strong>Next:</strong> {nextSection}
        </div>
      )}
    </div>
  );
}

export function InstructorNotes({ notes = [], timing, tips = [] }) {
  const [showNotes, setShowNotes] = useState(false);

  return (
    <div className={styles.instructorNotes}>
      <button 
        className={styles.notesToggle}
        onClick={() => setShowNotes(!showNotes)}
        title="Toggle instructor notes (visible to instructors only)"
      >
        👨‍🏫 Instructor Notes {showNotes ? '▼' : '▶'}
      </button>
      
      {showNotes && (
        <div className={styles.notesContent}>
          {timing && (
            <div className={styles.timing}>
              <strong>⏱️ Timing:</strong> {timing}
            </div>
          )}
          
          {notes.length > 0 && (
            <div className={styles.notesList}>
              <strong>📝 Notes:</strong>
              <ul>
                {notes.map((note, index) => (
                  <li key={index}>{note}</li>
                ))}
              </ul>
            </div>
          )}
          
          {tips.length > 0 && (
            <div className={styles.tipsList}>
              <strong>💡 Tips:</strong>
              <ul>
                {tips.map((tip, index) => (
                  <li key={index}>{tip}</li>
                ))}
              </ul>
            </div>
          )}
        </div>
      )}
    </div>
  );
}

export function QRCodeAccess({ url, title = "Access Workshop Materials" }) {
  const qrCodeUrl = `https://api.qrserver.com/v1/create-qr-code/?size=200x200&data=${encodeURIComponent(url)}`;
  
  return (
    <div className={styles.qrAccess}>
      <div className={styles.qrHeader}>
        <h4>📱 {title}</h4>
        <p>Scan to access on mobile device</p>
      </div>
      
      <div className={styles.qrContent}>
        <img 
          src={qrCodeUrl} 
          alt="QR Code for workshop access"
          className={styles.qrCode}
        />
        <div className={styles.qrUrl}>
          <strong>URL:</strong> <code>{url}</code>
        </div>
      </div>
    </div>
  );
}
```

# src/components/WorkshopTransition/styles.module.css

```css
.transition {
  background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
  color: white;
  padding: 0;
  margin: 2rem 0;
  border-radius: 12px;
  overflow: hidden;
  box-shadow: 0 8px 24px rgba(102, 126, 234, 0.3);
}

.header {
  padding: 2rem;
  text-align: center;
  background: rgba(255, 255, 255, 0.1);
  backdrop-filter: blur(10px);
}

.welcome h2 {
  margin: 0 0 0.5rem 0;
  font-size: 2.2rem;
  font-weight: 700;
}

.instructor {
  font-size: 1.2rem;
  opacity: 0.9;
  margin-bottom: 0.5rem;
}

.time {
  font-size: 1rem;
  opacity: 0.8;
  font-family: monospace;
  background: rgba(255, 255, 255, 0.2);
  padding: 0.5rem 1rem;
  border-radius: 20px;
  display: inline-block;
}

.content {
  padding: 2rem;
}

.section {
  margin-bottom: 2rem;
}

.section h3 {
  margin: 0 0 1.5rem 0;
  font-size: 1.4rem;
  color: #ffffff;
}

.slideRecap {
  background: rgba(255, 255, 255, 0.1);
  border-radius: 8px;
  padding: 1.5rem;
  backdrop-filter: blur(10px);
}

.recapHeader {
  margin-bottom: 1rem;
}

.recapHeader h4 {
  margin: 0 0 0.25rem 0;
  font-size: 1.1rem;
}

.recapSubtitle {
  font-size: 0.9rem;
  opacity: 0.8;
}

.recapItems {
  display: flex;
  flex-direction: column;
  gap: 1rem;
}

.recapItem {
  display: flex;
  align-items: flex-start;
  gap: 1rem;
  padding: 0.75rem;
  background: rgba(255, 255, 255, 0.1);
  border-radius: 6px;
}

.checkmark {
  font-size: 1rem;
  flex-shrink: 0;
}

.recapIcon {
  width: 2rem;
  height: 2rem;
  background: rgba(255, 255, 255, 0.2);
  border-radius: 50%;
  display: flex;
  align-items: center;
  justify-content: center;
  flex-shrink: 0;
  font-weight: bold;
}

.recapContent strong {
  display: block;
  margin-bottom: 0.25rem;
}

.recapContent p {
  margin: 0;
  font-size: 0.9rem;
  opacity: 0.9;
}

.recapNext {
  margin-top: 1rem;
  padding: 0.75rem;
  background: rgba(59, 130, 246, 0.3);
  border: 1px solid rgba(59, 130, 246, 0.5);
  border-radius: 6px;
  font-size: 0.9rem;
}

.handsOnInfo {
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
  gap: 1.5rem;
}

.infoCard {
  display: flex;
  align-items: flex-start;
  gap: 1rem;
  padding: 1.5rem;
  background: rgba(255, 255, 255, 0.1);
  border-radius: 8px;
  backdrop-filter: blur(10px);
  transition: transform 0.2s ease;
}

.infoCard:hover {
  transform: translateY(-2px);
}

.cardIcon {
  font-size: 2rem;
  flex-shrink: 0;
}

.cardContent h4 {
  margin: 0 0 0.5rem 0;
  font-size: 1.1rem;
}

.cardContent p {
  margin: 0;
  font-size: 0.9rem;
  line-height: 1.5;
  opacity: 0.9;
}

.actionSection {
  text-align: center;
  margin-top: 2rem;
}

.actionCard {
  background: rgba(255, 255, 255, 0.15);
  border-radius: 12px;
  padding: 2rem;
  backdrop-filter: blur(15px);
  border: 1px solid rgba(255, 255, 255, 0.2);
}

.actionHeader h3 {
  margin: 0 0 0.5rem 0;
  font-size: 1.5rem;
}

.actionHeader p {
  margin: 0 0 2rem 0;
  font-size: 1.1rem;
  opacity: 0.9;
}

.actionButtons {
  display: flex;
  gap: 1rem;
  justify-content: center;
  flex-wrap: wrap;
}

.primaryButton {
  background: linear-gradient(135deg, #10b981, #34d399);
  color: white;
  border: none;
  padding: 1rem 2rem;
  border-radius: 8px;
  font-weight: 600;
  font-size: 1.1rem;
  cursor: pointer;
  transition: all 0.3s ease;
  box-shadow: 0 4px 12px rgba(16, 185, 129, 0.3);
}

.primaryButton:hover {
  transform: translateY(-3px);
  box-shadow: 0 6px 20px rgba(16, 185, 129, 0.4);
}

.secondaryButton {
  background: rgba(255, 255, 255, 0.2);
  color: white;
  border: 2px solid rgba(255, 255, 255, 0.3);
  padding: 1rem 2rem;
  border-radius: 8px;
  font-weight: 600;
  font-size: 1.1rem;
  cursor: pointer;
  transition: all 0.3s ease;
}

.secondaryButton:hover {
  background: rgba(255, 255, 255, 0.3);
  transform: translateY(-2px);
}

/* Instructor Notes */
.instructorNotes {
  background: #fffbeb;
  border: 2px solid #fbbf24;
  border-radius: 8px;
  margin: 1.5rem 0;
  overflow: hidden;
}

.notesToggle {
  width: 100%;
  background: #fef3c7;
  color: #92400e;
  border: none;
  padding: 0.75rem 1rem;
  cursor: pointer;
  font-weight: 600;
  text-align: left;
  transition: background-color 0.2s ease;
  display: flex;
  justify-content: space-between;
  align-items: center;
}

.notesToggle:hover {
  background: #fde68a;
}

.notesContent {
  padding: 1rem;
  background: #fffbeb;
  color: #451a03;
}

.timing {
  margin-bottom: 1rem;
  padding: 0.5rem;
  background: rgba(255, 255, 255, 0.1);
  border-radius: 4px;
  font-family: monospace;
}

.notesList,
.tipsList {
  margin-bottom: 1rem;
}

.notesList ul,
.tipsList ul {
  margin: 0.5rem 0 0 0;
  padding-left: 1.5rem;
}

.notesList li,
.tipsList li {
  margin-bottom: 0.5rem;
  line-height: 1.4;
}

/* QR Code */
.qrAccess {
  background: rgba(255, 255, 255, 0.1);
  border-radius: 8px;
  padding: 1.5rem;
  text-align: center;
  backdrop-filter: blur(10px);
}

.qrHeader h4 {
  margin: 0 0 0.5rem 0;
  color: #fff;
}

.qrHeader p {
  margin: 0 0 1rem 0;
  opacity: 0.8;
  font-size: 0.9rem;
}

.qrContent {
  display: flex;
  flex-direction: column;
  align-items: center;
  gap: 1rem;
}

.qrCode {
  background: white;
  padding: 1rem;
  border-radius: 8px;
  box-shadow: 0 4px 12px rgba(0, 0, 0, 0.2);
}

.qrUrl {
  font-size: 0.8rem;
  opacity: 0.8;
  word-break: break-all;
}

.qrUrl code {
  background: rgba(0, 0, 0, 0.3);
  padding: 0.25rem 0.5rem;
  border-radius: 4px;
  font-family: monospace;
}

/* Responsive Design */
@media (max-width: 768px) {
  .transition {
    margin: 1rem 0;
  }

  .header {
    padding: 1.5rem;
  }

  .welcome h2 {
    font-size: 1.8rem;
  }

  .content {
    padding: 1.5rem;
  }

  .handsOnInfo {
    grid-template-columns: 1fr;
  }

  .infoCard {
    padding: 1rem;
  }

  .actionButtons {
    flex-direction: column;
  }

  .primaryButton,
  .secondaryButton {
    width: 100%;
  }
}

/* Dark mode adjustments */
[data-theme='dark'] .transition {
  background: linear-gradient(135deg, #4c51bf 0%, #553c9a 100%);
}

[data-theme='dark'] .instructorNotes {
  background: rgba(251, 191, 36, 0.15);
  border-color: #f59e0b;
}

[data-theme='dark'] .notesToggle {
  background: rgba(251, 191, 36, 0.2);
  color: #fbbf24;
}

[data-theme='dark'] .notesToggle:hover {
  background: rgba(251, 191, 36, 0.3);
}

[data-theme='dark'] .notesContent {
  background: rgba(251, 191, 36, 0.1);
  color: #fde68a;
}
```

# src/css/custom.css

```css
/**
 * Any CSS included here will be global. The classic template
 * bundles Infima by default. Infima is a CSS framework designed to
 * work well for content-centric websites.
 */

/* You can override the default Infima variables here. */
:root {
  --ifm-color-primary: #2e8555;
  --ifm-color-primary-dark: #29784c;
  --ifm-color-primary-darker: #277148;
  --ifm-color-primary-darkest: #205d3b;
  --ifm-color-primary-light: #33925d;
  --ifm-color-primary-lighter: #359962;
  --ifm-color-primary-lightest: #3cad6e;
  --ifm-code-font-size: 95%;
  --ifm-link-color: #016BF8;
  --ifm-menu-color-background-active: rgb(227, 252, 247);
  --ifm-breadcrumb-item-background-active: rgb(227, 252, 247);
  --ifm-menu-color-active: rgb(0, 30, 43);
  --ifm-breadcrumb-color-active: rgb(0, 30, 43);
  --ifm-table-stripe-background: rgb(249, 251, 250);
  --docusaurus-highlighted-code-line-bg: rgba(0, 0, 0, 0.1);
}

/* For readability concerns, you should choose a lighter palette in dark mode. */
[data-theme='dark'] {
  --ifm-color-primary: #25c2a0;
  --ifm-color-primary-dark: #21af90;
  --ifm-color-primary-darker: #1fa588;
  --ifm-color-primary-darkest: #1a8870;
  --ifm-color-primary-light: #29d5b0;
  --ifm-color-primary-lighter: #32d8b4;
  --ifm-color-primary-lightest: #4fddbf;
  --ifm-link-color: #0099FF;
  --docusaurus-highlighted-code-line-bg: rgba(0, 0, 0, 0.3);
}

.navbar-logo {
  margin-left: 15px;
}

.footer__title {
  font-size: 25px;
}

a.footer__link-item {
  font-size: 20px;
}

/* Sidebar Category Styling */
.sidebar-getting-started > .menu__link {
  background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
  color: white !important;
  font-weight: 600;
  margin-bottom: 0.5rem;
}

.sidebar-getting-started > .menu__link:hover {
  opacity: 0.9;
}

.sidebar-setup > .menu__link {
  background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%);
  color: white !important;
  font-weight: 600;
  margin-bottom: 0.5rem;
}

.sidebar-workflows > .menu__link {
  background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
  color: white !important;
  font-weight: 600;
  margin-bottom: 0.5rem;
}

.sidebar-exercises > .menu__link {
  background: linear-gradient(135deg, #ff9a56 0%, #ff6b9d 100%);
  color: white !important;
  font-weight: 600;
  margin-bottom: 0.5rem;
}

.sidebar-advanced > .menu__link {
  background: linear-gradient(135deg, #fa709a 0%, #fee140 100%);
  color: white !important;
  font-weight: 600;
  margin-bottom: 0.5rem;
}

.sidebar-resources > .menu__link {
  background: linear-gradient(135deg, #30cfd0 0%, #330867 100%);
  color: white !important;
  font-weight: 600;
  margin-bottom: 0.5rem;
}

/* Enhanced sidebar spacing */
.theme-doc-sidebar-container nav {
  padding: 1rem;
}

.menu__list-item:not(:first-child) {
  margin-top: 0.75rem;
}

/* Sidebar category icons and spacing */
.menu__link--sublist-caret:after {
  background-size: 1.5rem 1.5rem;
  margin-left: auto;
}

/* Ensure category headers have proper spacing for accordion arrow */
.menu__link--sublist {
  display: flex;
  align-items: center;
  justify-content: space-between;
  padding-right: 2.5rem; /* Make room for accordion arrow */
}

/* Active category highlighting */
.menu__list-item--active > .menu__link--sublist {
  font-weight: 700;
}

/* Hide checkmark on category headers entirely */
.menu__link--sublist::before {
  display: none !important;
}

/* Better sidebar item styling */
.menu__link {
  border-radius: 0.5rem;
  transition: all 0.2s ease;
  padding: 0.75rem 1rem;
}

.menu__link:hover {
  background-color: var(--ifm-menu-color-background-hover);
  transform: translateX(4px);
}

/* Nested item indentation */
.menu__list .menu__list {
  margin-left: 0;
  padding-left: 0.5rem;
  border-left: 2px solid var(--ifm-color-emphasis-300);
}

/* Progress indicator for completed sections - only for document links, not categories */
.menu__link--active:not(.menu__link--sublist) {
  position: relative;
}

.menu__link--active:not(.menu__link--sublist)::before {
  content: '✓';
  position: absolute;
  right: 1rem;
  color: var(--ifm-color-success);
  font-weight: bold;
  font-size: 0.9rem;
}

/* Workshop progress bar at top of sidebar */
.theme-doc-sidebar-container::before {
  content: '';
  display: block;
  height: 4px;
  background: linear-gradient(90deg, #10b981 0%, #10b981 var(--workshop-progress, 0%), #e5e7eb var(--workshop-progress, 0%), #e5e7eb 100%);
  margin-bottom: 1rem;
  border-radius: 2px;
}

/* Dark mode adjustments */
[data-theme='dark'] .menu__link {
  color: var(--ifm-menu-color);
}

[data-theme='dark'] .sidebar-getting-started > .menu__link,
[data-theme='dark'] .sidebar-setup > .menu__link,
[data-theme='dark'] .sidebar-workflows > .menu__link,
[data-theme='dark'] .sidebar-exercises > .menu__link,
[data-theme='dark'] .sidebar-advanced > .menu__link,
[data-theme='dark'] .sidebar-resources > .menu__link {
  color: white !important;
  opacity: 0.95;
}

/* Smooth transitions */
.menu__list-item {
  transition: all 0.3s ease;
}

/* Mobile responsive sidebar */
@media (max-width: 996px) {
  .menu__link {
    padding: 1rem 1.25rem;
  }
}

```

# src/pages/helloWorld.js

```js
import React from "react";
import Layout from "@theme/Layout";

export default function Hello() {
  return (
    <Layout title="Hello" description="Hello React Page">
      <div
        style={{
          display: "flex",
          justifyContent: "center",
          alignItems: "center",
          height: "50vh",
          fontSize: "20px",
        }}
      >
        <p>
          Edit <code>pages/helloWorld.js</code> and save to reload.
        </p>
      </div>
    </Layout>
  );
}

```

# src/pages/index.js

```js
import React from 'react';
import clsx from 'clsx';
import Link from '@docusaurus/Link';
import useDocusaurusContext from '@docusaurus/useDocusaurusContext';
import Layout from '@theme/Layout';
import HomepageFeatures from '@site/src/components/HomepageFeatures';

import styles from './index.module.css';

function HomepageHeader() {
  const { siteConfig } = useDocusaurusContext();
  return (
    <header className={clsx('hero hero--primary', styles.heroBanner)}>
      <div className="container">
        <h1 className="hero__title">{siteConfig.title}</h1>
        <p className="hero__subtitle">{siteConfig.tagline}</p>
        <div className={styles.buttons}>
          <Link
            className="button button--secondary button--lg"
            to="/docs/intro">
            {siteConfig.customFields.startButtonTitle}
          </Link>
        </div>
      </div>
    </header>
  );
}

export default function Home() {
  const { siteConfig } = useDocusaurusContext();
  const { title, tagline } = siteConfig;

  return (
    <Layout
      title={`${title}`}
      description={`${tagline}`} >
      <HomepageHeader />
      <main>
        <HomepageFeatures />
      </main>
    </Layout >
  );
}

```

# src/pages/index.module.css

```css
/**
 * CSS files with the .module.css suffix will be treated as CSS modules
 * and scoped locally.
 */

.heroBanner {
  padding: 4rem 0;
  text-align: center;
  position: relative;
  overflow: hidden;
}

@media screen and (max-width: 996px) {
  .heroBanner {
    padding: 2rem;
  }
}

.buttons {
  display: flex;
  align-items: center;
  justify-content: center;
}

```

# src/theme/MDXComponents.js

```js
import React from 'react';
// Import the original mapper
import MDXComponents from '@theme-original/MDXComponents';
import Link from "@site/src/components/Link";
import Screenshot from "@site/src/components/Screenshot";
import WorkshopExercise, { ExerciseStep, ExerciseValidation } from "@site/src/components/WorkshopExercise";
import CodeBlock, { TerminalCommand } from "@site/src/components/CodeBlock";
import ProgressTracker, { StepIndicator } from "@site/src/components/ProgressTracker";
import InteractiveDemo, { ConfigBuilder, ServiceTester } from "@site/src/components/InteractiveDemo";
import Quiz, { QuickCheck } from "@site/src/components/Quiz";
import EmbeddingTester, { EmbeddingVisualizer } from "@site/src/components/EmbeddingTester";
import QuickEmbeddingTest from "@site/src/components/QuickEmbeddingTest";
import WorkshopTransition, { SlideRecap, InstructorNotes, QRCodeAccess } from "@site/src/components/WorkshopTransition";
import WorkshopFeedback from "@site/src/components/WorkshopFeedback";
import WorkshopResources from "@site/src/components/WorkshopResources";
import LiveStatusBadge, { 
  StatusDot, 
  SystemHealthDashboard,
  CodespaceStatusBadge,
  DockerServicesStatusBadge,
  MongoDBAtlasStatusBadge,
  VoyageAIStatusBadge,
  WorkflowTestBadge
} from "@site/src/components/LiveStatusBadge";

export default {
  // Re-use the default mapping
  ...MDXComponents,
  Link,
  Screenshot,
  WorkshopExercise,
  ExerciseStep,
  ExerciseValidation,
  CodeBlock,
  TerminalCommand,
  ProgressTracker,
  StepIndicator,
  InteractiveDemo,
  ConfigBuilder,
  ServiceTester,
  Quiz,
  QuickCheck,
  EmbeddingTester,
  EmbeddingVisualizer,
  QuickEmbeddingTest,
  WorkshopTransition,
  SlideRecap,
  InstructorNotes,
  QRCodeAccess,
  WorkshopFeedback,
  WorkshopResources,
  LiveStatusBadge,
  StatusDot,
  SystemHealthDashboard,
  CodespaceStatusBadge,
  DockerServicesStatusBadge,
  MongoDBAtlasStatusBadge,
  VoyageAIStatusBadge,
  WorkflowTestBadge
};
```

# static/.nojekyll

```

```

# static/img/blank-workspace.png

This is a binary file of the type: Image

# static/img/codespaces-building.png

This is a binary file of the type: Image

# static/img/codespaces-button.png

This is a binary file of the type: Image

# static/img/codespaces-ports.png

This is a binary file of the type: Image

# static/img/coding.png

This is a binary file of the type: Image

# static/img/docu.svg

This is a file of the type: SVG Image

# static/img/expanded-leafy.png

This is a binary file of the type: Image

# static/img/favicon.ico

This is a binary file of the type: Binary

# static/img/favicon.svg

This is a file of the type: SVG Image

# static/img/gh-pages.png

This is a binary file of the type: Image

# static/img/gh-secret.png

This is a binary file of the type: Image

# static/img/highfive.png

This is a binary file of the type: Image

# static/img/indeximage-1.png

This is a binary file of the type: Image

# static/img/logo-dark.svg

This is a file of the type: SVG Image

# static/img/logo.png

This is a binary file of the type: Image

# static/img/logo.svg

This is a file of the type: SVG Image

# static/img/n8n-1.png

This is a binary file of the type: Image

# static/img/n8n-2.png

This is a binary file of the type: Image

# static/img/n8n-3.png

This is a binary file of the type: Image

# static/img/node.png

This is a binary file of the type: Image

# static/img/screenshot.png

This is a binary file of the type: Image

# static/img/typing.gif

This is a binary file of the type: Image

# static/img/writing.png

This is a binary file of the type: Image

# static/pdf/Stateless-Document-DB-Encryption-Scheme.pdf

This is a binary file of the type: PDF

# static/upload-interface.html

```html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Multimodal PDF Agent - Upload & Chat</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background-color: #f5f5f5;
            padding: 20px;
            max-width: 800px;
            margin: 0 auto;
        }
        
        .container {
            background: white;
            border-radius: 12px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            padding: 30px;
        }
        
        h1 {
            color: #333;
            margin-bottom: 10px;
        }
        
        .subtitle {
            color: #666;
            margin-bottom: 30px;
        }
        
        .upload-section {
            border: 2px dashed #ddd;
            border-radius: 8px;
            padding: 40px;
            text-align: center;
            margin-bottom: 30px;
            transition: all 0.3s ease;
        }
        
        .upload-section.dragover {
            border-color: #4CAF50;
            background-color: #f8fff9;
        }
        
        .file-input {
            display: none;
        }
        
        .upload-btn {
            background-color: #4CAF50;
            color: white;
            padding: 12px 24px;
            border: none;
            border-radius: 6px;
            cursor: pointer;
            font-size: 16px;
            transition: background-color 0.3s;
        }
        
        .upload-btn:hover {
            background-color: #45a049;
        }
        
        .status {
            margin-top: 20px;
            padding: 15px;
            border-radius: 6px;
            display: none;
        }
        
        .status.success {
            background-color: #d4edda;
            color: #155724;
            border: 1px solid #c3e6cb;
        }
        
        .status.error {
            background-color: #f8d7da;
            color: #721c24;
            border: 1px solid #f5c6cb;
        }
        
        .chat-section {
            display: none;
            margin-top: 30px;
            border-top: 1px solid #eee;
            padding-top: 30px;
        }
        
        .chat-input {
            display: flex;
            gap: 10px;
            margin-bottom: 20px;
        }
        
        .question-input {
            flex: 1;
            padding: 12px;
            border: 1px solid #ddd;
            border-radius: 6px;
            font-size: 16px;
        }
        
        .ask-btn {
            background-color: #2196F3;
            color: white;
            padding: 12px 24px;
            border: none;
            border-radius: 6px;
            cursor: pointer;
            font-size: 16px;
        }
        
        .ask-btn:hover {
            background-color: #1976D2;
        }
        
        .chat-messages {
            max-height: 400px;
            overflow-y: auto;
            border: 1px solid #eee;
            border-radius: 8px;
            padding: 20px;
        }
        
        .message {
            margin-bottom: 15px;
            padding: 12px;
            border-radius: 6px;
        }
        
        .message.user {
            background-color: #e3f2fd;
            text-align: right;
        }
        
        .message.ai {
            background-color: #f5f5f5;
        }
        
        .loading {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 3px solid #f3f3f3;
            border-radius: 50%;
            border-top: 3px solid #3498db;
            animation: spin 1s linear infinite;
        }
        
        @keyframes spin {
            0% { transform: rotate(0deg); }
            100% { transform: rotate(360deg); }
        }
        
        .file-info {
            background-color: #e8f5e9;
            padding: 10px;
            border-radius: 6px;
            margin-top: 15px;
            font-size: 14px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>🤖 Multimodal PDF Agent</h1>
        <p class="subtitle">Upload a PDF and ask questions about its content</p>
        
        <div class="upload-section" id="uploadSection">
            <p style="margin-bottom: 20px;">📄 Drag and drop your PDF here or click to upload</p>
            <input type="file" id="fileInput" class="file-input" accept=".pdf">
            <button class="upload-btn" onclick="document.getElementById('fileInput').click()">
                Choose PDF File
            </button>
        </div>
        
        <div id="status" class="status"></div>
        
        <div id="chatSection" class="chat-section">
            <h2>💬 Ask Questions</h2>
            <div class="chat-input">
                <input 
                    type="text" 
                    id="questionInput" 
                    class="question-input" 
                    placeholder="Ask a question about your PDF..."
                    onkeypress="if(event.key === 'Enter') askQuestion()"
                >
                <button class="ask-btn" onclick="askQuestion()">Ask</button>
            </div>
            <div id="chatMessages" class="chat-messages"></div>
        </div>
    </div>

    <script>
        // Configuration - Update these URLs to match your n8n webhooks
        const UPLOAD_URL = 'http://localhost:5678/webhook/pdf-upload';
        const ASK_URL = 'http://localhost:5678/webhook/ask';
        
        let currentFilename = null;
        
        // Drag and drop handlers
        const uploadSection = document.getElementById('uploadSection');
        const fileInput = document.getElementById('fileInput');
        const status = document.getElementById('status');
        const chatSection = document.getElementById('chatSection');
        const chatMessages = document.getElementById('chatMessages');
        
        uploadSection.addEventListener('dragover', (e) => {
            e.preventDefault();
            uploadSection.classList.add('dragover');
        });
        
        uploadSection.addEventListener('dragleave', () => {
            uploadSection.classList.remove('dragover');
        });
        
        uploadSection.addEventListener('drop', (e) => {
            e.preventDefault();
            uploadSection.classList.remove('dragover');
            
            const files = e.dataTransfer.files;
            if (files.length > 0) {
                handleFile(files[0]);
            }
        });
        
        fileInput.addEventListener('change', (e) => {
            if (e.target.files.length > 0) {
                handleFile(e.target.files[0]);
            }
        });
        
        async function handleFile(file) {
            if (!file.name.toLowerCase().endsWith('.pdf')) {
                showStatus('Please upload a PDF file', 'error');
                return;
            }
            
            showStatus('Uploading and processing PDF...', 'success');
            
            const formData = new FormData();
            formData.append('file', file);
            
            try {
                const response = await fetch(UPLOAD_URL, {
                    method: 'POST',
                    body: formData
                });
                
                const result = await response.json();
                
                if (response.ok) {
                    currentFilename = file.name;
                    showStatus(`✅ Successfully processed ${file.name}. ${result.pagesProcessed || 0} pages embedded.`, 'success');
                    chatSection.style.display = 'block';
                    
                    // Add file info
                    const fileInfo = document.createElement('div');
                    fileInfo.className = 'file-info';
                    fileInfo.innerHTML = `📄 Current file: <strong>${file.name}</strong>`;
                    status.appendChild(fileInfo);
                } else {
                    showStatus(`❌ Error: ${result.error || 'Upload failed'}`, 'error');
                }
            } catch (error) {
                showStatus(`❌ Error: ${error.message}`, 'error');
            }
        }
        
        async function askQuestion() {
            const questionInput = document.getElementById('questionInput');
            const question = questionInput.value.trim();
            
            if (!question) return;
            
            // Add user message
            addMessage(question, 'user');
            questionInput.value = '';
            
            // Add loading message
            const loadingId = Date.now();
            addMessage('<div class="loading"></div> Thinking...', 'ai', loadingId);
            
            try {
                const response = await fetch(ASK_URL, {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        question: question,
                        filename: currentFilename
                    })
                });
                
                const result = await response.json();
                
                // Remove loading message
                document.getElementById(`msg-${loadingId}`).remove();
                
                if (response.ok) {
                    addMessage(result.answer || result.response || 'No answer received', 'ai');
                } else {
                    addMessage(`Error: ${result.error || 'Failed to get answer'}`, 'ai');
                }
            } catch (error) {
                document.getElementById(`msg-${loadingId}`).remove();
                addMessage(`Error: ${error.message}`, 'ai');
            }
        }
        
        function addMessage(text, type, id) {
            const message = document.createElement('div');
            message.className = `message ${type}`;
            if (id) message.id = `msg-${id}`;
            message.innerHTML = text;
            chatMessages.appendChild(message);
            chatMessages.scrollTop = chatMessages.scrollHeight;
        }
        
        function showStatus(message, type) {
            status.textContent = message;
            status.className = `status ${type}`;
            status.style.display = 'block';
        }
    </script>
</body>
</html>
```

# vercel.json

```json
{
  "buildCommand": "npm run build",
  "outputDirectory": "build"
}
```

